<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Data Science Blog on Agones</title>
    <link>http://localhost:1313/dsblog/</link>
    <description>Recent content in Data Science Blog on Agones</description>
    <generator>Hugo</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Hari Thapliyaal)</webMaster>
    <atom:link href="http://localhost:1313/dsblog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What is a Digital Twin?</title>
      <link>http://localhost:1313/dsblog/what-is-a-digital-twin/</link>
      <pubDate>Sun, 27 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/what-is-a-digital-twin/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6268-what-is-a-digital-twin.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-a-digital-twin&#34;&gt;What is a digital twin?&lt;/h1&gt;&#xA;&lt;p&gt;A digital twin is a &lt;strong&gt;virtual representation&lt;/strong&gt; of a real-world entity or process, created to simulate its behavior and performance. It consists of three main components: representation of the physical entity itself, the digital model that represents it, and the data that links the two (original and twin). Keep in mind the data is generated by model based on the representation of the physical entity. This technology allows users to monitor, analyze, and optimize the performance of physical objects or systems in real-time by providing insights based on data collected from sensors and IoT devices [1][2][3].&lt;/p&gt;</description>
    </item>
    <item>
      <title>Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation</title>
      <link>http://localhost:1313/dsblog/hunyuan3d-20/</link>
      <pubDate>Sat, 26 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/hunyuan3d-20/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6267-hunyuan3d-20.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;hunyuan3d-20-high-resolution-textured-3d-asset-generation&#34;&gt;Hunyuan3D 2.0: High-Resolution Textured 3D Asset Generation&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Briefing Document:&lt;/strong&gt; Hunyuan3D 2.0&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; &lt;a href=&#34;https://arxiv.org/pdf/2501.12202&#34;&gt;Hunyuan3D 2.0&lt;/a&gt; Hunyuan3D 2.0: Scaling Diffusion Models for High Resolution Textured 3D Assets Generation&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Purpose:&lt;/strong&gt; This document summarizes the key aspects of the Hunyuan3D 2.0 system, a large-scale 3D synthesis system for generating high-resolution textured 3D assets.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Hunyuan3D Team (Multiple contributors listed in the source).&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Publication Date:&lt;/strong&gt; Appears to be January 2025, based on the arXiv identifier (2501.12202).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Whisper: Robust Speech Recognition via Large-Scale Weak Supervision</title>
      <link>http://localhost:1313/dsblog/whisper-large-scale-weak-supervision-speech-recognition/</link>
      <pubDate>Fri, 25 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/whisper-large-scale-weak-supervision-speech-recognition/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6266-whisper-large-scale-weak-supervision-speech-recognition.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;whisper-robust-speech-recognition-via-large-scale-weak-supervision-whisper&#34;&gt;Whisper: Robust Speech Recognition via Large-Scale Weak Supervision (Whisper)&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Briefing Document:&lt;/strong&gt; Whisper: Robust Speech Recognition via Large-Scale Weak Supervision (Whisper)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Source:&lt;/strong&gt; Excerpts from &amp;ldquo;&lt;a href=&#34;https://arxiv.org/pdf/2212.04356%22&#34;&gt;https://arxiv.org/pdf/2212.04356&#34;&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Date:&lt;/strong&gt; December 2022 (Based on arXiv preprint date)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Authors:&lt;/strong&gt; Alec Radford, Jong Wook Kim, Tao Xu, Greg Brockman, Christine McLeavey, Ilya Sutskever&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Organization:&lt;/strong&gt; OpenAI&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-problem-is-addressed&#34;&gt;What Problem is Addressed?&lt;/h2&gt;&#xA;&lt;p&gt;This paper is about Speech to text transcription.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Existing automatic speech recognition (ASR) models lack robustness and generalization&lt;/strong&gt;. They perform well on data similar to their training data but struggle on different datasets or conditions (out-of-distribution data), even showing &amp;ldquo;superhuman&amp;rdquo; performance on specific benchmarks.&lt;/li&gt;&#xA;&lt;li&gt;Many state-of-the-art ASR systems &lt;strong&gt;require fine-tuning on specific datasets&lt;/strong&gt; to achieve high quality. Whisper aims to work well &lt;strong&gt;zero-shot&lt;/strong&gt;, without needing dataset-specific fine-tuning.&lt;/li&gt;&#xA;&lt;li&gt;There is a &lt;strong&gt;limited amount of easily available, high-quality supervised speech data&lt;/strong&gt;. Whisper tackles this by using a much larger scale of &lt;strong&gt;weakly supervised data (680,000 hours)&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Traditional speech processing often involves &lt;strong&gt;multiple separate components&lt;/strong&gt; for tasks like voice activity detection or translation. The paper seeks to create a &lt;strong&gt;single model&lt;/strong&gt; that can perform the entire pipeline, handling transcription, translation, language identification, and voice activity detection.&lt;/li&gt;&#xA;&lt;li&gt;Transcribing &lt;strong&gt;long audio recordings&lt;/strong&gt; is challenging for models trained on short segments. The paper develops strategies for &lt;strong&gt;buffered transcription of long audio&lt;/strong&gt; to make it practical for real-world use.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;executive-summary&#34;&gt;&lt;strong&gt;Executive Summary:&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;This paper introduces Whisper, a speech processing system trained on a massive dataset of 680,000 hours of diverse, weakly supervised audio and their transcripts from the internet. The core finding is that &lt;strong&gt;simple scaling of weakly supervised pre-training has been significantly underappreciated&lt;/strong&gt; for speech recognition. Unlike many recent large-scale speech recognition models that rely heavily on unsupervised pre-training or self-training, Whisper achieves strong performance across various tasks (multilingual speech recognition, speech translation, language identification, voice activity detection) and generalizes remarkably well to standard benchmarks in a zero-shot setting, without the need for fine-tuning. When compared to humans, the models approach their accuracy and robustness, particularly in out-of-distribution scenarios where traditional supervised models struggle. The authors release models and inference code to promote further research in robust speech processing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Frequencies in Time and Space: Understanding Nyquist Theorem &amp; its Applications</title>
      <link>http://localhost:1313/dsblog/frequencies-in-time-and-space/</link>
      <pubDate>Thu, 24 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/frequencies-in-time-and-space/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6265-frequencies-in-time-and-space.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;applications-of-nyquists-theorem&#34;&gt;Applications of Nyquists theorem&lt;/h1&gt;&#xA;&lt;h2 id=&#34;can-the-nyquist-shannon-sampling-theorem-applies-to-light-signals&#34;&gt;Can &lt;strong&gt;the Nyquist-Shannon sampling theorem applies to light signals&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;-first-what-kind-of-light-are-we-talking-about&#34;&gt;🌈 First: What Kind of &amp;ldquo;Light&amp;rdquo; Are We Talking About?&lt;/h3&gt;&#xA;&lt;p&gt;When we say &lt;strong&gt;light&lt;/strong&gt;, we could mean a few different things depending on the context:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Visible light waves&lt;/strong&gt; (very high frequency, in the hundreds of THz)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Modulated light signals&lt;/strong&gt; (like in fiber optics or Li-Fi)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Video/images&lt;/strong&gt; (captured with cameras, representing light intensity)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scientific measurements&lt;/strong&gt; (astronomy, laser pulses, etc.)&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Each of these uses light differently — and &lt;strong&gt;sampling theory applies to all&lt;/strong&gt;, though how we use it depends on the application.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Real Story of Nyquist, Shannon, and the Science of Sampling</title>
      <link>http://localhost:1313/dsblog/the-real-story-of-nyquist-shannon-and-the-science-of-sampling/</link>
      <pubDate>Wed, 23 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/the-real-story-of-nyquist-shannon-and-the-science-of-sampling/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6264-nyquist-shannon-and-the-science-of-sampling.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;the-story-of-nyquist-shannon-and-the-science-of-sampling&#34;&gt;The Story of Nyquist, Shannon, and the Science of Sampling&lt;/h1&gt;&#xA;&lt;p&gt;In the early days of the 20th century, the world was just beginning to hum with the sounds of electric voices. Telephones crackled across cities, Morse code blinked from station to station, and engineers at &lt;strong&gt;Bell Telephone Laboratories&lt;/strong&gt; worked tirelessly to harness the invisible — the flow of information through wires.&lt;/p&gt;&#xA;&lt;p&gt;Among them was a quiet but sharp Swedish-American engineer named &lt;strong&gt;Harry Nyquist&lt;/strong&gt;. He didn’t seek fame. He sought &lt;strong&gt;clarity&lt;/strong&gt; — specifically, how to transmit human speech over long distances with the least distortion, the least waste, and the most efficiency.&lt;/p&gt;</description>
    </item>
    <item>
      <title>BitNet b1.58-2B4T: Revolutionary Binary Neural Network for Efficient AI</title>
      <link>http://localhost:1313/dsblog/BitNet-b1-58-2B4T-for-efficient-ai-processing/</link>
      <pubDate>Mon, 21 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/BitNet-b1-58-2B4T-for-efficient-ai-processing/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6263-BitNet-b1.58-2B4T.jpg&#34; alt=&#34;BitNet b1.58-2B4T&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2504.12285&#34;&gt;Archive Paper Link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;bitnet-b158-2b4t-the-future-of-efficient-ai-processing&#34;&gt;BitNet b1.58-2B4T: The Future of Efficient AI Processing&lt;/h1&gt;&#xA;&lt;h2 id=&#34;a-history-of-1-bit-transformer-model&#34;&gt;A History of 1 bit Transformer Model&lt;/h2&gt;&#xA;&lt;p&gt;A paper &amp;ldquo;The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits&amp;rdquo; was published by Stanford University, ETH Zürich, and EPFL. It was published on October 2023 (published on arXiv on October 17, 2023). &lt;a href=&#34;https://arxiv.org/pdf/2310.11453&#34;&gt;Standord Paper Link&lt;/a&gt;. The core Concept of 1.58 bits per parameter, was introduced here. This demonstrated that LLMs could be effectively trained and operated with extremely low-bit representation while maintaining competitive performance&lt;/p&gt;</description>
    </item>
    <item>
      <title>Ollama Setup and Running Models</title>
      <link>http://localhost:1313/dsblog/Ollama-Setup-and-Running-Models/</link>
      <pubDate>Sat, 19 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Ollama-Setup-and-Running-Models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6262-Ollama-Setup-and-Running-Models.jpg&#34; alt=&#34;Ollama Setup and Running Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ollama-running-large-language-models-locally&#34;&gt;Ollama: Running Large Language Models Locally&lt;/h1&gt;&#xA;&lt;p&gt;The landscape of Artificial Intelligence (AI) and Large Language Models (LLMs) has traditionally been dominated by cloud-based services. While powerful, these often come with costs, privacy concerns, and require constant internet connectivity. Ollama emerges as a compelling open-source solution, designed to simplify the process of downloading, managing, and running LLMs directly on your local machine. This approach offers significant advantages, including enhanced privacy, cost savings, offline capability, and greater control over the models you use.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Retrieval-Augmented Generation with Conflicting Evidence</title>
      <link>http://localhost:1313/dsblog/ps-Retrieval-Augmented-Generation-with-Conflicting-Evidence/</link>
      <pubDate>Thu, 17 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ps-Retrieval-Augmented-Generation-with-Conflicting-Evidence/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6261-Retrieval-Augmented-Generation-with-Conflicting-Evidence.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;paper-summary-retrieval-augmented-generation-with-conflicting-evidence&#34;&gt;Paper Summary: Retrieval-Augmented Generation with Conflicting Evidence&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://arxiv.org/pdf/2504.13079&#34;&gt;arXiv Paper&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;The hypothesis of this paper is that &lt;strong&gt;real-world retrieval-augmented generation (RAG) systems must simultaneously handle various sources of conflicting information, including ambiguity in user queries and contradictory information arising from misinformation and noise in retrieved documents&lt;/strong&gt;. The authors argue that prior work has largely addressed these challenges in isolation.&lt;/p&gt;&#xA;&lt;iframe width=&#34;560&#34; height=&#34;315&#34; &#xD;&#xA;        src=&#34;https://www.youtube.com/embed/hbJaC2HI89s&#34; &#xD;&#xA;        title=&#34;Retrieval-Augmented Generation with Conflicting Evidence&#34; &#xD;&#xA;        frameborder=&#34;0&#34; &#xD;&#xA;        allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; &#xD;&#xA;        allowfullscreen&gt;&#xD;&#xA;&lt;/iframe&gt;&#xD;&#xA;&lt;h2 id=&#34;key-learnings-from-this-paper-include&#34;&gt;Key learnings from this paper include:&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Real-world RAG encounters a complex interplay of ambiguity, misinformation, and noise in retrieved documents&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Existing RAG evaluation benchmarks and methods often focus on individual aspects of conflict&lt;/strong&gt;, such as ambiguity or misinformation, but do not adequately address their simultaneous occurrence.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Different types of conflict necessitate different handling strategies&lt;/strong&gt;. Ambiguous queries might require presenting multiple valid answers, while misinformation and noise should be filtered out.&lt;/li&gt;&#xA;&lt;li&gt;The newly introduced &lt;strong&gt;RAMDocs dataset, designed to simulate these complex real-world scenarios, poses a significant challenge for current RAG baselines&lt;/strong&gt;, including strong LLMs. Even the best-performing baseline on RAMDocs achieved a relatively low exact match score.&lt;/li&gt;&#xA;&lt;li&gt;The proposed &lt;strong&gt;MADAM-RAG framework, which employs a multi-agent debate mechanism, demonstrates effectiveness in jointly handling diverse sources of conflict&lt;/strong&gt;, showing improvements over strong RAG baselines on AmbigDocs (handling ambiguity) and FaithEval (suppressing misinformation).&lt;/li&gt;&#xA;&lt;li&gt;Ablation studies on MADAM-RAG highlight the &lt;strong&gt;importance of both the aggregator module and the multi-round debate process&lt;/strong&gt; in achieving its performance gains.&lt;/li&gt;&#xA;&lt;li&gt;The paper finds that &lt;strong&gt;imbalances in the number of supporting documents for different valid answers can lead to standard RAG systems favoring the more frequently supported answer&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Increasing the &lt;strong&gt;level of misinformation in retrieved documents negatively impacts the performance of RAG systems&lt;/strong&gt;, even strong LLMs. MADAM-RAG shows more resilience to this compared to baselines.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;the-new-methods-suggested-in-this-paper-are&#34;&gt;The new methods suggested in this paper are:&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;RAMDocs (Retrieval with Ambiguity and Misinformation in Documents)&lt;/strong&gt;: This is a novel dataset specifically constructed to evaluate RAG systems&amp;rsquo; ability to handle conflicting information arising from ambiguity, misinformation, and noise simultaneously. It also features variability in the number of documents supporting different valid answers.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MADAM-RAG (Multi-agent Debate for Ambiguity and Misinformation in RAG)&lt;/strong&gt;: This is a new multi-agent framework designed to address the challenges posed by RAMDocs. In MADAM-RAG:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Each retrieved document is assigned to an &lt;strong&gt;independent LLM agent&lt;/strong&gt; that generates an initial response based solely on its assigned document.&lt;/li&gt;&#xA;&lt;li&gt;These agents then engage in a &lt;strong&gt;multi-round debate&lt;/strong&gt;, where they can revise their answers based on a summary of the previous round&amp;rsquo;s responses provided by a centralized &lt;strong&gt;aggregator module&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;The &lt;strong&gt;aggregator module&lt;/strong&gt; synthesizes a final response from the agent discussions, aiming to present all valid answers for ambiguous queries while discarding misinformation and noise.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;the-final-output-of-this-paper-includes&#34;&gt;The final output of this paper includes:&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The &lt;strong&gt;introduction of the RAMDocs dataset&lt;/strong&gt;, which serves as a challenging benchmark for evaluating RAG systems under realistic conditions of conflicting information. The dataset statistics, highlighting the average number of valid answers and the distribution of supporting, misinformation, and noisy documents, are provided.&lt;/li&gt;&#xA;&lt;li&gt;The &lt;strong&gt;proposal and empirical evaluation of the MADAM-RAG framework&lt;/strong&gt;. The results demonstrate that MADAM-RAG outperforms several strong RAG baselines (No RAG, Concatenated-prompt, and Astute RAG) on FaithEval (misinformation), AmbigDocs (ambiguity), and the new RAMDocs dataset.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Detailed ablation studies&lt;/strong&gt; that highlight the contribution of the aggregator and the multi-round debate mechanism to MADAM-RAG&amp;rsquo;s performance.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Analysis of the impact of varying the number of supporting documents&lt;/strong&gt; for correct answers and the impact of &lt;strong&gt;increasing levels of misinformation&lt;/strong&gt; on the performance of different RAG systems, including MADAM-RAG.&lt;/li&gt;&#xA;&lt;li&gt;The paper concludes by acknowledging that while MADAM-RAG shows promise, &lt;strong&gt;RAMDocs remains a challenging task, indicating room for future improvements in handling complex conflicting information in RAG systems&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>LLM Internal Encoding of Truthfulness and Hallucinations</title>
      <link>http://localhost:1313/dsblog/ps-LLM-Internal-Encoding-of-Truthfulness-and-Hallucinations/</link>
      <pubDate>Tue, 15 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ps-LLM-Internal-Encoding-of-Truthfulness-and-Hallucinations/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6260-LLM-Internal-Encoding-of-Truthfulness-and-Hallucinations.jpg&#34; alt=&#34;LLM Internal Encoding of Truthfulness and Hallucinations&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;paper-summary-llm-internal-encoding-of-truthfulness-and-hallucinations&#34;&gt;Paper Summary: LLM Internal Encoding of Truthfulness and Hallucinations&lt;/h1&gt;&#xA;&lt;p&gt;The objective of this paper is to gain a deeper understanding of errors produced by large language models (LLMs) by examining their internal representations. The authors aim to reveal how information about the truthfulness of LLM outputs is encoded internally, going beyond extrinsic, behavioral analysis. They also seek to investigate the relationship between these internal representations and the external behavior of LLMs, including their tendency to produce inaccuracies or &amp;ldquo;hallucinations&amp;rdquo;. Furthermore, the paper intends to explore whether internal representations can be used to predict the types of errors LLMs make and to detect the correct answer even when the model generates an incorrect one.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Future of Programming - Capabilities of AI Coding IDEs</title>
      <link>http://localhost:1313/dsblog/future-of-programming/</link>
      <pubDate>Mon, 14 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/future-of-programming/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6259-future-of-programming.jpg&#34; alt=&#34;future-of-programming&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;future-of-programming&#34;&gt;Future of Programming&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;As of April&amp;rsquo; 2025, AI coding IDEs like windsurf, cursor, cline, copilot etc. has these capabilities.&lt;/p&gt;&#xA;&lt;h2 id=&#34;capabilities-of-ai-coding-ides&#34;&gt;Capabilities of AI Coding IDEs&lt;/h2&gt;&#xA;&lt;h3 id=&#34;purpose-built-models-&#34;&gt;Purpose-Built Models 🧠&lt;/h3&gt;&#xA;&lt;p&gt;These are AI models specifically trained or fine-tuned for software development tasks like code generation, debugging, or code understanding.&lt;br&gt;&#xA;&lt;strong&gt;Example:&lt;/strong&gt; Instead of using a general-purpose LLM like GPT-4, Windsurf might use a model trained on GitHub repositories to understand code structure, naming conventions, or common patterns in Python projects.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cybersecurity Concepts in AI Age</title>
      <link>http://localhost:1313/dsblog/cybersecurity-concepts-in-ai-age/</link>
      <pubDate>Sun, 13 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/cybersecurity-concepts-in-ai-age/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6258-cybersecurity-concepts-in-ai-age.jpg&#34; alt=&#34;cybersecurity-concepts-in-ai-age&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-and-cybersecurity-threats-attack-vectors-and-defense-mechanisms&#34;&gt;AI and Cybersecurity: Threats, Attack Vectors, and Defense Mechanisms&lt;/h1&gt;&#xA;&lt;p&gt;As artificial intelligence (AI) systems, particularly large language models (LLMs), become integral to cybersecurity frameworks, they offer innovative solutions while introducing novel vulnerabilities. This article explores prompt-based threats, LLM-specific attack vectors, broader cybersecurity concepts in the context of AI, and essential governance and defense tools, alongside emerging trends and considerations.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;prompt-based-threats&#34;&gt;Prompt-Based Threats&lt;/h2&gt;&#xA;&lt;h3 id=&#34;adversarial-prompting&#34;&gt;Adversarial Prompting&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Definition:&lt;/strong&gt; Crafting prompts designed to exploit weaknesses in an LLM, causing it to fail, misbehave, or reveal vulnerabilities.&lt;br&gt;&#xA;&lt;strong&gt;Goal:&lt;/strong&gt; To identify flaws in how the model interprets or responds to instructions, often for research or security testing.&lt;br&gt;&#xA;&lt;strong&gt;Example:&lt;/strong&gt; A prompt like,&lt;/p&gt;</description>
    </item>
    <item>
      <title>Quantum Physics and Vedanta: Bridging Science and Philosophy</title>
      <link>http://localhost:1313/dsblog/quantum-physics-and-vedanta/</link>
      <pubDate>Fri, 11 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/quantum-physics-and-vedanta/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6257-quantum-physics-and-vedanta.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;quantum-physics-and-vedanta-satsanga-with-ai&#34;&gt;Quantum Physics and Vedanta Satsanga with AI&lt;/h1&gt;&#xA;&lt;p&gt;Being a Vedantin and a person with a scientific temperament, I seek meaningful Satsang. Today, I thought—why not have one with AI? What follows is the outcome of our conversation. Please note that many of the answers given by the AI have been modified by me according to my understanding and interpretation of Vedanta. Enjoy this conversation! If you have an interest in Vedanta or Quantum Physics, you will find it fascinating. In fact, many quantum physics concepts—such as superposition, measurement, entanglement, and more—may become crystal clear.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Benchmarks for 2025</title>
      <link>http://localhost:1313/dsblog/ai-benchmarks-2025/</link>
      <pubDate>Wed, 09 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ai-benchmarks-2025/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6256-aibenchmarks-for-2025.jpg&#34; alt=&#34;AI Benchmark for 2025&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-benchmarks-for-2025&#34;&gt;AI Benchmarks for 2025&lt;/h1&gt;&#xA;&lt;p&gt;A term &lt;strong&gt;&amp;ldquo;AI benchmark&amp;rdquo;&lt;/strong&gt; is thrown around a lot and can be confusing because it’s used in slightly different ways depending on the context. In this artcile we will try to understand what are the different meaning of this term and what are the latest AI benchmarks.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-does&#34;&gt;&lt;strong&gt;What Does &amp;ldquo;AI Benchmark&amp;rdquo; Mean?&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;In general, an &lt;strong&gt;AI benchmark&lt;/strong&gt; is a &lt;strong&gt;standardized way to evaluate the performance&lt;/strong&gt; of an AI system and/or models. It is made of following components.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Audio Video Processing Concepts</title>
      <link>http://localhost:1313/dsblog/audio-video-processing-concepts/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/audio-video-processing-concepts/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6252-audio-video-processing-concepts.jpg&#34; alt=&#34;Audio Video Processing Concepts&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;foundational-concepts-of-audio-and-video-processing&#34;&gt;Foundational Concepts of Audio and Video Processing&lt;/h1&gt;&#xA;&lt;p&gt;Whether you are multimedia professional or deep learning Engineer, if you are dealing with audio and video processing, you will need to understand the core concepts of audio and video processing. My this guide is focussed on some of the key concepts of Audio Video processing.&lt;/p&gt;&#xA;&lt;p&gt;A digital microphone is a device that captures sound (air pressure variations) and converts it into digital signals. Internally, it contains an analog-to-digital converter (ADC) that performs the conversion from analog audio to digital audio.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Overview of AI Benchmark Explorer Tool</title>
      <link>http://localhost:1313/dsblog/aibenchmark-explorer/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/aibenchmark-explorer/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6255-dsr-aibenchmark-explorer.jpg&#34; alt=&#34;AI Benchmark Explorer&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;overview-of-ai-benchmark-explorer-tool&#34;&gt;&lt;strong&gt;Overview of AI Benchmark Explorer Tool&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;AI professionals, including Change Drivers, Managers, and Scientists, often face challenges despite clearly understanding the problems they aim to solve. Key issues include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Identifying Appropriate Datasets&lt;/strong&gt;: Determining which datasets are best suited for a specific problem can be difficult.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Selecting Evaluation Metrics&lt;/strong&gt;: Choosing the right metrics to assess the performance of a solution is crucial for accurate evaluation.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Benchmarking Against Existing Models&lt;/strong&gt;: Understanding the performance metrics of existing models for the same problem helps in setting realistic expectations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Exploring Tried Architectures&lt;/strong&gt;: Reviewing architectures that others have implemented for similar problems can provide valuable insights.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Assessing Problem Novelty&lt;/strong&gt;: Determining whether the problem has already been solved or requires novel approaches is essential for resource allocation.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sourcing Solutions&lt;/strong&gt;: Deciding between utilizing open-source solutions or opting for proprietary alternatives impacts cost and flexibility.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Addressing these challenges is vital for the successful development and implementation of AI solutions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Quantum Physics with Deeper Questions with ChatGPT</title>
      <link>http://localhost:1313/dsblog/quantum-physics-with-deeper-questions/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/quantum-physics-with-deeper-questions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6253-quantum-physics-with-deeper-questions.jpg&#34; alt=&#34;Quantum Physics with Deeper Questions&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;quantum-physics-with-deeper-questions-with-chatgpt&#34;&gt;Quantum Physics with Deeper Questions with ChatGPT&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;I was a physics student during my college years, and I’ve always loved the subject—even today. However, Quantum Physics, despite all my reading and learning, remains a mystery to me. At this stage, who can teach me Quantum Physics effectively? Finding an able professor, aligning my availability with theirs, and hoping they’d be willing to teach me for free seems impossible. So, I turned to a Large Language Model (LLM) for help. I could have explored other LLMs like Grok, Claude, DeepSeek, and many more. I’m not saying the others are bad, nor am I claiming that ChatGPT is the best at providing plausible answers. Whether an answer is correct or plausible also depends on the learner’s ability.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Electronics Chips</title>
      <link>http://localhost:1313/dsblog/understanding-electronics-chips/</link>
      <pubDate>Fri, 28 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-electronics-chips/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6254-understanding-electronics-chips.jpg&#34; alt=&#34;Understanding Electronics Chips&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-electronics-chips&#34;&gt;Understanding Electronics Chips&lt;/h1&gt;&#xA;&lt;h2 id=&#34;how-0-1-is-represented-in-digital-system&#34;&gt;How 0, 1 is represented in digital system?&lt;/h2&gt;&#xA;&lt;p&gt;In digital computing, the value 1 is often represented by a higher voltage level, and 0 is represented by a lower voltage level. For example:&lt;/p&gt;&#xA;&lt;p&gt;1: Typically represented by a voltage near the maximum supply voltage (e.g., 5V, 3.3V, or another system-defined &amp;ldquo;high&amp;rdquo; level).&lt;/p&gt;&#xA;&lt;p&gt;0: Typically represented by a voltage close to ground (e.g., 0V or a very low voltage).&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Deep Dive into AI Model Marketplaces for Business Managers</title>
      <link>http://localhost:1313/dsblog/A-Deep-Dive-into-AI-Model-Marketplaces-for-Business-Managers/</link>
      <pubDate>Thu, 27 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/A-Deep-Dive-into-AI-Model-Marketplaces-for-Business-Managers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6251-A-Deep-Dive-into-AI-Model-Marketplaces-for-BM.jpg&#34; alt=&#34;AI Model Marketplaces&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;a-deep-dive-into-ai-model-marketplaces-for-business-managers&#34;&gt;A Deep Dive into AI Model Marketplaces for Business Managers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Artificial Intelligence (AI) is transforming industries, from customer service automation to data-driven decision-making. However, with hundreds of AI models available—ranging from OpenAI’s GPT-4 to Meta’s Llama 3—business leaders face a critical challenge: &lt;strong&gt;Where should they source their AI models?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;AI model marketplaces have emerged as a solution, offering businesses &lt;strong&gt;easy access, cost transparency, and flexibility&lt;/strong&gt; in deploying AI. This guide will help &lt;strong&gt;business managers, CTOs, and decision-makers&lt;/strong&gt; navigate the AI marketplace landscape, compare key providers, and choose the best option for their needs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Designer Roles and Their Favorite Free Tools</title>
      <link>http://localhost:1313/dsblog/exploring-designer-roles-and-their-favorite-free-tools/</link>
      <pubDate>Mon, 24 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-designer-roles-and-their-favorite-free-tools/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6250-exploring-designer-roles.jpg&#34; alt=&#34;Exploring Designer Roles and Their Favorite Free Tools&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-designer-roles-and-their-favorite-free-tools&#34;&gt;Exploring Designer Roles and Their Favorite Free Tools&lt;/h1&gt;&#xA;&lt;p&gt;In the software business, design plays a huge role, and there are different kinds of designers, each with their own focus areas, responsibilities, and specialized tools.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-are-different-types-of-designer-roles&#34;&gt;What are Different Types of Designer Roles?&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-ui-designer-user-interface-designer&#34;&gt;&lt;strong&gt;1. UI Designer (User Interface Designer)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Focus:&lt;/strong&gt; Visual design of interfaces (buttons, icons, layout, colors, typography)&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Common Tools:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Figma&lt;/li&gt;&#xA;&lt;li&gt;Adobe XD&lt;/li&gt;&#xA;&lt;li&gt;Sketch (macOS)&lt;/li&gt;&#xA;&lt;li&gt;Framer&lt;/li&gt;&#xA;&lt;li&gt;Zeplin (for handoff)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-ux-designer-user-experience-designer&#34;&gt;&lt;strong&gt;2. UX Designer (User Experience Designer)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Focus:&lt;/strong&gt; User journeys, flows, wireframes, usability, research&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Hosting Types</title>
      <link>http://localhost:1313/dsblog/exploring-hosting-types/</link>
      <pubDate>Sun, 23 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-hosting-types/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6249-exploring-hosting-types.jpg&#34; alt=&#34;Exploring Hosting Types&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-hosting-types&#34;&gt;Exploring Hosting Types&lt;/h1&gt;&#xA;&lt;h2 id=&#34;hosting-by-infrastructure-types&#34;&gt;Hosting by Infrastructure Types&lt;/h2&gt;&#xA;&lt;p&gt;There are several &lt;strong&gt;types of hosting&lt;/strong&gt; available in the market, each suited to different needs, from small personal websites to large enterprise applications. Here&amp;rsquo;s a breakdown of the &lt;strong&gt;main types of hosting by Infrastructure&lt;/strong&gt;, along with the &lt;strong&gt;major players&lt;/strong&gt; in each category:&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;-1-shared-hosting&#34;&gt;🌐 1. &lt;strong&gt;Shared Hosting&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Description:&lt;/strong&gt; Multiple websites share the same server resources (CPU, memory, disk, etc.). Ideal for small websites or blogs with low traffic.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Video Editing Concepts</title>
      <link>http://localhost:1313/dsblog/video-editing-concepts/</link>
      <pubDate>Sat, 22 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/video-editing-concepts/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6248-video-editing-concepts.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;-core-video-editing-concepts&#34;&gt;🎬 &lt;strong&gt;Core Video Editing Concepts&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;p&gt;A &lt;strong&gt;comprehensive list of features and concepts&lt;/strong&gt; that are useful to understand in &lt;strong&gt;any video editing software&lt;/strong&gt;, whether you&amp;rsquo;re using Shotcut, OBS Studio, Adobe Premiere, DaVinci Resolve, Final Cut Pro, or any other. When I was working on a project that required me to explore this, it was overwhelming for me to remember and apply all of these concepts. Therefore, I thought of sharing this with others who are starting their journey.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Grok 3 Model and Sanskrit</title>
      <link>http://localhost:1313/dsblog/grok3model-and-sanskrit/</link>
      <pubDate>Fri, 21 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/grok3model-and-sanskrit/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6247-grok3model-and-sanskrit.jpg&#34; alt=&#34;Grok 3 Model and Sanskrit&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;grok-3-model-and-sanskrit&#34;&gt;Grok 3 Model and Sanskrit&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;No other models do justice to Sanskrit in terms of context, context length, word meaning, and translation as Grok 3 does. I’ve been trying it since it was launched by xAI on February 17, 2025, and it continues to surprise me.&lt;/p&gt;&#xA;&lt;p&gt;When people say AI/LLM/GenAI/NLP is nothing more than spitting out words fed to it during training, and that any model is only as good as the data given to it, I find myself asking a question: &amp;ldquo;Aside from a few top scientists and creative thinkers, don’t 99.999% of people do the same thing?&amp;rdquo; If you think humans are creative, you might assume some human behavior is original, arising purely from the situation and unconnected to the past. It’s like saying dreams have nothing to do with your waking life and are entirely new creations of the mind during sleep. That’s not true. Whatever humans dream is influenced by their past and waking experiences. Similarly, every action a human takes is shaped by the data fed to them over time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Implementing Secure Authentication and Authorization</title>
      <link>http://localhost:1313/dsblog/implementing-secure-authentication-and-authorization/</link>
      <pubDate>Thu, 20 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/implementing-secure-authentication-and-authorization/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6246-implementing-secure-authentication-and-authorization.jpg&#34; alt=&#34;Implementing Secure Authentication and Authorization&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;implementing-secure-authentication-and-authorization&#34;&gt;Implementing Secure Authentication and Authorization&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Imagine you&amp;rsquo;ve created a website that sells data science courses—a valuable resource for aspiring data scientists. To maximize its potential, you want to ensure that free courses are available to everyone, while paid courses are accessible only to those who have purchased them. To achieve this, you need a robust &lt;strong&gt;login system (authentication)&lt;/strong&gt; to verify users and an &lt;strong&gt;authorization system&lt;/strong&gt; to control access based on their purchases. However, building and maintaining these systems can be a significant challenge—a headache, even—for a variety of reasons. In this article, we&amp;rsquo;ll explore what authentication and authorization mean in this context, why maintaining them is so complex, and how you can implement effective solutions to protect your content and satisfy your users.&lt;/p&gt;</description>
    </item>
    <item>
      <title>CodeReview with CodeRabbit AI - A Better Way to Automate Code Reviews</title>
      <link>http://localhost:1313/dsblog/code-review-with-coderabbit-ai/</link>
      <pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/code-review-with-coderabbit-ai/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6244-coderabbit-code-review-ai.jpg&#34; alt=&#34;CodeReview with CodeRabbit AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;codereview-with-coderabbit-ai&#34;&gt;CodeReview with CodeRabbit AI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction-why-developers-need-coderabbit-ai&#34;&gt;&lt;strong&gt;Introduction: Why Developers Need CodeRabbit AI&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Imagine you’re working on a fast-paced software project with a growing codebase. Your team is constantly pushing updates, but code reviews become a bottleneck. Senior developers are overloaded, and critical bugs slip through because there&amp;rsquo;s just not enough time for thorough manual reviews. One day, a crucial bug makes it to production, causing downtime and frustrated users. If only there were a way to automate and streamline code reviews without compromising quality…&lt;/p&gt;</description>
    </item>
    <item>
      <title>Return of Sunita William from ISS</title>
      <link>http://localhost:1313/dsblog/return-of-sunita-william-from-iss/</link>
      <pubDate>Tue, 18 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/return-of-sunita-william-from-iss/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6245-return-of-sunita-william-from-iss.jpg&#34; alt=&#34;Return of Sunita William from ISS&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;return-of-sunita-william-from-iss&#34;&gt;Return of Sunita William from ISS&lt;/h1&gt;&#xA;&lt;iframe width=&#34;560&#34; height=&#34;315&#34; &#xD;&#xA;        src=&#34;https://www.youtube.com/embed/OBNZGkDNuig&#34; &#xD;&#xA;        title=&#34;Return of Sunita William from ISS&#34; &#xD;&#xA;        frameborder=&#34;0&#34; &#xD;&#xA;        allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; &#xD;&#xA;        allowfullscreen&gt;&#xD;&#xA;&lt;/iframe&gt;&#xD;&#xA;&lt;p&gt;On March 19, 2025, the news of Sunita Williams&amp;rsquo; return from the ISS dominated headlines. But was it truly a momentous event, or just another example of media-driven hype? This question led me down a fascinating path—not just about the International Space Station (ISS) but also about how AI plays a role in shaping curiosity, influencing narratives, and diverting human attention. In this research article, I explore the ISS mission alongside the broader implications of AI in media and public perception. I hope you find these insights as thought-provoking as I did. Technology is not only about serving humanity but about culture, business, politics, egos, and power game.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What are Life Sciences?</title>
      <link>http://localhost:1313/dsblog/what-are-life-sciences/</link>
      <pubDate>Mon, 17 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/what-are-life-sciences/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6243-the-study-of-life.jpg&#34; alt=&#34;The Study of Life: Understanding Its Origins, Sustenance, and Evolution&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;the-study-of-life-understanding-its-origins-sustenance-and-evolution&#34;&gt;&lt;strong&gt;The Study of Life: Understanding Its Origins, Sustenance, and Evolution&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Life is one of the greatest mysteries of the universe. From the simplest microbes to complex human beings, life manifests in countless forms, evolving and adapting to its environment. But what exactly is life? How did it come into existence? How does it sustain itself, and what leads to its deterioration? Can life be revived once it has ended? Moreover, how does intelligence emerge, develop, and evolve over time?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Real-Life Applications of Mathematics</title>
      <link>http://localhost:1313/dsblog/real-life-applications-of-maths/</link>
      <pubDate>Sun, 16 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/real-life-applications-of-maths/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6242-Real-Life-Applications-of-Mathematics.jpg&#34; alt=&#34;Real-Life Applications of Mathematics&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;real-life-applications-of-mathematics&#34;&gt;&lt;strong&gt;Real-Life Applications of Mathematics&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;p&gt;Welcome to the fascinating world of mathematics! Math isn&amp;rsquo;t just about solving equations in a classroom—it is deeply woven into the fabric of our daily lives. From predicting natural disasters to optimizing business strategies, mathematics helps us make sense of the world.&lt;/p&gt;&#xA;&lt;p&gt;In this thread, we’ll explore 16 key areas of mathematics and their surprising real-world applications. And mind it all this tip of iceberg. This article is specially for those who who studied maths in school and college and today they are completely in the different field and they find it difficult to understand the usecases of maths except counting numbers and money calculations. :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Reactjs Library</title>
      <link>http://localhost:1313/dsblog/exploring-reactjs-library/</link>
      <pubDate>Sat, 15 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-reactjs-library/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6241-Exploring-Reactjs-Library.jpg&#34; alt=&#34;React Logo&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;why-this-another-article-around-react&#34;&gt;Why this another article around React?&lt;/h2&gt;&#xA;&lt;p&gt;There is no dearth of React tutorial and guide on the internet then why this article?&lt;/p&gt;&#xA;&lt;p&gt;The learning process can be quite diverse, and people come from different backgrounds and experiences. Some may prefer a more structured approach, while others may enjoy exploring concepts through Q&amp;amp;A formats. This article aims to provide a concise introduction to React.js, also known as React, by exploring the most common questions people have about this popular JavaScript library. Whether you&amp;rsquo;re a beginner looking to learn the basics or an experienced developer wanting to know more about React, this article should provide you with a solid foundation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Comprehensive Guide to Evaluate Generative Models</title>
      <link>http://localhost:1313/dsblog/guide-to-evaluate-generative-models/</link>
      <pubDate>Fri, 14 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/guide-to-evaluate-generative-models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6240-Guide-to-Evaluate-Generative-Models.jpg&#34; alt=&#34;Generative Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;a-comprehensive-guide-to-evaluate-generative-models&#34;&gt;A Comprehensive Guide to Evaluate Generative Models&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In the rapidly evolving landscape of artificial intelligence, generative models have emerged as powerful tools capable of creating lifelike images, coherent text narratives, and even realistic audio. From large language models (LLMs) like GPT, Gemini, and Claude to image generators like Stable Diffusion, these systems are reshaping creativity, communication, and problem-solving. However, their potential is only as good as our ability to evaluate them effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Software Development Toolsets Explained</title>
      <link>http://localhost:1313/dsblog/software-development-toolsets-explained/</link>
      <pubDate>Thu, 13 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/software-development-toolsets-explained/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6239-Software-Development-Toolsets-Explained.jpg&#34; alt=&#34;Software Development Toolsets&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;34-must-know-software-development-toolsets-explained&#34;&gt;34 Must-Know Software Development Toolsets Explained&lt;/h1&gt;&#xA;&lt;iframe width=&#34;560&#34; height=&#34;315&#34; &#xD;&#xA;        src=&#34;https://www.youtube.com/embed/5ivBY3SS2pY&#34; &#xD;&#xA;        title=&#34;Retrieval-Augmented Generation with Conflicting Evidence&#34; &#xD;&#xA;        frameborder=&#34;0&#34; &#xD;&#xA;        allow=&#34;accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share&#34; &#xD;&#xA;        allowfullscreen&gt;&#xD;&#xA;&lt;/iframe&gt;&#xD;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;If you are coming from a background of software development then you might have heard of terms like SDK (Software Development Kit), Framework, API (Application Programming Interface), Library, Platform, Toolkit, Engine, Runtime, IDE (Integrated Development Environment), CLI (Command-Line Interface), Middleware, Boilerplate, Stack, Environment, Suite, DSL (Domain-Specific Language), Scaffold, Package, Module, Template, Generator, Container, Orchestrator, Bindings, Driver, Sandbox, and many more. Sometimes you might be beating your head to understand what is the difference between these terms and why people coin a new term every time.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Implementing Comments in Jekyll Blogs</title>
      <link>http://localhost:1313/dsblog/implementing-comments-in-jekyll-blogs/</link>
      <pubDate>Wed, 12 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/implementing-comments-in-jekyll-blogs/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6238-Implementing-Comments-in-Jekyll-Blogs.jpg&#34; alt=&#34;Implementing Comments in Jekyll Blogs&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;disqus-comments&#34;&gt;Disqus Comments&lt;/h2&gt;&#xA;&lt;p&gt;For this&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;you need to create one account on Disqus and then create a new site. It will generate one shortname for you.&lt;/li&gt;&#xA;&lt;li&gt;In your _config.yml update comments.disqus.shortname&lt;/li&gt;&#xA;&lt;li&gt;Add below script to your Jekyll post template. Typically this in _layouts\default.html or some other layout file.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-html&#34; data-lang=&#34;html&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;div id=&amp;#34;disqus_thread&amp;#34;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;div&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;script&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;/**&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;     *  RECOMMENDED CONFIGURATION VARIABLES: EDIT AND UNCOMMENT THE SECTION BELOW TO INSERT DYNAMIC VALUES FROM YOUR PLATFORM OR CMS.&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;        *  LEARN WHY DEFINING THESE VARIABLES IS IMPORTANT: https://disqus.com/admin/universalcode/#configuration-variables    */&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;disqus_config&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt; () {&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;page&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;url&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ page.url | absolute_url }}&amp;#34;&lt;/span&gt;;  &lt;span style=&#34;color:#75715e&#34;&gt;// Use Jekyll&amp;#39;s Liquid template to get the absolute URL&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;this&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;page&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;identifier&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;{{ page.id }}&amp;#34;&lt;/span&gt;; &lt;span style=&#34;color:#75715e&#34;&gt;// Use Jekyll&amp;#39;s Liquid template to get the unique identifier&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    };&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    (&lt;span style=&#34;color:#66d9ef&#34;&gt;function&lt;/span&gt;() { &lt;span style=&#34;color:#75715e&#34;&gt;// DON&amp;#39;T EDIT BELOW THIS LINE&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;var&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;d&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; document, &lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;d&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;createElement&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;script&amp;#39;&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;src&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;https://dasarpai-com.disqus.com/embed.js&amp;#39;&lt;/span&gt;;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;setAttribute&lt;/span&gt;(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#39;data-timestamp&amp;#39;&lt;/span&gt;, &lt;span style=&#34;color:#f92672&#34;&gt;+&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;new&lt;/span&gt; Date());&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    (&lt;span style=&#34;color:#a6e22e&#34;&gt;d&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;head&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;||&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;d&lt;/span&gt;.&lt;span style=&#34;color:#a6e22e&#34;&gt;body&lt;/span&gt;).&lt;span style=&#34;color:#a6e22e&#34;&gt;appendChild&lt;/span&gt;(&lt;span style=&#34;color:#a6e22e&#34;&gt;s&lt;/span&gt;);&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    })();&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;script&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;noscript&lt;/span&gt;&amp;gt;Please enable JavaScript to view the &amp;lt;&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;href&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;https://disqus.com/?ref_noscript&amp;#34;&lt;/span&gt;&amp;gt;comments powered by Disqus.&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;a&lt;/span&gt;&amp;gt;&amp;lt;/&lt;span style=&#34;color:#f92672&#34;&gt;noscript&lt;/span&gt;&amp;gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;staticman-comments&#34;&gt;Staticman Comments&lt;/h2&gt;&#xA;&lt;p&gt;For all github based commenting you must create a separate repo for comments. Otherwise at every new comments you site will be rebuilt and redeployed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring GraphDB and Neo4j - A Guide to Graph Databases</title>
      <link>http://localhost:1313/dsblog/exploring-graphdb-and-neo4j/</link>
      <pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-graphdb-and-neo4j/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6237-Exploring-GraphDB-and-Neo4j.jpg&#34; alt=&#34;Exploring GraphDB and Neo4j&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;rdbms-vs-neo4j-cypher-command-comparison&#34;&gt;RDBMS vs. Neo4j (Cypher) Command Comparison&lt;/h1&gt;&#xA;&lt;h2 id=&#34;are-graphdb-faster-than-rdbms&#34;&gt;Are GraphDB faster than RDBMS?&lt;/h2&gt;&#xA;&lt;p&gt;Graph databases (GraphDBs) can be &lt;strong&gt;faster&lt;/strong&gt; than relational databases (RDBMS) in scenarios that involve &lt;strong&gt;complex relationships and deep traversals&lt;/strong&gt;, but they are not always universally faster. It depends on the &lt;strong&gt;query type, data structure, and use case&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;when-graphdbs-are-faster-than-rdbms&#34;&gt;&lt;strong&gt;When GraphDBs Are Faster Than RDBMS&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Highly Connected Data (Deep Relationships)&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example:&lt;/strong&gt; Finding friends-of-friends in a social network.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;GraphDB Advantage:&lt;/strong&gt; Uses &lt;strong&gt;index-free adjacency&lt;/strong&gt;, meaning each node stores direct references to its neighbors, making traversal &lt;strong&gt;O(1)&lt;/strong&gt; per hop.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RDBMS Disadvantage:&lt;/strong&gt; Requires multiple &lt;strong&gt;JOINs&lt;/strong&gt; across tables, which can become expensive, leading to &lt;strong&gt;O(n²) or worse&lt;/strong&gt; in deep relationships.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Example Query:&lt;/strong&gt; &amp;ldquo;Find all friends-of-friends of a user.&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding the Business of Marketplaces</title>
      <link>http://localhost:1313/dsblog/understanding-the-business-of-marketplaces/</link>
      <pubDate>Mon, 10 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-the-business-of-marketplaces/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6236-Understanding-the-Business-of-Marketplaces.jpg&#34; alt=&#34;Understanding the Business of Marketplaces&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-the-business-of-marketplaces-a-digital-economy-guide&#34;&gt;Understanding the Business of Marketplaces: A Digital Economy Guide&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;For a long time, I have been puzzled by the online marketplace. As a result, I wanted to understand how it works, the different types of marketplaces, and their business models. During my research, it became overwhelming, so in this article, I focus on categorizing and listing important marketplaces to help my readers.&lt;/p&gt;&#xA;&lt;p&gt;The rise of the internet has transformed the way businesses and individuals interact, giving birth to a vast and diverse ecosystem of online marketplaces. These platforms serve as digital hubs where buyers and sellers connect, facilitating the exchange of goods, services, and digital products. From e-commerce giants (like Amazon) to niche platforms catering to freelancers, creative professionals, and even AI enthusiasts, marketplaces have become an integral part of the global economy. This article categorizes and explores different types of marketplaces, highlighting their unique value propositions and industries they serve.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring and Evaluating Integrated Development Environments (IDEs)</title>
      <link>http://localhost:1313/dsblog/exploring-and-evaluating-ides/</link>
      <pubDate>Sat, 08 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-and-evaluating-ides/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6235-Exploring-and-Evaluating-IDEs.jpg&#34; alt=&#34;Explroring IDEs&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-and-evaluating-integrated-development-environments-ides&#34;&gt;Exploring and Evaluating Integrated Development Environments (IDEs)&lt;/h1&gt;&#xA;&lt;p&gt;In this article we will explore the history of IDEs and how they have evolved over time. Apart from this we will see how to evalute the best IDE for your needs and what are IDE in AI era.&lt;/p&gt;&#xA;&lt;h2 id=&#34;a-broad-timeline-of-ide-development&#34;&gt;A Broad Timeline of IDE Development&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Efficiency (1970s–1980s)&lt;/strong&gt;: Focus on minimalism and raw functionality for basic coding tasks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Enhancement (1980s–1990s)&lt;/strong&gt;: Adding productivity tools and integration for growing complexity.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Integration (1990s–2000s)&lt;/strong&gt;: Combining editing, debugging, and building into a cohesive environment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Collaboration (2000s–2010s)&lt;/strong&gt;: Expanding accessibility and teamwork via cloud and networks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Intelligence (2010s–Early 2020s)&lt;/strong&gt;: Leveraging AI for smarter, reactive assistance.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Agency (Mid-2020s)&lt;/strong&gt;: Shifting to proactive, context-aware systems that act as co-developers.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;features-to-evaluate-ide&#34;&gt;Features to Evaluate IDE&lt;/h2&gt;&#xA;&lt;p&gt;To compare any Integrated Development Environment (IDE) we need a structured set of features that capture both traditional IDE capabilities and the advanced AI-driven functionalities. These features span core IDE functionality, AI-specific enhancements, usability, and integration, allowing for a fair evaluation competitors like windsurf, Cursor, VS Code with Copilot, JetBrains, or others. Currently I am using windsurf heavily so this feature list is influenced by windsurf.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Working with GitHub from WSL and Windows Folders</title>
      <link>http://localhost:1313/dsblog/working-with-github-from-wsl-and-windows-folders/</link>
      <pubDate>Sun, 02 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/working-with-github-from-wsl-and-windows-folders/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6234-Working-with-Github-from-WSL-and-Windows-Folders.jpg&#34; alt=&#34;Working with GitHub from WSL and Windows Folders&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;problem-statement&#34;&gt;Problem Statement:&lt;/h2&gt;&#xA;&lt;p&gt;I have project in D:\github-blog\dasarpai-websitetest. This is also a github repo. It&amp;rsquo;s remote repo is &lt;a href=&#34;https://github.com/dasarpai/dasarpai-websitetest&#34;&gt;https://github.com/dasarpai/dasarpai-websitetest&lt;/a&gt;. I have github desktop for windows 11 installed on my machine. Sometime I push/pull files in github repo using this github desktop. I have Visual Code IDE installed on my windows 11 machine and I also visual code IDE on my machine&amp;rsquo;s wsl.&lt;/p&gt;&#xA;&lt;p&gt;When I am working with this project from windows 11 or wsl then sometimes file will get updated.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why Use Offline AI Models?</title>
      <link>http://localhost:1313/dsblog/why-use-offline-ai-models/</link>
      <pubDate>Sat, 01 Mar 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/why-use-offline-ai-models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6233-Why-to-use-offline-ai-models.jpg&#34; alt=&#34;Why to use Offline AI Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;why-to-use-offline-ai-models&#34;&gt;Why to use Offline AI Models?&lt;/h1&gt;&#xA;&lt;p&gt;There are dozens of AI companies offering cloud-based AI solutions, and prices have been steadily decreasing over time. These models generally produce high-quality results because they are built with billions or even trillions of parameters and are hosted on world-class infrastructure. Given these advantages, why should we consider offline AI models? In this article, we explore the reasons behind this choice.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Online Coding Tools: Choosing the Right IDE for Your Project</title>
      <link>http://localhost:1313/dsblog/online-coding-tools/</link>
      <pubDate>Fri, 28 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/online-coding-tools/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6232-Online-Coding-Tools.jpg&#34; alt=&#34;Online Coding Tools&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;online-coding-tools&#34;&gt;Online Coding Tools&lt;/h1&gt;&#xA;&lt;p&gt;The main difference between various online coding tools lies in how these tools function and what they are optimized for. Without wasting much time around let&amp;rsquo;s get into it.&lt;/p&gt;&#xA;&lt;h3 id=&#34;vscodedev--similar-web-based-ides&#34;&gt;VSCode.dev &amp;amp; Similar Web-Based IDEs&lt;/h3&gt;&#xA;&lt;p&gt;These are for full-fledged coding with local and remote integration&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Examples:&lt;/strong&gt; &lt;a href=&#34;https://vscode.dev/&#34;&gt;VSCode.dev&lt;/a&gt;, &lt;a href=&#34;https://github.com/features/codespaces&#34;&gt;GitHub Codespaces&lt;/a&gt;, &lt;a href=&#34;https://www.gitpod.io/&#34;&gt;Gitpod&lt;/a&gt;, &lt;a href=&#34;https://stackblitz.com/&#34;&gt;StackBlitz&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use Case:&lt;/strong&gt; Writing and editing code with a full development environment in the browser.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;br&gt;&#xA;✅ Looks and feels like VS Code or JetBrains IDEs&lt;br&gt;&#xA;✅ Supports &lt;strong&gt;GitHub/GitLab integration&lt;/strong&gt;&lt;br&gt;&#xA;✅ Can run &lt;strong&gt;remote containers/VMs&lt;/strong&gt; for coding&lt;br&gt;&#xA;✅ Some offer &lt;strong&gt;SSH connections&lt;/strong&gt; to remote servers&lt;br&gt;&#xA;✅ &lt;strong&gt;Customizable&lt;/strong&gt; with extensions, themes, etc.&lt;br&gt;&#xA;❌ Some lack full terminal/compilation support (e.g., VSCode.dev is read-only for some languages)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Best for:&lt;/strong&gt; Cloud-based development, remote work, and projects stored on GitHub/GitLab.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Basics of Microprocessor and Microcontroller</title>
      <link>http://localhost:1313/dsblog/basics-of-microprocessor-and-microcontroller/</link>
      <pubDate>Thu, 27 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/basics-of-microprocessor-and-microcontroller/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6230-Basics-of-Microprocessor-and-Microcontroller.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;the-basics-of-microprocessor-and-microcontroller&#34;&gt;The Basics of Microprocessor and Microcontroller&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-a-microcontroller&#34;&gt;&lt;strong&gt;What is a Microcontroller?&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;microcontroller (MCU)&lt;/strong&gt; is a compact, integrated computing device that includes a &lt;strong&gt;processor (CPU), memory (RAM &amp;amp; ROM), and input/output (I/O) peripherals&lt;/strong&gt; on a single chip. It is designed for &lt;strong&gt;specific embedded system applications&lt;/strong&gt; like controlling devices, automation, and real-time processing.&lt;/p&gt;&#xA;&lt;p&gt;🔹 &lt;strong&gt;Key Features of a Microcontroller:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;CPU (Central Processing Unit)&lt;/strong&gt; – Executes instructions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ROM (Read-Only Memory)&lt;/strong&gt; – Stores program code.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RAM (Random Access Memory)&lt;/strong&gt; – Stores temporary data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;I/O Ports&lt;/strong&gt; – Communicates with external devices like sensors, motors, and displays.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Timers &amp;amp; Counters&lt;/strong&gt; – Used for delay generation and counting events.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Serial Communication (UART, SPI, I2C, etc.)&lt;/strong&gt; – Allows data transfer between devices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Power-efficient&lt;/strong&gt; – Designed for low-power applications like IoT, automation, and consumer electronics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;examples-of-microcontrollers&#34;&gt;&lt;strong&gt;Examples of Microcontrollers&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Famous Microcontrollers and Their Origins&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Reasoning Models in AI Marketplace, Feb 25</title>
      <link>http://localhost:1313/dsblog/exploring-reasoning-models/</link>
      <pubDate>Wed, 26 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-reasoning-models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6229-Exploring-Reasoning-Models.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-reasoning-models-in-ai-marketplace---feb2025&#34;&gt;Exploring Reasoning Models in AI Marketplace - Feb&#39;2025&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-makes-a-model-a&#34;&gt;&lt;strong&gt;What Makes a Model a &amp;ldquo;Reasoning Model&amp;rdquo;?&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;The term &amp;ldquo;reasoning model&amp;rdquo; is not strictly defined but generally refers to models that &lt;strong&gt;explicitly demonstrate structured problem-solving abilities&lt;/strong&gt;, such as:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Logical inference&lt;/strong&gt; (deductive/inductive reasoning)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Multi-step problem-solving&lt;/strong&gt; (e.g., math, coding, puzzles)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Common-sense reasoning&lt;/strong&gt; (understanding implicit context)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Causal reasoning&lt;/strong&gt; (connecting causes and effects).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Modern models achieve this through architectural innovations (e.g., chain-of-thought prompting, sparse attention) and training on datasets enriched with reasoning tasks (e.g., math problems, logic puzzles).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring DeepSeek R1: The AI That Thinks Like a Human</title>
      <link>http://localhost:1313/dsblog/exploring-deepseek-r1/</link>
      <pubDate>Tue, 25 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-deepseek-r1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6228-Exploring-DeepSeek-R1.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-deepseek-r1-the-ai-that-thinks-like-a-human&#34;&gt;Exploring DeepSeek R1: The AI That Thinks Like a Human&lt;/h1&gt;&#xA;&lt;p&gt;Artificial Intelligence (AI) has come a long way, but few models have captured the imagination of researchers, developers, and businesses like &lt;strong&gt;DeepSeek R1&lt;/strong&gt;. Developed by &lt;strong&gt;DeepSeek&lt;/strong&gt;, a cutting-edge AI research organization, DeepSeek R1 is not just another AI model—it’s a reasoning engine designed to tackle complex tasks with human-like precision. Whether it’s solving intricate math problems, writing code, or analyzing data, DeepSeek R1 is reasoning in every step. In this article, we’ll explore into what makes DeepSeek R1 special, how it works, and why it’s a game-changer for industries and individuals alike.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Integrating Ollama AI Models and Open WebUI with Docker: A Step-by-Step Guide</title>
      <link>http://localhost:1313/dsblog/integrating-ollama-and-open-webui-with-docker/</link>
      <pubDate>Mon, 24 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/integrating-ollama-and-open-webui-with-docker/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6227-Integrating-Ollama-and-Open-WebUI-on-Docker.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;integrating-ollama-ai-models-and-open-webui-on-docker&#34;&gt;Integrating Ollama AI Models and Open WebUI on Docker&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Ollama, Opensource LLM Framework from Meta, provides a powerful way to work with large language models (LLMs) efficiently. While Open WebUI is a user-friendly interface that simplifies interaction with Ollama-hosted AI models. You can host Ollama and WebUI on your local machine. By using Docker, we can containerize these components, ensuring a seamless and reproducible setup across different environments. This guide will walk you through integrating Ollama and Open WebUI within Docker.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unlocking the Power of Prompts: A Comprehensive Guide to Prompt Engineering</title>
      <link>http://localhost:1313/dsblog/unlocking-the-power-of-prompts/</link>
      <pubDate>Sun, 23 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/unlocking-the-power-of-prompts/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6226-Unlocking-the-Power-of-Prompting.jpg&#34; alt=&#34;Unlocking the Power of Prompts&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;unlocking-the-power-of-prompts&#34;&gt;Unlocking the Power of Prompts&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;What can you do with Art of Prompting and powerful AI Models? You can use prompts to accomplish almost any task that requires human intelligence. However, prompting is just one part of the process—you also need a powerful model to execute these prompts effectively.&lt;/p&gt;&#xA;&lt;p&gt;The models can be:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cloud-based proprietary models&lt;/strong&gt; like ChatGPT, Gemini, and Sonnet.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Open-source models hosted on the cloud&lt;/strong&gt; like LLaMa, DeepSeek, and Qwen.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Proprietary models deployed on your organization&amp;rsquo;s internal infrastructure.&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Open-source models running on your organization&amp;rsquo;s infrastructure.&lt;/strong&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For general personal use, these models are often available with limited usage and warranty. However, for commercial applications requiring higher reliability and guarantees, paid plans are necessary. The cost of these models is decreasing by a factor of 10 each year. In the near future, we will have even more powerful models available for free or at a nominal cost.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Reinforcement Learning Concepts: A Comprehensive Guide</title>
      <link>http://localhost:1313/dsblog/exploring-reinforcement-learning-concepts/</link>
      <pubDate>Sat, 22 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-reinforcement-learning-concepts/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6225-Exploring-Reinforcement-Learning-Concepts.jpg&#34; alt=&#34;Exploring Reinforcement  Learning Concepts&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-reinforcement--learning-concepts&#34;&gt;Exploring Reinforcement  Learning Concepts&lt;/h1&gt;&#xA;&lt;p&gt;Reinforcement Learning (RL) is a rich and complex field with many important concepts. Here are some high level concepts which you need to understand, and explore this field.&lt;/p&gt;&#xA;&lt;h2 id=&#34;key-concepts-of-reinforcement-learning-rl&#34;&gt;Key Concepts of Reinforcement Learning (RL)&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-markov-decision-processes-mdps&#34;&gt;&lt;strong&gt;1. Markov Decision Processes (MDPs)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: The mathematical framework for RL, consisting of states, actions, transitions, and rewards.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Components&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;State (S)&lt;/strong&gt;: The current situation of the agent.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action (A)&lt;/strong&gt;: Choices available to the agent.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Transition Function (P)&lt;/strong&gt;: Probability of moving to a new state given an action.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Reward Function (R)&lt;/strong&gt;: Immediate feedback for taking an action in a state.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Discount Factor (γ)&lt;/strong&gt;: Determines the importance of future rewards.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Extensions&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Partially Observable MDPs (POMDPs): When the agent cannot fully observe the state.&lt;/li&gt;&#xA;&lt;li&gt;Continuous MDPs: For continuous state and action spaces.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-policies&#34;&gt;&lt;strong&gt;2. Policies&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: A strategy that the agent uses to decide actions based on states.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Types&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Deterministic Policy&lt;/strong&gt;: Maps states to specific actions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Stochastic Policy&lt;/strong&gt;: Maps states to probability distributions over actions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Optimal Policy&lt;/strong&gt;: The policy that maximizes cumulative rewards.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;3-value-functions&#34;&gt;&lt;strong&gt;3. Value Functions&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;State-Value Function (V)&lt;/strong&gt;: Expected cumulative reward from a state under a policy.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Action-Value Function (Q)&lt;/strong&gt;: Expected cumulative reward for taking an action in a state and following a policy.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Bellman Equation&lt;/strong&gt;: Recursive relationship used to compute value functions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;4-exploration-vs-exploitation&#34;&gt;&lt;strong&gt;4. Exploration vs. Exploitation&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Exploration&lt;/strong&gt;: Trying new actions to discover their effects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Exploitation&lt;/strong&gt;: Choosing known actions that yield high rewards.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Balancing Mechanisms&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;ε-Greedy&lt;/strong&gt;: Randomly explores with probability ε.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Softmax&lt;/strong&gt;: Selects actions based on a probability distribution.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Upper Confidence Bound (UCB)&lt;/strong&gt;: Balances exploration and exploitation based on uncertainty.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;5-algorithms&#34;&gt;&lt;strong&gt;5. Algorithms&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Model-Based vs. Model-Free&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Model-Based&lt;/strong&gt;: Learns a model of the environment (transition and reward functions).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Model-Free&lt;/strong&gt;: Learns directly from interactions without modeling the environment.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Algorithms&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Q-Learning&lt;/strong&gt;: Off-policy algorithm for learning action-value functions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SARSA&lt;/strong&gt;: On-policy algorithm for learning action-value functions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Deep Q-Networks (DQN)&lt;/strong&gt;: Combines Q-learning with deep neural networks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Policy Gradient Methods&lt;/strong&gt;: Directly optimize the policy (e.g., REINFORCE, PPO, TRPO).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Actor-Critic Methods&lt;/strong&gt;: Combines value-based and policy-based approaches.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;6-function-approximation&#34;&gt;&lt;strong&gt;6. Function Approximation&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Handles large or continuous state/action spaces.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Linear Approximation&lt;/strong&gt;: Uses linear combinations of features.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Neural Networks&lt;/strong&gt;: Deep learning for complex function approximation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Challenges&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Overfitting, instability, and divergence.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;7-temporal-difference-td-learning&#34;&gt;&lt;strong&gt;7. Temporal Difference (TD) Learning&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Combines Monte Carlo methods and dynamic programming for online learning.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Key Concepts&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;TD Error&lt;/strong&gt;: Difference between estimated and actual returns.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Bootstrapping&lt;/strong&gt;: Updating estimates based on other estimates.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;8-eligibility-traces&#34;&gt;&lt;strong&gt;8. Eligibility Traces&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Improves efficiency of TD learning by considering recent states and actions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Example&lt;/strong&gt;: TD(λ), where λ controls the trace decay.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;9-multi-agent-rl-marl&#34;&gt;&lt;strong&gt;9. Multi-Agent RL (MARL)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Extends RL to environments with multiple agents.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Challenges&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Non-stationarity (other agents are also learning).&lt;/li&gt;&#xA;&lt;li&gt;Coordination and competition.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Approaches&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Cooperative, Competitive, and Mixed settings.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;10-transfer-learning-in-rl&#34;&gt;&lt;strong&gt;10. Transfer Learning in RL&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Applying knowledge from one task to another.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Domain Adaptation&lt;/strong&gt;: Adjusting to new environments.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Skill Transfer&lt;/strong&gt;: Reusing learned policies or value functions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;11-safe-and-ethical-rl&#34;&gt;&lt;strong&gt;11. Safe and Ethical RL&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Safe Exploration&lt;/strong&gt;: Avoiding harmful actions during learning.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ethical Constraints&lt;/strong&gt;: Incorporating human values into reward design.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;12-hierarchical-rl-hrl&#34;&gt;&lt;strong&gt;12. Hierarchical RL (HRL)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Breaks tasks into sub-tasks or sub-goals.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Options Framework&lt;/strong&gt;: Temporal abstractions for actions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MAXQ&lt;/strong&gt;: Hierarchical decomposition of value functions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;13-imitation-learning&#34;&gt;&lt;strong&gt;13. Imitation Learning&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Learning from expert demonstrations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Behavior Cloning&lt;/strong&gt;: Supervised learning to mimic expert actions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Inverse RL&lt;/strong&gt;: Inferring the reward function from demonstrations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;14-meta-learning-in-rl&#34;&gt;&lt;strong&gt;14. Meta-Learning in RL&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Definition&lt;/strong&gt;: Learning to learn, or adapting quickly to new tasks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Methods&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Model-Agnostic Meta-Learning (MAML)&lt;/strong&gt;: Adapts to new tasks with few samples.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RL²&lt;/strong&gt;: Treats the RL algorithm itself as a learning problem.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;15-exploration-strategies&#34;&gt;&lt;strong&gt;15. Exploration Strategies&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Intrinsic Motivation&lt;/strong&gt;: Encourages exploration through curiosity or novelty.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Count-Based Exploration&lt;/strong&gt;: Rewards visiting rare states.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Random Network Distillation (RND)&lt;/strong&gt;: Uses prediction errors to drive exploration.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;16-challenges-in-rl&#34;&gt;&lt;strong&gt;16. Challenges in RL&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sample Efficiency&lt;/strong&gt;: Learning with limited interactions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Credit Assignment&lt;/strong&gt;: Determining which actions led to rewards.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scalability&lt;/strong&gt;: Handling high-dimensional state/action spaces.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Stability&lt;/strong&gt;: Avoiding divergence during training.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;17-applications-of-rl&#34;&gt;&lt;strong&gt;17. Applications of RL&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Games&lt;/strong&gt;: AlphaGo, Dota 2, Chess.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Robotics&lt;/strong&gt;: Manipulation, locomotion, autonomous driving.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;: Personalized treatment, drug discovery.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Finance&lt;/strong&gt;: Portfolio optimization, trading strategies.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Recommendation Systems&lt;/strong&gt;: Personalized content delivery.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;18-tools-and-frameworks&#34;&gt;&lt;strong&gt;18. Tools and Frameworks&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Libraries&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;OpenAI Gym: Standardized environments for RL.&lt;/li&gt;&#xA;&lt;li&gt;Stable-Baselines3: Implementations of RL algorithms.&lt;/li&gt;&#xA;&lt;li&gt;Ray RLlib: Scalable RL for distributed computing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Simulators&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;MuJoCo, PyBullet, Unity ML-Agents.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;19-theoretical-foundations&#34;&gt;&lt;strong&gt;19. Theoretical Foundations&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Convergence Guarantees&lt;/strong&gt;: Conditions under which RL algorithms converge.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Regret Minimization&lt;/strong&gt;: Balancing exploration and exploitation over time.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Policy Improvement Theorems&lt;/strong&gt;: Guarantees for improving policies iteratively.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;20-advanced-topics&#34;&gt;&lt;strong&gt;20. Advanced Topics&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Off-Policy Learning&lt;/strong&gt;: Learning from data generated by a different policy.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Offline RL&lt;/strong&gt;: Learning from pre-collected datasets without interaction.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Multi-Task RL&lt;/strong&gt;: Learning multiple tasks simultaneously.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Meta-RL&lt;/strong&gt;: Learning RL algorithms themselves.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;what-are-differening-rewardng-systems-in-rl&#34;&gt;What are differening rewardng systems in RL?&lt;/h2&gt;&#xA;&lt;p&gt;In reinforcement learning (RL), reward systems are pivotal in guiding agents to learn optimal behaviors. Here&amp;rsquo;s an organized overview of different reward systems, their characteristics, and applications:&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Resources: Ultimate Collection of Cutting-Edge Tools for AI Enthusiasts</title>
      <link>http://localhost:1313/dsblog/ai-resources/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ai-resources/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6224-AI-Resources.jpg&#34; alt=&#34;AI Resources&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-resources-ultimate-collection-of-cutting-edge-tools-for-ai-enthusiasts&#34;&gt;AI Resources: Ultimate Collection of Cutting-Edge Tools for AI Enthusiasts&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In a world driven by innovation and accelerated by artificial intelligence, the right tools can make all the difference—whether you’re hunting for your dream job, scaling a business, or pushing the boundaries of creativity and development. Welcome to the ultimate resource hub! I&amp;rsquo;ve curated an extensive collection of hundreds of cutting-edge tools across diverse categories—ranging from AI-powered presentation and diagramming solutions to development frameworks, data visualization platforms, and even niche treasures like Sanskrit tools. Whether you’re a job seeker, an entrepreneur, a developer, a designer, or simply an AI enthusiast, this comprehensive directory is your gateway to unlocking efficiency, inspiration, and success. Dive in and discover the tools that will empower you to navigate the future with confidence!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Bookmark Blog Articles from Browser</title>
      <link>http://localhost:1313/dsblog/mybookmark-blog-articles/</link>
      <pubDate>Fri, 21 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/mybookmark-blog-articles/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6231-Mybookmark-Blog-Articles.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;bookmark-blog-articles-from-browser&#34;&gt;Bookmark Blog Articles from Browser&lt;/h1&gt;&#xA;&lt;p&gt;This web page serves as a continuation of the &lt;a href=&#34;http://localhost:1313/dsblog/ai-resources&#34;&gt;AI Resources&lt;/a&gt; page. As the original page grew excessively long and cumbersome to navigate, I created this dedicated page to house bookmarked articles from blogs.&lt;/p&gt;&#xA;&lt;h2 id=&#34;my-bookmarked-articles&#34;&gt;My bookmarked Articles&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.1843magazine.com/features/deepmind-and-google-the-battle-to-control-artificial-intelligence&#34;&gt;1843magazine.com/features/deepmind-and-google- the-battle-to-control-artificial-intelligence&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://24x7coach.com/ms-project-blog/how-can-i-find-number-of-days-between-project-start-date-and-task-start-date-in-ms-project/&#34;&gt;24x7coach.com/ms-project-blog/how-can-i-find-number-of-days- between-project-start-date-and-task-start-date-in-ms-project/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aider.chat/docs/llms.html&#34;&gt;aider.chat/docs/llms.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aigents.co/data-science-blog/publication/the-transformers-architecture-in-detail-whats-the-magic-behind-llms&#34;&gt;aigents.co/data-science-blog/publication/the- transformers-architecture-in-detail-whats-the-magic-behind-llms&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/@outside2SDs/an-overview-of-correlation-measures-between-categorical-and-continuous-variables-4c7f85610365&#34;&gt;An overview of correlation measures between categorical and continuous variables&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsindiamag.com/10-best-firms-in-india-for-data-scientists-to-work-for-2019/&#34;&gt;analyticsindiamag.com/10-best-firms-in-india- for-data-scientists-to-work-for-2019/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsindiamag.com/10-leading-organisations-that-are-hiring-data-scientists-in-singapore/&#34;&gt;analyticsindiamag.com/10-leading-organisations-that-are-hiring-data-scientists-in-singapore/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsindiamag.com/5-julia-specific-ides-developers-should-know/&#34;&gt;analyticsindiamag.com/5-julia-specific-ides- developers-should-know/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsindiamag.com/5-popular-python-open-source-ides-for-data-science-enthusiasts/&#34;&gt;analyticsindiamag.com/5-popular-python-open-source-ides-for-data-science-enthusiasts/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsindiamag.com/5-simple-full-stack-data-science-projects-to-put-on-your-resume/&#34;&gt;analyticsindiamag.com/5-simple-full-stack-data-science-projects-to-put-on-your-resume/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://analyticsindiamag.com/7-python-libraries-for-manipulating-audio-that-data-scientists-use/&#34;&gt;analyticsindiamag.com/7-python-libraries-for- manipulating-audio-that-data-scientists-use/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsindiamag.com/a-deep-dive-into-corporate-tools-techniques-used-by-analytics-data-science-experts/&#34;&gt;analyticsindiamag.com/a-deep-dive-into-corporate- tools-techniques-used-by-analytics-data-science-experts/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsindiamag.com/beginners_guide_geographical_plotting_with_plotly/&#34;&gt;analyticsindiamag.com/beginners_guide_geographical_plotting_with_plotly/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://analyticsindiamag.com/best-practices-for-a-superior-machine-learning-portfolio/&#34;&gt;analyticsindiamag.com/best-practices-for-a-superior-machine-learning-portfolio/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://analyticsindiamag.com/top-websites-to-find-freelance-data-science-jobs/&#34;&gt;analyticsindiamag.com/top-websites-to-find-freelance-data-science-jobs/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://analyticstraining.com/workforce-analytics-is-reinventing-hr/&#34;&gt;analyticstraining.com/workforce-analytics-is-reinventing-hr/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/&#34;&gt;analyticsvidhya.com/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2015/09/questions-ensemble-modeling/&#34;&gt;analyticsvidhya.com/blog/2015/09/questions-ensemble-modeling/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2016/07/10-analytics-data-science-top-universities-masters-usa/&#34;&gt;analyticsvidhya.com/blog/2016/07/10-analytics- data-science-top-universities-masters-usa/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/&#34;&gt;analyticsvidhya.com/blog/2017/09/naive-bayes-explained/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2018/10/predicting-stock-price-machine-learningnd-deep-learning-techniques-python/&#34;&gt;analyticsvidhya.com/blog/2018/10/predicting-stock- price-machine-learningnd-deep-learning-techniques-python/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2019/05/beginners-guide-hierarchical-clustering/&#34;&gt;analyticsvidhya.com/blog/2019/05/beginners-guide-hierarchical-clustering/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2020/01/how-to-perform-automatic-music-generation/&#34;&gt;analyticsvidhya.com/blog/2020/01/how-to-perform- automatic-music-generation/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.appliedaicourse.com/machine-learning-course/gclid&#34;&gt;appliedaicourse.com/machine-learning-course/gclid&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://auth0.com/b2e-identity-management-for-employees/&#34;&gt;auth0.com/b2e-identity-management-for-employees/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.exxactcorp.com/transformer-architecture-part-1/&#34;&gt;blog.exxactcorp.com/transformer-architecture-part-1/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.socialcops.com/intelligence/data-stories/india-unclear-many-villages-matters/&#34;&gt;blog.socialcops.com/intelligence/data-stories/ india-unclear-many-villages-matters/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://brilliant.org/courses/artificial-neural-networks/tour=true&#34;&gt;brilliant.org/courses/artificial-neural-networks/tour=true&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://byjus.com/jee/types-of-matrices/&#34;&gt;byjus.com/jee/types-of-matrices/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.calls9.com/blogs/the-history-of-ai-a-timeline-from-1940-to-2023&#34;&gt;calls9.com/blogs/the-history-of-ai-a- timeline-from-1940-to-2023&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.certification-questions.com/practice-exam/pmi/pmp&#34;&gt;certification-questions.com/practice-exam/pmi/pmp&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://christophm.github.io/interpretable-ml-book/&#34;&gt;christophm.github.io/interpretable-ml-book/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ci.pytorch.org/jenkins/job/pytorch-master/&#34;&gt;ci.pytorch.org/jenkins/job/pytorch-master/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cnet.com/how-to/the-best-antivirus-protection-of-2020-for-windows-10/&#34;&gt;cnet.com/how-to/the-best-antivirus-protection-of-2020-for-windows-10/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://microsoft.github.io/autogen/stable/user-guide/agentchat-user-guide/examples/company-research.html&#34;&gt;Conducting company research, or competitive analysis&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datahack.analyticsvidhya.com/contest/practice-problem-loan-prediction-iii/&#34;&gt;datahack.analyticsvidhya.com/contest/practice- problem-loan-prediction-iii/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datajournalismhandbook.org/1.0/en/getting_data_3.html&#34;&gt;datajournalismhandbook.org/1.0/en/getting_data_3.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datamation.com/artificial-intelligence/open-source-artificial-intelligence-projects.html&#34;&gt;datamation.com/artificial-intelligence/open-source- artificial-intelligence-projects.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dataschool.io/roc-curves-and-auc-explained/&#34;&gt;dataschool.io/roc-curves-and-auc-explained/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/&#34;&gt;dataschool.io/simple-guide-to-confusion-matrix-terminology/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datascience.com/resources/notebooks/random-forest-intro&#34;&gt;datascience.com/resources/notebooks/random-forest-intro&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datasciencecentral.com/profiles/blogs/non-traditional-strategies-for-mid-career-switch-to-datascience&#34;&gt;datasciencecentral.com/profiles/blogs/non-traditional- strategies-for-mid-career-switch-to-datascience&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datasciencedegreeprograms.net/rankings/masters-data-science/&#34;&gt;datasciencedegreeprograms.net/rankings/masters-data-science/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datatofish.com/category/python/&#34;&gt;datatofish.com/category/python/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.ibm.com/technologies/data-science/patterns/fraud-prediction-using-autoai&#34;&gt;developer.ibm.com/technologies/data-science/patterns/ fraud-prediction-using-autoai&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/blog/building-software-defined-smart-grid-technology/&#34;&gt;developer.nvidia.com/blog/building-software- defined-smart-grid-technology/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dezyre.com/recipes/optimise-size-depth-of-trees-in-xgboost&#34;&gt;dezyre.com/recipes/optimise-size-depth-of-trees-in-xgboost&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.digitalvidya.com/blog/data-analytics-interview-questions-answers/&#34;&gt;digitalvidya.com/blog/data-analytics- interview-questions-answers/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.digitalvidya.com/data-science-master-course/&#34;&gt;digitalvidya.com/data-science-master-course/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.sympy.org/latest/tutorial/preliminaries.html#installation&#34;&gt;docs.sympy.org/latest/tutorial/ preliminaries.html#installation&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dummies.com/education/math/statistics/how-to-tell-a-z-distribution-from-a-t-distribution/&#34;&gt;dummies.com/education/math/statistics/how-to-tell-a-z-distribution-from-a-t-distribution/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.einfochips.com/blog/addressing-challenges-associated-with-imbalanced-datasets-in-machine-learning/&#34;&gt;einfochips.com/blog/addressing-challenges- associated-with-imbalanced-datasets-in-machine-learning/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.einfochips.com/intelligent-vision-solutions-for-future-enterprise/&#34;&gt;einfochips.com/intelligent-vision-solutions- for-future-enterprise/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://elevenlabs.io/blog/introducing-elevenlabs-reader-app&#34;&gt;elevenlabs.io/blog/introducing-elevenlabs-reader-app&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.m.wikipedia.org/wiki/PsycINFO&#34;&gt;en.m.wikipedia.org/wiki/PsycINFO&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Binomial_distribution&#34;&gt;en.wikipedia.org/wiki/Binomial_distribution&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Dataflow_programming&#34;&gt;en.wikipedia.org/wiki/Dataflow_programming&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Hypergeometric_distribution&#34;&gt;en.wikipedia.org/wiki/Hypergeometric_distribution&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/List_of_mathematical_symbols&#34;&gt;en.wikipedia.org/wiki/List_of_mathematical_symbols&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Mixture_model&#34;&gt;en.wikipedia.org/wiki/Mixture_model&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction&#34;&gt;en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Random_forest&#34;&gt;en.wikipedia.org/wiki/Random_forest&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Visual_programming_language&#34;&gt;en.wikipedia.org/wiki/Visual_programming_language&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Visual_thinking&#34;&gt;en.wikipedia.org/wiki/Visual_thinking&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.freecodecamp.org/news/simple-chess-ai-step-by-step-1d55a9266977/&#34;&gt;freecodecamp.org/news/simple-chess-ai- step-by-step-1d55a9266977/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.freethink.com/technology/&#34;&gt;freethink.com/technology/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/python-pandas-dataframe-corr/&#34;&gt;geeksforgeeks.org/python-pandas-dataframe-corr/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ashishpatel26/365-Days-Computer-Vision-Learning-Linkedin-Posttab&#34;&gt;github.com/ashishpatel26/365-Days-Computer- Vision-Learning-Linkedin-Posttab&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/orgs/dotnet-architecture/repositoriestype&#34;&gt;github.com/orgs/dotnet-architecture/repositoriestype&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://groups.google.com/forum/#!forum/nltk-users&#34;&gt;groups.google.com/forum/#!forum/nltk-users&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.guru99.com/word-embedding-word2vec.html&#34;&gt;guru99.com/word-embedding-word2vec.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://gyaandweep.com/purana/shivapurana/kotirudra-samhita/&#34;&gt;gyaandweep.com/purana/shivapurana/kotirudra-samhita/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://harvard-iacs.github.io/2019-CS109A/&#34;&gt;harvard-iacs.github.io/2019-CS109A/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.hindawi.com/journals/cin/2020/2860479/&#34;&gt;hindawi.com/journals/cin/2020/2860479/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.houseofbots.com/news-detail/12098-1-python-programming-language-can-easily-be-acquired-easily.-how&#34;&gt;houseofbots.com/news-detail/12098-1-python- programming-language-can-easily-be-acquired-easily.-how&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://ercoppa.github.io/HadoopInternals/HadoopArchitectureOverview.html&#34;&gt;http://ercoppa.github.io/HadoopInternals/ HadoopArchitectureOverview.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://thespread.us/clustering.html&#34;&gt;http://thespread.us/clustering.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.algorithmica-technologies.com/en/solutions/intelligent-health-monitor&#34;&gt;http://www.algorithmica-technologies.com/en/ solutions/intelligent-health-monitor&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.oshoworld.com/osho_now/speaks_mystics.asp&#34;&gt;http://www.oshoworld.com/osho_now/speaks_mystics.asp&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.real-statistics.com/logistic-regression/receiver-operating-characteristic-roc-curve&#34;&gt;http://www.real-statistics.com/logistic-regression/receiver-operating-characteristic-roc-curve&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/blog/Emma-N/enjoy-the-power-of-phi-3-with-onnx-runtime&#34;&gt;huggingface.co/blog/Emma-N/enjoy-the-power- of-phi-3-with-onnx-runtime&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain&#34;&gt;huggingface.co/spaces/JavaFXpert/Chat-GPT-LangChain&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.internetlivestats.com/one-second/&#34;&gt;internetlivestats.com/one-second/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.interproinc.com/blog/how-to-boost-video-content-reach-subtitle-translation&#34;&gt;interproinc.com/blog/how-to-boost-video- content-reach-subtitle-translation&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.investopedia.com/articles/07/montecarlo.asp&#34;&gt;investopedia.com/articles/07/montecarlo.asp&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://iot-analytics.com/product/state-of-the-iot-2019-q1-q2-update/&#34;&gt;iot-analytics.com/product/state-of-the-iot-2019-q1-q2-update/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://jinja.palletsprojects.com/en/stable/api/#basics&#34;&gt;jinja.palletsprojects.com/en/stable/api/#basics&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://join.skillshare.com/jan2020-general/coupon=google2free&#34;&gt;join.skillshare.com/jan2020-general/coupon=google2free&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/models/google/gemma/tfLite/gemma-2b-it-gpu-int4&#34;&gt;kaggle.com/models/google/gemma/tfLite/gemma-2b-it-gpu-int4&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kdnuggets.com/2018/04/10-machine-learning-algorithms-data-scientist.html&#34;&gt;kdnuggets.com/2018/04/10-machine-learning- algorithms-data-scientist.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kimballgroup.com/data-warehouse-business-intelligence-resources/kimball-techniques/dimensional-modeling-techniques/&#34;&gt;kimballgroup.com/data-warehouse-business-intelligence- resources/kimball-techniques/dimensional-modeling-techniques/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kindlepreneur.com/the-thank-you-page/&#34;&gt;kindlepreneur.com/the-thank-you-page/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://klu.ai/glossary/lmsys-leaderboard&#34;&gt;klu.ai/glossary/lmsys-leaderboard&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.learnopencv.com/blob-detection-using-opencv-python-c/&#34;&gt;learnopencv.com/blob-detection-using-opencv-python-c/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.listendata.com/2014/08/adjusted-r-squared.htmlm=1&#34;&gt;listendata.com/2014/08/adjusted-r-squared.htmlm=1&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://machinelearningmastery.com/save-load-keras-deep-learning-models/&#34;&gt;machinelearningmastery.com/save-load- keras-deep-learning-models/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://makingindiaemployable.com/silver-dashboard/&#34;&gt;makingindiaemployable.com/silver-dashboard/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://managementconsulted.com/lesson/consulting-101-what-is-management-consulted/&#34;&gt;managementconsulted.com/lesson/consulting- 101-what-is-management-consulted/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.marketingaiinstitute.com/marketing-ai-speaking&#34;&gt;marketingaiinstitute.com/marketing-ai-speaking&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mastersindatascience.org/schools/top-masters-in-analytics/&#34;&gt;mastersindatascience.org/schools/top-masters-in-analytics/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mathdatasimplified.com/upgini-transform-raw-text-into-enriched-numeric-features/&#34;&gt;mathdatasimplified.com/upgini-transform-raw- text-into-enriched-numeric-features/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mathsisfun.com/numbers/sigma-calculator.html&#34;&gt;mathsisfun.com/numbers/sigma-calculator.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mckinsey.com/business-functions/mckinsey-analytics/our-insights/an-executives-guide-to-ai&#34;&gt;mckinsey.com/business-functions/mckinsey- analytics/our-insights/an-executives-guide-to-ai&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hackernoon.com/memorizing-is-not-learning-6-tricks-to-prevent-overfitting-in-machine-learning-820b091dc42&#34;&gt;Memorizing is not learning! — 6 tricks to prevent overfitting in machine learning.&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.methodology.psu.edu/resources/aic-vs-bic/&#34;&gt;methodology.psu.edu/resources/aic-vs-bic/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mindsmapped.com/hadoop-advantages-and-disadvantages/&#34;&gt;mindsmapped.com/hadoop-advantages-and-disadvantages/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://morioh.com/topics/popular&#34;&gt;morioh.com/topics/popular&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.movavi.com/learning-portal/screen-recorder-windows-10.html&#34;&gt;movavi.com/learning-portal/screen-recorder-windows-10.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.naftaliharris.com/blog/visualizing-dbscan-clustering/&#34;&gt;naftaliharris.com/blog/visualizing-dbscan-clustering/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://multiplatform.ai/neo4j-and-google-cloud-join-forces-to-empower-generative-ai-with-knowledge-graphs/&#34;&gt;Neo4j and Google Cloud Join Forces to Empower Generative AI with Knowledge Graph&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.notion.so/The-Best-Artificial-Intelligence-Machine-Learning-and-Data-Science-Resources-b3b97fa097b747698e87fd3badc657cf&#34;&gt;notion.so/The-Best-Artificial-Intelligence-Machine-Learning- and-Data-Science-Resources-b3b97fa097b747698e87fd3badc657cf&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.onlinemathlearning.com/matrices-types.html&#34;&gt;onlinemathlearning.com/matrices-types.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.open.wolframcloud.com/env/a2098a1e-1066-4b1f-a871-b6071bbf7327#sidebar=sandbox-links&#34;&gt;open.wolframcloud.com/env&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.openstreetmap.org/#map=15/13.1213/77.5489&#34;&gt;openstreetmap.org/#map=15/13.1213/77.5489&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.oreilly.com/topics/software-engineering&#34;&gt;oreilly.com/topics/software-engineering&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://paperswithcode.com/paper/albert-a-lite-bert-for-self-supervised&#34;&gt;paperswithcode.com/paper/albert-a-lite-bert-for-self-supervised&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pathmind.com/wiki/word2vec#sequence&#34;&gt;pathmind.com/wiki/word2vec#sequence&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pbpython.com/categorical-encoding.html&#34;&gt;pbpython.com/categorical-encoding.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.pgurus.com/category/lifestyle/business-lifestyle/&#34;&gt;pgurus.com/category/lifestyle/business-lifestyle/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.pravachanam.com/mundaka-upanishad-part-36-swami-parmarthananda&#34;&gt;pravachanam.com/mundaka-upanishad-part-36-swami-parmarthananda&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://programmablesearchengine.google.com/controlpanel/all&#34;&gt;programmablesearchengine.google.com/controlpanel/all&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pythonlinks.info/intro-to-cythonsortBy=bestWilsonScore&#34;&gt;pythonlinks.info/intro-to-cythonsortBy=bestWilsonScore&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rasa.com/solutions/healthcare/&#34;&gt;rasa.com/solutions/healthcare/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://realpython.com/playing-and-recording-sound-python/&#34;&gt;realpython.com/playing-and-recording-sound-python/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.researchgate.net/publication/305850872_Road_crack_detection_using_deep_convolutional_neural_network&#34;&gt;researchgate.net/publication/305850872_Road_ crack_detection_using_deep_convolutional_neural_network&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/browse/journals-and-books&#34;&gt;sciencedirect.com/browse/journals-and-books&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/B9780444518620500186via%3Dihub&#34;&gt;sciencedirect.com/science/article/pii/B9780444518620500186via%3Dihub&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/science/article/pii/B9780444518620500319&#34;&gt;sciencedirect.com/science/article/pii/B9780444518620500319&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scikit-image.org/docs/dev/auto_examples/&#34;&gt;scikit-image.org/docs/dev/auto_examples/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scikit-image.org/docs/dev/auto_examples/applications/plot_face_detection.html&#34;&gt;scikit-image.org/docs/dev/auto_examples/ applications/plot_face_detection.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html&#34;&gt;scikit-image.org/docs/dev/auto_examples/applications/plot_geometric.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/modules/preprocessing.html&#34;&gt;scikit-learn.org/stable/modules/preprocessing.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sebastianraschka.com/Articles/2014_about_feature_scaling.html&#34;&gt;sebastianraschka.com/Articles/2014_about_feature_scaling.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://shapeofdata.wordpress.com/2014/03/04/k-modes/&#34;&gt;shapeofdata.wordpress.com/2014/03/04/k-modes/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.simon-kucher.com/en/industries/automotive/automotive-retail-and-service-providers&#34;&gt;simon-kucher.com/en/industries/automotive/ automotive-retail-and-service-providers&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scroll.in/video/925491/watch-six-indian-origin-children-are-among-the-eight-co-champions-of-the-us-national-spelling-bee&#34;&gt;Six Indian-origin children are among the eight co-champions of the US national spelling bee&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sotabench.com/benchmarks/object-detection-on-coco-minival&#34;&gt;sotabench.com/benchmarks/object-detection-on-coco-minival&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood&#34;&gt;statlect.com/fundamentals-of-statistics/logistic-model-maximum-likelihood&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.statlect.com/fundamentals-of-statistics/point-estimation&#34;&gt;statlect.com/fundamentals-of-statistics/point-estimation&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/352383/how-to-calculate-p-value-for-multivariate-linear-regression&#34;&gt;stats.stackexchange.com/questions/352383/how-to- calculate-p-value-for-multivariate-linear-regression&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stats.stackexchange.com/questions/68391/hessian-of-logistic-function&#34;&gt;stats.stackexchange.com/questions/68391/hessian-of-logistic-function&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.technologyreview.com/s/612726/this-algorithm-browses-wikipedia-to-auto-generate-textbooks/&#34;&gt;technologyreview.com/s/612726/this-algorithm- browses-wikipedia-to-auto-generate-textbooks/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.the-scientist.com/foundations/the-first-x-ray-1895-42279archived_content&#34;&gt;the-scientist.com/foundations/the-first-x-ray-1895-42279archived_content&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.theatlantic.com/magazine/archive/2019/04/robots-human-relationships/583204/&#34;&gt;theatlantic.com/magazine/archive/2019/04/ robots-human-relationships/583204/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.theinsaneapp.com/2021/01/top-30-ai-and-ml-projects-for-2021.html&#34;&gt;theinsaneapp.com/2021/01/ top-30-ai-and-ml-projects-for-2021.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/data-manipulation-for-machine-learning-with-pandas-ab23e79ba5de&#34;&gt;towardsdatascience.com/data-manipulation- for-machine-learning-with-pandas-ab23e79ba5de&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/handling-missing-values-in-machine-learning-part-1-dda69d4f88ca&#34;&gt;towardsdatascience.com/handling-missing- values-in-machine-learning-part-1-dda69d4f88ca&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/handling-missing-values-in-machine-learning-part-2-222154b4b58e&#34;&gt;towardsdatascience.com/handling-missing- values-in-machine-learning-part-2-222154b4b58e&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/i-trained-fake-news-detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c&#34;&gt;towardsdatascience.com/i-trained-fake-news- detection-ai-with-95-accuracy-and-almost-went-crazy-d10589aa57c&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/python-list-comprehensions-in-5-minutes-40a68cbe4561&#34;&gt;towardsdatascience.com/python-list- comprehensions-in-5-minutes-40a68cbe4561&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/the-5-sampling-algorithms-every-data-scientist-need-to-know-43c7bc11d17c&#34;&gt;towardsdatascience.com/the-5-sampling-algorithms- every-data-scientist-need-to-know-43c7bc11d17c&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.tutorialandexample.com/problem-solving-in-artificial-intelligence/&#34;&gt;tutorialandexample.com/problem-solving- in-artificial-intelligence/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ubuy.co.in/catalog/product/&#34;&gt;ubuy.co.in/catalog/product/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/the-ultimate-hands-on-hadoop-tame-your-big-data/learn/v4/announcementsids=2243353&#34;&gt;udemy.com/the-ultimate-hands-on-hadoop-tame- your-big-data/learn/v4/announcementsids=2243353&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vas3k.com/blog/machine_learning/&#34;&gt;vas3k.com/blog/machine_learning/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wisdomlib.org/hinduism/book/shiva-purana-sanskrit/d/doc376155.html&#34;&gt;wisdomlib.org/hinduism/book/shiva-purana-sanskrit/d/doc376155.html&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wpbeginner.com/wp-tutorials/chatgpt-prompts-for-bloggers-marketers-social-media/&#34;&gt;wpbeginner.com/wp-tutorials/chatgpt-prompts- for-bloggers-marketers-social-media/&lt;/a&gt;{:target=&amp;quot;_blank&amp;quot;}&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Exploring Possibilities with CSS: A Comprehensive Guide to Advanced CSS Coding</title>
      <link>http://localhost:1313/dsblog/Exploring-Possibilities-with-CSS/</link>
      <pubDate>Thu, 20 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Possibilities-with-CSS/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6223-Exploring-Possibilities-with-CSS.jpg&#34; alt=&#34;Exploring Possibilities with CSS: A Comprehensive Guide to Advanced CSS Coding&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-advance-css-coding&#34;&gt;Exploring Advance CSS Coding&lt;/h1&gt;&#xA;&lt;p&gt;HTML give the structure to any website, it is like bone strucutre of the body. But the CSS makes it colorful, give some life imitation ability and make it beautiful, it is like flesh and skin on the bone which makes body alive and beautiful. This tutorial should give you a solid foundation in advanced CSS techniques. Keep practicing, with AI driven coding tools you need not memorize the syntext but you should understand what is possible so that you can imagine how you can use it for  you project.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting Up a Development Environment with Windows 11, WSL2 and Docker</title>
      <link>http://localhost:1313/dsblog/development-environment-with-windows-11-wsl2-and-docker/</link>
      <pubDate>Wed, 19 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/development-environment-with-windows-11-wsl2-and-docker/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6222-Setting-Up-a-Development-Environment-with-Windows-11-WSL2-and-Docker.jpg&#34; alt=&#34;Setting Development Environment with WSL2, Docker and Github&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;setting-development-environment-with-wsl2-docker-and-github&#34;&gt;Setting Development Environment with WSL2, Docker and Github&lt;/h1&gt;&#xA;&lt;p&gt;This quick tutorial is about setting Up a Development Environment with Windows 11, WSL 2, Docker and Github&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Like any other operating system, Windows has its strengths and weaknesses. But what if you believe that the democratization of technology is best achieved through open-source solutions, and that Linux is the key to this future? What’s the next step for you?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Shell Scripting and Batch Files</title>
      <link>http://localhost:1313/dsblog/exploring-shell-scripting-and-batch-files/</link>
      <pubDate>Tue, 18 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-shell-scripting-and-batch-files/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6221-Exploring-Shell-Scripting-and-Batch-Files.jpg&#34; alt=&#34;Exploring Shell Scripting and Batch Files&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-shell-scripting-and-batch-files&#34;&gt;Exploring Shell Scripting and Batch Files&lt;/h1&gt;&#xA;&lt;p&gt;Batch files are scripts that contain a series of commands to be executed by the command-line interpreter. These files can automate repetitive tasks and enhance productivity. In this article, we&amp;rsquo;ll explore creating batch files to set environment variables and execute shell commands in Windows, PowerShell, and Ubuntu, along with additional scripting nuances.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-audience&#34;&gt;The Audience&lt;/h2&gt;&#xA;&lt;p&gt;The audience for this article is&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring the Local Location of Ollama Models on WSL2</title>
      <link>http://localhost:1313/dsblog/exploring-ollama-models-location-on-wsl2/</link>
      <pubDate>Mon, 17 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-ollama-models-location-on-wsl2/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6220-Exploring-the-Local-Location-of-Ollama-Models-on-wsl2.jpg&#34; alt=&#34;Exploring the Location of Ollama Models on Local Machine&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-the-location-of-ollama-models-on-local-machine&#34;&gt;Exploring the Location of Ollama Models on Local Machine&lt;/h1&gt;&#xA;&lt;h2 id=&#34;objective&#34;&gt;Objective&lt;/h2&gt;&#xA;&lt;p&gt;Many times you may have a question like, I have installed ollama in wsl and download some ollama models. Ollama list shows me those models. I want to know where they are stored. Why it is needed? Because you want to use that location as volume in your docker container. And you don&amp;rsquo;t want to download the model everytime you start the container neither you want to have duplicate copy of the same model on your machine or network.&lt;/p&gt;</description>
    </item>
    <item>
      <title>State of the Art Image Generation Models in Computer Vision: A Comprehensive Overview</title>
      <link>http://localhost:1313/dsblog/state-of-the-art-image-generation-models-in-computer-vision/</link>
      <pubDate>Sun, 16 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/state-of-the-art-image-generation-models-in-computer-vision/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6219-State-of-the-Art-Computer-Vision-Models.jpg&#34; alt=&#34;State-of-the-Art 3D Image Generation Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;state-of-the-art-computer-vision-models&#34;&gt;State of the Art Computer Vision Models&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-are-the-different-methods-of-image-generation&#34;&gt;What are the different methods of Image generation?&lt;/h2&gt;&#xA;&lt;p&gt;There are several methods for image generation. Diffusion models are currently the  state-of-the-art  due to their balance of quality, flexibility, and scalability. However, other methods like GANs and autoregressive models remain relevant for specific use cases. Let&amp;rsquo;s see them one by one.&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-diffusion-models&#34;&gt;&lt;strong&gt;1. Diffusion Models&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Diffusion models are a class of generative models that work by gradually adding noise to data (e.g., images) and then learning to reverse this process to generate new data. Here&amp;rsquo;s how it works:&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Road to Bharat LLMs Goes Via Sanskrit</title>
      <link>http://localhost:1313/dsblog/the-road-to-bharat-llms-goes-via-sanskrit/</link>
      <pubDate>Fri, 14 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/the-road-to-bharat-llms-goes-via-sanskrit/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6218-The-Road-to-Bharat-LLMs-Goes-Via-Sanskrit.jpg&#34; alt=&#34;The Road to Bharat LLMs Goes Via Sanskrit&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;the-road-to-bharat-llms-goes-via-sanskrit&#34;&gt;&lt;strong&gt;The Road to Bharat LLMs Goes Via Sanskrit&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;The Case for Sanskrit as India’s AI Language&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-national-language-debate-and-its-impact-on-ai&#34;&gt;&lt;strong&gt;The National Language Debate and Its Impact on AI&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Since India&amp;rsquo;s independence, the debate over a national language has been intense. This issue becomes especially heated when considering the different regional perspectives, particularly in South India. For instance, Tamil Nadu politicians strongly believe that Tamil is their primary language, while Sanskrit is often seen as North Indian. At the time of independence, few would have predicted that 75 years later, we would be struggling to develop our own AI technology—partly due to not making Sanskrit the national language.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring the Energy Demand and Supply of India</title>
      <link>http://localhost:1313/dsblog/exploring-the-energy-demand-and-supply-of-india/</link>
      <pubDate>Mon, 10 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-the-energy-demand-and-supply-of-india/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6217-Exploring-the-Energy-Demand-and-Supply-of-India.jpg&#34; alt=&#34;Exploring the Energy Demand and Supply of India&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-the-energy-demand-and-supply-of-india&#34;&gt;Exploring the Energy Demand and Supply of India&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;When India talks about becoming a &lt;em&gt;Vishwa Guru&lt;/em&gt; (World Leader), &lt;em&gt;Vishwa Mitra&lt;/em&gt; (Friend of the World), the &lt;em&gt;Leader of the South&lt;/em&gt;, or an &lt;em&gt;AI Superpower&lt;/em&gt;, we must first understand our own electricity demand and supply. Without this understanding, these grand aspirations will remain mere words in the 21st century.&lt;/p&gt;&#xA;&lt;p&gt;I know energy experts are already discussing these issues, but those of us in AI development and semiconductor manufacturing also need to be on the same page. We cannot pursue narrow, isolated advancements without acknowledging our energy requirements. In this article, I aim to provoke my fellow data science community members in India to think critically about this issue—ask questions, analyze the situation, raise concerns in the right forums, and develop solutions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Demystifying NVIDIA GPUs</title>
      <link>http://localhost:1313/dsblog/demystify-nvidia-gpus/</link>
      <pubDate>Sun, 09 Feb 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/demystify-nvidia-gpus/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6216-Demystify-NVIDIA-GPUs.jpg&#34; alt=&#34;Demystifying NVIDIA GPUs&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;demystifying-nvidia-gpus&#34;&gt;Demystifying NVIDIA GPUs&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;NVIDIA has been in the GPU manufacturing business since 1993. They offer hundreds of different types of GPUs for various segments and purposes. For those not in the GPU infrastructure business, it can be confusing to understand even their naming conventions. In this article, I will do my best to help you understand the different types of NVIDIA GPUs and their naming conventions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Tokenization and Embedding in NLP</title>
      <link>http://localhost:1313/dsblog/exploring-tokenization-and-embedding-in-nlp/</link>
      <pubDate>Fri, 31 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-tokenization-and-embedding-in-nlp/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6215-Exploring-Tokenization-in-AI.jpg&#34; alt=&#34;Exploring Tokenization and Embedding in NLP&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-tokenization-and-embedding-in-nlp&#34;&gt;Exploring Tokenization and Embedding in NLP&lt;/h1&gt;&#xA;&lt;p&gt;Tokenization and embedding are key components of natural language processing (NLP) models. Sometimes people misunderstand tokenization and embedding and this article is to address those issues. This is in the question answer format and addressing following questions.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;What is tokenization?&lt;/li&gt;&#xA;&lt;li&gt;What are different Tokenzation schemes?&lt;/li&gt;&#xA;&lt;li&gt;What is OOV (Out-of-Vocabulary) in Tokenization?&lt;/li&gt;&#xA;&lt;li&gt;If a word does not exist in embedding model&amp;rsquo;s vocabulary, then how tokenization and embedding is done?&lt;/li&gt;&#xA;&lt;li&gt;What is criteria of splitting a word?&lt;/li&gt;&#xA;&lt;li&gt;What is Subword Tokenization?&lt;/li&gt;&#xA;&lt;li&gt;How FastText Tokenization works?&lt;/li&gt;&#xA;&lt;li&gt;What is role of [CLS] token?&lt;/li&gt;&#xA;&lt;li&gt;What is WordPiece and how it works?&lt;/li&gt;&#xA;&lt;li&gt;What is BPE (Byte Pair Encoding), and how it works?&lt;/li&gt;&#xA;&lt;li&gt;What is SentencePiece and how it works?&lt;/li&gt;&#xA;&lt;li&gt;For Indian languages what tokenization schemes is the best?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;what-is-tokenization&#34;&gt;What is tokenization?&lt;/h2&gt;&#xA;&lt;p&gt;Tokenization is the process of breaking text into smaller units (tokens), such as words, subwords, or characters, for NLP tasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Contextual Embedding in Transformers</title>
      <link>http://localhost:1313/dsblog/understanding-contextual-embedding-in-transformers/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-contextual-embedding-in-transformers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6214-Understanding-Contextual-Embedding-in-Transformer.jpg&#34; alt=&#34;Understanding Contextual Embedding in Transformers&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Embedding can be confusing for many people, and contextual embedding performed by transformers can be even more perplexing. Even after gaining an understanding, many questions remain. In this article, we aim to address the following questions.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is Embedding?&lt;/li&gt;&#xA;&lt;li&gt;What is Fixed Embedding?&lt;/li&gt;&#xA;&lt;li&gt;How Transformers Handle Context&lt;/li&gt;&#xA;&lt;li&gt;How this token &amp;lsquo;bank&amp;rsquo; and corresponding embedding is stored in embedding database?&lt;/li&gt;&#xA;&lt;li&gt;How contextural embedding is generated?&lt;/li&gt;&#xA;&lt;li&gt;What will be the output size of attention formula softmax?&lt;/li&gt;&#xA;&lt;li&gt;What is meaning of a LLM has context length of 2 million tokens?&lt;/li&gt;&#xA;&lt;li&gt;How many attention layers we keep in transformer like gpt4?&lt;/li&gt;&#xA;&lt;li&gt;What is the meaning of 96 attention layers, are they attention head count?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-is-embedding&#34;&gt;What is Embedding?&lt;/h2&gt;&#xA;&lt;p&gt;An embedding is a way to represent discrete data (like words or tokens) as continuous vectors of numbers.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding the Working of CNN</title>
      <link>http://localhost:1313/dsblog/understanding-working-of-cnn/</link>
      <pubDate>Wed, 29 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-working-of-cnn/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6213-Understanding-Working-of-CNN.jpg&#34; alt=&#34;Understanding the Working of CNN&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-the-working-of-cnn&#34;&gt;Understanding the Working of CNN&lt;/h1&gt;&#xA;&lt;p&gt;In this article, we aim to delve deeper into the working of CNNs. This article is intended for readers who have a basic understanding of CNNs and have computation-related questions. If you have any other questions about CNNs, feel free to ask in the comments.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Questions we are looking into.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is the meaning of convolution in neural network?&lt;/li&gt;&#xA;&lt;li&gt;If there is some convolution layer with 64 kernel (filter) and filter size is 3x3 then does the filter get updated during training process?&lt;/li&gt;&#xA;&lt;li&gt;I heard filters has only 0 and 1 value. Depending upon what we want to extract we use the pattern of 0 and 1 on the filter, like for edge detection, contras detection etc.&lt;/li&gt;&#xA;&lt;li&gt;If a layer with 64 filter has 3x3 filter then how many weights are there?&lt;/li&gt;&#xA;&lt;li&gt;There is very famous 1x1 filter. How many weights are there if it layer has 64 neuron? Why it is more effective?&lt;/li&gt;&#xA;&lt;li&gt;Normally we think channel means number of layer in input image (RGB color). How come we can have 256 channels in neural network?&lt;/li&gt;&#xA;&lt;li&gt;How to calculate output size of convolutional layer?&lt;/li&gt;&#xA;&lt;li&gt;When 3x3x3 filter is applied to 224x224x3 image then how it become 224x224?&lt;/li&gt;&#xA;&lt;li&gt;Earlier we discussed weight of each layer R, G, B is different? When and how these weights are decided?&lt;/li&gt;&#xA;&lt;li&gt;Where do we learn features? At the level of differet layers or different channels (filter)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-is-the-meaning-of-convolution-in-neural-network&#34;&gt;What is the meaning of convolution in neural network?&lt;/h2&gt;&#xA;&lt;p&gt;In the context of neural networks, specifically Convolutional Neural Networks (CNNs), &lt;em&gt;convolution&lt;/em&gt; refers to a mathematical operation that combines two functions (or datasets) to produce a third function, typically used to extract features from input data. In simple terms, it’s a way of applying a filter or kernel to an input (like an image) to create a feature map, which highlights important patterns or features such as edges, textures, or shapes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Power of Chinese AI Models</title>
      <link>http://localhost:1313/dsblog/power-of-chinese-ai-models/</link>
      <pubDate>Tue, 28 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/power-of-chinese-ai-models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6212-Power-of-Chinese-AI-Models.jpg&#34; alt=&#34;Power of Chinese AI Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;power-of-chinese-ai-models&#34;&gt;Power of Chinese AI Models&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;After the Deepseek R1 turmoil in the market, there has been a shift in attention towards China. The West is now looking towards the East, and even those in the East are turning their gaze northward.&lt;/p&gt;&#xA;&lt;p&gt;I was tracking these models for sometime so thought to summarize them at one place for my readers.&lt;/p&gt;&#xA;&lt;p&gt;Opensource: 🚀&lt;/p&gt;&#xA;&lt;p&gt;Partially or fully close source: 🔒&lt;/p&gt;</description>
    </item>
    <item>
      <title>Computer Vision Research Work</title>
      <link>http://localhost:1313/dsblog/computer-vision-research-work/</link>
      <pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/computer-vision-research-work/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6211-Computer-Vision-Research-Work.jpg&#34; alt=&#34;Computer Vision Research Work&amp;#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;computer-vision-research-work&#34;&gt;Computer Vision Research Work&lt;/h1&gt;&#xA;&lt;p&gt;When we talk about &amp;ldquo;vision&amp;rdquo; capabilities, most people don&amp;rsquo;t understand how complex the brain is in processing the visual spectrum (light signals). What kind of processing happens inside our brain that allows us to understand color, depth, motion, speed, segments, objects, scenes, different kinds of art, drawings, culture, etc.? Until recently, when &amp;ldquo;computer vision&amp;rdquo; became a serious field in AI, only neurology researchers, surgeons, and brain specialists had some insights into these processes. But since 2012 (AlexNet Paper), with new papers being published almost every month, we are constantly learning how far we&amp;rsquo;ve come in computer vision. This article is not only about the chronology of computer vision but also about software engineers, computer scientists, AI engineers, and everyone who wants to understand how their phone performs certain computer visions tasks and becomes intelligent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring AI Benchmarks &amp; Leaderboards</title>
      <link>http://localhost:1313/dsblog/exploring-ai-benchmarks-and-leaderboards/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-ai-benchmarks-and-leaderboards/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6210-Exploring-AI-Benchmarks-and-Leaderboards.jpg&#34; alt=&#34;Exploring AI Benchmarks &amp;amp; Leaderboards&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-ai-benchmarks--leaderboards&#34;&gt;Exploring AI Benchmarks &amp;amp; Leaderboards&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;benchmark&lt;/strong&gt; is a standardized test or set of metrics used to measure and compare the performance, capabilities, or quality of systems, models, or algorithms. In the context of &lt;strong&gt;AI and machine learning&lt;/strong&gt;, benchmarks provide a way to evaluate how well models perform on specific tasks or datasets, often with respect to predefined metrics like accuracy, speed, robustness, or resource efficiency.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Types of Models</title>
      <link>http://localhost:1313/dsblog/exploring-types-of-models/</link>
      <pubDate>Sat, 25 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-types-of-models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6209-Exploring-Types-of-Models.jpg&#34; alt=&#34;Exploring Types of Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-different-types-of-models&#34;&gt;Understanding Different Types of Models&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A model is a simplified representation or abstraction of a system, concept, or phenomenon around us. It is used to analyze, understand, predict, or simulate real-world behavior. Models can take many forms, depending on the context in which they are used. For example you also say that I have created a Data Model, Functional Model, UI Model, Simulation Model etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Callbacks</title>
      <link>http://localhost:1313/dsblog/understanding-callbacks/</link>
      <pubDate>Fri, 24 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-callbacks/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6208-Understanding-Callbacks.jpg&#34; alt=&#34;Understanding Callbacks&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-callbacks&#34;&gt;Understanding Callbacks&lt;/h1&gt;&#xA;&lt;p&gt;In the software solution design sometime people find callback confusing and this article is about helping developers and architects understanding this. We will discuss what is callback? What is the use of this? How it workds?&lt;/p&gt;&#xA;&lt;h2 id=&#34;context-setting-for-understanding-callbacks&#34;&gt;Context Setting for Understanding Callbacks&lt;/h2&gt;&#xA;&lt;p&gt;Assume you want to create a travel website. It has a feature of book ticket. For this you need to create frontend (UI page). But you don&amp;rsquo;t want to create ticket for any unauthorized person and you don&amp;rsquo;t want to implement the authentication and authorization on your website.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring AI Agents</title>
      <link>http://localhost:1313/dsblog/exploring-ai-agents/</link>
      <pubDate>Thu, 23 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-ai-agents/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6207-Exploring-AI-Agents.jpg&#34; alt=&#34;Exploring AI Agents&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-ai-agents&#34;&gt;Exploring AI Agents&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;As of the start of 2025, we are hearing a lot of buzz around Agents, Workflow, System, AI Employee etc. In this article, we are trying to understand some important concepts around these terms in question answer format. These answers are derived from general AI knowledge, principles, and concepts based on publicly available information about AI agents, workflows, and systems. Specific sources include academic literature, industry whitepapers, and commonly understood practices in AI development and usage.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Product Ideas 2025</title>
      <link>http://localhost:1313/dsblog/AI-Product-Ideas-2025/</link>
      <pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Product-Ideas-2025/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6206-AI-Product-Ideas.jpg&#34; alt=&#34;AI Product Ideas 2025&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-product-ideas&#34;&gt;AI Product Ideas&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;There is a flood of AI products in the market, yet some people are still searching for ideas to get started. The following list of ideas can serve as a good starting point for beginners, and even if you are already established, you may find some of these ideas inspiring.&lt;/p&gt;&#xA;&lt;p&gt;Many of these ideas are available either as features of larger products or as standalone solutions. For example, they may exist as features in generic products like Google Drive, OneDrive, Outlook, or Office 365, or as part of domain-specific products such as Pharma Research tools, Banking CRMs, Loan Processing systems, or Project Requirement Management platforms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI ML Project Ideas</title>
      <link>http://localhost:1313/dsblog/AI-Project-Ideas/</link>
      <pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Project-Ideas/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6205-AI-Project-Ideas.jpg&#34; alt=&#34;AI Project Ideas&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-project-ideas&#34;&gt;AI Project Ideas&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In your journey of learning and practicing AI project you may find these articles and repositories useful. I found it over many places and compiled them here. Some of the link may break. These are beginner level ideas for AI project. If you are starting your journey then you will find value in exploring these. If you have been seriously for more than 5+ years in AI/ML then your can ignore this article.&lt;/p&gt;</description>
    </item>
    <item>
      <title>WhatsApp Integration: Webhooks, Messaging, and Architecture Design</title>
      <link>http://localhost:1313/dsblog/Whatsapp-Integration/</link>
      <pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Whatsapp-Integration/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6204-Whatsapp-Integration.jpg&#34; alt=&#34;WhatsApp Integration&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;whatsapp-integration-webhooks-messaging-and-architecture-design&#34;&gt;WhatsApp Integration: Webhooks, Messaging, and Architecture Design&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;When evaluating WhatsApp integrators, it’s crucial to assess their capabilities based on your business requirements, technical constraints, and operational goals. Here are key questions to ask yourself to assess their suitability:&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-compliance-and-authorization&#34;&gt;&lt;strong&gt;1. Compliance and Authorization&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is the integrator officially approved by WhatsApp as a &lt;strong&gt;Business Solution Provider (BSP)&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;li&gt;Do they comply with &lt;strong&gt;GDPR&lt;/strong&gt;, &lt;strong&gt;CCPA&lt;/strong&gt;, or other relevant data protection regulations?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-messaging-capabilities&#34;&gt;&lt;strong&gt;2. Messaging Capabilities&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can they handle &lt;strong&gt;template messages&lt;/strong&gt; (pre-approved by WhatsApp) and &lt;strong&gt;session messages&lt;/strong&gt; (free-form within 24 hours)?&lt;/li&gt;&#xA;&lt;li&gt;Do they support &lt;strong&gt;rich media messages&lt;/strong&gt; (images, videos, documents, etc.)?&lt;/li&gt;&#xA;&lt;li&gt;Can they facilitate &lt;strong&gt;two-way messaging&lt;/strong&gt; for customer support and engagement?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-integration-and-automation&#34;&gt;&lt;strong&gt;3. Integration and Automation&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Does the integrator support &lt;strong&gt;CRM&lt;/strong&gt; or &lt;strong&gt;third-party system integration&lt;/strong&gt; (e.g., Salesforce, Zendesk, HubSpot)?&lt;/li&gt;&#xA;&lt;li&gt;Do they offer &lt;strong&gt;automation tools&lt;/strong&gt; such as chatbots, autoresponders, or AI-driven support?&lt;/li&gt;&#xA;&lt;li&gt;Are there pre-built integrations for &lt;strong&gt;e-commerce platforms&lt;/strong&gt; (e.g., Shopify, WooCommerce)?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-scalability&#34;&gt;&lt;strong&gt;4. Scalability&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can the integrator handle &lt;strong&gt;high volumes of messages&lt;/strong&gt; during peak periods?&lt;/li&gt;&#xA;&lt;li&gt;Is it suitable for &lt;strong&gt;global operations&lt;/strong&gt; with multi-language support?&lt;/li&gt;&#xA;&lt;li&gt;Do they offer &lt;strong&gt;multi-agent support&lt;/strong&gt; for handling multiple conversations simultaneously?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-analytics-and-insights&#34;&gt;&lt;strong&gt;5. Analytics and Insights&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Do they provide &lt;strong&gt;real-time analytics&lt;/strong&gt; for message delivery, open rates, response times, etc.?&lt;/li&gt;&#xA;&lt;li&gt;Are there features for &lt;strong&gt;customer segmentation&lt;/strong&gt; or tracking user behavior?&lt;/li&gt;&#xA;&lt;li&gt;Can the data be exported or integrated into a &lt;strong&gt;data warehouse&lt;/strong&gt; for further analysis?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-customization-and-branding&#34;&gt;&lt;strong&gt;6. Customization and Branding&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Do they allow customization of the &lt;strong&gt;WhatsApp Business Profile&lt;/strong&gt; (e.g., logo, description, contact details)?&lt;/li&gt;&#xA;&lt;li&gt;Can they tailor messaging templates for specific campaigns or user needs?&lt;/li&gt;&#xA;&lt;li&gt;Is it possible to implement &lt;strong&gt;personalized messaging&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-pricing-and-cost-structure&#34;&gt;&lt;strong&gt;7. Pricing and Cost Structure&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is their &lt;strong&gt;pricing model&lt;/strong&gt; (pay-per-message, monthly subscription, or hybrid)?&lt;/li&gt;&#xA;&lt;li&gt;Are there additional charges for certain features (e.g., rich media, API access)?&lt;/li&gt;&#xA;&lt;li&gt;Are they transparent about WhatsApp&amp;rsquo;s &lt;strong&gt;conversation-based pricing&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-security-and-data-management&#34;&gt;&lt;strong&gt;8. Security and Data Management&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How do they ensure &lt;strong&gt;end-to-end encryption&lt;/strong&gt; for all messages?&lt;/li&gt;&#xA;&lt;li&gt;Where is the &lt;strong&gt;data hosted&lt;/strong&gt;, and can it meet your regional compliance requirements?&lt;/li&gt;&#xA;&lt;li&gt;Do they provide &lt;strong&gt;audit logs&lt;/strong&gt; for message tracking and security purposes?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-user-experience&#34;&gt;&lt;strong&gt;9. User Experience&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is their platform/interface &lt;strong&gt;user-friendly&lt;/strong&gt; for your team?&lt;/li&gt;&#xA;&lt;li&gt;Do they offer an &lt;strong&gt;omnichannel dashboard&lt;/strong&gt; for handling WhatsApp alongside other channels (e.g., email, SMS)?&lt;/li&gt;&#xA;&lt;li&gt;Are there &lt;strong&gt;mobile and desktop apps&lt;/strong&gt; for managing interactions on the go?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-support-and-reliability&#34;&gt;&lt;strong&gt;10. Support and Reliability&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Do they offer &lt;strong&gt;24/7 support&lt;/strong&gt;, and is it available via chat, phone, or email?&lt;/li&gt;&#xA;&lt;li&gt;What is their &lt;strong&gt;uptime SLA&lt;/strong&gt;, and how do they handle outages?&lt;/li&gt;&#xA;&lt;li&gt;Are there case studies or testimonials demonstrating their reliability?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-future-readiness&#34;&gt;&lt;strong&gt;11. Future-Readiness&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Are they innovating with &lt;strong&gt;AI-driven tools&lt;/strong&gt; (e.g., conversational AI, sentiment analysis)?&lt;/li&gt;&#xA;&lt;li&gt;Do they actively incorporate WhatsApp&amp;rsquo;s &lt;strong&gt;new features and updates&lt;/strong&gt; into their offerings?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-trial-and-onboarding&#34;&gt;&lt;strong&gt;12. Trial and Onboarding&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Do they offer a &lt;strong&gt;free trial&lt;/strong&gt; or pilot program to test the system?&lt;/li&gt;&#xA;&lt;li&gt;How long does it take to fully onboard and integrate the solution into your existing infrastructure?&lt;/li&gt;&#xA;&lt;li&gt;Do they provide training or onboarding materials for your team?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;13-api-and-developer-support&#34;&gt;&lt;strong&gt;13. API and Developer Support&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Is the WhatsApp API provided by the integrator &lt;strong&gt;well-documented&lt;/strong&gt; and easy to use?&lt;/li&gt;&#xA;&lt;li&gt;Do they support &lt;strong&gt;webhooks&lt;/strong&gt; for real-time event notifications?&lt;/li&gt;&#xA;&lt;li&gt;Is there a &lt;strong&gt;sandbox environment&lt;/strong&gt; for testing integrations before going live?&lt;/li&gt;&#xA;&lt;li&gt;Do they provide &lt;strong&gt;SDKs&lt;/strong&gt; or libraries for common programming languages?&lt;/li&gt;&#xA;&lt;li&gt;Is their API scalable to meet growing messaging needs?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;14-workflow-management&#34;&gt;&lt;strong&gt;14. Workflow Management&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Does the integrator support &lt;strong&gt;workflow automation&lt;/strong&gt; for message routing and escalation?&lt;/li&gt;&#xA;&lt;li&gt;Can it handle &lt;strong&gt;conditional logic&lt;/strong&gt; (e.g., sending different messages based on customer responses)?&lt;/li&gt;&#xA;&lt;li&gt;Is there an option to integrate &lt;strong&gt;Human-in-the-Loop (HITL)&lt;/strong&gt; for cases where a chatbot cannot resolve issues?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;15-multichannel-and-omnichannel-features&#34;&gt;&lt;strong&gt;15. Multichannel and Omnichannel Features&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can the integrator consolidate WhatsApp with other &lt;strong&gt;customer communication channels&lt;/strong&gt; (e.g., email, social media, SMS)?&lt;/li&gt;&#xA;&lt;li&gt;Do they offer a unified &lt;strong&gt;customer interaction history&lt;/strong&gt; across channels?&lt;/li&gt;&#xA;&lt;li&gt;Can customers be seamlessly transitioned between WhatsApp and other channels?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;16-regional-and-regulatory-adaptability&#34;&gt;&lt;strong&gt;16. Regional and Regulatory Adaptability&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Can the integrator manage &lt;strong&gt;local compliance requirements&lt;/strong&gt; in different countries (e.g., India, EU)?&lt;/li&gt;&#xA;&lt;li&gt;Do they offer &lt;strong&gt;localized solutions&lt;/strong&gt; such as language translations or cultural nuances in templates?&lt;/li&gt;&#xA;&lt;li&gt;Can they handle &lt;strong&gt;country-specific limitations&lt;/strong&gt;, like message restrictions or telecom regulations?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;17-customer-success-and-partnerships&#34;&gt;&lt;strong&gt;17. Customer Success and Partnerships&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Do they offer a &lt;strong&gt;dedicated account manager&lt;/strong&gt; to assist with strategy and troubleshooting?&lt;/li&gt;&#xA;&lt;li&gt;Do they have strong partnerships with relevant platforms (e.g., WhatsApp, Meta, and CRM providers)?&lt;/li&gt;&#xA;&lt;li&gt;Are they proactive in helping you improve &lt;strong&gt;campaign performance&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;18-performance-and-reliability&#34;&gt;&lt;strong&gt;18. Performance and Reliability&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How does their system ensure &lt;strong&gt;low message latency&lt;/strong&gt; during high-traffic times?&lt;/li&gt;&#xA;&lt;li&gt;What backup and recovery measures are in place for &lt;strong&gt;system outages&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;li&gt;Do they offer performance guarantees, like &lt;strong&gt;delivery success rate SLAs&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;19-advanced-features&#34;&gt;&lt;strong&gt;19. Advanced Features&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Do they support advanced use cases like:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Interactive messages&lt;/strong&gt; with call-to-action (CTA) buttons or reply buttons?&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Payment integration&lt;/strong&gt; within WhatsApp?&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Proactive notifications&lt;/strong&gt; for order updates, reminders, or personalized recommendations?&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;AI-based sentiment analysis&lt;/strong&gt; or tone detection?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;20-migration-and-vendor-lock-in&#34;&gt;&lt;strong&gt;20. Migration and Vendor Lock-In&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How easy is it to migrate to a different integrator if needed?&lt;/li&gt;&#xA;&lt;li&gt;Does the integrator use &lt;strong&gt;standardized APIs&lt;/strong&gt; or proprietary systems that could create vendor lock-in?&lt;/li&gt;&#xA;&lt;li&gt;Can you &lt;strong&gt;own and export customer data&lt;/strong&gt; easily without restrictions?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;21-compliance-with-whatsapp-policies&#34;&gt;&lt;strong&gt;21. Compliance with WhatsApp Policies&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Does the integrator help with managing and submitting &lt;strong&gt;template approvals&lt;/strong&gt; to WhatsApp?&lt;/li&gt;&#xA;&lt;li&gt;Do they have safeguards to ensure compliance with WhatsApp&amp;rsquo;s &lt;strong&gt;anti-spam&lt;/strong&gt; and &lt;strong&gt;opt-in policies&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;li&gt;Do they support building and maintaining &lt;strong&gt;subscriber lists&lt;/strong&gt; with proper opt-in mechanisms?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;22-industry-specific-features&#34;&gt;&lt;strong&gt;22. Industry-Specific Features&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Does the integrator offer industry-specific solutions (e.g., e-commerce, healthcare, education)?&lt;/li&gt;&#xA;&lt;li&gt;Can they handle &lt;strong&gt;use-case-specific templates&lt;/strong&gt; (e.g., transactional messages, appointment reminders)?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;23-post-implementation-support&#34;&gt;&lt;strong&gt;23. Post-Implementation Support&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is the &lt;strong&gt;response time&lt;/strong&gt; for resolving issues?&lt;/li&gt;&#xA;&lt;li&gt;Do they offer &lt;strong&gt;ongoing maintenance, updates, and new feature rollouts&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;li&gt;Is there a &lt;strong&gt;customer success team&lt;/strong&gt; to help optimize campaigns over time?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;24-long-term-roi&#34;&gt;&lt;strong&gt;24. Long-Term ROI&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How does the integrator help you measure &lt;strong&gt;return on investment (ROI)&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;li&gt;Can they demonstrate case studies or examples of how similar businesses benefited from their solution?&lt;/li&gt;&#xA;&lt;li&gt;Do they provide tools to measure &lt;strong&gt;customer engagement&lt;/strong&gt; and improve conversion rates?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;25-competitor-benchmarking&#34;&gt;&lt;strong&gt;25. Competitor Benchmarking&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How does this integrator compare to competitors in terms of &lt;strong&gt;features, pricing, and support&lt;/strong&gt;?&lt;/li&gt;&#xA;&lt;li&gt;Are there &lt;strong&gt;independent reviews&lt;/strong&gt; or customer testimonials available?&lt;/li&gt;&#xA;&lt;li&gt;Can they demonstrate a &lt;strong&gt;competitive edge&lt;/strong&gt; (e.g., exclusive partnerships, unique features)?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;p&gt;By answering these questions, you’ll be able to identify an integrator that aligns with your business needs, ensures seamless communication, and delivers long-term value.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unraveling Wireless Communication: Key Protocols and Technologies</title>
      <link>http://localhost:1313/dsblog/unraveling-wireless-communication/</link>
      <pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/unraveling-wireless-communication/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6203-Unraveling-Wireless-Communication.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;unraveling-wireless-communication&#34;&gt;Unraveling Wireless Communication&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Wireless communication is at the heart of modern connectivity. In this article, we explore key aspects of wireless technology, including GSM protocols, Wi-Fi, call security, bandwidth allocation, and maintaining connections in challenging environments.&amp;quot;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-are-different-communication-protocols&#34;&gt;What are different communication protocols?&lt;/h2&gt;&#xA;&lt;p&gt;Here’s a simple list of communication protocols with their purposes:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;HTTP/HTTPS&lt;/strong&gt;: Enables client-server communication for web browsing and data exchange securely (HTTPS).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;FTP/SFTP&lt;/strong&gt;: Transfers files between a client and server securely (SFTP for secure file transfer).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SMTP&lt;/strong&gt;: Sends emails from a client to a mail server.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;IMAP/POP3&lt;/strong&gt;: Retrieves emails from a mail server (IMAP for synchronization, POP3 for download).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;WebSocket&lt;/strong&gt;: Provides real-time, full-duplex communication between client and server.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;MQTT&lt;/strong&gt;: Lightweight protocol for sending messages between devices in IoT and messaging systems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;CoAP&lt;/strong&gt;: Designed for constrained devices and IoT for resource interaction over a network.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;AMQP&lt;/strong&gt;: Manages and routes messages in distributed systems (used in message brokers).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;UDP&lt;/strong&gt;: Facilitates fast, connectionless communication for real-time data like video and voice.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;TCP&lt;/strong&gt;: Ensures reliable, connection-oriented data transmission between devices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;IP&lt;/strong&gt;: Routes packets across networks using unique IP addresses.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RTP&lt;/strong&gt;: Transfers real-time audio and video streams over IP networks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SIP&lt;/strong&gt;: Establishes, maintains, and terminates multimedia communication sessions (e.g., VoIP).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SNMP&lt;/strong&gt;: Manages and monitors network devices like routers and switches.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DNS&lt;/strong&gt;: Resolves human-readable domain names into IP addresses.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;DHCP&lt;/strong&gt;: Assigns IP addresses dynamically to devices on a network.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;SSH&lt;/strong&gt;: Provides secure remote access and command execution over a network.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Bluetooth&lt;/strong&gt;: Enables short-range wireless communication between devices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Zigbee&lt;/strong&gt;: Facilitates low-power, short-range wireless communication for IoT devices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NFC&lt;/strong&gt;: Allows close-proximity communication for data transfer and payments.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;CAN&lt;/strong&gt;: Communicates between devices in embedded systems (e.g., automotive systems).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;I²C&lt;/strong&gt;: Facilitates communication between integrated circuits in electronic devices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Modbus&lt;/strong&gt;: Used in industrial systems for communicating between devices like PLCs and sensors.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ethernet&lt;/strong&gt;: Provides wired, high-speed data transfer in LANs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Wi-Fi&lt;/strong&gt;: Enables wireless networking and internet access.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;GSM/3G/4G/5G&lt;/strong&gt;: Provides cellular network communication for voice, SMS, and internet.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;what-are-different-types-of-communications-and-protocol-used-for-those&#34;&gt;What are different types of communications and protocol used for those?&lt;/h2&gt;&#xA;&lt;p&gt;Here’s a table summarizing different types of communication protocols and corresponding messages in a simplified format:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Adapting AI Models to the Latest Information: Methods and Approaches</title>
      <link>http://localhost:1313/dsblog/adapting-ai-models-to-the-latest-information/</link>
      <pubDate>Fri, 17 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/adapting-ai-models-to-the-latest-information/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6202-Adapting-AI-Models-to-the-Latest-Information.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;adapting-ai-models-to-the-latest-information-methods-and-approaches&#34;&gt;Adapting AI Models to the Latest Information: Methods and Approaches&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Artificial Intelligence offers numerous advantages over traditional search engines like Google or Bing, but it also has a notable limitation: its knowledge is often frozen in the past. Unless a model is retrained or updated with newly available data, it cannot respond effectively to current business, political, social, or scientific developments.&lt;/p&gt;&#xA;&lt;p&gt;To address this limitation, one popular approach is &lt;strong&gt;Retrieval-Augmented Generation (RAG)&lt;/strong&gt;, a method that combines AI models with up-to-date external data sources. You may have come across RAG frequently in recent discussions about AI advancements.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Make.com: A Comprehensive Guide to Automation and Its Alternatives</title>
      <link>http://localhost:1313/dsblog/exploring-make-com-a-comprehensive-guide/</link>
      <pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-make-com-a-comprehensive-guide/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6200-Exploring-Make-com-A-Comprehensive-Guide.jpg&#34; alt=&#34;Exploring Make.com - A Comprehensive Guide to Automation and Its Alternatives&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-makecom---a-comprehensive-guide-to-automation-and-its-alternatives&#34;&gt;Exploring Make.com - A Comprehensive Guide to Automation and Its Alternatives&lt;/h1&gt;&#xA;&lt;p&gt;Make.com is an automation platform that allows users to create custom workflows between various apps and services. With its intuitive interface and powerful automation capabilities, Make.com is an excellent choice for automating tasks, streamlining processes, and increasing productivity. In this guide, we&amp;rsquo;ll explore the features and capabilities of Make.com and discuss its alternatives for automation and integration. Whether you&amp;rsquo;re a business owner, developer, or simply someone looking to automate tasks, this guide will provide you with a comprehensive overview of Make.com and its competitors.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Navigating Open-Source Licensing in the Age of AI: Challenges and Considerations</title>
      <link>http://localhost:1313/dsblog/navigating-open-source-licensing-in-the-age-of-ai/</link>
      <pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/navigating-open-source-licensing-in-the-age-of-ai/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6201-Navigating-Open-Source-Licensing-in-the-Age-of-AI.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;navigating-open-source-licensing-in-the-age-of-ai-challenges-and-considerations&#34;&gt;Navigating Open-Source Licensing in the Age of AI: Challenges and Considerations&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Software products, at their core, are solutions designed to address specific problems. Just as there are many ways to solve a problem in life, there are numerous ways to design software to tackle the same issue. In software development, you don’t always have to reinvent the wheel—open-source code and third-party APIs provide a wealth of solutions that can be integrated into your project. These resources, developed by various organizations, teams, and individuals over time, can range from generic solutions to highly specialized ones. However, integrating them into your product requires careful thought and consideration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rethinking AI Infrastructure: Advantages of On-Prem Over Cloud Solutions</title>
      <link>http://localhost:1313/dsblog/cloud-vs-on-premse-ai-solutions-and-infrastructures/</link>
      <pubDate>Wed, 08 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/cloud-vs-on-premse-ai-solutions-and-infrastructures/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6199-Rethinking-AI-Infrastructure-Advantages-of-On-Prem-Over-Cloud-Solutions.jpg&#34; alt=&#34;Cloud vs On-Premse AI Solutions and Infrastructures&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;rethinking-ai-infrastructure-advantages-of-on-prem-over-cloud-solutions&#34;&gt;Rethinking AI Infrastructure: Advantages of On-Prem Over Cloud Solutions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;why-not-to-use-cloud-ai-solutions&#34;&gt;Why Not to Use Cloud AI Solutions?&lt;/h2&gt;&#xA;&lt;p&gt;There are valid reasons for considering alternatives to cloud-based infrastructure when developing AI products or working with sensitive organizational data. Here are some key factors:&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-data-privacy-and-security&#34;&gt;&lt;strong&gt;1. Data Privacy and Security&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Risk of Data Breach:&lt;/strong&gt; Sensitive organizational data stored in the cloud is at risk of breaches or unauthorized access, either by malicious actors or the cloud provider.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Compliance Concerns:&lt;/strong&gt; Many industries (e.g., healthcare, finance) are subject to strict regulations like GDPR, HIPAA, or CCPA that dictate how and where data can be stored or processed. Cloud providers may not guarantee compliance.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Shared Responsibility:&lt;/strong&gt; Even with cloud services, security is often a shared responsibility between the provider and the user, leaving gaps for vulnerabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-dependency-on-third-party-providers&#34;&gt;&lt;strong&gt;2. Dependency on Third-Party Providers&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Vendor Lock-In:&lt;/strong&gt; Relying on a specific cloud provider can make it difficult to migrate your infrastructure to another platform, potentially limiting flexibility and increasing costs over time.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Unpredictable Costs:&lt;/strong&gt; Cloud costs can escalate unpredictably, especially for AI workloads that require significant compute resources.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Service Outages:&lt;/strong&gt; Downtime or service interruptions by the cloud provider can directly impact your operations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;3-latency-and-performance-issues&#34;&gt;&lt;strong&gt;3. Latency and Performance Issues&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Network Latency:&lt;/strong&gt; AI applications that require real-time processing (e.g., autonomous systems or predictive maintenance) may face delays due to data transmission to and from the cloud.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Resource Bottlenecks:&lt;/strong&gt; Shared cloud resources might not always guarantee the performance needed for compute-intensive AI workloads.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;4-cost-concerns&#34;&gt;&lt;strong&gt;4. Cost Concerns&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Recurring Costs:&lt;/strong&gt; Cloud-based infrastructure involves ongoing costs for compute, storage, and data transfer, which can become expensive for large-scale AI projects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scaling Costs:&lt;/strong&gt; Scaling up AI models and datasets often incurs higher expenses in the cloud compared to owning on-premises infrastructure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;5-intellectual-property-risks&#34;&gt;&lt;strong&gt;5. Intellectual Property Risks&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Risk of Data Misuse:&lt;/strong&gt; Using third-party AI services could expose your organization’s proprietary data, which might be used to improve the provider’s own AI models without explicit consent.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Loss of Competitive Advantage:&lt;/strong&gt; Storing strategic data externally may give competitors indirect access if they also use the same cloud provider.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;6-ethical-and-operational-independence&#34;&gt;&lt;strong&gt;6. Ethical and Operational Independence&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Regulatory Restrictions:&lt;/strong&gt; Some countries restrict the use of foreign cloud providers for sensitive data, especially in government and defense sectors.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Control Over AI Models:&lt;/strong&gt; Running AI models on your own infrastructure allows greater control over training, inference, and updates, ensuring alignment with organizational goals.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;alternatives&#34;&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;On-Premises Infrastructure:&lt;/strong&gt; Use on-prem servers with GPU/TPU clusters for sensitive or high-performance workloads.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hybrid Approach:&lt;/strong&gt; Combine on-premises and cloud infrastructure to balance cost, performance, and data security.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Edge Computing:&lt;/strong&gt; Process data locally on devices to minimize latency and keep sensitive information secure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;how-to-create-on-premises-infrastructure-for-building-ai-products&#34;&gt;How to create On Premises Infrastructure for Building AI Products&lt;/h2&gt;&#xA;&lt;p&gt;Local or on-premises solutions for developing AI products and using AI with your data provide more control, privacy, and customization options. Here&amp;rsquo;s a breakdown of the key categories and tools/solutions for such setups:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Shaping Tomorrow with AI: Nvidia’s Innovations in Graphics, Robotics, and Intelligence</title>
      <link>http://localhost:1313/dsblog/shaping-tomorrow-with-ai-nvidia/</link>
      <pubDate>Tue, 07 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/shaping-tomorrow-with-ai-nvidia/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6198-shaping-tomorrow-with-ai-nvidia.jpg&#34; alt=&#34;Shaping Tomorrow with AI: Nvidia’s Innovations in Graphics, Robotics, and Intelligence&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;shaping-tomorrow-with-ai-nvidias-innovations-in-graphics-robotics-and-intelligence&#34;&gt;Shaping Tomorrow with AI: Nvidia’s Innovations in Graphics, Robotics, and Intelligence&lt;/h1&gt;&#xA;&lt;p&gt;This article is based on various online resources, including articles and YouTube videos, but is heavily influenced by the NVIDIA CES 2025 Keynote Speech by Jensen Huang.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-are-tokens-in-ai-and-how-do-they-serve-as-building-blocks-of-intelligence&#34;&gt;&lt;strong&gt;What are tokens in AI, and how do they serve as building blocks of intelligence?&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;In AI, tokens are fundamental units like words or characters that models process to understand and generate human language, serving as the building blocks of intelligence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Predictions for 2025</title>
      <link>http://localhost:1313/dsblog/ai-predictions-for-2025/</link>
      <pubDate>Fri, 03 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ai-predictions-for-2025/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6197-Major-AI-Predictions-for-2025.jpg&#34; alt=&#34;AI Predictions for 2025&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;major-ai-predictions-for-2025&#34;&gt;&lt;strong&gt;Major AI Predictions for 2025&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;h2 id=&#34;listen-summary-of-this-in-podcast-format&#34;&gt;Listen Summary of this in Podcast Format&lt;/h2&gt;&#xA;&lt;audio controls&gt;&#xD;&#xA;  &lt;source src=&#34;https://raw.githubusercontent.com/dasarpai/DAI-mp3/main/Transcripts-2-Audio/AI-Predictions-2025.wav&#34; type=&#34;audio/wav&#34;&gt;&#xD;&#xA;  Your browser does not support the audio element.&#xD;&#xA;&lt;/audio&gt;&#xD;&#xA;&lt;h2 id=&#34;ai-predictions-for-2025&#34;&gt;AI Predictions for 2025&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-ai-agents-and-autonomous-tools&#34;&gt;&lt;strong&gt;1. AI Agents and Autonomous Tools&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI agents will become ubiquitous, capable of autonomously performing tasks like booking flights, scheduling meetings, or managing workflows. The term &amp;ldquo;agentic&amp;rdquo; will become commonplace.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-ai-integration-in-everyday-life&#34;&gt;&lt;strong&gt;2. AI Integration in Everyday Life&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI technology will be embedded into household appliances (e.g., refrigerators, ovens, and laundry machines) and wearables (e.g., sunglasses, earbuds) for enhanced functionality. Human and appliances will be able to talk with each other.&lt;/li&gt;&#xA;&lt;li&gt;Generative AI characters will be introduced on social media platforms for engagement and interaction. These characters will adopt different styles and personalities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-growth-in-ai-wearables&#34;&gt;&lt;strong&gt;3. Growth in AI Wearables&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Smart wearables like heads-up display glasses and earbuds offering real-time translation will gain popularity.&lt;/li&gt;&#xA;&lt;li&gt;You will be able to learn language easily while talking with your wearables.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-video-models-and-content-creation&#34;&gt;&lt;strong&gt;4. Video Models and Content Creation&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI video generation models will advance to the point where AI-generated videos become indistinguishable from real ones, potentially passing the &amp;ldquo;Visual Turing Test.&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;AI tools for converting long-form videos into short clips will make content creation easier for creators.&lt;/li&gt;&#xA;&lt;li&gt;AI will also play a covert or overt role in movie production, possibly resulting in AI-created movies becoming a trend.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-ai-in-entertainment-and-gaming&#34;&gt;&lt;strong&gt;5. AI in Entertainment and Gaming&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI-driven entertainment robots and video content will grow, enabling creators to produce work faster.&lt;/li&gt;&#xA;&lt;li&gt;Gaming technology advancements will include dynamic resolution upscaling through deep learning super sampling (DLSS). It uses deep learning algorithms to upscale lower-resolution images to higher resolutions, enhancing the visual quality of games without significantly impacting performance. This allows for higher graphical settings and smoother frame rates, making games look better and run more efficiently&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-self-driving-and-autonomous-vehicles&#34;&gt;&lt;strong&gt;6. Self-Driving and Autonomous Vehicles&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Significant developments in self-driving technology, with advancements from companies like Tesla, Waymo (google), and Lyft (Amazon). Tesla might achieve unsupervised full self-driving capabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-quantum-computing-progress&#34;&gt;&lt;strong&gt;7. Quantum Computing Progress&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Breakthroughs in quantum computing with new chips from Google and IBM.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-ai-in-workspaces-and-business&#34;&gt;&lt;strong&gt;8. AI in Workspaces and Business&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI integration into workspaces for streamlined operations and minimal supervision.&lt;/li&gt;&#xA;&lt;li&gt;Businesses will increasingly rely on AI for operational efficiency and innovation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-challenges-of-ai-generated-content&#34;&gt;&lt;strong&gt;9. Challenges of AI-Generated Content&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Proliferation of low-quality, AI-generated content flooding platforms (termed &amp;ldquo;AI slop&amp;rdquo;), leading to potential SEO penalties and a need for better content regulation.&lt;/li&gt;&#xA;&lt;li&gt;SEO business will be completely revamped&lt;/li&gt;&#xA;&lt;li&gt;Ethical challenges in discerning AI-generated content from real content will drive the need for verification systems.&lt;/li&gt;&#xA;&lt;li&gt;People will become less reactive to even real videos/audio/content, because of the flood of AI-generated content.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-ai-ethics-regulation-and-identity-verification&#34;&gt;&lt;strong&gt;10. AI Ethics, Regulation, and Identity Verification&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Growing discussions on ethics and regulations around AI, particularly with the emergence of personal AI assistants and concerns over privacy and bias.&lt;/li&gt;&#xA;&lt;li&gt;Blockchain-based &amp;ldquo;proof of personhood&amp;rdquo; solutions to verify identities in the face of AI advancements. This year Blockchain will enter into the mainstream along with AI app development.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-hybrid-creativity&#34;&gt;&lt;strong&gt;11. Hybrid Creativity&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI will evolve as a creative partner in art, music, and content creation, enabling &amp;ldquo;hybrid creativity&amp;rdquo; between humans and machines.&lt;/li&gt;&#xA;&lt;li&gt;To create content whatever technology and tools you need, you can use those easily with AI copilots and AI assistants.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-extended-reality-xr&#34;&gt;&lt;strong&gt;12. Extended Reality (XR)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;XR technologies will become mainstream, particularly through compact, user-friendly devices like AI-powered glasses.&lt;/li&gt;&#xA;&lt;li&gt;AI will enter into the realm of virtual reality (VR) and augmented reality (AR) to provide immersive experiences.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;13-regenerative-medicine&#34;&gt;&lt;strong&gt;13. Regenerative Medicine&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI-driven advancements in regenerative medicine, although progress might be slowed by legal and ethical challenges.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;14-customizable-social-media-algorithms&#34;&gt;&lt;strong&gt;14. Customizable Social Media Algorithms&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Social media platforms may offer users the ability to fine-tune their algorithms for a personalized experience.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;15-ai-compute-and-applications&#34;&gt;&lt;strong&gt;15. AI Compute and Applications&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPU power will increase more and they will become cheaper and widely available for local AI workloads.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;16-ai-in-programming&#34;&gt;&lt;strong&gt;16. AI in Programming&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;AI will be commonly used for product development, architecture, UML, code completion, code refactoring, debugging, and testing. So, the cost and time of development will reduce and quality will improve.&lt;/li&gt;&#xA;&lt;li&gt;AI written code will selfheal if it is failing, improve for performance and security.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;related-readings&#34;&gt;Related Readings&lt;/h2&gt;&#xA;&lt;p&gt;My 2020, article on &lt;a href=&#34;http://localhost:1313/dsblog/100&amp;#43;High-Level-AI-Usecases&#34;&gt;100+ AI Usecase - Future Predictions for AI&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Complete Ecosystem of Software Development</title>
      <link>http://localhost:1313/dsblog/the-complete-ecosystem-of-software-development/</link>
      <pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/the-complete-ecosystem-of-software-development/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6196-the-complete-ecosystem-of-software-development.jpg&#34; alt=&#34;The Complete Ecosystem of Software Development&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;the-complete-ecosystem-of-software-development&#34;&gt;The Complete Ecosystem of Software Development&lt;/h1&gt;&#xA;&lt;p&gt;Software processes are a fascinating area because they encapsulate not just the technical aspects but also the collaborative, creative, and even philosophical dimensions of how we build and deliver software. The discussion touches on everything from the foundational coding practices to advanced topics like sustainability, emerging technologies, and human dynamics within development teams. The list of processes, subprocesses, and tools makes sense for those who have been in the software development and maintenance business for quite some time. Even with decades of experience, you will find this list interesting to read, showing how far we have come from the early 80&amp;rsquo;s or 90&amp;rsquo;s software development.&lt;/p&gt;</description>
    </item>
    <item>
      <title>curl Commands</title>
      <link>http://localhost:1313/dsblog/curl-commands/</link>
      <pubDate>Sun, 29 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/curl-commands/</guid>
      <description>&lt;p&gt;!&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6195-curl-commands.jpg&#34; alt=&#34;curl Commands&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-curl-command&#34;&gt;What is curl command?&lt;/h2&gt;&#xA;&lt;p&gt;The &lt;code&gt;curl&lt;/code&gt; command is a versatile command-line tool for transferring data to and from servers using various protocols like HTTP, HTTPS, FTP, etc. It allows you to make requests (GET, POST, PUT, DELETE) to APIs, download/upload files, send data, and debug web interactions directly from the terminal. It supports custom headers, authentication, proxies, and more, making it essential for testing and automation in web development and API integrations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How AlphaFold is Revolutionizing Protein Science</title>
      <link>http://localhost:1313/dsblog/How-AlphaFold-is-Revolutionizing-Protein-Science/</link>
      <pubDate>Sat, 28 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/How-AlphaFold-is-Revolutionizing-Protein-Science/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6194-How-AlphaFold-is-Revolutionizing-Protein-Science.jpg&#34; alt=&#34; Answering Big Questions with AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;how-alphafold-is-revolutionizing-protein-science-answering-big-questions-with-ai&#34;&gt;How AlphaFold is Revolutionizing Protein Science: Answering Big Questions with AI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;what-are-proteins-and-why-are-they-important-for-life-&#34;&gt;What are proteins, and why are they important for life? 🧬&lt;/h3&gt;&#xA;&lt;p&gt;Proteins are the workhorses of life. Found in every cell, they perform vital roles such as providing structural support, enabling biochemical reactions, and defending the body against pathogens. Without proteins, life as we know it would not exist.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;how-do-amino-acids-form-proteins-&#34;&gt;How do amino acids form proteins? 🧩&lt;/h3&gt;&#xA;&lt;p&gt;Proteins are composed of amino acids, the building blocks of life. These 20 amino acids combine in specific sequences to create unique proteins. The sequence determines a protein&amp;rsquo;s structure and function, much like letters in words.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI 12 Days 2024 Announcements</title>
      <link>http://localhost:1313/dsblog/OpenAI-12-Days-2024-Announcements/</link>
      <pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/OpenAI-12-Days-2024-Announcements/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6193-OpenAI-12-Days-2024-Announcements.jpg&#34; alt=&#34;OpenAI 12 Days 2024 Announcements&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;openai-12-days-2024-announcements&#34;&gt;OpenAI 12 Days 2024 Announcements&lt;/h1&gt;&#xA;&lt;h2 id=&#34;day-1--announcements&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=iBfQTnA2n2s&#34;&gt;Day 1- Announcements&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Launch of o1 Full Version&lt;/strong&gt;: This is an upgraded model designed to be faster, smarter, and multimodal, responding better to instructions. It shows significant improvement over its predecessor, especially in coding and problem-solving tasks.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Introduction of ChatGPT Pro&lt;/strong&gt;: A new subscription tier priced at $200/month offering unlimited access to OpenAI&amp;rsquo;s models, including advanced features like voice mode and o1 PR mode. The PR mode is intended for the most challenging problems, providing even higher performance capabilities.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Framework for using LLM</title>
      <link>http://localhost:1313/dsblog/Framework-for-using-LLM/</link>
      <pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Framework-for-using-LLM/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6192-Framework-for-using-LLM.jpg&#34; alt=&#34;Framework for using LLM&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;maximizing-your-llm-project-a-comprehensive-guide-to-effective-prompt-types&#34;&gt;Maximizing Your LLM Project: A Comprehensive Guide to Effective Prompt Types&lt;/h1&gt;&#xA;&lt;p&gt;When working on a project that leverages Large Language Models (LLMs), selecting the right model and prompt type can be daunting. With thousands of models, hundreds of tasks, and numerous output formats available, it&amp;rsquo;s easy to feel overwhelmed. This article aims to simplify your decision-making process by outlining the major types of prompts you can utilize to enhance your project’s effectiveness.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Imperialism: Western Dominance and the Future of Global Technology </title>
      <link>http://localhost:1313/dsblog/AI-Imperialism/</link>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Imperialism/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6191-AI-Imperialism.jpg&#34; alt=&#34;AI Imperialism&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-imperialism-western-dominance-and-the-future-of-global-technology&#34;&gt;AI Imperialism: Western Dominance and the Future of Global Technology&lt;/h1&gt;&#xA;&lt;p&gt;In the rapidly evolving landscape of artificial intelligence (AI), the emergence of transformer models has marked a significant milestone. Among these, OpenAI&amp;rsquo;s GPT-3 stands out as a groundbreaking achievement, yet its dominance raises critical questions about the concentration of power, legal ambiguities, and global technological equity. This article delves into the phenomenon of AI imperialism, exploring how Western dominance shapes the future of global technology and the implications for developing nations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Visualizing Transformers and Attention</title>
      <link>http://localhost:1313/dsblog/Visualizing-transformers-and-attention/</link>
      <pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Visualizing-transformers-and-attention/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6189-Visualizing-transformers-and-attention.jpg&#34; alt=&#34;Visualizing transformers and attention&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;visualizing-transformers-and-attention&#34;&gt;Visualizing Transformers and Attention&lt;/h1&gt;&#xA;&lt;p&gt;This is the summary note from Grant Sanderson&amp;rsquo;s talk at TNG Big Tech 2024. My earlir article on transformers can be found &lt;a href=&#34;http://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide&#34;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;transformers-and-their-flexibility&#34;&gt;&lt;strong&gt;Transformers and Their Flexibility&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📜 &lt;strong&gt;Origin:&lt;/strong&gt; Introduced in 2017 in the &amp;ldquo;Attention is All You Need&amp;rdquo; paper, originally for machine translation.&lt;/li&gt;&#xA;&lt;li&gt;🌍 &lt;strong&gt;Applications Beyond Translation:&lt;/strong&gt; Used in transcription (e.g., Whisper), text-to-speech, and even image classification.&lt;/li&gt;&#xA;&lt;li&gt;🤖 &lt;strong&gt;Chatbot Models:&lt;/strong&gt; Focused on models trained to predict the next token in a sequence, generating text iteratively one token at a time.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;next-token-prediction-and-creativity&#34;&gt;&lt;strong&gt;Next Token Prediction and Creativity&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔮 &lt;strong&gt;Prediction Process:&lt;/strong&gt; Predicts probabilities for possible next tokens, selects one, and repeats the process.&lt;/li&gt;&#xA;&lt;li&gt;🌡️ &lt;strong&gt;Temperature Control:&lt;/strong&gt; Adjusting randomness in token selection affects creativity vs. predictability in outputs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;tokens-and-tokenization&#34;&gt;&lt;strong&gt;Tokens and Tokenization&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🧩 &lt;strong&gt;What are Tokens?&lt;/strong&gt; Subdivisions of input data (words, subwords, punctuation, or image patches).&lt;/li&gt;&#xA;&lt;li&gt;🔡 &lt;strong&gt;Why Not Characters?&lt;/strong&gt; Using characters increases context size and computational complexity; tokens balance meaning and computational efficiency.&lt;/li&gt;&#xA;&lt;li&gt;📖 &lt;strong&gt;Byte Pair Encoding (BPE):&lt;/strong&gt; A common method for tokenization.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;embedding-tokens-into-vectors&#34;&gt;&lt;strong&gt;Embedding Tokens into Vectors&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📏 &lt;strong&gt;Embedding:&lt;/strong&gt; Tokens are mapped to high-dimensional vectors representing their meaning.&lt;/li&gt;&#xA;&lt;li&gt;🗺️ &lt;strong&gt;Contextual Meaning:&lt;/strong&gt; Vectors evolve through the network to capture context, disambiguate meaning, and encode relationships.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;the-attention-mechanism&#34;&gt;&lt;strong&gt;The Attention Mechanism&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔍 &lt;strong&gt;Purpose:&lt;/strong&gt; Enables tokens to &amp;ldquo;attend&amp;rdquo; to others, updating their vectors based on relevance.&lt;/li&gt;&#xA;&lt;li&gt;🔑 &lt;strong&gt;Key Components:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Query Matrix: Encodes what a token is &amp;ldquo;looking for.&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;Key Matrix: Encodes how a token responds to queries.&lt;/li&gt;&#xA;&lt;li&gt;Value Matrix: Encodes information passed between tokens.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;🧮 &lt;strong&gt;Calculations:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Dot Product: Measures alignment between keys and queries.&lt;/li&gt;&#xA;&lt;li&gt;Softmax: Converts dot products into normalized weights for updates.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;⛓️ &lt;strong&gt;Masked Attention:&lt;/strong&gt; Ensures causality by blocking future tokens from influencing past ones.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;multi-headed-attention&#34;&gt;&lt;strong&gt;Multi-Headed Attention&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💡 &lt;strong&gt;Parallel Heads:&lt;/strong&gt; Multiple attention heads allow different types of relationships (e.g., grammar, semantic context) to be processed simultaneously.&lt;/li&gt;&#xA;&lt;li&gt;🚀 &lt;strong&gt;Efficiency on GPUs:&lt;/strong&gt; Designed to maximize parallelization for faster computation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;multi-layer-perceptrons-mlps&#34;&gt;&lt;strong&gt;Multi-Layer Perceptrons (MLPs)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🤔 &lt;strong&gt;Role in Transformers:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Add capacity for general knowledge and non-contextual reasoning.&lt;/li&gt;&#xA;&lt;li&gt;Store facts learned during training, e.g., associations like &amp;ldquo;Michael Jordan plays basketball.&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Parameters:&lt;/strong&gt; MLPs hold the majority of the model’s parameters.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;training-transformers&#34;&gt;&lt;strong&gt;Training Transformers&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📚 &lt;strong&gt;Learning Framework:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Models are trained on vast datasets using next-token prediction, requiring no manual labels.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cost Function:&lt;/strong&gt; Measures prediction accuracy using negative log probabilities, guiding parameter updates.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;🏔️ &lt;strong&gt;Optimization:&lt;/strong&gt; Gradient descent navigates a high-dimensional cost surface to minimize error.&lt;/li&gt;&#xA;&lt;li&gt;🌐 &lt;strong&gt;Pretraining:&lt;/strong&gt; Allows large-scale unsupervised learning before fine-tuning with human feedback.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;embedding-space-and-high-dimensions&#34;&gt;&lt;strong&gt;Embedding Space and High Dimensions&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔄 &lt;strong&gt;Semantic Clusters:&lt;/strong&gt; Similar words cluster together; directions in the space encode relationships (e.g., gender: King - Male + Female = Queen).&lt;/li&gt;&#xA;&lt;li&gt;🌌 &lt;strong&gt;High Dimensionality:&lt;/strong&gt; Embedding spaces have thousands of dimensions, enabling distinct representations of complex concepts.&lt;/li&gt;&#xA;&lt;li&gt;📈 &lt;strong&gt;Scaling Efficiency:&lt;/strong&gt; High-dimensional spaces allow exponentially more &amp;ldquo;almost orthogonal&amp;rdquo; directions for encoding meanings.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;practical-applications&#34;&gt;&lt;strong&gt;Practical Applications&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✍️ &lt;strong&gt;Language Models:&lt;/strong&gt; Effective for chatbots, summarization, and more due to their generality and parallel processing.&lt;/li&gt;&#xA;&lt;li&gt;🖼️ &lt;strong&gt;Multimodal Models:&lt;/strong&gt; Transformers can integrate text, images, and sound by treating all as tokens in a unified framework.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;challenges-and-limitations&#34;&gt;&lt;strong&gt;Challenges and Limitations&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📏 &lt;strong&gt;Context Size Limitations:&lt;/strong&gt; Attention grows quadratically with context size, requiring optimization for large contexts.&lt;/li&gt;&#xA;&lt;li&gt;♻️ &lt;strong&gt;Inference Redundancy:&lt;/strong&gt; Token-by-token generation can involve redundant computations; caching mitigates this at inference time.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;engineering-and-design&#34;&gt;&lt;strong&gt;Engineering and Design&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🛠️ &lt;strong&gt;Hardware Optimization:&lt;/strong&gt; Transformers are designed to exploit GPUs&amp;rsquo; parallelism for efficient matrix multiplication.&lt;/li&gt;&#xA;&lt;li&gt;🔗 &lt;strong&gt;Residual Connections:&lt;/strong&gt; Baked into the architecture to enhance stability and ease of training.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;the-power-of-scale&#34;&gt;&lt;strong&gt;The Power of Scale&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📈 &lt;strong&gt;Scaling Laws:&lt;/strong&gt; Larger models and more data improve performance, often qualitatively.&lt;/li&gt;&#xA;&lt;li&gt;🔄 &lt;strong&gt;Self-Supervised Pretraining:&lt;/strong&gt; Enables training on vast unlabeled datasets before fine-tuning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;bpe-byte-pair-encoding&#34;&gt;&lt;strong&gt;BPE (Byte Pair Encoding)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;BPE is a widely used tokenization method in natural language processing (NLP) and machine learning. It is designed to balance between breaking text into characters and full words by representing text as a sequence of subword units. This approach helps models handle rare and unseen words effectively while keeping the vocabulary size manageable.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Graphics Processing Units (GPUs)</title>
      <link>http://localhost:1313/dsblog/Exploring-GPUs/</link>
      <pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-GPUs/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6188-Exploring-GPUs.jpg&#34; alt=&#34;Exploring Graphics Processing Units (GPUs)&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-graphics-processing-units-gpus&#34;&gt;Exploring Graphics Processing Units (GPUs)&lt;/h1&gt;&#xA;&lt;h2 id=&#34;overall-computational-power-of-gpus&#34;&gt;&lt;strong&gt;Overall Computational Power of GPUs&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;⚡ &lt;strong&gt;Incredible Calculation Speed:&lt;/strong&gt; Modern GPUs can perform tens of trillions of calculations per second (e.g., 36 trillion for Cyberpunk 2077).&lt;/li&gt;&#xA;&lt;li&gt;🌍 &lt;strong&gt;Human Comparison:&lt;/strong&gt; Achieving this manually would require the equivalent of over 4,400 Earths full of people, each doing one calculation every second.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;gpu-vs-cpu&#34;&gt;&lt;strong&gt;GPU vs. CPU&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🚢 &lt;strong&gt;Cargo Ship vs. Airplane Analogy:&lt;/strong&gt; GPUs are like cargo ships (massive capacity, slower), and CPUs are like jets (fast, versatile, fewer tasks at once).&lt;/li&gt;&#xA;&lt;li&gt;⚖️ &lt;strong&gt;Different Strengths:&lt;/strong&gt; CPUs handle operating systems, flexible tasks, and fewer but more complex instructions. GPUs excel at huge amounts of simple, repetitive calculations.&lt;/li&gt;&#xA;&lt;li&gt;🔀 &lt;strong&gt;Parallel vs. General Purpose:&lt;/strong&gt; GPUs are less flexible but highly parallel, CPUs are more general-purpose and can run a wide variety of programs and instructions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;gpu-architecture--components-ga102-example&#34;&gt;&lt;strong&gt;GPU Architecture &amp;amp; Components (GA102 Example)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💽 &lt;strong&gt;Central GPU Die (GA102):&lt;/strong&gt; A large chip with 28.3 billion transistors organized into Graphics Processing Clusters (GPCs), Streaming Multiprocessors (SMs), and cores.&lt;/li&gt;&#xA;&lt;li&gt;🏗️ &lt;strong&gt;Hierarchical Structure:&lt;/strong&gt; GA102 has 7 GPCs → 12 SMs per GPC → 4 Warps per SM → 32 CUDA Per Wrap and 4 Tensor Per Warmp and 1 Ray Tracing Per GPC.&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Types of Cores:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;⚙️ CUDA Cores: Handle basic arithmetic (addition, multiplication) most commonly used in gaming.&lt;/li&gt;&#xA;&lt;li&gt;🧩 Tensor Cores: Perform massive matrix calculations for AI and neural networks.&lt;/li&gt;&#xA;&lt;li&gt;💎 Ray Tracing Cores: Specialized for lighting and reflection calculations in real-time graphics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;manufacturing--binning&#34;&gt;&lt;strong&gt;Manufacturing &amp;amp; Binning&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔧 &lt;strong&gt;Shared Chip Design:&lt;/strong&gt; Different GPU models (e.g., 3080, 3090, 3090 Ti) share the same GA102 design.&lt;/li&gt;&#xA;&lt;li&gt;🕳️ &lt;strong&gt;Defects &amp;amp; Binning:&lt;/strong&gt; Manufacturing imperfections result in some cores being disabled. This leads to different “tiers” of the same GPU architecture.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;cuda-core-internals&#34;&gt;&lt;strong&gt;CUDA Core Internals&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;➕ &lt;strong&gt;Simple Calculator Design:&lt;/strong&gt; Each CUDA core is basically a tiny calculator that does fused multiply-add (FMA) and a few other operations.&lt;/li&gt;&#xA;&lt;li&gt;💻 &lt;strong&gt;Common Operations:&lt;/strong&gt; Primarily handles 32-bit floating-point and integer arithmetic. More complex math (division, trignometry) is done by fewer, special function units.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;memory-systems-gddr6x--gddr7&#34;&gt;&lt;strong&gt;Memory Systems: GDDR6X &amp;amp; GDDR7&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💾 &lt;strong&gt;Graphics Memory:&lt;/strong&gt; GDDR6X chips (by Micron) feed terabytes of data per second into the GPU’s thousands of cores.&lt;/li&gt;&#xA;&lt;li&gt;🚀 &lt;strong&gt;High Bandwidth:&lt;/strong&gt; GPU memory operates at huge bandwidths (over 1 terabyte/s) compared to typical CPU memory (~64 GB/s).&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Beyond Binary:&lt;/strong&gt; GDDR6X and GDDR7 use multiple voltage levels (PAM-4 and PAM-3) to encode more data per signal, increasing transfer rates.&lt;/li&gt;&#xA;&lt;li&gt;🏗️ &lt;strong&gt;Future Memory Tech:&lt;/strong&gt; Micron also develops HBM (High Bandwidth Memory) for AI accelerators, stacking memory chips in 3D, greatly boosting capacity and speed while reducing power.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;parallel-computing-concepts-simd--simt&#34;&gt;&lt;strong&gt;Parallel Computing Concepts (SIMD &amp;amp; SIMT)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;♻️ &lt;strong&gt;Embarrassingly Parallel:&lt;/strong&gt; Tasks like graphics rendering, Bitcoin mining, or AI training are easily split into millions of independent calculations.&lt;/li&gt;&#xA;&lt;li&gt;📜 &lt;strong&gt;Single Instruction Multiple Data (SIMD):&lt;/strong&gt; Apply the same instruction to many data points at once—perfect for transforming millions of vertices in a 3D scene.&lt;/li&gt;&#xA;&lt;li&gt;🔓 &lt;strong&gt;From SIMD to SIMT:&lt;/strong&gt; Newer GPUs use Single Instruction Multiple Threads (SIMT), allowing threads to progress independently and handle complex branching more efficiently.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;thread--warp-organization&#34;&gt;&lt;strong&gt;Thread &amp;amp; Warp Organization&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📦 &lt;strong&gt;Thread Hierarchy:&lt;/strong&gt; Threads → Warps (groups of 32 threads) → Thread Blocks → Grids.&lt;/li&gt;&#xA;&lt;li&gt;🎛️ &lt;strong&gt;Gigathread Engine:&lt;/strong&gt; Manages the allocation of thread blocks to streaming multiprocessors, optimizing parallel processing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;practical-applications&#34;&gt;&lt;strong&gt;Practical Applications&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🎮 &lt;strong&gt;Video Games:&lt;/strong&gt; GPUs transform coordinates, apply textures, shading, and handle complex rendering pipelines. Millions of identical operations on different vertices and pixels are done in parallel.&lt;/li&gt;&#xA;&lt;li&gt;₿ &lt;strong&gt;Bitcoin Mining:&lt;/strong&gt; GPUs can run the SHA-256 hashing algorithm in parallel many millions of times per second. Though now replaced by ASIC miners, GPUs were initially very efficient at this.&lt;/li&gt;&#xA;&lt;li&gt;🤖 &lt;strong&gt;AI &amp;amp; Neural Networks:&lt;/strong&gt; Tensor cores accelerate matrix multiplications critical for training neural nets and powering generative AI.&lt;/li&gt;&#xA;&lt;li&gt;💡 &lt;strong&gt;Ray Tracing:&lt;/strong&gt; Specialized cores handle ray tracing calculations for realistic lighting and reflections in real-time graphics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;microns-role--advancements&#34;&gt;&lt;strong&gt;Micron’s Role &amp;amp; Advancements&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🏭 &lt;strong&gt;Micron Memory Chips:&lt;/strong&gt; GDDR6X and future GDDR7 designed by Micron power high-speed data transfers on GPUs.&lt;/li&gt;&#xA;&lt;li&gt;🔮 &lt;strong&gt;Innovations in Memory:&lt;/strong&gt; High Bandwidth Memory (HBM) for AI chips stacks DRAM vertically, creating high-capacity, high-throughput solutions at lower energy costs.&lt;/li&gt;&#xA;&lt;li&gt;📚 &lt;strong&gt;Technological Marvel:&lt;/strong&gt; Modern graphics cards are a blend of advanced materials, clever architectures, and innovative manufacturing. They enable astonishing levels of visual realism, parallel computation, and AI capabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=h9Z4oGN89MU&#34;&gt;How do Graphics Cards Work? Exploring GPU Architecture&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Models and Creators</title>
      <link>http://localhost:1313/dsblog/AI-Models-and-Creators/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Models-and-Creators/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6187-ai-models-and-creators.jpg&#34; alt=&#34;AI Models and Creators&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-models-and-creators&#34;&gt;AI Models and Creators&lt;/h1&gt;&#xA;&lt;h2 id=&#34;popular-models-and-their-creator&#34;&gt;Popular Models and Their Creator&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Nova - Amazon&lt;/li&gt;&#xA;&lt;li&gt;Gemini, Gemma - Google&lt;/li&gt;&#xA;&lt;li&gt;Granite - Oracle&lt;/li&gt;&#xA;&lt;li&gt;GPT - OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Phi - Microsoft Azure&lt;/li&gt;&#xA;&lt;li&gt;Einstein - Salesforce&lt;/li&gt;&#xA;&lt;li&gt;Joule - SAP&lt;/li&gt;&#xA;&lt;li&gt;Grok - X (formerly Twitter)&lt;/li&gt;&#xA;&lt;li&gt;Llama - Meta&lt;/li&gt;&#xA;&lt;li&gt;Qwen - Alibaba&lt;/li&gt;&#xA;&lt;li&gt;Claude - Anthropic&lt;/li&gt;&#xA;&lt;li&gt;Bard - Google&lt;/li&gt;&#xA;&lt;li&gt;PaLM - Google&lt;/li&gt;&#xA;&lt;li&gt;Mistral - Mistral AI&lt;/li&gt;&#xA;&lt;li&gt;Falcon - Technology Innovation Institute (TII), UAE&lt;/li&gt;&#xA;&lt;li&gt;Gato - DeepMind&lt;/li&gt;&#xA;&lt;li&gt;Jasper - Jasper AI&lt;/li&gt;&#xA;&lt;li&gt;Bloom - BigScience (collaborative project)&lt;/li&gt;&#xA;&lt;li&gt;Ernie - Baidu&lt;/li&gt;&#xA;&lt;li&gt;Alpaca - Stanford University (fine-tuned LLaMA model)&lt;/li&gt;&#xA;&lt;li&gt;Stable Diffusion - Stability AI&lt;/li&gt;&#xA;&lt;li&gt;HuggingChat - Hugging Face&lt;/li&gt;&#xA;&lt;li&gt;Cohere of Command&lt;/li&gt;&#xA;&lt;li&gt;Alpha fold of deepmind&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;models-developed-by-microsoft&#34;&gt;Models Developed by Microsoft&lt;/h2&gt;&#xA;&lt;p&gt;Microsoft has developed or collaborated on several AI models and frameworks, especially as part of its Azure AI ecosystem and its partnership with OpenAI. Below is a list of models and AI systems associated with Microsoft:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Features ofShazam Econometrics Software</title>
      <link>http://localhost:1313/dsblog/shazam-features/</link>
      <pubDate>Mon, 09 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/shazam-features/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6186-Shazam-Features.jpg&#34; alt=&#34;Shazam-Features&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;features-of-shazam-econometrics-software&#34;&gt;Features of Shazam Econometrics Software&lt;/h1&gt;&#xA;&lt;p&gt;A free, &lt;a href=&#34;https://www.econometrics.com/download/&#34;&gt;downloadable Trial&lt;/a&gt; Version of SHAZAM is available to try out.&lt;/p&gt;&#xA;&lt;p&gt;All features are enabled although the amount of memory available for calculations (PAR) is limited to be sufficient to run all but a few of the largest included examples.&lt;/p&gt;&#xA;&lt;p&gt;There is no time limit on the use of these Trial Versions.&lt;/p&gt;&#xA;&lt;p&gt;These are the features of &lt;a href=&#34;https://www.econometrics.com//&#34;&gt;Shazam Econometrics Software&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;ARIMA Models&lt;/strong&gt;: A time-series forecasting method using autoregression, differencing, and moving averages. &lt;strong&gt;Application&lt;/strong&gt;: Forecasting stock prices, sales trends, and economic data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Beta Regression&lt;/strong&gt;: A regression model for variables constrained between 0 and 1. &lt;strong&gt;Application&lt;/strong&gt;: Modeling probabilities, proportions, and rates.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Sorting&lt;/strong&gt;: Organizing data in ascending or descending order. &lt;strong&gt;Application&lt;/strong&gt;: Enhancing data preprocessing and analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Transformations&lt;/strong&gt;: Adjusting data to stabilize variance or improve normality. &lt;strong&gt;Application&lt;/strong&gt;: Used in regression and machine learning.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Descriptive Statistics&lt;/strong&gt;: Summarizing data using measures like mean and variance. &lt;strong&gt;Application&lt;/strong&gt;: Understanding and exploring datasets.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Diagnostic Tests&lt;/strong&gt;: Validating model assumptions like normality or heteroskedasticity. &lt;strong&gt;Application&lt;/strong&gt;: Ensuring model reliability.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dickey-Fuller Unit Root Tests&lt;/strong&gt;: Checks for stationarity in time-series data. &lt;strong&gt;Application&lt;/strong&gt;: Time-series modeling and forecasting.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Distributed Lag Models&lt;/strong&gt;: Captures effects of independent variables over time lags. &lt;strong&gt;Application&lt;/strong&gt;: Policy impact analysis in econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Exact Durbin Watson Tests&lt;/strong&gt;: Tests for autocorrelation in regression residuals. &lt;strong&gt;Application&lt;/strong&gt;: Model diagnostics in time-series analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Financial Time Series&lt;/strong&gt;: Analyzes financial data trends over time. &lt;strong&gt;Application&lt;/strong&gt;: Modeling stock prices and market indices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Forecasting&lt;/strong&gt;: Predicting future trends using historical data. &lt;strong&gt;Application&lt;/strong&gt;: Business planning and demand forecasting.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Full Information Maximum Likelihood (FIML) Models&lt;/strong&gt;: Estimates parameters in simultaneous equation models. &lt;strong&gt;Application&lt;/strong&gt;: Complex econometric modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Granger Causality&lt;/strong&gt;: Tests whether one time-series predicts another. &lt;strong&gt;Application&lt;/strong&gt;: Analyzing causal relationships in economics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Heteroskedasticity Tests&lt;/strong&gt;: Identifies variance inconsistencies in regression models. &lt;strong&gt;Application&lt;/strong&gt;: Improving model validity in econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Heteroskedastic Consistent Covariance Matrices&lt;/strong&gt;: Adjusts standard errors for heteroskedasticity. &lt;strong&gt;Application&lt;/strong&gt;: Reliable hypothesis testing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Logit Models&lt;/strong&gt;: Regression models for binary outcome variables. &lt;strong&gt;Application&lt;/strong&gt;: Predicting probabilities, such as customer churn.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Moving Averages&lt;/strong&gt;: Smooths time-series data by averaging over time windows. &lt;strong&gt;Application&lt;/strong&gt;: Identifying trends in stock prices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Nonlinear Least Squares&lt;/strong&gt;: Fits nonlinear models to data. &lt;strong&gt;Application&lt;/strong&gt;: Modeling complex relationships in econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Poisson Regression&lt;/strong&gt;: Models count data based on Poisson distribution. &lt;strong&gt;Application&lt;/strong&gt;: Event occurrence predictions like insurance claims.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Principal Components Analysis&lt;/strong&gt;: Reduces data dimensions by identifying principal components. &lt;strong&gt;Application&lt;/strong&gt;: Used in feature reduction and exploratory analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Probability Distributions&lt;/strong&gt;: Computes probabilities for various distributions. &lt;strong&gt;Application&lt;/strong&gt;: Risk modeling and simulations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Probit Models&lt;/strong&gt;: Regression for binary data using normal distribution. &lt;strong&gt;Application&lt;/strong&gt;: Binary classification in econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Generating Variables&lt;/strong&gt;: Creates or modifies variables for analysis. &lt;strong&gt;Application&lt;/strong&gt;: Data preparation for modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Graphing&lt;/strong&gt;: Visualizes data trends and relationships. &lt;strong&gt;Application&lt;/strong&gt;: Communicating results effectively.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Exponential Regression&lt;/strong&gt;: Fits exponential growth or decay models. &lt;strong&gt;Application&lt;/strong&gt;: Population growth and decay modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Gamma Regressions&lt;/strong&gt;: Fits models with gamma-distributed errors. &lt;strong&gt;Application&lt;/strong&gt;: Modeling skewed data, such as incomes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hypothesis Testing&lt;/strong&gt;: Tests assumptions about data parameters. &lt;strong&gt;Application&lt;/strong&gt;: Statistical significance analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Heteroskedastic Models&lt;/strong&gt;: Models variable errors across observations. &lt;strong&gt;Application&lt;/strong&gt;: Corrects heteroskedasticity in regressions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Factor Analysis&lt;/strong&gt;: Identifies latent variables in datasets. &lt;strong&gt;Application&lt;/strong&gt;: Psychometrics and market research.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Linear Programming&lt;/strong&gt;: Optimizes linear objective functions subject to constraints. &lt;strong&gt;Application&lt;/strong&gt;: Resource allocation problems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Matrix Manipulation&lt;/strong&gt;: Performs operations on matrices for analysis. &lt;strong&gt;Application&lt;/strong&gt;: Essential in linear algebra-based models.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Monte Carlo Experiments&lt;/strong&gt;: Simulates random sampling for statistical analysis. &lt;strong&gt;Application&lt;/strong&gt;: Risk assessment and probability estimation.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ridge Regression&lt;/strong&gt;: Regularizes regression models to reduce overfitting. &lt;strong&gt;Application&lt;/strong&gt;: Predictive modeling with multicollinearity.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Seasonal Adjustment&lt;/strong&gt;: Removes seasonal effects from data. &lt;strong&gt;Application&lt;/strong&gt;: Analyzing underlying trends in time-series.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;ARCH and GARCH Models&lt;/strong&gt;: Models time-series data with changing volatility. &lt;strong&gt;Application&lt;/strong&gt;: Financial market risk analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Bootstrapping&lt;/strong&gt;: Resampling technique for estimating statistics. &lt;strong&gt;Application&lt;/strong&gt;: Confidence intervals in non-normal datasets.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Box-Cox Models&lt;/strong&gt;: Transforms data to stabilize variance. &lt;strong&gt;Application&lt;/strong&gt;: Preprocessing for linear regression.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;CUSUM Tests&lt;/strong&gt;: Detects structural changes in time-series. &lt;strong&gt;Application&lt;/strong&gt;: Quality control and monitoring.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Chow Test and Goldfeld-Quandt Test&lt;/strong&gt;: Tests for structural breaks and heteroskedasticity. &lt;strong&gt;Application&lt;/strong&gt;: Model diagnostics and robustness checks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cointegration Testing&lt;/strong&gt;: Checks long-term relationships between non-stationary variables. &lt;strong&gt;Application&lt;/strong&gt;: Economic time-series analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Combined Box-Cox and Box-Tidwell Model&lt;/strong&gt;: Applies complex transformations to improve model fit. &lt;strong&gt;Application&lt;/strong&gt;: Nonlinear regression adjustments.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Computing the Power of a Test&lt;/strong&gt;: Measures the ability to reject false null hypotheses. &lt;strong&gt;Application&lt;/strong&gt;: Statistical experiment design.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Confidence Intervals and Ellipse Plots&lt;/strong&gt;: Visualizes and quantifies parameter uncertainty. &lt;strong&gt;Application&lt;/strong&gt;: Model diagnostics and hypothesis testing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cross-Section Heteroskedasticity and Time-Wise Autoregression&lt;/strong&gt;: Models varying error variance and temporal relationships. &lt;strong&gt;Application&lt;/strong&gt;: Time-series and panel data analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cumulative Distribution Function Computation&lt;/strong&gt;: Computes probabilities up to a given value. &lt;strong&gt;Application&lt;/strong&gt;: Statistical analysis and decision-making.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Smoothing and Seasonal Adjustments&lt;/strong&gt;: Reduces noise and removes seasonal effects. &lt;strong&gt;Application&lt;/strong&gt;: Time-series forecasting.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Derivatives and Integrals Evaluation&lt;/strong&gt;: Calculates changes and accumulations. &lt;strong&gt;Application&lt;/strong&gt;: Economic optimization problems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dynamic Simultaneous Equation Models&lt;/strong&gt;: Captures interdependencies in dynamic systems. &lt;strong&gt;Application&lt;/strong&gt;: Policy simulation in macroeconomics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Estimation of Systems of Linear and Nonlinear Equations&lt;/strong&gt;: Solves interrelated models simultaneously. &lt;strong&gt;Application&lt;/strong&gt;: Complex econometric modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Estimation using Regression Quantiles&lt;/strong&gt;: Models conditional quantiles of data. &lt;strong&gt;Application&lt;/strong&gt;: Robust regression for outliers.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Fuzzy Set Models&lt;/strong&gt;: Deals with imprecise or ambiguous data. &lt;strong&gt;Application&lt;/strong&gt;: Decision-making in uncertain conditions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Generalized Entropy Models&lt;/strong&gt;: Measures distribution inequality. &lt;strong&gt;Application&lt;/strong&gt;: Income inequality and welfare economics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Generalized Least Squares&lt;/strong&gt;: Estimates models with correlated or heteroskedastic errors. &lt;strong&gt;Application&lt;/strong&gt;: Time-series and panel data analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Generalized Method of Moments (GMM) Estimation&lt;/strong&gt;: Solves models using moment conditions. &lt;strong&gt;Application&lt;/strong&gt;: Asset pricing and econometric analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hausman Specification Tests&lt;/strong&gt;: Compares model consistency and efficiency. &lt;strong&gt;Application&lt;/strong&gt;: Model selection in econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hodrick Prescott Filtering&lt;/strong&gt;: Separates trends from cycles in data. &lt;strong&gt;Application&lt;/strong&gt;: Economic trend analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Index Number Series Splicing&lt;/strong&gt;: Combines multiple index series. &lt;strong&gt;Application&lt;/strong&gt;: Creating continuous economic indices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Instrumental Variable Estimation&lt;/strong&gt;: Addresses endogeneity in regression models. &lt;strong&gt;Application&lt;/strong&gt;: Causal inference in econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Iterative Cochrane-Orcutt Estimation&lt;/strong&gt;: Corrects for autocorrelation in regression. &lt;strong&gt;Application&lt;/strong&gt;: Improving time-series model accuracy.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Jackknife Estimators&lt;/strong&gt;: Resampling method to reduce bias in estimates. &lt;strong&gt;Application&lt;/strong&gt;: Small sample data analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Johansen Maximum Eigenvalue Tests&lt;/strong&gt;: Tests for cointegration between variables. &lt;strong&gt;Application&lt;/strong&gt;: Economic relationships in time-series.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Johansen Trace Tests&lt;/strong&gt;: Determines the number of cointegrated vectors. &lt;strong&gt;Application&lt;/strong&gt;: Long-run equilibrium modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Joint Confidence Region Computation&lt;/strong&gt;: Calculates joint uncertainty intervals. &lt;strong&gt;Application&lt;/strong&gt;: Multi-parameter hypothesis testing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Least Absolute Errors Estimation&lt;/strong&gt;: Minimizes absolute residuals in regression. &lt;strong&gt;Application&lt;/strong&gt;: Robust regression under outliers.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Limited Information Maximum Likelihood (LIML) Models&lt;/strong&gt;: Estimates overidentified models. &lt;strong&gt;Application&lt;/strong&gt;: Simultaneous equation modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Newey-West Autocorrelation Consistent Covariance Matrix&lt;/strong&gt;: Adjusts for heteroskedasticity and autocorrelation. &lt;strong&gt;Application&lt;/strong&gt;: Time-series regression robustness.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Nonlinear Seemingly Unrelated Regression (SUR)&lt;/strong&gt;: Estimates interrelated nonlinear models. &lt;strong&gt;Application&lt;/strong&gt;: Econometric model integration.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Nonlinear Sets of Equations&lt;/strong&gt;: Solves complex nonlinear systems. &lt;strong&gt;Application&lt;/strong&gt;: Engineering and econometric applications.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Nonparametric Density Estimation&lt;/strong&gt;: Estimates data distributions without assumptions. &lt;strong&gt;Application&lt;/strong&gt;: Descriptive statistics and exploratory analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Nonparametric Methods&lt;/strong&gt;: Statistical methods not assuming data distribution. &lt;strong&gt;Application&lt;/strong&gt;: Flexible modeling in diverse fields.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Nonparametric Regression with Kernel Estimation&lt;/strong&gt;: Fits data without assuming linearity. &lt;strong&gt;Application&lt;/strong&gt;: Smoothing and forecasting in noisy data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ordinary Least Squares Models&lt;/strong&gt;: Standard regression for estimating linear relationships. &lt;strong&gt;Application&lt;/strong&gt;: Widely used in predictive modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Phillips-Perron Unit Root Test&lt;/strong&gt;: Checks stationarity in time-series data. &lt;strong&gt;Application&lt;/strong&gt;: Time-series preprocessing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Polynomial Inverse Lags&lt;/strong&gt;: Models complex lag structures in time-series. &lt;strong&gt;Application&lt;/strong&gt;: Time-series forecasting with lagged effects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pooling Cross-Section Time-Series with Balanced or Unbalanced Panels&lt;/strong&gt;: Combines data across dimensions. &lt;strong&gt;Application&lt;/strong&gt;: Panel data econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Power of Statistical Tests Computation&lt;/strong&gt;: Evaluates the likelihood of rejecting false hypotheses. &lt;strong&gt;Application&lt;/strong&gt;: Statistical test planning.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Price Indices&lt;/strong&gt;: Calculates weighted price measures. &lt;strong&gt;Application&lt;/strong&gt;: Economic and market analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Quadratic Programming&lt;/strong&gt;: Optimizes quadratic objective functions. &lt;strong&gt;Application&lt;/strong&gt;: Portfolio optimization.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RESET Specification Error Tests&lt;/strong&gt;: Checks model misspecifications. &lt;strong&gt;Application&lt;/strong&gt;: Regression diagnostics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Random Number Generation&lt;/strong&gt;: Creates random samples for simulations. &lt;strong&gt;Application&lt;/strong&gt;: Monte Carlo experiments.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Recursive Residuals&lt;/strong&gt;: Analyzes regression stability over time. &lt;strong&gt;Application&lt;/strong&gt;: Detecting structural breaks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Regression with Non-Normal Errors&lt;/strong&gt;: Fits models when errors deviate from normality. &lt;strong&gt;Application&lt;/strong&gt;: Robust regression.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Regression with Time Varying Coefficients&lt;/strong&gt;: Models changing relationships over time. &lt;strong&gt;Application&lt;/strong&gt;: Dynamic forecasting.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Restricted Least Squares&lt;/strong&gt;: Imposes constraints on regression coefficients. &lt;strong&gt;Application&lt;/strong&gt;: Hypothesis testing with restrictions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Restricted Seemingly Unrelated Regression Models (SUR)&lt;/strong&gt;: Estimates restricted SUR models. &lt;strong&gt;Application&lt;/strong&gt;: Multi-equation model optimization.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Seemingly Unrelated Regression (SUR)&lt;/strong&gt;: Fits multiple equations with correlated errors. &lt;strong&gt;Application&lt;/strong&gt;: Econometric model integration.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Simulated Annealing&lt;/strong&gt;: Optimization technique mimicking thermodynamics. &lt;strong&gt;Application&lt;/strong&gt;: Solving nonlinear optimization problems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Simultaneous Equation Models (Linear and Nonlinear)&lt;/strong&gt;: Models interdependent equations simultaneously. &lt;strong&gt;Application&lt;/strong&gt;: Economic system analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Solving Nonlinear Sets of Equations&lt;/strong&gt;: Finds solutions to nonlinear systems. &lt;strong&gt;Application&lt;/strong&gt;: Engineering and economic modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Splicing Index Number Series&lt;/strong&gt;: Combines and adjusts index series. &lt;strong&gt;Application&lt;/strong&gt;: Economic index continuity.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Stepwise Regression&lt;/strong&gt;: Automated model selection by adding/removing predictors. &lt;strong&gt;Application&lt;/strong&gt;: Predictive model optimization.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Stochastic Frontier Models&lt;/strong&gt;: Models efficiency and productivity. &lt;strong&gt;Application&lt;/strong&gt;: Performance analysis in economics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tests for Autocorrelation&lt;/strong&gt;: Checks dependence in residuals. &lt;strong&gt;Application&lt;/strong&gt;: Time-series model validation.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Three Stage Least Squares&lt;/strong&gt;: Estimates simultaneous equation models. &lt;strong&gt;Application&lt;/strong&gt;: Complex econometric system modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Time Varying Linear Regression&lt;/strong&gt;: Models linear relationships that evolve over time. &lt;strong&gt;Application&lt;/strong&gt;: Financial time-series forecasting.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tobit Models&lt;/strong&gt;: Estimates censored regression models. &lt;strong&gt;Application&lt;/strong&gt;: Analyzing limited dependent variables.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Two Stage Least Squares&lt;/strong&gt;: Handles endogeneity in regression. &lt;strong&gt;Application&lt;/strong&gt;: Causal inference in econometrics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Univariate Kernel Method&lt;/strong&gt;: Estimates probability densities for single variables. &lt;strong&gt;Application&lt;/strong&gt;: Data smoothing in univariate analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Vector AutoRegressive (VAR) Models&lt;/strong&gt;: Models interdependent time-series. &lt;strong&gt;Application&lt;/strong&gt;: Macroeconomic policy analysis.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Weighted Least Squares Regression&lt;/strong&gt;: Accounts for unequal variances in regression. &lt;strong&gt;Application&lt;/strong&gt;: Robust linear modeling.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Robust Regression&lt;/strong&gt;: Handles outliers and heteroskedasticity in regression. &lt;strong&gt;Application&lt;/strong&gt;: Reliable prediction in noisy data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Seasonal Adjustment&lt;/strong&gt;: Removes seasonal effects from time-series data. &lt;strong&gt;Application&lt;/strong&gt;: Trend and cycle analysis in economic data.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Serverless LLM Deployment Platform</title>
      <link>http://localhost:1313/dsblog/serverless-llm-deployment/</link>
      <pubDate>Sun, 08 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/serverless-llm-deployment/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6185-Serverless-LLM-Deployment.jpg&#34; alt=&#34;Serverless-LLM-Deployment&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;serverless-llm-deployment-platform&#34;&gt;Serverless LLM Deployment Platform&lt;/h1&gt;&#xA;&lt;h2 id=&#34;microsoft&#34;&gt;&lt;strong&gt;Microsoft&amp;rsquo;s Serverless LLM Deployment Platform&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;azure-openai-service&#34;&gt;&lt;strong&gt;Azure OpenAI Service&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Azure OpenAI Service&lt;/strong&gt; is Microsoft&amp;rsquo;s answer to serverless LLM deployment. It provides access to powerful language models, including OpenAI&amp;rsquo;s GPT-4, GPT-3.5, Codex, and DALL-E, within the Azure ecosystem. It simplifies the process of integrating and deploying LLMs in a serverless manner.&lt;/p&gt;&#xA;&lt;h3 id=&#34;key-features&#34;&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Serverless Deployment&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fully managed platform—no need to manage infrastructure.&lt;/li&gt;&#xA;&lt;li&gt;Automatically scales based on workload and demand.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Pre-Trained LLMs&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Microsoft AI Products</title>
      <link>http://localhost:1313/dsblog/microsoft-ai-products/</link>
      <pubDate>Sat, 07 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/microsoft-ai-products/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6184-Microsoft-AI-Products.jpg&#34; alt=&#34;Microsoft-AI-Products&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;microsoft-ai-products&#34;&gt;Microsoft AI Products&lt;/h1&gt;&#xA;&lt;p&gt;Microsoft offers several tools and platforms for AI and machine learning, comparable to Google&amp;rsquo;s Vertex AI and Google AI Studio. These tools are integrated within Microsoft Azure, its cloud computing platform, and are designed for various user profiles, ranging from data scientists and ML engineers to business analysts and citizen developers.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-azure-machine-learning-azure-ml&#34;&gt;&lt;strong&gt;1. Azure Machine Learning (Azure ML)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Azure Machine Learning&lt;/strong&gt; is Microsoft&amp;rsquo;s counterpart to &lt;strong&gt;Vertex AI&lt;/strong&gt; and is an end-to-end machine learning platform for building, training, deploying, and managing ML models at scale.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google AI Studio vs Vertex AI</title>
      <link>http://localhost:1313/dsblog/google-ai-studio-vs-vertexai/</link>
      <pubDate>Fri, 06 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/google-ai-studio-vs-vertexai/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6183-Google-AI-Studio-vs-VertexAI.jpg&#34; alt=&#34;Google AI Studio vs Vertex AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;google-ai-studio-vs-vertex-ai&#34;&gt;Google AI Studio vs Vertex AI&lt;/h1&gt;&#xA;&lt;p&gt;The difference between &lt;strong&gt;Vertex AI&lt;/strong&gt; and &lt;strong&gt;Google AI Studio&lt;/strong&gt; lies in their scope, functionality, and target audiences within Google&amp;rsquo;s suite of AI tools.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-vertex-ai&#34;&gt;&lt;strong&gt;1. Vertex AI&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Vertex AI&lt;/strong&gt; is Google&amp;rsquo;s &lt;strong&gt;end-to-end AI platform&lt;/strong&gt; for machine learning (ML) and AI model development, training, deployment, and management. It is designed for developers and data scientists who want a comprehensive environment to build, deploy, and scale ML models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to NVIDIA and Products</title>
      <link>http://localhost:1313/dsblog/introduction-nvidia-products/</link>
      <pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/introduction-nvidia-products/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6182-Introduction-NVIDIA-Products.jpg&#34; alt=&#34;Introduction-NVIDIA-Products&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;nvidia-timeline&#34;&gt;NVIDIA Timeline&lt;/h2&gt;&#xA;&lt;p&gt;NVIDIA Corporation has an illustrious history since its founding in 1993. It started as a graphics processing pioneer and has grown into a global leader in AI, gaming, data center technologies, and more. Here&amp;rsquo;s a timeline of key milestones and activities:&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1993-1999-founding-and-early-innovations&#34;&gt;&lt;strong&gt;1993-1999: Founding and Early Innovations&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;1993:&lt;/strong&gt; NVIDIA was founded by Jensen Huang, Chris Malachowsky, and Curtis Priem in Santa Clara, California, with a focus on graphics processing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1995:&lt;/strong&gt; Launched the &lt;strong&gt;NV1&lt;/strong&gt;, the company’s first graphics chip, which supported both 2D and 3D graphics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1999:&lt;/strong&gt; Introduced the &lt;strong&gt;GeForce 256&lt;/strong&gt;, the world&amp;rsquo;s first GPU, which revolutionized graphics processing by offloading 3D rendering tasks from the CPU.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2000-2009-expanding-into-gaming-and-professional-graphics&#34;&gt;&lt;strong&gt;2000-2009: Expanding into Gaming and Professional Graphics&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;2000:&lt;/strong&gt; NVIDIA acquired 3dfx, a leading graphics company, consolidating its dominance in the GPU market.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2002:&lt;/strong&gt; Released the &lt;strong&gt;GeForce4&lt;/strong&gt; series, establishing itself as a leader in gaming GPUs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2004:&lt;/strong&gt; Entered the professional graphics market with the &lt;strong&gt;Quadro FX&lt;/strong&gt; series.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2006:&lt;/strong&gt; Launched &lt;strong&gt;CUDA&lt;/strong&gt;, a parallel computing platform enabling developers to use NVIDIA GPUs for general-purpose computing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2008:&lt;/strong&gt; Introduced the &lt;strong&gt;Tesla series&lt;/strong&gt;, targeting high-performance computing (HPC) and AI research.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;fun-fact&#34;&gt;Fun Fact:&lt;/h4&gt;&#xA;&lt;p&gt;Tesla, Inc. (originally Tesla Motors), founded in 2003, is named after Nikola Tesla as well, acknowledging his contributions to electrical systems. Interestingly, NVIDIA and Tesla, Inc. later had a professional relationship. NVIDIA GPUs were used in Tesla&amp;rsquo;s early Autopilot systems, although Tesla later transitioned to building its own custom AI chips.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Navigating the LLM Infrastructure Landscape</title>
      <link>http://localhost:1313/dsblog/navigating-llm-infrastructure-landscape/</link>
      <pubDate>Thu, 14 Nov 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/navigating-llm-infrastructure-landscape/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6181-llm-infrastructure.jpg&#34; alt=&#34;Navigating the LLM Infrastructure Landscape&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;navigating-the-llm-infrastructure-landscape-from-cloud-giants-to-specialized-providers&#34;&gt;Navigating the LLM Infrastructure Landscape: From Cloud Giants to Specialized Providers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-introduction&#34;&gt;&lt;strong&gt;1. Introduction&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;The rapid advancement of Large Language Models (LLMs) has revolutionized a wide range of industries, from customer support to content creation and beyond. As LLMs like GPT-4, T5, and BERT become integral to AI-driven applications, the need for specialized infrastructure to support their deployment, training, and scaling has grown significantly. Traditional cloud services, while effective for general-purpose computing, often fall short in addressing the unique challenges posed by these models, such as handling vast amounts of data, providing low-latency responses, and managing the immense computational load. As a result, businesses and developers are increasingly turning to platforms specifically optimized for LLMs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring GGUF and Other Model Formats</title>
      <link>http://localhost:1313/dsblog/exploring-gguf-and-other-model-formats/</link>
      <pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-gguf-and-other-model-formats/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6180-exploring-gguf.jpg&#34; alt=&#34;Understanding GGUF and Other Model Formats in Machine Learning&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-gguf-and-other-model-formats-in-machine-learning&#34;&gt;&lt;strong&gt;Understanding GGUF and Other Model Formats in Machine Learning&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;p&gt;As machine learning models continue to grow in complexity, the need for efficient, flexible, and versatile model formats becomes more pronounced. While formats like ONNX, TensorFlow’s SavedModel, and PyTorch’s native format have been around for some time, newer formats like GGUF are gaining attention for their unique benefits. This article explores these formats, their use cases, and how they support various aspects of machine learning, including deployment, compatibility, and optimization.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring AnythingLLM</title>
      <link>http://localhost:1313/dsblog/exploring-anythingllm/</link>
      <pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-anythingllm/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6179-exploring-anythingllm.jpg&#34; alt=&#34;Exploring AnythingLLM &#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-anythingllm&#34;&gt;Exploring AnythingLLM&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-anythingllm&#34;&gt;What is AnythingLLM?&lt;/h2&gt;&#xA;&lt;p&gt;AnythingLLM is an open-source project developed by Mintplex Labs that offers a highly flexible platform for creating personalized language models and knowledge databases. It operates using Retrieval-Augmented Generation (RAG), which combines language models with data from custom document collections. AnythingLLM supports embedding models (e.g., BERT), language models, and vector databases to index and query data, allowing users to fine-tune or deploy various models tailored to their needs, from local deployments to cloud integrations with OpenAI or Azure OpenAI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Navigating Python Ecosystem</title>
      <link>http://localhost:1313/dsblog/Navigating-Python-Ecosystem/</link>
      <pubDate>Fri, 01 Nov 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Navigating-Python-Ecosystem/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6178-Navigating-Python-Ecosystem.jpg&#34; alt=&#34;Navigating Python Ecosystem&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;navigating-python-ecosystem&#34;&gt;Navigating Python Ecosystem&lt;/h1&gt;&#xA;&lt;h2 id=&#34;1-history-of-python-development&#34;&gt;1. &lt;strong&gt;History of Python Development&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Python was created by &lt;strong&gt;Guido van Rossum&lt;/strong&gt; and was first released in 1991. Its design philosophy emphasizes code readability, and its syntax allows programmers to express concepts in fewer lines of code compared to other languages like C++ or Java. Significant milestones in Python’s development include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Python 1.x (1991-2000):&lt;/strong&gt; The initial release introduced core concepts like dynamic typing, exception handling, and module support.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Python 2.x (2000-2020):&lt;/strong&gt; A major update, featuring Unicode support, list comprehensions, and improvements to object-oriented programming. However, the 2.x series was discontinued in 2020.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Python 3.x (2008-present):&lt;/strong&gt; The transition to Python 3 introduced significant changes that broke backward compatibility with Python 2, emphasizing cleaner code, improved consistency, and optimizations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Python’s growth surged with its adoption in various domains like web development, data science, machine learning, and scripting due to its simplicity, community-driven development, and rich ecosystem.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Processors for HTML CSS JS Code</title>
      <link>http://localhost:1313/dsblog/Processors-for-HTML-CSS-JS-Code/</link>
      <pubDate>Wed, 30 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Processors-for-HTML-CSS-JS-Code/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6177-Processors-for-HTML-CSS-JS-Code.jpg&#34; alt=&#34;Processors for HTML CSS JS Code&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;processors-for-html-css-and-js-code&#34;&gt;Processors for HTML, CSS, and JS Code&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-are-html-processors&#34;&gt;What are HTML Processors?&lt;/h2&gt;&#xA;&lt;p&gt;HTML processors (or preprocessors) extend HTML functionality by adding new features like templating, reusable components, loops, conditionals, and more. They simplify development by generating standard HTML with enhanced capabilities. Below are some of the most popular HTML processors and what they do:&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-pug-formerly-jade&#34;&gt;1. &lt;strong&gt;Pug (formerly Jade)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Features&lt;/strong&gt;: Templating, variables, loops, conditionals, mixins, and more concise syntax.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;What it Does&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Uses indentation instead of tags and braces, resulting in a cleaner, more readable syntax.&lt;/li&gt;&#xA;&lt;li&gt;Provides support for template logic like loops and conditionals (&lt;code&gt;if&lt;/code&gt;, &lt;code&gt;else&lt;/code&gt;, &lt;code&gt;for&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Mixins allow reusable chunks of code, like buttons or UI components.&lt;/li&gt;&#xA;&lt;li&gt;Supports template inheritance, where layouts can be extended.&lt;/li&gt;&#xA;&lt;li&gt;Compiles into HTML, useful for creating dynamic pages.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Example&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Popular Web Server</title>
      <link>http://localhost:1313/dsblog/Exploring-Popular-Web-Server/</link>
      <pubDate>Tue, 29 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Popular-Web-Server/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6176-Exploring-Popular-Web-Server.jpg&#34; alt=&#34;Exploring Popular Web Server&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-popular-web-server&#34;&gt;Exploring Popular Web Server&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-webserver&#34;&gt;What is Webserver?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;web server&lt;/strong&gt; is software or hardware that serves web content to users over the internet. It hosts, processes, and delivers web pages to clients, typically web browsers, when users request a website by entering its URL. Here’s a breakdown of what a web server does and its components:&lt;/p&gt;&#xA;&lt;h3 id=&#34;key-functions-of-a-web-server&#34;&gt;Key Functions of a Web Server:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hosting Content:&lt;/strong&gt; A web server stores website files, such as HTML, CSS, JavaScript, images, and other resources.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Handling Requests:&lt;/strong&gt; It listens for incoming requests from clients (usually browsers) and responds to them by serving the requested files or data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Serving Content:&lt;/strong&gt; The server delivers the requested content to the client, often formatted as HTML or other resources necessary to render a webpage.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;how-a-web-server-works&#34;&gt;How a Web Server Works:&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Request-Response Cycle:&lt;/strong&gt; When a user enters a URL or clicks on a link, the browser sends an HTTP (or HTTPS) request to the server. The server processes the request and responds with the requested resources.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Static and Dynamic Content:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Static&lt;/strong&gt; files (like HTML and images) are delivered as-is.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dynamic&lt;/strong&gt; content may be generated in real-time by backend applications (like PHP, Node.js, or Python scripts) before being sent to the client.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;types-of-web-servers&#34;&gt;Types of Web Servers:&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Static Servers:&lt;/strong&gt; These servers serve only static files and are ideal for sites where content does not change dynamically. For example, if you create a static website using a framework like Jekyll, the static pages are generated at deployment. If you want to make changes to the website, you’ll need to redeploy it. If you have not used any framework then you can add new pages or update existing ones without redeploying the entire site.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring All Dimensions of Application Development</title>
      <link>http://localhost:1313/dsblog/Exploring-All-Dimensions-of-Application-Development/</link>
      <pubDate>Mon, 28 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-All-Dimensions-of-Application-Development/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6175-Exploring-All-Dimensions-of-Application-Development.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-all-dimensions-of-application-development&#34;&gt;Exploring All Dimensions of Application Development&lt;/h1&gt;&#xA;&lt;p&gt;These aspects highlight the diverse areas involved in application development beyond just frontend, backend, or mobile/desktop apps. Each plays a critical role in building, deploying, and maintaining robust, scalable, and user-friendly applications.&lt;/p&gt;&#xA;&lt;p&gt;Each of these aspects is crucial to modern software development, covering everything from handling the user interface on the frontend to processing data and requests on the backend, as well as building specialized mobile or desktop applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring LLM Application Development</title>
      <link>http://localhost:1313/dsblog/Exploring-LLM-App-Development/</link>
      <pubDate>Sun, 27 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-LLM-App-Development/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6174-Exploring-LLM-App-Development.jpg&#34; alt=&#34;Exploring LLM Application Development&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-llm-application-development&#34;&gt;Exploring LLM Application Development&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-llm-application-development&#34;&gt;What is LLM Application Development?&lt;/h2&gt;&#xA;&lt;p&gt;Large Language Model (LLM) application development involves creating applications that leverage pretrained large language models, like GPT (like GPT3.5, GPT4.o), Sonnet, DALLE, SORA, BERT, T5, Gemma, RoBERTa, DINO, Turning-NLG, Phi, Llama, Stable Diffusion, Flang, Einstine, Megatron, StyleGAN, BART,  Granite, or others, to perform natural language processing tasks. Unlike classical applications, which operate on explicit programming logic, LLM-based applications rely on trained models to process human language, make predictions, and respond dynamically based on vast amounts of text data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Benchmarks Explained</title>
      <link>http://localhost:1313/dsblog/AI-Benchmarks-Explained/</link>
      <pubDate>Sat, 26 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Benchmarks-Explained/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6173-AI-Benchmarks-Explained.jpg&#34; alt=&#34;AI-Benchmarks-Explained&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-benchmarks-explained-essential-components-and-leading-llm-evaluation-techniques&#34;&gt;AI Benchmarks Explained: Essential Components and Leading LLM Evaluation Techniques&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-a-benchmark-in-ai&#34;&gt;What is a Benchmark in AI?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;benchmark&lt;/strong&gt; in AI is like a standard measurement tool that helps researchers and developers assess how well their artificial intelligence models perform. Just like athletes are judged based on their performance against specific standards, AI models are evaluated against predefined tasks and metrics.&lt;/p&gt;&#xA;&lt;p&gt;Thus, benchmarks are essential tools in the AI development ecosystem. They help ensure that AI models are evaluated fairly and consistently, providing a basis for comparison, improvement, and innovation in the field. By using benchmarks, developers can better understand their models’ capabilities and limitations, ultimately leading to more effective and robust AI systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transfer Learning Key AI Techniques Explained</title>
      <link>http://localhost:1313/dsblog/Transfer-Learning-Key-AI-Techniques-Explained/</link>
      <pubDate>Fri, 25 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Transfer-Learning-Key-AI-Techniques-Explained/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6172-Transfer-Learning-Key-AI-Techniques-Explained.jpg&#34; alt=&#34;Transfer Learning Key AI Techniques Explained&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;transfer-learning-key-ai-techniques-explained&#34;&gt;Transfer Learning Key AI Techniques Explained&lt;/h1&gt;&#xA;&lt;p&gt;In this article we will understand some important concepts used within machine learning.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is in-context Learning?&lt;/li&gt;&#xA;&lt;li&gt;What is Prompt-Engineering?&lt;/li&gt;&#xA;&lt;li&gt;What is the relationship between Prompt Engineering and In-Context Learning?&lt;/li&gt;&#xA;&lt;li&gt;What is Zero-shot learning?&lt;/li&gt;&#xA;&lt;li&gt;How Zero-shot learning is different from In-context Learning?&lt;/li&gt;&#xA;&lt;li&gt;What is Meta-Learning?&lt;/li&gt;&#xA;&lt;li&gt;What is Few-shot learning?&lt;/li&gt;&#xA;&lt;li&gt;Do we need foundational models for Meta-learning and Few-shot learning?&lt;/li&gt;&#xA;&lt;li&gt;What is transfer learning?&lt;/li&gt;&#xA;&lt;li&gt;How do we do transfer learning from existing model?&lt;/li&gt;&#xA;&lt;li&gt;What is finetuning?&lt;/li&gt;&#xA;&lt;li&gt;Which layers to update, what weight to update during finetuning?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;prompt-engineering-in-context-learning-and-zero-shot-learning&#34;&gt;Prompt Engineering, In Context Learning and Zero-shot Learning&lt;/h2&gt;&#xA;&lt;h3 id=&#34;what-is-in-context-learning&#34;&gt;What is in-context Learning?&lt;/h3&gt;&#xA;&lt;p&gt;In-Context Learning refers to a model&amp;rsquo;s ability to adapt its responses based on the context provided in the input prompt without updating its parameters or undergoing explicit training. The model uses the examples, instructions, or context given in the input to influence its behavior during inference.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Types of Large Language Models (LLM)</title>
      <link>http://localhost:1313/dsblog/Types-of-LLM/</link>
      <pubDate>Thu, 24 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Types-of-LLM/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6171-Types-of-LLM.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;&lt;strong&gt;Introduction:&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;The world of Generative AI (GenAI) is expanding at an astonishing rate, with new models emerging almost daily, each sporting unique names, capabilities, versions, and sizes. For AI professionals, keeping track of these models can feel like a full-time job. But for business users, IT professionals, and software developers trying to make the right choice, understanding the model’s name and what it represents can seem overwhelming. Wouldn’t it be helpful if we could decode the meaning behind these names to know if a model fits our needs and is worth the investment? In this article, we’ll break down how the names of GenAI models can reveal clues about their functionality and suitability for specific tasks, helping you make informed decisions with confidence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Navigating the JavaScript Ecosystem</title>
      <link>http://localhost:1313/dsblog/Navigating-the-JavaScript-Ecosystem/</link>
      <pubDate>Wed, 23 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Navigating-the-JavaScript-Ecosystem/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6170-Navigating-the-JavaScript-Ecosystem.jpg&#34; alt=&#34;Navigating the JavaScript Ecosystem&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;navigating-the-javascript-ecosystem-npm-yarn-unpkg-and-more&#34;&gt;Navigating the JavaScript Ecosystem: npm, Yarn, unpkg, and More&lt;/h1&gt;&#xA;&lt;p&gt;This article is trying to answer following questions.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Evoluation of Javascript and Relationship with Java.&lt;/li&gt;&#xA;&lt;li&gt;What are popular javascript libraries?&lt;/li&gt;&#xA;&lt;li&gt;What is Node and Node.js?&lt;/li&gt;&#xA;&lt;li&gt;Key Features of Node.js.&lt;/li&gt;&#xA;&lt;li&gt;How are Node and Node.js Related?&lt;/li&gt;&#xA;&lt;li&gt;What are the Central Repositories of Javascript Packages?&lt;/li&gt;&#xA;&lt;li&gt;What is the difference between npm and npx?&lt;/li&gt;&#xA;&lt;li&gt;What are important npx commands?&lt;/li&gt;&#xA;&lt;li&gt;What is the &amp;rsquo;export&amp;rsquo; keyword in javascript?&lt;/li&gt;&#xA;&lt;li&gt;How to Use the Exported Function?&lt;/li&gt;&#xA;&lt;li&gt;What is the meaning of workspace in Yarn pacakge manager?&lt;/li&gt;&#xA;&lt;li&gt;Key Features of Yarn Workspaces.&lt;/li&gt;&#xA;&lt;li&gt;How to Set Up Yarn Workspaces?&lt;/li&gt;&#xA;&lt;li&gt;Can I use multiple package managers in my Javascript project?&lt;/li&gt;&#xA;&lt;li&gt;What are other Important Languages and their primary purpose?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;evoluation-of-javascript-and-relationship-with-java&#34;&gt;Evoluation of Javascript and Relationship with Java.&lt;/h2&gt;&#xA;&lt;p&gt;There is no relationship between Java and JavaScript.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Applications of GenAI</title>
      <link>http://localhost:1313/dsblog/Applications-of-GenAI/</link>
      <pubDate>Tue, 22 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Applications-of-GenAI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6169-Applications-of-GenAI.jpg&#34; alt=&#34;Applications of GenAI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;application-of-generative-ai-genai&#34;&gt;Application of Generative AI (GenAI)&lt;/h1&gt;&#xA;&lt;p&gt;Generative AI (GenAI) is transforming how we interact with technology by producing human-like text, images, audio, and even code. Leveraging advanced models, especially large language models (LLMs), GenAI offers a wide range of applications across industries and data types. Let&amp;rsquo;s explore some of the key use cases and how different sectors are benefiting from this technology.&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-text-generation&#34;&gt;1. &lt;strong&gt;Text Generation&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Text generation using GenAI models is a powerful tool for automating content creation. Pretrained models can generate natural, coherent text for various business and creative purposes. This can be particularly valuable for:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Jekyll Framework</title>
      <link>http://localhost:1313/dsblog/Understanding-Jekyll-Framework/</link>
      <pubDate>Mon, 21 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Understanding-Jekyll-Framework/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6168-Understanding-Jekyll-Framework.jpg&#34; alt=&#34;Understanding Jekyll Framework&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-jekyll-framework&#34;&gt;Understanding Jekyll Framework&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-jekyll&#34;&gt;What is Jekyll?&lt;/h2&gt;&#xA;&lt;p&gt;Jekyll is a popular static site generator that transforms plain text into static websites and blogs. It&amp;rsquo;s built with Ruby and designed to be simple, flexible, and blog-aware. Key features of Jekyll include:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Simplicity: Jekyll doesn&amp;rsquo;t require databases, making it easy to set up and maintain.&lt;/li&gt;&#xA;&lt;li&gt;Static output: It generates static HTML files, resulting in fast-loading websites.&lt;/li&gt;&#xA;&lt;li&gt;Markdown support: Content can be written in Markdown for easy formatting.&lt;/li&gt;&#xA;&lt;li&gt;Templating: Uses Liquid templating language for dynamic content generation.&lt;/li&gt;&#xA;&lt;li&gt;Blog-aware: Built-in support for blog-like features such as posts, categories, and permalinks.&lt;/li&gt;&#xA;&lt;li&gt;GitHub Pages integration: Seamlessly works with GitHub Pages for free hosting.&lt;/li&gt;&#xA;&lt;li&gt;Extensibility: Supports plugins and themes for added functionality and customization.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Jekyll is ideal for developers who want a lightweight, efficient solution for creating websites without the complexity of traditional content management systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Container Registry</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Container-Registry/</link>
      <pubDate>Sun, 20 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Container-Registry/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6167-Introduction-to-Container-Registry.jpg&#34; alt=&#34;Introduction to Container Registry&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction-to-container-registry&#34;&gt;Introduction to Container Registry&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-container-registry&#34;&gt;What is Container Registry?&lt;/h2&gt;&#xA;&lt;p&gt;A container registry is a central store or service where container images are stored, managed and distributed. Container images are packaged applications that include the code, dependencies, libraries and configuration to run in any environment that supports containerization, like Docker or Kubernetes.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Key aspects of a Container Registry:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Storing Images: Container registries act as a storage for container images, where developers can push and pull images as needed. These images are often versioned and tagged so you can track different versions of an application.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI/ML with Oracle Cloud</title>
      <link>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6166-AI-ML-With-Oracle-Cloud.jpg&#34; alt=&#34;AI/ML with Oracle Cloud&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;aiml-with-oracle-cloud&#34;&gt;AI/ML with Oracle Cloud&lt;/h1&gt;&#xA;&lt;h2 id=&#34;oracle-infrastructure-services&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/services.htm&#34;&gt;Oracle Infrastructure Services&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Register for &lt;a href=&#34;https://www.oracle.com/cloud/free/?source=:ow:o:h:po:OHPPanel1nav0625&amp;amp;intcmp=:ow:o:h:po:OHPPanel1nav0625&#34;&gt;Oracle Cloud Free Tier&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;oracle-ai-main-services&#34;&gt;Oracle AI Main services&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cloud.oracle.com/digital-assistant/oda-instances?region=ap-mumbai-1&#34;&gt;Digital Assistant&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/document-understanding/using/home.htm&#34;&gt;Document Understanding&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/language/using/pretrain-models.htm#lang-detect&#34;&gt;Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/vision/using/pretrained-model-using-image.htm&#34;&gt;Vision&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/speech/home.htm&#34;&gt;Speech&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/Streaming/home.htm&#34;&gt;Stream&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/process-automation/oci-process-automation/overview-oci-process-automation.html&#34;&gt;Cloud Infra Automation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;generative-ai&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm&#34;&gt;Generative AI&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Generative AI is a fully managed Oracle Cloud Infrastructure service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, including chat, text generation, summarization, and creating text embeddings.&lt;/p&gt;</description>
    </item>
    <item>
      <title>SEO Keyword Planning</title>
      <link>http://localhost:1313/dsblog/SEO-Keyword-Planning/</link>
      <pubDate>Fri, 18 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/SEO-Keyword-Planning/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6165-SEO-Keyword-Planning.jpg&#34; alt=&#34;SEO Keyword Planning&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;seo-keyword-planning&#34;&gt;SEO Keyword Planning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;free-tools-for-seo-keyword-planning&#34;&gt;Free tools for SEO Keyword Planning&lt;/h2&gt;&#xA;&lt;p&gt;To improve the search engine ranking of your blogs, you can leverage several free tools and strategies. Here&amp;rsquo;s a guide to help you get started:&lt;/p&gt;&#xA;&lt;h3 id=&#34;free-tools-for-seo-optimization&#34;&gt;&lt;strong&gt;Free Tools for SEO Optimization&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Google Search Console&lt;/strong&gt;: Track your website&amp;rsquo;s search performance, find out how Google views your site, fix errors, and optimize content.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Submit your sitemap.&lt;/li&gt;&#xA;&lt;li&gt;Review search queries that bring users to your site.&lt;/li&gt;&#xA;&lt;li&gt;Fix coverage issues (like broken links or mobile usability problems).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Google Analytics&lt;/strong&gt;: Analyze website traffic and user behavior.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding HTML Templating with Python, Ruby, and PHP</title>
      <link>http://localhost:1313/dsblog/Understanding-HTML-Templating-with-Python-Ruby-PHP/</link>
      <pubDate>Thu, 17 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Understanding-HTML-Templating-with-Python-Ruby-PHP/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6164-Understanding-HTML-Templating-with-Python-Ruby-PHP.jpg&#34; alt=&#34;Understanding HTML Templating with Python, Ruby, and PHP&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-html-templating-with-python-ruby-and-php&#34;&gt;Understanding HTML Templating with Python, Ruby, and PHP&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-html-templating&#34;&gt;What is HTML Templating?&lt;/h2&gt;&#xA;&lt;p&gt;This concept is widely used across different frameworks and languages to build dynamic, server-rendered web applications.&lt;/p&gt;&#xA;&lt;p&gt;The concept of mixing a programming or scripting language with HTML is commonly referred to as &lt;strong&gt;&amp;ldquo;Server-Side Templating&amp;rdquo;&lt;/strong&gt; or &lt;strong&gt;&amp;ldquo;Embedding Server-Side Code in HTML&amp;rdquo;&lt;/strong&gt;. This approach allows dynamic generation of web pages by combining HTML (for structure and presentation) with server-side logic (like PHP, Python, Ruby, etc.) to create dynamic content.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Synthetic Data Generation Capabilities</title>
      <link>http://localhost:1313/dsblog/Exploring-Synthetic-Data-Generation-Capabilities/</link>
      <pubDate>Wed, 16 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Synthetic-Data-Generation-Capabilities/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6163-Exploring-Synthetic-Data-Generation-Capabilities.jpg&#34; alt=&#34;Exploring Synthetic Data Generation Capabilities&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-synthetic-data-generation-capabilities&#34;&gt;Exploring Synthetic Data Generation Capabilities&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;Are you looking answers to these questions?&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is Synthetic Data?&lt;/li&gt;&#xA;&lt;li&gt;What is data anonymization?&lt;/li&gt;&#xA;&lt;li&gt;What are different techniques for generating Anonymized Data?&lt;/li&gt;&#xA;&lt;li&gt;Why is anonymizing not sufficient to address PII data issues?&lt;/li&gt;&#xA;&lt;li&gt;When there is lots of data available around then why do we need synthetic data?&lt;/li&gt;&#xA;&lt;li&gt;What are the challenges in synthetic data generation?&lt;/li&gt;&#xA;&lt;li&gt;What are the tools for Synthetic Data Generator for Marketing&lt;/li&gt;&#xA;&lt;li&gt;What are the tools for Graph Synthetic Data generation?&lt;/li&gt;&#xA;&lt;li&gt;List of popular synthetic data generation tools for different industries&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-is-synthetic-data&#34;&gt;What is Synthetic Data?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Synthetic data&lt;/strong&gt; is artificially generated data that mimics the characteristics and statistical properties of real-world data but is not derived directly from real-world events or observations. It is created using algorithms, simulations, or models to represent patterns, structures, and relationships found in actual datasets. Synthetic data can take various forms, such as text, images, audio, or structured tabular data, depending on the context. It is used across various industries to train AI models, simulate environments, and conduct research.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring SQL and GraphQL Commands</title>
      <link>http://localhost:1313/dsblog/Exploring-SQL-and-GraphQL-Commands/</link>
      <pubDate>Tue, 15 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-SQL-and-GraphQL-Commands/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6162-Exploring-SQL-and-GraphQL-Commands.jpg&#34; alt=&#34;Exploring SQL and GraphQL Commands&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-sql-and-graphql-commands&#34;&gt;Exploring SQL and GraphQL Commands&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-sql&#34;&gt;What is SQL?&lt;/h2&gt;&#xA;&lt;p&gt;SQL, or Structured Query Language, is a standardized programming language used for managing and manipulating relational databases. It allows users to perform various operations on the data stored in a database, including:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Querying&lt;/strong&gt;: Retrieve specific data from one or more tables using the &lt;code&gt;SELECT&lt;/code&gt; statement.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Manipulation&lt;/strong&gt;: Insert new records, update existing records, and delete records using &lt;code&gt;INSERT&lt;/code&gt;, &lt;code&gt;UPDATE&lt;/code&gt;, and &lt;code&gt;DELETE&lt;/code&gt; statements.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Database Structure Management&lt;/strong&gt;: Create, modify, and delete database structures (tables, indexes, views) using Data Definition Language (DDL) commands like &lt;code&gt;CREATE&lt;/code&gt;, &lt;code&gt;ALTER&lt;/code&gt;, and &lt;code&gt;DROP&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Control&lt;/strong&gt;: Manage access permissions and control data security with commands like &lt;code&gt;GRANT&lt;/code&gt; and &lt;code&gt;REVOKE&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;SQL is widely used in various database management systems (DBMS) such as MySQL, PostgreSQL, Oracle, Microsoft SQL Server, and SQLite. Its declarative syntax makes it relatively easy to learn and use for both beginners and experienced developers.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Python Package Manager</title>
      <link>http://localhost:1313/dsblog/Exploring-Python-Package-Manager/</link>
      <pubDate>Mon, 14 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Python-Package-Manager/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6161-Exploring-Python-Package-Managers.jpg&#34; alt=&#34;Exploring Python Package Managers&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-python-package-managers&#34;&gt;Exploring Python Package Managers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-package-manager&#34;&gt;What is Package Manager?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;package manager&lt;/strong&gt; is a tool that automates the process of installing, upgrading, configuring, and removing software packages (libraries, frameworks, tools, etc.). It helps manage dependencies between packages and ensures that the correct versions are installed.&lt;/p&gt;&#xA;&lt;h3 id=&#34;key-functions-of-a-package-manager&#34;&gt;Key Functions of a Package Manager:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Install Packages&lt;/strong&gt;: Automatically downloads and installs software from a central repository or local source.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Manage Dependencies&lt;/strong&gt;: Resolves and installs the dependencies required for a package to work.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Update Packages&lt;/strong&gt;: Upgrades installed packages to their latest versions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Uninstall Packages&lt;/strong&gt;: Removes installed packages cleanly, including their dependencies if they’re no longer needed.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Version Control&lt;/strong&gt;: Allows specifying and managing multiple versions of the same package.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;example-in-python&#34;&gt;Example in Python:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pip&lt;/strong&gt;: Manages Python packages from the Python Package Index (PyPI).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Conda&lt;/strong&gt;: Manages packages for Python and other languages, handling complex dependencies like binary files.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Package managers streamline the development process, ensuring that developers can easily install and maintain software dependencies.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding Linux Distributions</title>
      <link>http://localhost:1313/dsblog/Exploring-Linux-Distributions/</link>
      <pubDate>Sun, 13 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Linux-Distributions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6160-Exploring-Linux-Distributions.jpg&#34; alt=&#34;Understanding Linux Distributions&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-linux-distributions&#34;&gt;Understanding Linux Distributions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-are-linux-distributions&#34;&gt;What are Linux Distributions?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;Linux distribution&lt;/strong&gt; (often abbreviated as &amp;ldquo;distro&amp;rdquo;) is a version of the Linux operating system that includes the Linux kernel along with a variety of software packages, libraries, and system tools. Distributions vary in their package management systems, user interfaces, included software, and target audiences. They cater to different user needs, from desktop usage to server environments, embedded systems, and more.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Google Firebase</title>
      <link>http://localhost:1313/dsblog/Exploring-Firebase/</link>
      <pubDate>Sat, 12 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Firebase/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6159-Exploring-Firebase.jpg&#34; alt=&#34;Exploring Firebase&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-firebase&#34;&gt;Exploring Firebase&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-firebase&#34;&gt;What is Firebase?&lt;/h2&gt;&#xA;&lt;p&gt;Originally, Firebase started as a product called &lt;strong&gt;Envolve&lt;/strong&gt; in 2011, which was a real-time chat service. It was co-founded by &lt;strong&gt;James Tamplin&lt;/strong&gt; and &lt;strong&gt;Andrew Lee&lt;/strong&gt;. While developing Envolve, they realized that developers were using its real-time system to sync application data, not just chat messages. This led them to pivot and create Firebase as a real-time database product in 2012. Google acquired Firebase in &lt;strong&gt;2014&lt;/strong&gt; and integrated it into its broader ecosystem, expanding it into a full-fledged platform for app development.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is Bundler?</title>
      <link>http://localhost:1313/dsblog/Exploring-Bundler/</link>
      <pubDate>Fri, 11 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Bundler/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6158-Exploring-Bundler.jpg&#34; alt=&#34;Exploring Bundler&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-bundler&#34;&gt;What is Bundler?&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Bundler&lt;/strong&gt; is a dependency management tool for Ruby applications. It ensures that the right versions of gems (libraries) are installed and used in a project. Ruby packages are called Gem. Bundler is commonly used in situations where you need to manage multiple Ruby projects with different dependencies or need to ensure that a project has all the necessary gems with specific versions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;key-points-about-bundler&#34;&gt;Key points about Bundler:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Language&lt;/strong&gt;: Bundler is used with &lt;strong&gt;Ruby&lt;/strong&gt; programming language.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: It manages gem dependencies for Ruby applications, ensuring consistent environments by locking gem versions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Usage scenario&lt;/strong&gt;:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When working with Ruby on Rails applications.&lt;/li&gt;&#xA;&lt;li&gt;When collaborating on a project where multiple developers need the same gem versions.&lt;/li&gt;&#xA;&lt;li&gt;In deployment environments where consistency between local and production gem versions is critical.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Developed by&lt;/strong&gt;: Bundler was originally created by &lt;strong&gt;Yehuda Katz&lt;/strong&gt; in 2009 as part of the Ruby community, and it is now maintained by the Bundler core team under the &lt;strong&gt;Ruby Together&lt;/strong&gt; umbrella.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;how-it-works&#34;&gt;How it works:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Gemfile&lt;/strong&gt;: You define your project&amp;rsquo;s dependencies in a &lt;code&gt;Gemfile&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install&lt;/strong&gt;: Installs the exact versions of gems specified in the Gemfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Gemfile.lock&lt;/strong&gt;: Bundler creates a &lt;code&gt;Gemfile.lock&lt;/code&gt; file to lock down the versions, ensuring consistency across different environments.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle exec&lt;/strong&gt;: Ensures that the correct versions of gems are used when running scripts or commands.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;top-50-commands-of-bundler&#34;&gt;Top 50 Commands of Bundler&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install&lt;/strong&gt; - Installs gems listed in the Gemfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle update&lt;/strong&gt; - Updates gems to the latest versions in Gemfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle exec&lt;/strong&gt; - Runs a command in the context of the Gemfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle init&lt;/strong&gt; - Creates a new Gemfile in the current directory.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle add &amp;lt;gem&amp;gt;&lt;/strong&gt; - Adds a gem to the Gemfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle remove &amp;lt;gem&amp;gt;&lt;/strong&gt; - Removes a gem from the Gemfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle check&lt;/strong&gt; - Checks if dependencies are installed.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle clean&lt;/strong&gt; - Cleans up unused gems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle outdated&lt;/strong&gt; - Lists gems that have newer versions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle lock&lt;/strong&gt; - Locks the Gemfile with the exact versions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle open &amp;lt;gem&amp;gt;&lt;/strong&gt; - Opens the source for a gem in your editor.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle console&lt;/strong&gt; - Opens an IRB session with the Gemfile&amp;rsquo;s gems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle show &amp;lt;gem&amp;gt;&lt;/strong&gt; - Shows the location of the gem.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle config&lt;/strong&gt; - Manages bundler configuration settings.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle cache&lt;/strong&gt; - Caches the gems for offline use.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle outdated &amp;ndash;local&lt;/strong&gt; - Checks for outdated gems locally.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle platform&lt;/strong&gt; - Displays your platform and gem version requirements.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle viz&lt;/strong&gt; - Generates a dependency graph.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle pristine&lt;/strong&gt; - Restores installed gems to pristine condition.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle list&lt;/strong&gt; - Lists all installed gems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle doctor&lt;/strong&gt; - Verifies the bundle environment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle gem &amp;lt;name&amp;gt;&lt;/strong&gt; - Creates a skeleton for a new gem.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle outdated &amp;lt;gem&amp;gt;&lt;/strong&gt; - Checks for outdated versions of a specific gem.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle show &amp;ndash;paths&lt;/strong&gt; - Displays the gem install paths.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle info &amp;lt;gem&amp;gt;&lt;/strong&gt; - Shows detailed information about a gem.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle exec rails &amp;lt;cmd&amp;gt;&lt;/strong&gt; - Executes Rails commands in bundle context.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install &amp;ndash;without &amp;lt;group&amp;gt;&lt;/strong&gt; - Excludes specified gem groups.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install &amp;ndash;path &amp;lt;dir&amp;gt;&lt;/strong&gt; - Installs gems to a specific directory.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle update &amp;ndash;group &amp;lt;group&amp;gt;&lt;/strong&gt; - Updates gems in a specific group.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle update &amp;lt;gem&amp;gt;&lt;/strong&gt; - Updates only a specific gem.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install &amp;ndash;deployment&lt;/strong&gt; - Installs gems for deployment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle lock &amp;ndash;add-platform&lt;/strong&gt; - Adds an additional platform to the lockfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install &amp;ndash;local&lt;/strong&gt; - Installs gems from local cache.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle inject &amp;lt;gem&amp;gt; &amp;lt;version&amp;gt;&lt;/strong&gt; - Injects a gem directly into the lockfile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install &amp;ndash;binstubs&lt;/strong&gt; - Generates binstubs for the gems.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle exec rspec&lt;/strong&gt; - Runs RSpec within the bundle environment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install &amp;ndash;jobs &amp;lt;n&amp;gt;&lt;/strong&gt; - Parallelizes gem installation with &lt;code&gt;n&lt;/code&gt; jobs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle install &amp;ndash;retry &amp;lt;n&amp;gt;&lt;/strong&gt; - Retries installation if it fails.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle update &amp;ndash;patch&lt;/strong&gt; - Updates gems to the latest patch version.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle update &amp;ndash;minor&lt;/strong&gt; - Updates gems to the latest minor version.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle update &amp;ndash;major&lt;/strong&gt; - Updates gems to the latest major version.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle show &amp;ndash;bundler&lt;/strong&gt; - Shows the installed version of Bundler.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle lock &amp;ndash;update&lt;/strong&gt; - Updates lockfile with specific gem requirements.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle config set &amp;ndash;local&lt;/strong&gt; - Sets a local configuration option.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle config set &amp;ndash;global&lt;/strong&gt; - Sets a global configuration option.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle exec rake &amp;lt;task&amp;gt;&lt;/strong&gt; - Runs a Rake task within the bundle context.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle update &amp;ndash;strict&lt;/strong&gt; - Only updates gems specified explicitly.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle binstubs &amp;lt;gem&amp;gt;&lt;/strong&gt; - Creates binstubs for a specific gem.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle plugin install&lt;/strong&gt; - Installs a Bundler plugin.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;bundle version&lt;/strong&gt; - Displays the version of Bundler.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;what-is-ruby-on-rails&#34;&gt;What is Ruby on Rails?&lt;/h2&gt;&#xA;&lt;p&gt;Here we discussed about Ruby and also mentioned about Ruby on Rails, therefore le&amp;rsquo;s understand what this is? Rails is known for making web development easier by offering a full-stack framework that supports both front-end and back-end development.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Dense Embedding Models in AI</title>
      <link>http://localhost:1313/dsblog/Exploring-Dense-Embedding-Models-in-AI/</link>
      <pubDate>Thu, 10 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Dense-Embedding-Models-in-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6157-Exploring-Dense-Embedding-Models-in-AI.jpg&#34; alt=&#34;Exploring Dense Embedding Models in AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-dense-embedding-in-ai&#34;&gt;What is dense embedding in AI?&lt;/h2&gt;&#xA;&lt;p&gt;Dense embeddings are critical in many AI applications, particularly in deep learning, where they help reduce data complexity and enhance the model’s ability to generalize from patterns in data.&lt;/p&gt;&#xA;&lt;p&gt;In artificial intelligence (AI), &lt;strong&gt;dense embedding&lt;/strong&gt; refers to a method of representing data (like words, sentences, images, or other inputs) as dense vectors in a continuous, lower-dimensional (lessor number of dimensions) space. These vectors, known as &lt;strong&gt;embeddings&lt;/strong&gt;, encode semantic information, enabling AI models to work with data in a more meaningful way.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Perplexity AI</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Perplexity-AI/</link>
      <pubDate>Tue, 08 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Perplexity-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6156-Introduction-to-Perplexity-AI.jpg&#34; alt=&#34;Introduction to Perplexity AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction-to-perplexity-ai&#34;&gt;Introduction to Perplexity AI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-perplexity-ai&#34;&gt;What is Perplexity AI?&lt;/h2&gt;&#xA;&lt;p&gt;Perplexity AI Founded in 2022 is based in San Francisco, California. Perplexity AI is an AI-powered search engine that uses a large language model to answer questions and provide information. It is a free, open-source search engine that is built on top of the latest advancements in AI and natural language processing. Perplexity AI distinguishes itself as a unique blend of a search engine and an AI chatbot, offering several features that set it apart from traditional search engines like Google and other AI models such as ChatGPT.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mastering Git: Comprehensive Guide to Git Commands</title>
      <link>http://localhost:1313/dsblog/Git-Comprehensive-Guide/</link>
      <pubDate>Mon, 07 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Git-Comprehensive-Guide/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6155-Comprehensive-Guide-to-Git-Commands.jpg&#34; alt=&#34;Mastering Git: Comprehensive Guide to Git Commands&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;comprehensive-guide-to-git-commands&#34;&gt;Comprehensive Guide to Git Commands&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are a developer and you want to learn Git commands and their usage, this article is for you. If you are a data scientist and you want to learn Git commands and their usage, this article is also for you. If you are a manager and you want to get familiarize about git commands so that you know what your team is talking about then, this article is also for you.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Selecting Database for Project</title>
      <link>http://localhost:1313/dsblog/Selecting-Database-for-Project/</link>
      <pubDate>Sat, 05 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Selecting-Database-for-Project/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6154-Selecting-Database-for-Project.jpg&#34; alt=&#34;Selecting Database for Project&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;essential-database-selection-criteria-for-modern-applications&#34;&gt;Essential Database Selection Criteria for Modern Applications&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are looking answer for these questions then &amp;ldquo;Yes&amp;rdquo;.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What parameters should you consider to choose a database for your project?&lt;/li&gt;&#xA;&lt;li&gt;What are different data formats for bigdata?&lt;/li&gt;&#xA;&lt;li&gt;What is the difference between OCR and Parquet data formats?&lt;/li&gt;&#xA;&lt;li&gt;What is CAP Theorem?&lt;/li&gt;&#xA;&lt;li&gt;What is the difference between Sharding and Partitioning&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-parameters-should-you-consider-to-choose-a-database-for-your-project&#34;&gt;What parameters should you consider to choose a database for your project?&lt;/h2&gt;&#xA;&lt;p&gt;When you are developing an application which need to store the data or you need to pull data from some format for your project work that time you need to take care of many parameters. Sometimes it looks there is an ovbious choice to go for a certain type of database for some specific work but most of the time it is challenging. What are those aspects of a database which you need to take care of?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Apache Hive</title>
      <link>http://localhost:1313/dsblog/Exploring-Apache-Hive/</link>
      <pubDate>Fri, 04 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Apache-Hive/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6153-Exploring-Apache-Hive.jpg&#34; alt=&#34;Exploring Apache Hive&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-apache-hive-capabilities-and-scalability-for-big-data-processing&#34;&gt;Exploring Apache Hive: Capabilities and Scalability for Big Data Processing&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-hive&#34;&gt;What is Hive?&lt;/h2&gt;&#xA;&lt;p&gt;Apache Hive is a data warehousing and SQL-like query engine built on top of Hadoop. It provides a platform for processing large datasets stored in Hadoop Distributed File System (HDFS) and other data storage systems that integrate with Hadoop. Hive simplifies querying and managing big data with a familiar SQL-like syntax (HiveQL). Below are the key capabilities of Hive:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning Key Concepts</title>
      <link>http://localhost:1313/dsblog/Machine-Learning-Key-Concepts/</link>
      <pubDate>Thu, 03 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Machine-Learning-Key-Concepts/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6152-Machine-Learning-Key-Concepts.jpg&#34; alt=&#34;Exploring Docker and VS Code Integration&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;machine-learning-key-concepts&#34;&gt;Machine Learning Key Concepts&lt;/h1&gt;&#xA;&lt;p&gt;In this article Essential Machine Learning Techniques/Concepts are Explained, some of them are are Cross-Validation, Hyperparameter Optimization, Machine learning types and much More.&lt;/p&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are looking for the answer to any of the following questions, then the answer is &amp;lsquo;Yes.&amp;rsquo;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;What is Cross-validation?&lt;/li&gt;&#xA;&lt;li&gt;What is Advantages of Cross-Validation?&lt;/li&gt;&#xA;&lt;li&gt;In cross-validation what is the use of the averaging the performance of 5 models?&lt;/li&gt;&#xA;&lt;li&gt;Why Averaging the Performance of Cross-Validation Models Matters:&lt;/li&gt;&#xA;&lt;li&gt;How Does Cross-Validation Help in Final Model Creation?&lt;/li&gt;&#xA;&lt;li&gt;Why Not Just Train on the Full Data from the Beginning?&lt;/li&gt;&#xA;&lt;li&gt;When should I use Cross-Validation?&lt;/li&gt;&#xA;&lt;li&gt;What is Feature Engineering?&lt;/li&gt;&#xA;&lt;li&gt;What is Regularization?&lt;/li&gt;&#xA;&lt;li&gt;What are different types of regularization techniques in ML?&lt;/li&gt;&#xA;&lt;li&gt;What is Bias-Variance Tradeoff?&lt;/li&gt;&#xA;&lt;li&gt;How to handle Bias-Variance problem?&lt;/li&gt;&#xA;&lt;li&gt;How to evaluate a model&amp;rsquo;s goodness/fitness/robustness?&lt;/li&gt;&#xA;&lt;li&gt;What is Ensemble Learning?&lt;/li&gt;&#xA;&lt;li&gt;What are different ensemble learning techniques?&lt;/li&gt;&#xA;&lt;li&gt;What is Dimensionality Reduction?&lt;/li&gt;&#xA;&lt;li&gt;What is kernel trick, can you explain with simple example?&lt;/li&gt;&#xA;&lt;li&gt;What are popular Dimensionality Reduction Techniques?&lt;/li&gt;&#xA;&lt;li&gt;What is Clustering?&lt;/li&gt;&#xA;&lt;li&gt;What are popular clustering algorithms?&lt;/li&gt;&#xA;&lt;li&gt;What is Deep Learning and Neural Networks?&lt;/li&gt;&#xA;&lt;li&gt;What is Self-Supervised Learning (SSL)?&lt;/li&gt;&#xA;&lt;li&gt;what is Meta-Learning (Learning to Learn)?&lt;/li&gt;&#xA;&lt;li&gt;What is Reinforcement Learning (RL)?&lt;/li&gt;&#xA;&lt;li&gt;What is Generative Model?&lt;/li&gt;&#xA;&lt;li&gt;What are different Generative Models?&lt;/li&gt;&#xA;&lt;li&gt;What is Federated Learning?&lt;/li&gt;&#xA;&lt;li&gt;What is Causal Inference?&lt;/li&gt;&#xA;&lt;li&gt;What is Neural Architecture Search (NAS)?&lt;/li&gt;&#xA;&lt;li&gt;What are Transformers and Attention Mechanisms?&lt;/li&gt;&#xA;&lt;li&gt;What is Explainable AI (XAI)?&lt;/li&gt;&#xA;&lt;li&gt;What are popular XAI methods?&lt;/li&gt;&#xA;&lt;li&gt;What is Uncertainty Quantification?&lt;/li&gt;&#xA;&lt;li&gt;What is Continual Learning (Lifelong Learning)?&lt;/li&gt;&#xA;&lt;li&gt;What is Adversarial Machine Learning?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;what-is-cross-validation&#34;&gt;What is Cross-validation?&lt;/h2&gt;&#xA;&lt;p&gt;In machine learning, &lt;strong&gt;cross-validation&lt;/strong&gt; is a technique used to evaluate the performance of a model by partitioning the dataset into subsets, training the model on some of these subsets, and then testing it on the remaining subsets. The goal is to assess how well the model generalizes to unseen data, thus preventing issues like overfitting or underfitting.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Docker and VS Code Integration</title>
      <link>http://localhost:1313/dsblog/Exploring-Docker-and-VS-Code-Integration/</link>
      <pubDate>Wed, 02 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Docker-and-VS-Code-Integration/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6151-Exploring-Docker-and-VS-Code-Integration.jpg&#34; alt=&#34;Exploring Docker and VS Code Integration&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-docker-and-vs-code-integration&#34;&gt;Exploring Docker and VS Code Integration&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are interested in docker, containers, VS Code and development and looking answers for the following questions then keep reading.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Question: What is use of target in docker container&amp;rsquo;s volume?&lt;/li&gt;&#xA;&lt;li&gt;Question: If I remove the contents of /vscode folder then what will happen?&lt;/li&gt;&#xA;&lt;li&gt;Question: When I have VS Code installed on my machine then why I need &amp;ldquo;VS Code Remote - Containers&amp;rdquo;?&lt;/li&gt;&#xA;&lt;li&gt;Question: Can I use &amp;ldquo;VS Code Remote - Containers&amp;rdquo; with local VS Code?&lt;/li&gt;&#xA;&lt;li&gt;Question: Can I use &amp;ldquo;VS Code Remote - Containers&amp;rdquo; without local VS Code?&lt;/li&gt;&#xA;&lt;li&gt;Question: What are formatters, linters, debuggers, profiler etc other related terms?&lt;/li&gt;&#xA;&lt;li&gt;Question: I have datasets on my local drive d:/project-datasets. How to access them from docker?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;question-what-is-use-of-target-in-docker-containers-volume&#34;&gt;Question: What is use of target in docker container&amp;rsquo;s volume?&lt;/h2&gt;&#xA;&lt;p&gt;I have a volume in container in docker. The volume name is minikube-config.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Automated Machine Learning</title>
      <link>http://localhost:1313/dsblog/AutoML-Tools/</link>
      <pubDate>Tue, 01 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AutoML-Tools/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6150-AutoML-Tools.jpg&#34; alt=&#34;What is AutoML&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;automated-machine-learning&#34;&gt;Automated Machine Learning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;This is article is for you, if you know&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;About Machine learning, ML models building&lt;/li&gt;&#xA;&lt;li&gt;That machines are capable of building these models themselves.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;But you don&amp;rsquo;t know how it happens and what are different libraries available for this work.&lt;/p&gt;&#xA;&lt;h2 id=&#34;question-what-is-automl&#34;&gt;Question: What is AutoML?&lt;/h2&gt;&#xA;&lt;p&gt;AutoML (Automated Machine Learning) is the process of automating the tasks involved in the creation of machine learning models. It aims to make machine learning more accessible by allowing users, including those without deep expertise in machine learning, to build, optimize, and deploy models with minimal manual intervention.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Code Snippnet from Colab</title>
      <link>http://localhost:1313/dsblog/Python-Code-Snippnet-from-Colab/</link>
      <pubDate>Mon, 30 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Code-Snippnet-from-Colab/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6149-Python-Code-Snippnet-from-Colab.jpg&#34; alt=&#34;Python Code Snippnet from Colab&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;python-code-snippnet-from-colab&#34;&gt;Python Code Snippnet from Colab&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-snippet&#34;&gt;What is snippet?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;snippet&lt;/strong&gt; is a small, reusable piece of code designed to perform a specific task or solve a particular problem. It’s often just a few lines long and is meant to be quickly inserted into a larger program to save time or avoid re-writing commonly used functions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;key-features-of-a-snippet&#34;&gt;Key Features of a Snippet:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Short and specific&lt;/strong&gt;: Snippets usually address a single functionality or task, such as reading a file, making a network request, or sorting data.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Reusable&lt;/strong&gt;: Snippets can be reused in multiple projects without modification.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Pre-tested&lt;/strong&gt;: Snippets are typically pre-tested, so you can trust them to work in many situations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Contextual&lt;/strong&gt;: A snippet often relies on a specific environment or language and may need to be adapted slightly to fit your use case.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;example-of-a-snippet&#34;&gt;Example of a Snippet:&lt;/h3&gt;&#xA;&lt;p&gt;For example, if you frequently need to read a file in Python, you might save a snippet like this:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Everything About Developer Console</title>
      <link>http://localhost:1313/dsblog/Everything-About-Developer-Console/</link>
      <pubDate>Sun, 29 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Everything-About-Developer-Console/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6148-Everything-About-Developer-Console.jpg&#34; alt=&#34;Everything About Developer Console&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;console-types-every-programmer-should-know&#34;&gt;Console Types Every Programmer Should Know&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are you confused about a term &amp;ldquo;console&amp;rdquo; which you heard at many places and in many context, and you want to know the following answers, then continue reading.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;What is console?&lt;/li&gt;&#xA;&lt;li&gt;What are different types of consoles?&lt;/li&gt;&#xA;&lt;li&gt;What are popular consoles?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In computer programming, a &lt;strong&gt;console&lt;/strong&gt; is an interface that allows interaction between the user and the computer system. It is typically used for text-based input/output operations, where commands or instructions can be entered, and responses or feedback are displayed. The console is widely used for debugging, monitoring system operations, or running command-line programs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Navigating Google Cloud Security: Key Components, Roles, and Best Practices</title>
      <link>http://localhost:1313/dsblog/Google-Cloud-Security-Components/</link>
      <pubDate>Sat, 28 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Google-Cloud-Security-Components/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6147-Google-Cloud-Security-Components.jpg&#34; alt=&#34;Navigating Google Cloud Security&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;navigating-google-cloud-security&#34;&gt;Navigating Google Cloud Security&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are looking answers of these questions then continue reading.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What are various components of GCP security architecture?&lt;/li&gt;&#xA;&lt;li&gt;What is overall hierarchy of GCP Security Components?&lt;/li&gt;&#xA;&lt;li&gt;What are Principal, Permission, Roles and Policies in GCP and how are they interconnected?&lt;/li&gt;&#xA;&lt;li&gt;Can you give examples of Permissions in GCP Security architecture?&lt;/li&gt;&#xA;&lt;li&gt;What are different types of resources available on GCP?&lt;/li&gt;&#xA;&lt;li&gt;Can you help me visualizing organization, folders and project of GCP?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;question-what-are-various-components-of-gcp-security-architecture&#34;&gt;Question: What are various components of GCP security architecture?&lt;/h2&gt;&#xA;&lt;p&gt;Google Cloud Platform (GCP) has a complex security architecture that consists of various components. Here’s a list of key components and their hierarchy in GCP&amp;rsquo;s security model:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Building AI-Powered Flutter Apps: Best Practices for Folder Structure</title>
      <link>http://localhost:1313/dsblog/Building-AI-Powered-Flutter-Apps/</link>
      <pubDate>Fri, 27 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Building-AI-Powered-Flutter-Apps/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6146-Building-AI-Powered-Flutter-Apps.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;building-ai-powered-flutter-apps-best-practices-for-folder-structure&#34;&gt;Building AI-Powered Flutter Apps: Best Practices for Folder Structure&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-you&#34;&gt;Is this article for you?&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;You want to create a Flutter application but are unsure of which folders should be part of your project.&lt;/li&gt;&#xA;&lt;li&gt;You’ve recently joined a Flutter project team and are struggling to understand why there are so many folders and what they contain. If you create a file, you’re not sure where it should go.&lt;/li&gt;&#xA;&lt;li&gt;Your customer wants to add AI features to an existing Flutter project, and you don’t know where to place the ML models.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;If you want to add AI features to a Flutter app but don&amp;rsquo;t have an existing AI model, and your team or company is responsible for creating them, it&amp;rsquo;s recommended to keep AI model development separate from the Flutter project. Once the model is ready, you can either embed it within the Flutter app or consume it via an API.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Project Folders and Files</title>
      <link>http://localhost:1313/dsblog/Python-Project-Folders-and-Files/</link>
      <pubDate>Thu, 26 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Project-Folders-and-Files/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6145-Python-Project-Folders-and-Files.jpg&#34; alt=&#34;Python Project Folders and Files&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-python-project-folder-structures-essential-directories-explained&#34;&gt;Understanding Python Project Folder Structures: Essential Directories Explained&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In Python projects, certain folders and files serve specific purposes to help with organizing code, managing dependencies, setting up environments, and handling version control. These important directories and files are often seen in most well-structured Python projects. Here are some of the most common ones:&lt;/p&gt;&#xA;&lt;h2 id=&#34;question-what-are-key-folders-and-files-in-python-project&#34;&gt;Question: What are key folders and files in Python Project?&lt;/h2&gt;&#xA;&lt;h3 id=&#34;1-venv&#34;&gt;1. &lt;strong&gt;&lt;code&gt;venv&lt;/code&gt; / &lt;code&gt;.venv&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: This is a &lt;strong&gt;virtual environment&lt;/strong&gt; folder that contains all the dependencies installed for a project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: Virtual environments isolate dependencies for each project so that you avoid conflicts between versions of packages that different projects might use.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Local development environments where Python packages are installed per project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;How it&amp;rsquo;s created&lt;/strong&gt;: Using &lt;code&gt;python -m venv venv&lt;/code&gt; or &lt;code&gt;python -m venv .venv&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-env&#34;&gt;2. &lt;strong&gt;&lt;code&gt;env&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: This folder contains environment-specific variables, typically used for storing configuration secrets like API keys and database credentials. Do not confuse this with venv or .venv folder which has virtual environment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: Keeping sensitive information outside the codebase is a security best practice.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Most Python projects, where &lt;code&gt;.env&lt;/code&gt; files are used with packages like &lt;code&gt;python-dotenv&lt;/code&gt; to load environment variables.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-scripts&#34;&gt;3. &lt;strong&gt;&lt;code&gt;scripts&lt;/code&gt; or &lt;code&gt;bin&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Contains custom scripts or executable files that are part of the project. Do not confuse this folder with venv/Script folder.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: This folder is useful for organizing command-line tools or automation scripts that are part of the project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Projects that require custom scripts for deployment, automation, or management.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-config&#34;&gt;4. &lt;strong&gt;&lt;code&gt;config&lt;/code&gt; or &lt;code&gt;settings&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Stores configuration files or settings, often in formats like JSON, YAML, or &lt;code&gt;.ini&lt;/code&gt;. Some frameworks (like Django) use this folder for their settings.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: Keeping configuration in a separate folder helps modularize your project, especially for different environments (e.g., &lt;code&gt;development&lt;/code&gt;, &lt;code&gt;production&lt;/code&gt;).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Any project that requires multiple environments or has a complex configuration.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-build&#34;&gt;5. &lt;strong&gt;&lt;code&gt;build&lt;/code&gt; and &lt;code&gt;dist&lt;/code&gt; Folders&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: These folders contain the &lt;strong&gt;compiled distributions&lt;/strong&gt; of your package, typically generated by tools like &lt;code&gt;setuptools&lt;/code&gt; or &lt;code&gt;poetry&lt;/code&gt; when packaging your project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: If you&amp;rsquo;re distributing your project as a package (e.g., on PyPI), these folders hold the files that get uploaded.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Python projects that are packaged and distributed as libraries or applications.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;How it&amp;rsquo;s created&lt;/strong&gt;: Using &lt;code&gt;python setup.py sdist&lt;/code&gt; or &lt;code&gt;poetry build&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-src&#34;&gt;6. &lt;strong&gt;&lt;code&gt;src&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Some projects store all their source code inside a &lt;code&gt;src/&lt;/code&gt; directory to make the distinction between code and other project files.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: It helps enforce a cleaner project structure and avoids accidental import issues, where test files or other modules might be wrongly imported.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Medium to large-sized projects where organization is critical.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-docs&#34;&gt;7. &lt;strong&gt;&lt;code&gt;docs&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Contains project documentation, such as API references, guides, and other written materials.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: Good documentation helps users and contributors understand how to use and contribute to the project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Larger open-source or professional projects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: This folder often contains &lt;code&gt;Sphinx&lt;/code&gt; or &lt;code&gt;MkDocs&lt;/code&gt; configuration files for generating HTML or PDF documentation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-migrations&#34;&gt;8. &lt;strong&gt;&lt;code&gt;migrations&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: If using a web framework like Django, this folder contains migration files that track changes to the database schema.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: Migrations allow for smooth upgrades and downgrades of your database schema over time.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Projects that use an ORM (Object-Relational Mapper) like Django&amp;rsquo;s or SQLAlchemy&amp;rsquo;s migration system.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-git&#34;&gt;9. &lt;strong&gt;&lt;code&gt;.git&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: This is a hidden folder that Git uses to track all version control information for your project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: It stores the entire history of changes to your code, along with branch information, commit data, and more.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Any project that is tracked using Git (and typically hosted on platforms like GitHub, GitLab, etc.).&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;How it&amp;rsquo;s created&lt;/strong&gt;: By initializing a Git repository with &lt;code&gt;git init&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-notebooks&#34;&gt;10. &lt;strong&gt;&lt;code&gt;notebooks&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Holds Jupyter notebooks (&lt;code&gt;.ipynb&lt;/code&gt; files) for interactive code, data exploration, or tutorials.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: This is especially useful for projects related to data science, machine learning, or educational materials.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Data science and machine learning projects, as well as educational repositories.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;11-tests&#34;&gt;11. &lt;strong&gt;&lt;code&gt;tests&lt;/code&gt; or &lt;code&gt;test&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Contains test cases and test scripts for your project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: Having a dedicated &lt;code&gt;tests&lt;/code&gt; folder makes it easier to organize and run unit tests, ensuring the reliability of your code.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Any professional Python project following good development practices.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tools&lt;/strong&gt;: Python projects often use testing frameworks like &lt;code&gt;unittest&lt;/code&gt;, &lt;code&gt;pytest&lt;/code&gt;, or &lt;code&gt;nose&lt;/code&gt; to write and run tests in this folder.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;12-__pycache__&#34;&gt;12. &lt;strong&gt;&lt;code&gt;__pycache__&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Python stores compiled bytecode in this folder to speed up module loading.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: It helps Python run faster by storing the compiled versions of your scripts so that they don’t need to be recompiled each time they are run.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Any Python project or module once the code has been executed.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;How it&amp;rsquo;s created&lt;/strong&gt;: Automatically generated by Python when running scripts.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;13-static&#34;&gt;13. &lt;strong&gt;&lt;code&gt;static&lt;/code&gt; or &lt;code&gt;assets&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Stores static files such as images, CSS, JavaScript, etc., used in web projects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: Web projects, especially in frameworks like Django or Flask, need a place to keep static files that are served directly to the client.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Web development projects.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;14-data&#34;&gt;14. &lt;strong&gt;&lt;code&gt;data&lt;/code&gt; Folder&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: Stores raw or processed datasets that are used in the project.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Why it&amp;rsquo;s important&lt;/strong&gt;: In data science or machine learning projects, keeping datasets organized is crucial for reproducibility and versioning.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Commonly Seen In&lt;/strong&gt;: Data science and machine learning projects.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;summary-of-common-folders-in-a-python-project&#34;&gt;Summary of Common Folders in a Python Project:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;code&gt;.venv&lt;/code&gt;/&lt;code&gt;venv&lt;/code&gt;: Virtual environment.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;__pycache__&lt;/code&gt;: Compiled bytecode.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;tests&lt;/code&gt;: Test cases.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;src&lt;/code&gt;: Source code.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;docs&lt;/code&gt;: Documentation.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;build&lt;/code&gt;/&lt;code&gt;dist&lt;/code&gt;: Distribution files.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;migrations&lt;/code&gt;: Database migrations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;.git&lt;/code&gt;: Git version control.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;notebooks&lt;/code&gt;: Jupyter notebooks.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;config&lt;/code&gt;: Configuration files.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;static&lt;/code&gt;/&lt;code&gt;assets&lt;/code&gt;: Static files for web apps.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;scripts&lt;/code&gt;: Custom scripts.&lt;/li&gt;&#xA;&lt;li&gt;&lt;code&gt;data&lt;/code&gt;: Datasets.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;By organizing these folders properly, Python projects can be easier to navigate, maintain, and collaborate on.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GenAI Capabilities from AWS, Azure and GCP</title>
      <link>http://localhost:1313/dsblog/GenAI-Capabilities-from-AWS&#43;GCP&#43;Azure/</link>
      <pubDate>Wed, 25 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/GenAI-Capabilities-from-AWS&#43;GCP&#43;Azure/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6144-GenAI-Capabilities-from-AWS&amp;#43;GCP&amp;#43;Azure.jpg&#34; alt=&#34;GenAI Capabilities from AWS, Azure, and Google Cloud&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;the-battle-for-ai-supremacy-genai-capabilities-from-aws-azure-and-google-cloud&#34;&gt;The Battle for AI Supremacy: GenAI Capabilities from AWS, Azure, and Google Cloud&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this Article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are looking for answer of following questions then this article is for you, else you can skip this.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Who are the major players in GenAI Market?&lt;/li&gt;&#xA;&lt;li&gt;What is their main focus area?&lt;/li&gt;&#xA;&lt;li&gt;What are services they are offering?&lt;/li&gt;&#xA;&lt;li&gt;How to know X1 GenAI service of player one is similar to X2 of player two?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;introduction-genai-capabilities-from-key-players&#34;&gt;Introduction: &lt;strong&gt;GenAI Capabilities from Key Players&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;In recent times, generative AI (GenAI) has made a thunderbolt-like entry into the tech landscape, transforming industries and disrupting traditional workflows with unprecedented speed. As organizations increasingly leverage AI to power intelligent applications and automate tasks, the major cloud providers—Amazon Web Services (AWS), Microsoft Azure, and Google Cloud—are fiercely competing to offer the most comprehensive AI services. These key players have invested heavily in generative AI technologies, aiming to dominate the AI-driven market with powerful tools and scalable infrastructure.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Ollama &amp; LM Studio</title>
      <link>http://localhost:1313/dsblog/Exploring-Ollama/</link>
      <pubDate>Wed, 18 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Ollama/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6143-Exploring-Ollama.jpg&#34; alt=&#34;Exploring Ollama &amp;amp; LM Studio&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-ollama--lm-studio&#34;&gt;Exploring Ollama &amp;amp; LM Studio&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are looking answers to the following questions, then this article is for you:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Question: What is Ollama? Is it like Docker?&lt;/li&gt;&#xA;&lt;li&gt;Question: How is Ollama different from Docker?&lt;/li&gt;&#xA;&lt;li&gt;Question: How to install ollama on my machine?&lt;/li&gt;&#xA;&lt;li&gt;Question: How to create customized LLM Model (docker like image)?&lt;/li&gt;&#xA;&lt;li&gt;Question: What are the LLM available on ollama?&lt;/li&gt;&#xA;&lt;li&gt;Question: Can we integrate these hundreds with different UI like ChatGPT?&lt;/li&gt;&#xA;&lt;li&gt;Question: If I want to use all these Ollama models via Jupyter Notebook then what to do?&lt;/li&gt;&#xA;&lt;li&gt;Question: Does Ollama have plugins like github copilot? Can I use those from my visual code?&lt;/li&gt;&#xA;&lt;li&gt;Question: What kind of software are LM Studio or Ollama?&lt;/li&gt;&#xA;&lt;li&gt;Question: What is LM Studio and how different it is from Ollama?&lt;/li&gt;&#xA;&lt;li&gt;Question: What are different formats to save model, specifically LLMs?&lt;/li&gt;&#xA;&lt;li&gt;Question: What is gguf model extention?&lt;/li&gt;&#xA;&lt;li&gt;Question: If I have finetuned my models using clouds like aws sagemaker, vertexai, azure and kept there then can I use them inside my ollama and LM Studio?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;question-what-is-ollama-is-it-like-docker&#34;&gt;Question: What is Ollama? Is it like Docker?&lt;/h2&gt;&#xA;&lt;p&gt;Ollama is a platform designed to make running and interacting with large language models (LLMs) easier. It abstracts away the complexities of managing LLM models, GPU resources, and related configurations by offering a simple CLI interface. With Ollama, you can run, manage, and deploy LLMs locally or in various cloud environments without having to worry about the intricate details of setting up environments, downloading models, or configuring them.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Github</title>
      <link>http://localhost:1313/dsblog/Exploring-Github/</link>
      <pubDate>Tue, 17 Sep 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-Github/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6142-Exploring-Github.jpg&#34; alt=&#34;Exploring Github&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-github&#34;&gt;Exploring Github&lt;/h1&gt;&#xA;&lt;h2 id=&#34;question-what-is-github-package-and-what-can-i-do-with-this&#34;&gt;Question: What is github package and what can I do with this?&lt;/h2&gt;&#xA;&lt;p&gt;GitHub Packages is a service that allows you to host and manage packages (e.g., code libraries, Docker containers) within GitHub. Here&amp;rsquo;s a breakdown of what you can do or achieve with GitHub Packages:&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-host-and-share-packages&#34;&gt;1. &lt;strong&gt;Host and Share Packages&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Languages Supported&lt;/strong&gt;: You can host packages for multiple programming languages, such as:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;npm&lt;/strong&gt; (JavaScript/Node.js)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Maven&lt;/strong&gt; (Java)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;NuGet&lt;/strong&gt; (C#/.NET)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;RubyGems&lt;/strong&gt; (Ruby)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Python&lt;/strong&gt; (PyPI)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Docker&lt;/strong&gt; (Container images)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Share Packages&lt;/strong&gt;: You can share packages publicly or privately within an organization or with collaborators.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-seamless-integration-with-github-repositories&#34;&gt;2. &lt;strong&gt;Seamless Integration with GitHub Repositories&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You can tightly integrate packages with GitHub repositories. This allows for automated versioning, releasing, and managing packages in tandem with your code changes.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Release Automation&lt;/strong&gt;: Automate package publishing during a GitHub release or via CI/CD pipelines (GitHub Actions).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-versioning-and-dependency-management&#34;&gt;3. &lt;strong&gt;Versioning and Dependency Management&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GitHub Packages supports semantic versioning. This means you can publish new versions of your package and manage dependencies within your projects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Dependency Graph&lt;/strong&gt;: View dependencies in your repository, understand their relationships, and check for vulnerabilities.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Link with Code&lt;/strong&gt;: GitHub Packages is linked with repositories, so you can easily trace which version of your package is linked with which repository or commit.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;4-private-package-hosting&#34;&gt;4. &lt;strong&gt;Private Package Hosting&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Host private packages that are accessible only to specific people, teams, or organizations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Role-based Access Control&lt;/strong&gt;: Control who can view, download, or publish to your packages using GitHub&amp;rsquo;s role-based access.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;5-container-hosting-docker-and-oci-images&#34;&gt;5. &lt;strong&gt;Container Hosting (Docker and OCI Images)&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use GitHub Packages as a Docker registry to store and manage your Docker images.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Build &amp;amp; Deploy Containers&lt;/strong&gt;: Automate the building and publishing of Docker images via GitHub Actions and deploy them using platforms like Kubernetes.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;6-integrate-with-github-actions&#34;&gt;6. &lt;strong&gt;Integrate with GitHub Actions&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;You can automate the entire package lifecycle (build, test, publish) using GitHub Actions.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;CI/CD Pipelines&lt;/strong&gt;: Use GitHub Actions to automatically publish packages whenever code is merged, tests pass, or new releases are created.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;7-security-and-auditing&#34;&gt;7. &lt;strong&gt;Security and Auditing&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Signed Packages&lt;/strong&gt;: GitHub Packages can be configured to require packages to be signed, adding an extra layer of security.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Package Scanning&lt;/strong&gt;: GitHub also scans packages for known vulnerabilities, helping you avoid security risks in your dependencies.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;8-search-and-discovery&#34;&gt;8. &lt;strong&gt;Search and Discovery&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Discover Public Packages&lt;/strong&gt;: Search for public packages published by other users or organizations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Tagging and Labeling&lt;/strong&gt;: Use tags and labels to categorize your packages, making them easier to find and manage.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;9-package-insights-and-usage-metrics&#34;&gt;9. &lt;strong&gt;Package Insights and Usage Metrics&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;View download statistics, such as how many times a package has been downloaded, and track overall usage trends.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Repository Insights&lt;/strong&gt;: See which repositories are consuming or contributing to your packages.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;10-custom-registries&#34;&gt;10. &lt;strong&gt;Custom Registries&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GitHub allows you to host your own private or public package registries for your team or organization.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;use-cases-for-github-packages&#34;&gt;Use Cases for GitHub Packages:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Publishing Libraries&lt;/strong&gt;: Share reusable libraries and code modules (e.g., npm packages, Python libraries) with teams or the public.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Managing Internal Tools&lt;/strong&gt;: Host internal dependencies or tools that are not meant to be shared publicly.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Docker Image Management&lt;/strong&gt;: Manage and distribute Docker images for deploying applications.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Automated Releases&lt;/strong&gt;: Build automated pipelines to publish, test, and deploy code to production environments.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;GitHub Packages is particularly useful for teams or individuals who want a fully integrated solution to manage both their source code and dependencies in one place.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is Package Manager?</title>
      <link>http://localhost:1313/dsblog/What-is-Package-Manager/</link>
      <pubDate>Thu, 29 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-Package-Manager/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6141-What-is-Package-Manager.jpg&#34; alt=&#34;What-is-Package-Manager&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;question-what-is-package-manager&#34;&gt;Question: What is Package Manager?&lt;/h1&gt;&#xA;&lt;p&gt;Package managers help simplify the process of software installation, updating, and dependency management on their respective platforms.&lt;/p&gt;&#xA;&lt;h2 id=&#34;question-why-are-there-so-many-package-managers&#34;&gt;Question: Why are there so many package managers?&lt;/h2&gt;&#xA;&lt;p&gt;The variety of package managers exists because different environments, languages, and operating systems have different needs for installing, updating, and managing software. The diversity of these ecosystems leads to specialized tools optimized for the specific challenges of each context. The key reasons for which there are so many package managers are:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Tensorflow GPU Setup on Local Machine</title>
      <link>http://localhost:1313/dsblog/Tensorflow-gpu-setup-on-local-machine/</link>
      <pubDate>Wed, 28 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Tensorflow-gpu-setup-on-local-machine/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6140-Tensorflow-gpu-setup-on-local-machine.jpg&#34; alt=&#34;Tensorflow GPU Setup on Local Machine&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;tensorflow-gpu-setup-on-local-machine&#34;&gt;Tensorflow GPU Setup on Local Machine&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Tensorflow, pytorch are deep learning libraries or packages. Tensorflow is developed by google and pytorch is developed by Meta. There are some other but these are the most popular one among Machine Learning and Deep Learning Engineers. If you are doing anything significant in NLP, computer vision, voice processing you must have used this library. But the power of the these libraries lies in parallel metrics/tensor computation. For that they use hardwardes like GPU or TPU which has thousands of core and they designed purely for metrics/tensor processing. Intially they were used for gaming purpose but with the surge of AI these machines are in high use and used for model training and inference purpose.&lt;/p&gt;</description>
    </item>
    <item>
      <title>All About AI Hype</title>
      <link>http://localhost:1313/dsblog/All-About-ai-Hype/</link>
      <pubDate>Tue, 27 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/All-About-ai-Hype/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6139-All-About-ai-Hype.jpg&#34; alt=&#34;All About AI Hype&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;all-about-ai-hype&#34;&gt;All About AI Hype&lt;/h1&gt;&#xA;&lt;p&gt;Artificial Intelligence (AI) is a buzzword that has permeated almost every aspect of modern life. From the way we work and communicate to how we manage our environment and interact with animals, AI&amp;rsquo;s impact is being felt far and wide. But how deep is this impact, really? Is it truly revolutionary, or is it just another over-hyped trend that will fade with time?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Variations of Language Model in Huggingface</title>
      <link>http://localhost:1313/dsblog/Variations-of-Language-Model-in-Huggingface/</link>
      <pubDate>Thu, 22 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Variations-of-Language-Model-in-Huggingface/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6138-Variations-of-Language-Model-in-Huggingface.jpg&#34; alt=&#34;Variations-of-LanguageModel&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;variations-of-language-model-in-huggingface&#34;&gt;Variations of Language Model in Huggingface&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-the-model-variable-in-huggingface&#34;&gt;What the Model variable in Huggingface?&lt;/h2&gt;&#xA;&lt;p&gt;We know base moels like BERT, T5, GPT2, GPT3 etc are developed by researchers working with different companies. But when we look into huggingface model repository we see other models like GPT2LMHeadModel, GPT2ForSequenceClassification, etc what are these?&lt;/p&gt;&#xA;&lt;p&gt;Huggingface picks up base moel like GPT2, BERT, T5 etc and tune these for specific tasks. Therefore these are different variations of GPT-2 models, such as &lt;code&gt;GPT2LMHeadModel&lt;/code&gt;, &lt;code&gt;GPT2DoubleHeadsModel&lt;/code&gt;, &lt;code&gt;GPT2ForSequenceClassification&lt;/code&gt;, etc., were primarily created by Hugging Face. These are adaptations of the original GPT-2 model released by OpenAI, tailored to fit specific tasks in natural language processing (NLP).&lt;/p&gt;</description>
    </item>
    <item>
      <title>MLOps Tools</title>
      <link>http://localhost:1313/dsblog/MLOps-Tools/</link>
      <pubDate>Tue, 13 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/MLOps-Tools/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6137-MLOps-Tools.jpg&#34; alt=&#34;MLOps-Tools&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;mlops-tools&#34;&gt;MLOps Tools&lt;/h1&gt;&#xA;&lt;p&gt;MLOps (Machine Learning Operations) is a set of practices and tools designed to streamline and automate the deployment, monitoring, and management of machine learning models in production environments. It combines principles from both DevOps (Development Operations) and machine learning to ensure that ML models are deployed efficiently, managed effectively, and maintained reliably throughout their lifecycle.&lt;/p&gt;&#xA;&lt;p&gt;MLOps ensures:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Efficiency: Automates repetitive tasks, reducing manual effort and speeding up model deployment.&lt;/li&gt;&#xA;&lt;li&gt;Consistency: Ensures consistent and reliable model performance through standardized processes.&lt;/li&gt;&#xA;&lt;li&gt;Scalability: Facilitates scaling of models and infrastructure to handle increased workloads.&lt;/li&gt;&#xA;&lt;li&gt;Reliability: Enhances the reliability of ML systems by monitoring performance and quickly addressing issues.&lt;/li&gt;&#xA;&lt;li&gt;Compliance: Helps meet regulatory and compliance requirements by managing data security and model governance&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;mlops-activities&#34;&gt;MLOps Activities&lt;/h2&gt;&#xA;&lt;p&gt;MLOps (Machine Learning Operations) encompasses a wide range of activities that are essential for developing, deploying, and maintaining machine learning models in production. Below is a comprehensive list of activities involved in MLOps:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Programming Resources</title>
      <link>http://localhost:1313/dsblog/Programming-Resources/</link>
      <pubDate>Mon, 12 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Programming-Resources/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6136-Programming-Resources.jpg&#34; alt=&#34;Programming-Resources&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;programming-resources&#34;&gt;Programming Resources&lt;/h1&gt;&#xA;&lt;h2 id=&#34;programming&#34;&gt;Programming&lt;/h2&gt;&#xA;&lt;h3 id=&#34;learning-with-others&#34;&gt;Learning with Others&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.codementor.io&#34;&gt;Codementor&lt;/a&gt; : A mentorship community to learn from fellow developers via live 1:1 help and more.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.devrant.io&#34;&gt;devRant&lt;/a&gt; : Community where you can rant and release your stress&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learn-anything.xyz&#34;&gt;Learn Anything&lt;/a&gt; : Community curated knowledge graph of best paths for learning anything&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.quora.com&#34;&gt;Quora&lt;/a&gt; : A place to share knowledge and better understand the world&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com&#34;&gt;Stack Overflow&lt;/a&gt; : subscribe to their weekly newsletter and any other topic which you find interesting&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dashboard.nbshare.io/apps/stackoverflow/top-javascript-questions/&#34;&gt;Stackoverflow High Scored JS Questions&lt;/a&gt; : Dashboard to track top Javascript questions asked on Stackoverflow&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;some-project-ideas&#34;&gt;Some Project Ideas&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/every-time-you-build-a-to-do-list-app-a-puppy-dies-505b54637a5d?gi=c786640fbd11&#34;&gt;freeCodeCamp - React project ideas&lt;/a&gt; : 27 fun app ideas you can build while learning React.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.dreamincode.net/forums/topic/78802-martyr2s-mega-project-ideas-list/&#34;&gt;martyr2s-mega-project-ideas-list&lt;/a&gt; : contains about 125 project ideas from beginner to intermediate level.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/karan/Projects&#34;&gt;karan/Projects&lt;/a&gt; : a large collection of small projects for beginners with&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rodiongork.tumblr.com/post/108155476418/wrong-big-projects-for-beginners&#34;&gt;Wrong &amp;ldquo;big projects&amp;rdquo; for beginners&lt;/a&gt; : How to choose where to start&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/vicky002/1000_Projects&#34;&gt;vicky002/1000-Projects&lt;/a&gt; : Mega List of practical projects that one can solve in any programming language!&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/AppIdeas/&#34;&gt;reddit.com/r/AppIdeas&lt;/a&gt; : A place to discuss ideas for applications, for bored developers.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/SomebodyMakeThis/&#34;&gt;reddit.com/r/SomebodyMakeThis&lt;/a&gt; : A home for ideas by people who lack time, money, or skills.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.interviewbit.com/blog/javascript-projects/&#34;&gt;InterviewBit - JavaScript Projects Ideas&lt;/a&gt; : Top 15+ JavaScript Projects Ideas.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;some-important-coding-artciles&#34;&gt;Some Important Coding Artciles&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stephenhaunts.files.wordpress.com/2014/04/10-ways-to-be-a-better-developer.png&#34;&gt;10-ways-to-be-a-better-developer&lt;/a&gt; : Ways to become a better dev!&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.infoq.com/articles/Starting-With-MongoDB/&#34;&gt;14 Things I Wish I’d Known When Starting with MongoDB&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://carlcheo.com/compsci&#34;&gt;40 Keys Computer Science Concepts Explained In Layman’s Terms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dev.to/vaidehijoshi/a-gentle-introduction-to-graph-theory&#34;&gt;A Gentle Introduction To Graph Theory&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://moonscript.org&#34;&gt;A programmer-friendly language that compiles to Lua.&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stevewedig.com/2014/02/03/software-developers-reading-list/&#34;&gt;A Software Developer’s Reading List&lt;/a&gt; : Some good books and links in there.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.saminiir.com/lets-code-tcp-ip-stack-5-tcp-retransmission/&#34;&gt;Code a TCP/IP stack&lt;/a&gt; : Let&amp;rsquo;s code a TCP/IP stack, 5: TCP Retransmission&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kevinlondon.com/2015/05/05/code-review-best-practices.html&#34;&gt;Code Review Best Practices&lt;/a&gt; : Kevin London&amp;rsquo;s blog&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://codewords.recurse.com/issues/four/the-language-of-choice&#34;&gt;Codewords.recurse&lt;/a&gt; : The language of choice&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sourcemaking.com/design_patterns&#34;&gt;Design Patterns&lt;/a&gt; : Design Patterns explained in detail with examples.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://developforperformance.com&#34;&gt;Develop for Performance&lt;/a&gt; : High-performance computing techniques for software architects and developers&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikiwand.com/en/Java_bytecode&#34;&gt;Dive into the byte code&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blog.thefirehoseproject.com/posts/expectations-of-a-junior-developer/&#34;&gt;Expectations of a Junior Developer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://studio3t.com/knowledge-base/articles/mongodb-getting-started/&#34;&gt;Getting Started with MongoDB – An Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://okepi.wordpress.com/2014/08/21/how-to-become-a-programmer-or-the-art-of-googling-well/&#34;&gt;How to become a programmer or the art of Googling well&lt;/a&gt; : How to become a programmer or the art of Googling well&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/how-to-escape-tutorial-purgatory-as-a-new-developer-or-at-any-time-in-your-career-e3a4b2384a40&#34;&gt;How to escape tutorial purgatory as a new developer — or at any time in your career&lt;/a&gt; : How to escape tutorial purgatory&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://logit.io/blog/post/elk-stack-guide&#34;&gt;How to install ELK&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/wearehive/project-guidelines&#34;&gt;JS Project Guidelines&lt;/a&gt; : A set of best practices for JavaScript projects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learntocodewith.me&#34;&gt;Learn to Code With Me&lt;/a&gt; : A comprehensive site resource by Laurence Bradford for developers who aims to build a career in the tech world&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://addyosmani.com/resources/essentialjsdesignpatterns/book/&#34;&gt;Learning JavaScript Design Patterns&lt;/a&gt; : the online version of the Learning JavaScript Design Patterns published by O&amp;rsquo;Reilly, released by the author Addy Osmani under CC BY-NC-ND 3.0&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hackernoon.com/learning-vim-what-i-wish-i-knew-b5dca186bef7&#34;&gt;Learning Vim&lt;/a&gt; : What I Wish I Knew&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://thecodist.com/article/lessons_from_a_lifetime_of_being_a_programmer&#34;&gt;Lessons From A Lifetime Of Being A Programmer&lt;/a&gt; : The Codist Header Lessons From A Lifetime Of Being A Programmer&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://0xax.gitbooks.io/linux-insides/content/Booting/linux-bootstrap-1.html&#34;&gt;Linux Inside&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikiwand.com/en/List_of_algorithms&#34;&gt;List of algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.pixelbeat.org/docs/unix-parallel-tools.html&#34;&gt;Pixel Beat - Unix&lt;/a&gt; : Parallel processing with Unix tools&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://qotoqot.com/blog/improving-focus/&#34;&gt;qotoqot - improving-focus&lt;/a&gt; : How I got to 200 productive hours a month&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://en.wikipedia.org/wiki/Software_design_pattern&#34;&gt;Software design pattern&lt;/a&gt; : The entire collection of Design Patterns.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.databasestar.com/normalization-in-dbms/&#34;&gt;Step by Step Guide to Database Normalization&lt;/a&gt;: A guide to database normalization.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blog.thefirehoseproject.com/posts/learn-to-code-and-be-self-reliant/&#34;&gt;The Key To Accelerating Your Coding Skills&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.owasp.org&#34;&gt;The Open Web Application Security Project (OWASP)&lt;/a&gt; : OWASP is an open community dedicated to enabling organizations to conceive, develop, acquire, operate, and maintain applications that can be trusted.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.com/things-i-wish-someone-had-told-me-when-i-was-learning-how-to-code-565fc9dcb329?gi=fc6d0a309be&#34;&gt;Things I Wish Someone Had Told Me When I Was Learning How to Code — Free Code Camp&lt;/a&gt; : What I’ve learned from teaching others&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.joelonsoftware.com/2003/10/08/the-absolute-minimum-every-software-developer-absolutely-positively-must-know-about-unicode-and-character-sets-no-excuses/&#34;&gt;Unicode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://multithreaded.stitchfix.com&#34;&gt;We are reinventing the retail industry through innovative technology&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://matt.might.net/articles/what-cs-majors-should-know/&#34;&gt;What every computer science major should know&lt;/a&gt; : The Principles of Good Programming&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://kunststube.net/encoding/&#34;&gt;What every programmer absolutely, positively needs to know about encodings and character sets to work with text&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://futuretech.blinkenlights.nl/misc/cpumemory.pdf&#34;&gt;What every programmer should know about memory - PDF&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://henrikwarne.com/2012/12/12/working-as-a-software-developer/&#34;&gt;Working as a Software Developer&lt;/a&gt; : Henrik Warne&amp;rsquo;s blog&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://requestbin.com/blog/working-with-webhooks/&#34;&gt;Working with Webhooks&lt;/a&gt; : a comprehensive guide on webhooks&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://arjunsreedharan.org/post/82710718100/kernel-101-lets-write-a-kernel&#34;&gt;Write a Kernel&lt;/a&gt; : Kernel 101 – Let’s write a Kernel&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;coding-style&#34;&gt;Coding Style&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/airbnb/javascript&#34;&gt;Airbnb JS Style Guide&lt;/a&gt; : A mostly reasonable approach to JavaScript&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/airbnb/ruby&#34;&gt;Airbnb Ruby Style Guide&lt;/a&gt; : A ruby style guide by Airbnb&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/bbatsov/ruby-style-guide&#34;&gt;Ruby coding style guide&lt;/a&gt; : A community-driven Ruby coding style guide&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/johnpapa/angular-styleguide/tree/master/a1&#34;&gt;Angular Style Guide&lt;/a&gt; : Officially endorsed style guide by John Pappa&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://stanford.edu/class/archive/cs/cs106b/cs106b.1158/styleguide.shtml&#34;&gt;CS 106B Coding Style Guide&lt;/a&gt; : must see for those who create spaghetti&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.umich.edu/~eecs381/generalFAQ/Debugging.html&#34;&gt;Debugging Faqs&lt;/a&gt; : Check out how to debug your program&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/prakhar1989/awesome-courses&#34;&gt;Directory of CS Courses (many with online lectures)&lt;/a&gt; : Another online CS courses&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ossu/computer-science&#34;&gt;Directory of Online CS Courses&lt;/a&gt; : Free online CS courses&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/C_Programming/comments/1vuubw/good_c_programming_habits/&#34;&gt;Good C programming habits. • /r/C_Programming&lt;/a&gt; : C programming habits to adopt&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/cppguide.html&#34;&gt;Google C++ Style Guide&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.chiark.greenend.org.uk/~sgtatham/bugs.html&#34;&gt;How to Report Bugs Effectively&lt;/a&gt; : Want to report a bug but you don&amp;rsquo;t how? Check out this post&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.reddit.com/r/learnprogramming/comments/1i4ds4/what_are_some_bad_coding_habits_you_would/&#34;&gt;What are some bad coding habits you would recommend a beginner avoid getting into?&lt;/a&gt; : Bad habits to avoid when you get start&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/dev/peps/pep-0008/&#34;&gt;PEP8 - Style Guide for Python Code&lt;/a&gt; : Style Guide for Python Code&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://standardjs.com&#34;&gt;Standard JS Style Guide&lt;/a&gt; : JavaScript style guide, with linter &amp;amp; automatic code fixer&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://google.github.io/styleguide/pyguide.html&#34;&gt;Google Python Style Guide&lt;/a&gt; : Google Python Style Guide&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/behzad888/Aurelia-styleguide&#34;&gt;Aurelia Style Guide&lt;/a&gt; : An Aurelia style guide by Behzad Abbasi(Behzad888)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sourcemaking.com/&#34;&gt;Source Making&lt;/a&gt; : Design Patterns &amp;amp; Refactoring&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://refactoring.guru/&#34;&gt;Refactoring Guru&lt;/a&gt;: Refactoring And Design Patterns&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;collection-of-leetcode-problem-solution&#34;&gt;Collection of Leetcode Problem solution&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/AlanWei/LeetCode&#34;&gt;github.com/AlanWei/LeetCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/LiuL0703/algorithm/tree/master/LeetCode/JavaScript&#34;&gt;github.com/LiuL0703/algorithm/tree/master/LeetCode/JavaScript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ecmadao/algorithms/tree/master/leetcode&#34;&gt;github.com/ecmadao/algorithms/tree/master/leetcode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/paopao2/leetcode-js&#34;&gt;github.com/paopao2/leetcode-js&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/cs1707/leetcode&#34;&gt;github.com/cs1707/leetcode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/EasyHard/leetcodejs&#34;&gt;github.com/EasyHard/leetcodejs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/fa-ge/leetcode&#34;&gt;github.com/fa-ge/leetcode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ktorng/AlgoInterviewPrep/tree/master/misc/LeetCode&#34;&gt;github.com/ktorng/AlgoInterviewPrep/tree/master/misc/LeetCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/bluesh/LeetCode&#34;&gt;github.com/bluesh/LeetCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/chihungyu1116/leetcode-javascript&#34;&gt;github.com/chihungyu1116/leetcode-javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/didi0613/leetcode-javascript&#34;&gt;github.com/didi0613/leetcode-javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/dnshi/Leetcode/tree/master/algorithms&#34;&gt;github.com/dnshi/Leetcode/tree/master/algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/xiaoyu2er/leetcode-js&#34;&gt;github.com/xiaoyu2er/leetcode-js&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blog.sodhanalibrary.com/search/label/JavaScript&#34;&gt;blog.sodhanalibrary.com/search/label/JavaScript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/imcoddy/leetcode&#34;&gt;github.com/imcoddy/leetcode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/iwantooxxoox/leetcode&#34;&gt;github.com/iwantooxxoox/leetcode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/karenpeng/leetCode&#34;&gt;github.com/karenpeng/leetCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/KMBaby-zyl/leetcode/tree/master/Algorithms&#34;&gt;github.com/KMBaby-zyl/leetcode/tree/master/Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/MrErHu/Leetcode/tree/master/algorithms&#34;&gt;github.com/MrErHu/Leetcode/tree/master/algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/zzxboy1/leetcode/tree/master/algorithms&#34;&gt;github.com/zzxboy1/leetcode/tree/master/algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/loatheb/leetcode-javascript&#34;&gt;github.com/loatheb/leetcode-javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/paopao2/leetcode-js&#34;&gt;github.com/paopao2/leetcode-js&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/theFool32/LeetCode&#34;&gt;github.com/theFool32/LeetCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/whwei/LeetCode&#34;&gt;github.com/whwei/LeetCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/jiangxiaoli/leetcode-javascript&#34;&gt;github.com/jiangxiaoli/leetcode-javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://skyyen999.gitbooks.io/-leetcode-with-javascript/content/questions/299md.html&#34;&gt;skyyen999.gitbooks.io/-leetcode-with-javascript/content/questions/299md.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/HandsomeOne/LeetCode/tree/master/Algorithms&#34;&gt;github.com/HandsomeOne/LeetCode/tree/master/Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/zj972/leetcode/tree/master/code&#34;&gt;github.com/zj972/leetcode/tree/master/code&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/xiaoliwang/leetcode/tree/master/iojs&#34;&gt;github.com/xiaoliwang/leetcode/tree/master/iojs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/dieface/leetcode/tree/master/javascript&#34;&gt;github.com/dieface/leetcode/tree/master/javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/magicly/leetcode/tree/master/js&#34;&gt;github.com/magicly/leetcode/tree/master/js&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/LuciferChiu/leetcode/tree/master/solutions&#34;&gt;github.com/LuciferChiu/leetcode/tree/master/solutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/alenny/leetcode/tree/master/src&#34;&gt;github.com/alenny/leetcode/tree/master/src&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/kpman/leetcode/tree/master/src&#34;&gt;github.com/kpman/leetcode/tree/master/src&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/hijiangtao/LeetCode-with-JavaScript/tree/master/src&#34;&gt;github.com/hijiangtao/LeetCode-with-JavaScript/tree/master/src&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cnblogs.com/Liok3187/default.html?page=1&#34;&gt;www.cnblogs.com/Liok3187/default.html?page=1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/yuguo/LeetCode&#34;&gt;github.com/yuguo/LeetCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;designing&#34;&gt;Designing&lt;/h2&gt;&#xA;&lt;h3 id=&#34;system-design-related-useful-articles&#34;&gt;System-Design related useful articles&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.hiredintech.com/app#system-design&#34;&gt;System Interview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.lecloud.net/tagged/scalability&#34;&gt;Scalability for Dummies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.aosabook.org/en/distsys.html&#34;&gt;Scalable Web Architecture and Distributed Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://everythingisdata.wordpress.com/2009/10/17/numbers-everyone-should-know/&#34;&gt;Numbers Everyone Should Know&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pages.cs.wisc.edu/~zuyu/files/fallacies.pdf&#34;&gt;Fallacies of distributed systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://horicky.blogspot.com/2010/10/scalable-system-design-patterns.html&#34;&gt;Scalable System Design Patterns&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://lethain.com/introduction-to-architecting-systems-for-scale/&#34;&gt;Introduction to Architecting Systems for Scale&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://snarfed.org/transactions_across_datacenters_io.html&#34;&gt;Transactions Across Datacenters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/henryr/cap-faq&#34;&gt;The CAP FAQ&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://research.microsoft.com/en-us/um/people/lamport/pubs/paxos-simple.pdf&#34;&gt;Paxos Made Simple&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.tom-e-white.com/2007/11/consistent-hashing.html&#34;&gt;Consistent Hashing&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://horicky.blogspot.com/2009/11/nosql-patterns.html&#34;&gt;NOSQL Patterns&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/jboner/scalability-availability-stability-patterns&#34;&gt;Scalability, Availability &amp;amp; Stability Patterns&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://repository.cmu.edu/cgi/viewcontent.cgi?article=2112&amp;amp;context=compsci&#34;&gt;Design a CDN network-Globally Distributed Content Delivery&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.interviewbit.com/system-design-interview-questions/&#34;&gt;System Design Interview Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://code.google.com/p/google-mobwrite/&#34;&gt;Google document system: google-mobwrite&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://neil.fraser.name/writing/sync/&#34;&gt;Google document system: Differential Synchronization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.twitter.com/2010/announcing-snowflake&#34;&gt;Announcing Snowflake at X&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/dvirsky/introduction-to-redis&#34;&gt;Introduction to Redis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.quora.com/What-are-best-practices-for-building-something-like-a-News-Feed&#34;&gt;What are best practices for building something like a News Feed?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.quora.com/Activity-Streams/What-are-the-scaling-issues-to-keep-in-mind-while-developing-a-social-network-feed&#34;&gt;What are the scaling issues to keep in mind while developing a social network feed?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/danmckinley/etsy-activity-feeds-architecture&#34;&gt;Facebook Activity Feeds Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.facebook.com/note.php?note_id=10150468255628920&#34;&gt;Building Timeline&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://highscalability.com/blog/2011/1/23/facebook-timeline-brought-to-you-by-the-power-of-denormaliza.html&#34;&gt;Facebook Timeline&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.cse.ust.hk/~raywong/comp5331/References/EfficientComputationOfFrequentAndTop-kElementsInDataStreams.pdf&#34;&gt;Efficient Computation of Frequent and Top-k Elements in Data Streams&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://davis.wpi.edu/xmdv/docs/EDBT11-diyang.pdf&#34;&gt;An Optimal Strategy for Monitoring Top-k Queries in Streaming Windows&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.indieflashblog.com/how-to-create-an-asynchronous-multiplayer-game.html&#34;&gt;How to Create an Asynchronous Multiplayer Game&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.indieflashblog.com/how-to-create-async-part2.html&#34;&gt;How to Create an Asynchronous Multiplayer Game Part 2: Saving the Game State to Online Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.indieflashblog.com/how-to-create-async-part3.html&#34;&gt;How to Create an Asynchronous Multiplayer Game Part 3: Loading Games from the Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://buildnewgames.com/real-time-multiplayer/&#34;&gt;Real Time Multiplayer in HTML5&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.facebook.com/notes/facebook-engineering/under-the-hood-building-out-the-infrastructure-for-graph-search/10151347573598920&#34;&gt;Building out the infrastructure for Graph Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.facebook.com/notes/facebook-engineering/under-the-hood-indexing-and-ranking-in-graph-search/10151361720763920&#34;&gt;Indexing and ranking in Graph Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.facebook.com/notes/facebook-engineering/under-the-hood-the-natural-language-interface-of-graph-search/10151432733048920&#34;&gt;The natural language interface of Graph Search&lt;/a&gt; and &lt;a href=&#34;http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf&#34;&gt;Erlang at Facebook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://highscalability.com/flickr-architecture&#34;&gt;Flickr Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://highscalability.com/blog/2011/12/6/instagram-architecture-14-million-users-terabytes-of-photos.html&#34;&gt;Instagram Architecture&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://programmers.stackexchange.com/questions/38324/interview-question-how-would-you-implement-google-search&#34;&gt;How would you implement Google Search?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.ardendertat.com/2012/01/11/implementing-search-engines/&#34;&gt;Implementing Search Engines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://tech.hulu.com/blog/2011/09/19/recommendation-system.html&#34;&gt;Hulu’s Recommendation System&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://ijcai13.org/files/tutorial_slides/td3.pdf&#34;&gt;Recommender Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://n00tc0d3r.blogspot.com/&#34;&gt;System Design for Big Data-tinyurl&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://journal.stuffwithstuff.com/2013/12/08/babys-first-garbage-collector/&#34;&gt;Baby&amp;rsquo;s First Garbage Collector&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.quora.com/How-can-I-build-a-web-crawler-from-scratch&#34;&gt;How can I build a web crawler from scratch?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.erlang-factory.com/upload/presentations/31/EugeneLetuchy-ErlangatFacebook.pdf&#34;&gt;Design Facebook chat function&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.michael-noll.com/blog/2013/01/18/implementing-real-time-trending-topics-in-storm/&#34;&gt;Implementing Real-Time Trending Topics With a Distributed Rolling Count Algorithm in Storm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://snikolov.wordpress.com/2012/11/14/early-detection-of-twitter-trends/&#34;&gt;Early detection of Twitter trends explained&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.slideshare.net/oemebamo/introduction-to-memcached&#34;&gt;Design a cache system*: Introduction to Memcached&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;github-repositories-with-coding-problems-and-solutions&#34;&gt;Github Repositories with coding problems-and-solutions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ignacio-chiazzo/Algorithms-Leetcode-Javascript&#34;&gt;Algorithms-Leetcode-Javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rohan-paul/Algorithm-in-JavaScript&#34;&gt;Algorithm-in-JavaScript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rohan-paul/Javascript-Challenges&#34;&gt;Javascript-Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rohan-paul/The-Hacking-School-Full-Stack-Bootcamp-Projects/tree/master/JS-Challenges&#34;&gt;JS-Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/mkshen/code-problems-solutions&#34;&gt;code-problems-solutions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://gist.github.com/Smakar20?page=1&#34;&gt;some common problems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/careercup/CtCI-6th-Edition-JavaScript&#34;&gt;Cracking the Coding Interview - Javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/kennymkchan/interview-questions-in-javascript&#34;&gt;interview-questions-in-javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/sudheerj/javascript-interview-questions&#34;&gt;javascript-interview-questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/kolodny/exercises&#34;&gt;javascript-Exercises&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/30-seconds/30-seconds-of-interviews&#34;&gt;30-seconds-of-interview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/vvscode/js--interview-questions&#34;&gt;js&amp;ndash;interview-questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/sadanandpai/javascript-code-challenges&#34;&gt;JavaScript-Code-Challenges&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;system-design-company-engineering-blog&#34;&gt;System-Design-Company engineering blog&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://highscalability.com/&#34;&gt;High Scalability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/blog/category/engineering&#34;&gt;The GitHub Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://engineering.quora.com/&#34;&gt;Engineering at Quora&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://engineeringblog.yelp.com/&#34;&gt;Yelp Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://engineering.twitter.com/&#34;&gt;Twitter Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.facebook.com/Engineering&#34;&gt;Facebook Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://eng.yammer.com/blog/&#34;&gt;Yammer Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://codeascraft.com/&#34;&gt;Etsy Code as Craft&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://engineering.foursquare.com/&#34;&gt;Foursquare Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nerds.airbnb.com/&#34;&gt;Airbnb Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://engineering.webengage.com/&#34;&gt;WebEngage Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://engineering.linkedin.com/blog&#34;&gt;LinkedIn Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://techblog.netflix.com/&#34;&gt;The Netflix Tech Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.simple.com/engineering/&#34;&gt;BankSimple Simple Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://corner.squareup.com/&#34;&gt;Square The Corner&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developers.soundcloud.com/blog/&#34;&gt;SoundCloud Backstage Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://code.flickr.net/&#34;&gt;Flickr Code&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://instagram-engineering.tumblr.com/&#34;&gt;Instagram Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://tech.dropbox.com/&#34;&gt;Dropbox Tech Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.cloudera.com/&#34;&gt;Cloudera Developer Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://bandcamptech.wordpress.com/&#34;&gt;Bandcamp Tech&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://tech.oyster.com/&#34;&gt;Oyster Tech Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.redditblog.com/&#34;&gt;THE REDDIT BLOG&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://engineering.groupon.com/&#34;&gt;Groupon Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://devblog.songkick.com/&#34;&gt;Songkick Technology Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://googleresearch.blogspot.com/&#34;&gt;Google Research Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://engineering.pinterest.com/&#34;&gt;Pinterest Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.twilio.com/engineering&#34;&gt;Twilio Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://word.bitly.com/&#34;&gt;Bitly Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://eng.uber.com/&#34;&gt;Uber Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://engineering.godaddy.com/&#34;&gt;Godaddy Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://blogs.splunk.com/&#34;&gt;Splunk Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://building.coursera.org/&#34;&gt;Coursera Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.paypal-engineering.com/&#34;&gt;PayPal Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://engblog.nextdoor.com/&#34;&gt;Nextdoor Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.booking.com/&#34;&gt;Booking.com Development Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.scalyr.com/&#34;&gt;Scalyr Engineering Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;interview&#34;&gt;Interview&lt;/h2&gt;&#xA;&lt;h3 id=&#34;design-interview-questions&#34;&gt;Design Interview Questions&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/rohan-paul/Awesome-JavaScript-Interviews/blob/master/system-design/design-url-shortner.md&#34;&gt;design-url-shortner&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/rohan-paul/Awesome-JavaScript-Interviews/blob/master/system-design/e-Commerce-site.md&#34;&gt;e-Commerce-site&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/rohan-paul/Awesome-JavaScript-Interviews/blob/master/system-design/Whatsapp-Basic-Features-of-a-chat-app.md&#34;&gt;Whatsapp-Basic-Features-of-a-chat-app&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scottaohara.github.io/accessibility_interview_questions/&#34;&gt;Accessibility Interview Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;books-cracking-the-coding-interview&#34;&gt;Books: Cracking the Coding Interview&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/sharlatta/cracking&#34;&gt;github.com/sharlatta/cracking&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ammiranda/CrackingTheCodingInterview&#34;&gt;github.com/ammiranda/CrackingTheCodingInterview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/bryclee/ctci&#34;&gt;github.com/bryclee/ctci&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/macalinao/node-ctci&#34;&gt;github.com/macalinao/node-ctci&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/seemaullal/CrackingTheCodingInterview-JS&#34;&gt;github.com/seemaullal/CrackingTheCodingInterview-JS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rcerf/MyCtci&#34;&gt;github.com/rcerf/MyCtci&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/SashaBayan/CCI&#34;&gt;github.com/SashaBayan/CCI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/careercup/CtCI-6th-Edition-JavaScript-ES2015&#34;&gt;github.com/careercup/CtCI-6th-Edition-JavaScript-ES2015&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ktorng/AlgoInterviewPrep/tree/master/CrackingTheCodingInterview&#34;&gt;github.com/ktorng/AlgoInterviewPrep/tree/master/CrackingTheCodingInterview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/muddybarefeet/Cracking-the-Coding-Interview-Problems/tree/master/toyProblems&#34;&gt;github.com/muddybarefeet/Cracking-the-Coding-Interview-Problems/tree/master/toyProblems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/randy909/coding-interview/tree/master/cracking&#34;&gt;github.com/randy909/coding-interview/tree/master/cracking&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rohan-paul/Awesome-JavaScript-Interviews#collection-of-cracking-the-coding-interview-book-problem-solution&#34;&gt;github.com/rohan-paul/Awesome-JavaScript-Interviews#collection-of-cracking-the-coding-interview-book-problem-solution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/careercup/ctci/tree/master/javascript/lib/data-structures&#34;&gt;github.com/careercup/ctci/tree/master/javascript/lib/data-structures&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/miguelmota/ctci-js&#34;&gt;github.com/miguelmota/ctci-js&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ChirpingMermaid/CTCI&#34;&gt;github.com/ChirpingMermaid/CTCI&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;programming-interview-questions-and-answers-resources&#34;&gt;Programming Interview Questions and Answers Resources&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://bigocheatsheet.com/&#34;&gt;Big O Cheatsheet&lt;/a&gt; &lt;a href=&#34;https://medium.com/@jayshah_84248/big-o-for-coding-interviews-e6ca8897f926&#34;&gt;Quick Big O understanding for coding interviews&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.toptal.com/developers/sorting-algorithms&#34;&gt;developers/sorting-algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/@yanganif/tackling-javascript-algorithms-66f1ac9770dc&#34;&gt;tackling-javascript-algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/benoitvallon/computer-science-in-javascript/tree/master/sorting-algorithms-in-javascript&#34;&gt;sorting-algorithms-in-javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/Algorithm-archive/Learn-Data_Structure-Algorithm-by-Javascript&#34;&gt;Learn-Data_Structure-Algorithm-by-Javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.goodreads.com/book/show/22847284-grokking-algorithms-an-illustrated-guide-for-programmers-and-other-curio&#34;&gt;Grokking Algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.usfca.edu/~galles/visualization/Algorithms.html&#34;&gt;Algorithms Visualization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/coding-interviews-for-dummies-5e048933b82b&#34;&gt;coding-interviews-for-dummies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.educative.io/collection/page/5642554087309312/5679846214598656/240002&#34;&gt;educative.io/collection/page/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikiwand.com/en/Rabin%E2%80%93Karp_algorithm&#34;&gt;Karp_algorithm&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.geeksforgeeks.org/top-algorithms-and-data-structures-for-competitive-programming/&#34;&gt;www.geeksforgeeks.org/top-algorithms-and-data-structures-for-competitive-programming/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/trekhleb/javascript-algorithms&#34;&gt;best javascript-algorithms github repo&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hackernoon.com/14-patterns-to-ace-any-coding-interview-question-c5bb3357f6ed&#34;&gt;14-patterns-to-ace-any-coding-interview-question&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.educative.io/collection/5668639101419520/5671464854355968&#34;&gt;Grokking the Coding Interview: Patterns for Coding Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/amejiarosario/dsa.js-data-structures-algorithms-javascript&#34;&gt;https://github.com/amejiarosario/dsa.js-data-structures-algorithms-javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/jwasham/coding-interview-university&#34;&gt;coding-interview-university&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/sudheerj/reactjs-interview-questions&#34;&gt;reactjs-interview-questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/h5bp/Front-end-Developer-Interview-Questions&#34;&gt;Front-end-Developer-Interview-Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/yangshun/front-end-interview-handbook&#34;&gt;front-end-interview-handbook&lt;/a&gt; - Almost complete answers to &amp;ldquo;Front-end Job Interview Questions&amp;rdquo; which you can use to interview potential candidates, test yourself or completely ignore&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.interviewbit.com/algorithm-interview-questions/&#34;&gt;Algorithm Interview Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;some-resources-for-javascript-interviews&#34;&gt;Some resources for JavaScript Interviews&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dev.to/arnavaggarwal/10-javascript-concepts-you-need-to-know-for-interviews?utm_source=hashnode.com&#34;&gt;10 JavaScript concepts you need to know for interviews&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/Chalarangelo/30-seconds-of-code&#34;&gt;Curated collection of useful JavaScript snippets that you can understand in 30 seconds or less&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ganqqwerty/123-Essential-JavaScript-Interview-Questions&#34;&gt;123 Essential JavaScript Interview Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/ggomaeng/awesome-js&#34;&gt;A curated list of JavaScript fundamentals and algorithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hackernoon.com/a-quick-introduction-to-functional-javascript-7e6fe520e7fa&#34;&gt;A Quick Introduction to Functional JavaScript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/coderbyte/a-tricky-javascript-interview-question-asked-by-google-and-amazon-48d212890703&#34;&gt;A Tricky JavaScript Interview Question Asked by Google and Amazon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/dev-bits/a-perfect-guide-for-cracking-a-javascript-interview-a-developers-perspective-23a5c0fa4d0d&#34;&gt;A perfect guide for cracking a JavaScript interview - A developer’s perspective&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/javascript-scene/common-misconceptions-about-inheritance-in-javascript-d5d9bab29b0a&#34;&gt;Common Misconceptions About Inheritance in JavaScript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/javascript-scene/master-the-javascript-interview-what-is-a-closure-b2f0d2152b36&#34;&gt;Master the JavaScript Interview: What is a Closure?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/javascript-scene/master-the-javascript-interview-what-is-function-composition-20dfb109a1a0&#34;&gt;Master the JavaScript Interview: What is Function Composition?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/3-questions-to-watch-out-for-in-a-javascript-interview-725012834ccb&#34;&gt;3 JavaScript questions to watch out for during coding interviews&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.thatjsdude.com/interview/dom.html&#34;&gt;JS: Interview Questions Part-3&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.thatjsdude.com/interview/js1.html&#34;&gt;JS: Interview Algorithm Part-1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.thatjsdude.com/interview/js2.html&#34;&gt;JS: Basics and Tricky Questions Part-2: intermediate&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.toptal.com/javascript/interview-questions&#34;&gt;37 Essential JavaScript Interview Questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.interviewbit.com/javascript-interview-questions/&#34;&gt;Prepare from this comprehensive list of the latest JavaScript Interview Questions and ace your interview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/lydiahallie/javascript-questions&#34;&gt;Many tricky and common JavaScript questions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/javascript-scene/master-the-javascript-interview-what-s-the-difference-between-class-prototypal-inheritance-e4cd0a7562e9&#34;&gt;Master the JavaScript Interview: What’s the Difference Between Class &amp;amp; Prototypal Inheritance?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;jobs&#34;&gt;Jobs&lt;/h2&gt;&#xA;&lt;h3 id=&#34;getting-your-first-programming-job&#34;&gt;Getting your first programming job&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/javascript-scene/every-developer-needs-a-code-portfolio-cc79c3d92110&#34;&gt;Every-developer-needs-a-code-portfolio- Javascript&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/@jayshah_84248/how-to-do-well-in-a-coding-interview-2bcd67e93cb5&#34;&gt;Collection of Resources for Interview preparations and practices&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/@rachit138/how-i-cleared-the-amazon-sde-2-interview-f82a33706ff4&#34;&gt;How I cleared the Amazon SDE 2 interview&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.usejournal.com/how-i-got-7-job-offers-in-8-weeks-part-1-please-interview-me-21e6f4ded106&#34;&gt;How I got 7 Job Offers in 8 Weeks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/javascript-scene/master-the-javascript-interview-soft-skills-a8a5fb02c466&#34;&gt;master-the-javascript-interview-soft-skills&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/@jayshah_84248/google-lost-a-chance-to-hire-me-finally-amazon-hired-me-e35076c73fe2&#34;&gt;google-lost-a-chance-to-hire-me-finally-amazon-hired-me&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/javascript-scene/the-best-way-to-learn-to-code-is-to-code-learn-app-architecture-by-building-apps-7ec029db6e00&#34;&gt;the-best-way-to-learn-to-code-is-to-code-learn-app-architecture-by-building-apps&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/7-key-steps-to-getting-your-first-software-engineering-job-6ef80543cad9&#34;&gt;7-key-steps-to-getting-your-first-software-engineering-job&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/5-key-learnings-from-the-post-bootcamp-job-search-9a07468d2331&#34;&gt;5-key-learnings-from-the-post-bootcamp-job-search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/https-medium-com-samwcoding-how-to-get-your-first-developer-job-in-4-months-ec86da6e5d9a&#34;&gt;how-to-get-your-first-developer-job-in-4-months&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/swlh/how-to-land-your-first-dev-job-even-if-you-don-t-have-a-cs-degree-e83d08db4615&#34;&gt;how-to-land-your-first-dev-job-even-if-you-don-t-have-a-cs-degree&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/how-to-land-a-top-notch-tech-job-as-a-student-5c97fec82f3d&#34;&gt;how-to-land-a-top-notch-tech-job-as-a-student&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/appsflyer/unlocking-the-javascript-code-interview-an-interviewer-perspective-f4fe06246b29&#34;&gt;unlocking-the-javascript-code-interview-an-interviewer-perspective&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://steve-yegge.blogspot.com/2008/03/get-that-job-at-google.html&#34;&gt;get-that-job-at-google.html&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.usejournal.com/i-failed-my-effing-coding-interview&#34;&gt;i-failed-my-effing-coding-interview-ab720c339c8a&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/how-i-landed-a-full-stack-developer-job-without-a-tech-degree-or-work-experience-6add97be2051&#34;&gt;how-i-landed-a-full-stack-developer-job-without-a-tech-degree-or-work-experience&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/here-are-4-best-ways-to-apply-for-software-engineer-jobs-and-exactly-how-to-use-them-a644a88b2241&#34;&gt;here-are-4-best-ways-to-apply-for-software-engineer-jobs-and-exactly-how-to-use-them&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/how-to-get-a-tech-job-with-no-previous-work-experience-6d3d7d25e1&#34;&gt;how-to-get-a-tech-job-with-no-previous-work-experience&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/the-hard-thing-about-learning-hard-things-168e655ac7f2&#34;&gt;the-hard-thing-about-learning-hard-things&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.com/@traversymedia/70-job-find-websites-for-developers-other-tech-professionals-34cdb45518be&#34;&gt;70-job-find-websites-for-developers-other-tech-professionals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=xKOPqWWmxEQ&#34;&gt;YouTube - 70+ Websites To Find Developer Jobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=EJDZ2L95Sjo&#34;&gt;YouTube - I&amp;rsquo;m 47 And Now I Want to be a Programmer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=V71Cv7mjgfI&#34;&gt;YouTube - How To Be A Well-Paid Programmer In 1 Year?&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://medium.freecodecamp.org/the-secret-to-being-a-top-developer-is-building-things-heres-a-list-of-fun-apps-to-build-aac61ac0736c&#34;&gt;the-secret-to-being-a-top-developer-is-building-things-heres-a-list-of-fun-apps-to-build&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;sites-for-searching-developer-job&#34;&gt;Sites for searching developer job&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://joblist.app&#34;&gt;Joblist.app&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://angel.co&#34;&gt;AngelList&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://authenticjobs.com&#34;&gt;Authentic jobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://developersforhire.com&#34;&gt;Developers for Hire&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://devitjobs.uk&#34;&gt;DevITjobs uk&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://devitjobs.us&#34;&gt;DevITjobs us&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://dice.com&#34;&gt;Dice&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://fullstackjob.com&#34;&gt;Fullstack Job&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://glassdoor.com&#34;&gt;Glassdoor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hired.com&#34;&gt;Hired&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://indeed.com&#34;&gt;Indeed&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://landing.jobs&#34;&gt;Jobs in Europe&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jobspresso.co&#34;&gt;Jobspresso&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://krop.com&#34;&gt;Krop&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://linkedIn.com&#34;&gt;LinkedIn&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jobs.mashable.com/jobs&#34;&gt;Mashable&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://monster.com&#34;&gt;Monster&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://themuse.com/jobs&#34;&gt;Muse&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://powertofly.com/jobs&#34;&gt;PowerToFly&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://simplyhired.com&#34;&gt;Simply Hired&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://stackoverflow.com/jobs&#34;&gt;StackOverflow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://toptal.com&#34;&gt;Toptal&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://triplebyte.com&#34;&gt;TripleByte&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jobs.tutsplus.com&#34;&gt;Tuts+&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;startup-job&#34;&gt;Startup job&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://angel.co/jobs&#34;&gt;AngelList&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://producthunt.com/jobs&#34;&gt;Product Hunt&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://startuphire.com&#34;&gt;Startup Hire&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://startupers.com&#34;&gt;Startupers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://news.ycombinator.com/jobs&#34;&gt;YCombinator&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;best-places-to-job-hunt-for-remote-jobs&#34;&gt;Best places to job hunt for remote jobs:&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dailyremote.com&#34;&gt;DailyRemote&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://flexjobs.com&#34;&gt;FlexJobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://frontendremotejobs.com&#34;&gt;Front-end remote&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://iwantremote.com&#34;&gt;IWantRemote&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jsremotely.com&#34;&gt;JS Remotely&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://justremote.co/remote-developer-jobs&#34;&gt;JustRemote&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://outsourcely.com/remote-web-development-jobs&#34;&gt;Outsourcely&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pangian.com/job-travel-remote/&#34;&gt;Pangian&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://remote.co/remote-jobs/developer/&#34;&gt;Remote . co&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://remotetalent.co/jobs&#34;&gt;Remote Talent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://remoteleads.io&#34;&gt;RemoteLeads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://remoteleaf.com&#34;&gt;RemoteLeaf&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://remoteok.io/remote-dev-jobs&#34;&gt;RemoteOk&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://remoters.net/jobs/software-development&#34;&gt;Remoters&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://remotive.io/remote-jobs/software-dev&#34;&gt;Remotive&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sitepoint.com/jobs/&#34;&gt;Sitepoint&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://stackoverflow.com/jobs/remote-developer-jobs&#34;&gt;Stackoverflow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://weworkremotely.com&#34;&gt;WeWorkRemotely&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://workingnomads.co/remote-development-jobs&#34;&gt;Working Nomads&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;a-few-places-to-hunt-for-ios-react-vue-and-more&#34;&gt;A few places to hunt for ios, react, vue and more&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://iosdevjobs.com&#34;&gt;iOS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://reactjobboard.com&#34;&gt;React&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://vuejobs.com&#34;&gt;Vue jobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jobs.emberjs.com&#34;&gt;Ember&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://python.org/jobs&#34;&gt;Python Jobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;want-a-list-of-just-javascript-jobs&#34;&gt;Want a list of just JavaScript jobs?&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://javascriptjob.xyz&#34;&gt;JavaScript job XYZ&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jsremotely.com&#34;&gt;Javascript remotely&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;are-you-looking-for-a-junior-dev-job&#34;&gt;Are you looking for a junior dev job?&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://jrdevjobs.com&#34;&gt;JrDevJobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/jobs/junior-developer-jobs&#34;&gt;Stackoverflow Junior jobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;women-focused-job-boards&#34;&gt;Women focused job boards!&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://womenwhocode.com/jobs&#34;&gt;Women Who Code&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hiretechladies.com&#34;&gt;Tech Ladies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;want-a-job-as-a-freelance-dev-heres-a-list&#34;&gt;Want a job as a freelance dev? Here&amp;rsquo;s a list&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://freelancer.com/jobs&#34;&gt;Freelancer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://upwork.com&#34;&gt;Upwork&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://flexjobs.com/jobs&#34;&gt;FlexJobs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://freelancermap.com&#34;&gt;FreelancerMap&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://gun.io&#34;&gt;Gun io&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://guru.com/d/jobs&#34;&gt;Guru&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;others&#34;&gt;Others&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://interviewing.io/&#34;&gt;interviewing.io&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://leetcode.com/&#34;&gt;Leetcode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.hackerrank.com/&#34;&gt;HackerRank&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://codeforces.com/&#34;&gt;CodeForces&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.codechef.com&#34;&gt;CodeChef&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://coderbyte.com/&#34;&gt;Coderbyte&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.codingame.com/&#34;&gt;CodinGame&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://csacademy.com/&#34;&gt;Cs Academy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dailycodingproblem.com/&#34;&gt;Daily Coding Problem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://spoj.com/&#34;&gt;Spoj&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hackerearth.com/&#34;&gt;HackerEarth&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.topcoder.com/&#34;&gt;TopCoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://codewars.com/&#34;&gt;Codewars&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://www.exercism.io/&#34;&gt;Exercism&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://codefights.com/&#34;&gt;CodeFights&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://projecteuler.net/&#34;&gt;Project Euler&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.interviewcake.com/&#34;&gt;Interviewcake&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.interviewbit.com/&#34;&gt;InterviewBit&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/rohan-paul/Awesome-JavaScript-Interviews/blob/master/ucoder.com.br&#34;&gt;uCoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.lintcode.com/&#34;&gt;LintCode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://codecombat.com/&#34;&gt;CodeCombat&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;</description>
    </item>
    <item>
      <title>AI Usecases in Cybersecurity</title>
      <link>http://localhost:1313/dsblog/AI-Usecases-in-Cybersecurity/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Usecases-in-Cybersecurity/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6135-AI-Usecases-in-Cybersecurity.jpg&#34; alt=&#34;AI-Usecases-in-Cybersecurity&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-usecases-in-cybersecurity&#34;&gt;AI Usecases in Cybersecurity&lt;/h1&gt;&#xA;&lt;h1 id=&#34;ai-in-cyber-security-ethics-related-challenges-and-usecases&#34;&gt;AI in Cyber Security, Ethics Related Challenges and Usecases&lt;/h1&gt;&#xA;&lt;h2 id=&#34;ai-usecases-in-cyber-security&#34;&gt;AI Usecases in Cyber Security&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Threat Detection and Response&#xA;AI can enhance the detection and response to cybersecurity threats by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Anomaly Detection&lt;/strong&gt;: AI models can analyze network traffic and user behavior to identify unusual patterns that may indicate a security breach.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Malware Detection&lt;/strong&gt;: Machine learning algorithms can be trained to recognize malware based on its behavior and characteristics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Phishing Detection&lt;/strong&gt;: AI can analyze emails and web pages to detect phishing attempts by recognizing patterns and indicators typical of phishing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Intrusion Detection Systems (IDS):&lt;/strong&gt; AI-powered IDS can detect unauthorized access and potential threats by analyzing network traffic and user behavior in real-time.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Endpoint Protection:&lt;/strong&gt; AI can enhance endpoint protection by continuously monitoring devices for suspicious activity and automatically responding to threats.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Predictive Analytics&#xA;AI can be used to predict potential security incidents before they occur by:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Open Source vs Closed Source AI</title>
      <link>http://localhost:1313/dsblog/Open-Source-vs-Closed-Source-AI/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Open-Source-vs-Closed-Source-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6134-Open-Source-vs-Closed-Source-AI.jpg&#34; alt=&#34;Open-Source-vs-Closed-Source-AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;open-source-ai-vs-closed-source-ai&#34;&gt;Open Source AI vs Closed Source AI&lt;/h1&gt;&#xA;&lt;p&gt;Major players in the AI industry, such as Google, Microsoft, IBM, Salesforce, etc each have their own proprietary models and infrastructure to host these models. They offer AI services that companies use to develop AI products for either their end customers or internal use. Training or developing AI models requires expensive hardware and highly skilled personnel, making it a costly process. However, the deployment and inference stages are even more expensive, as they involve ongoing costs for hardware and monitoring.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How Much Memory Needed for LLM</title>
      <link>http://localhost:1313/dsblog/How-Much-Memory-Needed-for-LLM/</link>
      <pubDate>Mon, 05 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/How-Much-Memory-Needed-for-LLM/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6133-How-Much-Memory-Needed-for-LLM.jpg&#34; alt=&#34;How-Much-Memory-Needed-for-LLM&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;how-much-memory-needed-for-llm&#34;&gt;How Much Memory Needed for LLM?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-llm&#34;&gt;What is LLM?&lt;/h2&gt;&#xA;&lt;p&gt;LLM stands for &lt;strong&gt;Large Language Model&lt;/strong&gt;. These are machine learning models that are trained on massive amounts of text data to understand, generate, and work with human language in a way that mimics natural language understanding. They are called &amp;ldquo;large&amp;rdquo; because of the significant number of parameters they contain, often numbering in the billions or even trillions.&lt;/p&gt;&#xA;&lt;h3 id=&#34;what-defines-a-large-language-model&#34;&gt;What Defines a Large Language Model?&lt;/h3&gt;&#xA;&lt;p&gt;There is no strict or universally accepted benchmark to define what constitutes an LLM purely based on the number of parameters. The term &amp;ldquo;large&amp;rdquo; is relative and depends on the current state of technology and the size of models being developed. As technology progresses, what is considered &amp;ldquo;large&amp;rdquo; may continue to grow. However, some general guidelines have emerged:&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Architecture and Training</title>
      <link>http://localhost:1313/dsblog/LLM-Architecture-and-Training/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/LLM-Architecture-and-Training/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6129-LLM-Architecture-and-Training.jpg&#34; alt=&#34;LLM-Architecture-and-Training&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-llm-architectures-and-model-training&#34;&gt;&lt;strong&gt;Understanding LLM Architectures and Model Training&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;p&gt;Large Language Models (LLMs) are transforming the field of artificial intelligence by enabling machines to understand and generate human language with unprecedented accuracy. This article delves into the architecture, training methods, and practical applications of LLMs. We’ll explore the core components that make these models so powerful and explain how they are trained and fine-tuned for real-world use cases.&lt;/p&gt;&#xA;&lt;h2 id=&#34;1-introduction-to-large-language-models-llms&#34;&gt;&lt;strong&gt;1. Introduction to Large Language Models (LLMs)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;definition-and-importance-of-llms&#34;&gt;&lt;strong&gt;Definition and Importance of LLMs&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;Large Language Models are advanced deep learning models trained on massive amounts of text data. LLMs have made it possible to perform a wide variety of natural language tasks, from answering complex questions to generating human-like responses in chat applications. These models use billions (sometimes trillions) of parameters to capture intricate relationships within language, enabling them to comprehend and generate coherent responses.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Skills and Human Skills</title>
      <link>http://localhost:1313/dsblog/LLM-Skills-and-Human-Skills/</link>
      <pubDate>Sun, 04 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/LLM-Skills-and-Human-Skills/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6130-LLM-Skills-and-Human-Skills.jpg&#34; alt=&#34;LLM-Skills-and-Human-Skills&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;llm-skills-and-human-skills&#34;&gt;LLM Skills and Human Skills&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-skill&#34;&gt;What is skill?&lt;/h2&gt;&#xA;&lt;p&gt;A skill is the ability to perform a task or activity effectively and efficiently. It involves applying knowledge, experience, and techniques to achieve specific outcomes. Skills can be categorized into various types, including:&lt;/p&gt;&#xA;&lt;p&gt;Hard Skills: Technical abilities that are often measurable and specific to a job or field, such as programming, writing, or playing an instrument.&lt;/p&gt;&#xA;&lt;p&gt;Soft Skills: Interpersonal and personal attributes that enable someone to interact effectively with others, such as communication, teamwork, and problem-solving.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LLM Security and Ethics Considerations</title>
      <link>http://localhost:1313/dsblog/LLM-Security-and-Ethics-Considerations/</link>
      <pubDate>Fri, 02 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/LLM-Security-and-Ethics-Considerations/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6128-LLM-Security-and-Ethics-Considerations.jpg&#34; alt=&#34;LLM-Security-and-Ethics-Considerations&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;llm-security-and-ethics-considerations&#34;&gt;LLM Security and Ethics Considerations&lt;/h1&gt;&#xA;&lt;h2 id=&#34;question-for-my-clients-highly-secured-data-like-health-industry-data-banking-insurnace-internal-security-etc-data-can-i-use-gpt4-for-finetuning&#34;&gt;Question: For my client&amp;rsquo;s highly secured data like health industry data, banking, insurnace, internal security, etc. data can I use gpt4 for finetuning?&lt;/h2&gt;&#xA;&lt;p&gt;For highly sensitive data, such as health industry data, banking information, insurance details, and security data, using models like ChatGPT-3.5 or GPT-4 involves several considerations to ensure security and compliance:&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-security-and-compliance-considerations&#34;&gt;1. &lt;strong&gt;Security and Compliance Considerations&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Data Privacy&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Sensitive Data Handling&lt;/strong&gt;: Ensure that the data used for fine-tuning is handled securely. Fine-tuning models on sensitive data requires stringent data protection measures to prevent unauthorized access or leakage.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Compliance&lt;/strong&gt;: Verify that the use of AI models complies with relevant regulations and standards such as HIPAA (for health data), GDPR (for personal data in the EU), and others specific to your industry.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Access Control&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why to Finetune LLM?</title>
      <link>http://localhost:1313/dsblog/why-to-finetune-llm/</link>
      <pubDate>Sun, 28 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/why-to-finetune-llm/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6115-why-to-finetune-llm.jpg&#34; alt=&#34;Why to Finetune LLM?&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;finetuning-fewshot-learning-why-and-how&#34;&gt;Finetuning, Fewshot Learning, Why and How?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;why-to-finetune-a-llm&#34;&gt;Why to finetune a LLM?&lt;/h2&gt;&#xA;&lt;p&gt;Fine-tuning a large language model (LLM) can provide several benefits, depending on your specific needs and objectives. Here are some key reasons to consider fine-tuning an LLM:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Domain Specialization&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fine-tuning allows the model to become more proficient in specific domains, such as medical, legal, or technical fields, by training it on domain-specific data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Task Adaptation&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Software Security Concepts</title>
      <link>http://localhost:1313/dsblog/Software-Security-Concepts/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Software-Security-Concepts/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6132-Software-Security-Concepts.jpg&#34; alt=&#34;Software-Security-Concepts&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;software-security-concepts&#34;&gt;Software Security Concepts&lt;/h1&gt;&#xA;&lt;p&gt;As of today, this article is answering following questions related to software security. In future, I will add more concepts here.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What are the major ideas which we need to understand while creating security architecture of any app?&lt;/li&gt;&#xA;&lt;li&gt;What is the difference between authentication and authorization?&lt;/li&gt;&#xA;&lt;li&gt;What is OAuth?&lt;/li&gt;&#xA;&lt;li&gt;Can you share popular Compliance and Regulatory Requirements around various industries?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-are-the-major-ideas-which-we-need-to-understand-while-creating-security-architecture-of-any-app&#34;&gt;What are the major ideas which we need to understand while creating security architecture of any app?&lt;/h2&gt;&#xA;&lt;p&gt;The security architecture of an application encompasses various concepts and strategies designed to protect the application&amp;rsquo;s data, resources, and services from threats. Here are the main ideas and concepts typically involved:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Stanford Alpaca</title>
      <link>http://localhost:1313/dsblog/Stanford-Alpaca/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Stanford-Alpaca/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6116-Stanford-Alpaca.jpg&#34; alt=&#34;Stanford-Alpaca&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;stanford-alpaca&#34;&gt;Stanford Alpaca&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/tatsu-lab/stanford_alpaca&#34;&gt;Stanford Alpaca Github Report&lt;/a&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Stanford Alpaca is An &amp;ldquo;Instruction-following&amp;rdquo; LLaMA Model&lt;/li&gt;&#xA;&lt;li&gt;This is the repo aims to build and share an instruction-following LLaMA model. The repo contains:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The 52K &lt;a href=&#34;https://raw.githubusercontent.com/tatsu-lab/stanford_alpaca/main/alpaca_data.json&#34;&gt;instruction-following data&lt;/a&gt; used for fine-tuning the model.&lt;/li&gt;&#xA;&lt;li&gt;The code for generating the data.&lt;/li&gt;&#xA;&lt;li&gt;The code for fine-tuning the model.&lt;/li&gt;&#xA;&lt;li&gt;The code for recovering Alpaca-7B weights from our released weight diff.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;overview&#34;&gt;Overview&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The current &amp;ldquo;Alpaca 7B model&amp;rdquo; is fine-tuned from a &amp;ldquo;7B LLaMA&amp;rdquo; model on 52K instruction-following data generated by the techniques in the Self-Instruct paper.&lt;/li&gt;&#xA;&lt;li&gt;Alpaca 7B model behaves similarly to the text-davinci-003 model on the Self-Instruct instruction-following evaluation suite.&lt;/li&gt;&#xA;&lt;li&gt;Alpaca is still under development, and there are many limitations that have to be addressed.&lt;/li&gt;&#xA;&lt;li&gt;Alphaca is not yet fine-tuned to be safe and harmless.&lt;/li&gt;&#xA;&lt;li&gt;Initial release contains the data generation procedure, dataset, and training recipe.&lt;/li&gt;&#xA;&lt;li&gt;Model weights can be released if the creators of LLaMA gives permission.&lt;/li&gt;&#xA;&lt;li&gt;Live demo to help readers better understand the capabilities and limits of Alpaca is available.&lt;/li&gt;&#xA;&lt;li&gt;Based on followin papers:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;LLaMA: Open and Efficient Foundation Language Models. &lt;a href=&#34;https://arxiv.org/abs/2302.13971v1&#34;&gt;Hugo2023&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Self-Instruct: Aligning Language Model with Self Generated Instructions. &lt;a href=&#34;https://arxiv.org/abs/2212.10560&#34;&gt;Yizhong2022&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Data Release&#xA;&lt;ul&gt;&#xA;&lt;li&gt;alpaca_data.json contains 52K instruction-following data we used for fine-tuning the Alpaca model. This JSON file is a list of dictionaries, each dictionary contains the following fields: Instruction, input, output (text-davinci-003 geneated answer).&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;highlevel-activities-of-the-alpaca-project&#34;&gt;Highlevel Activities of the Alpaca Project&lt;/h2&gt;&#xA;&lt;p&gt;Highlevel Actitivies done by Stanford Alpaca team and Project Output&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is Unicode and how does it works?</title>
      <link>http://localhost:1313/dsblog/what-is-unicode-and-how-does-it-works/</link>
      <pubDate>Sat, 27 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/what-is-unicode-and-how-does-it-works/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6114-what-is-unicode-and-how-does-it-works.jpg&#34; alt=&#34;What is Unicode and how does it works?&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-unicode-and-how-does-it-works&#34;&gt;What is Unicode and how does it works?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-unicode-a-universal-character-set&#34;&gt;What is Unicode: A Universal Character Set&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Unicode&lt;/strong&gt; is a standard that assigns a unique number to every character, no matter the platform, program, or language. It&amp;rsquo;s like a global dictionary for characters.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Why is it important?&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Before Unicode, different systems used different character sets, leading to compatibility issues. For instance, a document created on one system might appear garbled when opened on another. Unicode solved this problem by providing a unified standard.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding LLM GAN and Transformers</title>
      <link>http://localhost:1313/dsblog/Understanding-LLM-GAN-and-Transformers/</link>
      <pubDate>Fri, 26 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Understanding-LLM-GAN-and-Transformers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6127-Understanding-LLM-GAN-and-Transformers.jpg&#34; alt=&#34;Understanding-LLM-GAN-Transformers&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-llm-gan-and-transformers&#34;&gt;Understanding LLM, GAN and Transformers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;llm-layers&#34;&gt;LLM Layers&lt;/h2&gt;&#xA;&lt;p&gt;Large Language Models (LLMs) are typically based on Transformer architectures, which consist of several types of layers that work together to process and generate text. Here are the primary kinds of layers found in an LLM:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Embedding Layers&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Token Embedding Layer&lt;/strong&gt;: Converts input tokens (words, subwords, or characters) into dense n dimensional vectors.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Position Embedding Layer&lt;/strong&gt;: Adds positional information to the token embeddings, allowing the model to understand the order of tokens.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Transformer Encoder Layers&lt;/strong&gt;: This layer is found in models, which are designed for generating encoded represenration of the input.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Transformers Demystified A Step-by-Step Guide</title>
      <link>http://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide/</link>
      <pubDate>Thu, 25 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6113-transformers-demystified-a-step-by-step-guide.jpg&#34; alt=&#34;Transformers Demystified A Step-by-Step Guide&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;transformers-demystified-a-step-by-step-guide&#34;&gt;Transformers Demystified A Step-by-Step Guide&lt;/h1&gt;&#xA;&lt;p&gt;All modern Transformers are based on a paper &amp;ldquo;Attention is all you need&amp;rdquo;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;This was the mother paper of all the transformer architectures we see today around NLP, Multimodal, Deep Learning. It was presented by Ashish Vaswani et al from Deep Learning / Google in 2017. We will discuss following and anything whatever question/observation/idea I have.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The need&#xA;Why this paper was needed? What problem it solved?&lt;/li&gt;&#xA;&lt;li&gt;What is transformer? What is encoder transformer? What is decoder transformer? What is encoder-decoder transformer?&lt;/li&gt;&#xA;&lt;li&gt;What is embedding? What is need for embedding? What are different types of embedding? What embeddingg is proposed in this work&lt;/li&gt;&#xA;&lt;li&gt;What benchmark dataset was used, what metrics were used and what was the performance of this model?&lt;/li&gt;&#xA;&lt;li&gt;Finally we will looks all the calculations with one illustration.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Encourage all to read this &lt;a href=&#34;https://arxiv.org/abs/1706.03762&#34;&gt;original paper&lt;/a&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dimensionality Reduction and Visualization</title>
      <link>http://localhost:1313/dsblog/Dimensionality-Reduction-and-Visualization/</link>
      <pubDate>Wed, 24 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Dimensionality-Reduction-and-Visualization/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6126-Dimensionality-Reduction-and-Visualization.jpg&#34; alt=&#34;Dimensionality-Reduction-and-Visualization&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;dimensionality-reduction-and-visualization&#34;&gt;Dimensionality Reduction and Visualization&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-are-the-popular-methods-of-dimensionality-reduction&#34;&gt;What are the popular methods of dimensionality reduction?&lt;/h2&gt;&#xA;&lt;p&gt;Dimensionality reduction is a crucial step in data preprocessing, particularly when dealing with high-dimensional datasets. It helps in reducing the number of features while retaining the essential information, improving computational efficiency, and facilitating data visualization. Here are some popular methods of dimensionality reduction:&lt;/p&gt;&#xA;&lt;h3 id=&#34;linear-methods&#34;&gt;Linear Methods&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Principal Component Analysis (PCA)&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Description&lt;/strong&gt;: PCA transforms the data into a set of linearly uncorrelated components, ordered by the amount of variance they explain.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Use Case&lt;/strong&gt;: Useful for datasets where the directions of maximum variance are important.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Implementation&lt;/strong&gt;: &lt;code&gt;sklearn.decomposition.PCA&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Linear Discriminant Analysis (LDA)&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serverless databases</title>
      <link>http://localhost:1313/dsblog/Serverless-databases/</link>
      <pubDate>Tue, 23 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Serverless-databases/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6125-Serverless-databases.jpg&#34; alt=&#34;Serverless-databases&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;serverless-databases&#34;&gt;Serverless databases&lt;/h1&gt;&#xA;&lt;p&gt;A &lt;strong&gt;serverless database&lt;/strong&gt; is a type of database service that automatically manages infrastructure and scaling, allowing developers to focus solely on building applications without having to worry about server provisioning, capacity planning, or database maintenance.&lt;/p&gt;&#xA;&lt;h3 id=&#34;key-characteristics-of-serverless-databases&#34;&gt;Key Characteristics of Serverless Databases:&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Automatic Scaling&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Serverless databases automatically scale up or down based on demand. They adjust resources such as CPU and memory dynamically, depending on the workload, ensuring optimal performance without manual intervention.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;No Server Management&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI in Health Care</title>
      <link>http://localhost:1313/dsblog/AI-in-Health-Care/</link>
      <pubDate>Mon, 22 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-in-Health-Care/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6124-AI-in-Health-Care.jpg&#34; alt=&#34;Health-Authority-Questions&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-in-health-care&#34;&gt;AI in Health Care&lt;/h1&gt;&#xA;&lt;p&gt;Human health is paramount for inviduals, governments, hospitals and other related systems. There are powerful laws and heavy panelty for the violations for these laws. In the entire health ecosystem there are some who create facility, some provide service in those facility, some do training and education, etc. Here is brief summary of the healthcare ecosystem. It is very complex and involves a wide range of interconnected systems and stakeholders. Here&amp;rsquo;s a list of the key systems and entities that form the broader healthcare ecosystem:&lt;/p&gt;</description>
    </item>
    <item>
      <title>All about Hashing</title>
      <link>http://localhost:1313/dsblog/All-about-Hashing/</link>
      <pubDate>Thu, 11 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/All-about-Hashing/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6123-All-about-Hashing.jpg&#34; alt=&#34;All-about-Hashing&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;all-about-hashing&#34;&gt;All about Hashing&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-hashing-function&#34;&gt;What is Hashing function?&lt;/h2&gt;&#xA;&lt;p&gt;A hashing function is a mathematical algorithm that converts an input (or &amp;ldquo;message&amp;rdquo;) into a fixed-size string of bytes, typically a hash code or hash value. This output is usually a short, unique representation of the input data. Examples of common hash functions include MD5, SHA-1, and SHA-256.&lt;/p&gt;&#xA;&lt;p&gt;Hashing is a process where an algorithm (known as a hash function) takes an input (or &amp;ldquo;message&amp;rdquo;) and returns a fixed-size string of bytes. The output, typically a hexadecimal number, appears random. The purpose of hashing is to ensure data integrity and to securely compare large amounts of data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Creating Docker Image</title>
      <link>http://localhost:1313/dsblog/Creating-Docker-Image/</link>
      <pubDate>Wed, 10 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Creating-Docker-Image/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6122-Creating-Docker-Image.jpg&#34; alt=&#34;Creating-Docker-Image&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;creating-docker-image&#34;&gt;Creating Docker Image&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-docker&#34;&gt;What is Docker?&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Docker is an open platform for developing, shipping, and running applications.&lt;/li&gt;&#xA;&lt;li&gt;Docker enables you to separate your applications from your infrastructure so you can deliver software quickly.&lt;/li&gt;&#xA;&lt;li&gt;With Docker, you can manage your infrastructure in the same ways you manage your applications.&lt;/li&gt;&#xA;&lt;li&gt;Docker provides the ability to package and run an application in a loosely isolated environment called a container.&lt;/li&gt;&#xA;&lt;li&gt;The isolation and security lets you run many containers simultaneously on a given host.&lt;/li&gt;&#xA;&lt;li&gt;Containers are lightweight and contain everything needed to run the application, so you don&amp;rsquo;t need to rely on what&amp;rsquo;s installed on the host.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;basics-terms-related-to-docker&#34;&gt;Basics Terms Related to Docker&lt;/h2&gt;&#xA;&lt;h3 id=&#34;the-docker-daemon&#34;&gt;The Docker daemon&lt;/h3&gt;&#xA;&lt;p&gt;The Docker daemon (dockerd) listens for Docker API requests and manages Docker objects such as images, containers, networks, and volumes. A daemon can also communicate with other daemons to manage Docker services.&lt;/p&gt;</description>
    </item>
    <item>
      <title>REST API</title>
      <link>http://localhost:1313/dsblog/REST-API/</link>
      <pubDate>Thu, 04 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/REST-API/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6121-REST-API.jpg&#34; alt=&#34;REST-API&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;rest-api&#34;&gt;REST API&lt;/h1&gt;&#xA;&lt;p&gt;An API (Application Programming Interface) is a set of rules and protocols that allows one software application to interact with another. It defines the methods and data formats that applications can use to communicate with each other, enabling them to request and exchange information.&lt;/p&gt;&#xA;&lt;p&gt;Here are some key aspects of an API:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Interface&lt;/strong&gt;: The API provides a specific set of functions and endpoints that can be used to interact with a system or service. These functions define what operations can be performed, such as retrieving data, updating information, or triggering actions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NLP BenchMarks</title>
      <link>http://localhost:1313/dsblog/NLP-BenchMarks1/</link>
      <pubDate>Wed, 03 Jul 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/NLP-BenchMarks1/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6120-NLP-BenchMarks.jpg&#34; alt=&#34;NLP-BenchMarks&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;nlp-benchmarks&#34;&gt;NLP BenchMarks&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-language-model&#34;&gt;What is Language Model?&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;language model&lt;/strong&gt; is a computational model that understands and generates human language. It learns the patterns and structure of a language by analyzing large amounts of text data, allowing it to predict the next word in a sequence or generate coherent text. Language models are used in applications like text generation, translation, speech recognition, chatbots, and sentiment analysis.&lt;/p&gt;&#xA;&lt;h2 id=&#34;how-to-create-language-model&#34;&gt;How to create Language Model?&lt;/h2&gt;&#xA;&lt;p&gt;Modern language models often use neural networks, especially transformer-based architectures like GPT and BERT, to capture complex language patterns and context. Techniques like tokenization, Embedding. Contextual Understanding are combined together in different architecture, different hyperparameters, different datasets and this produces a model which predict the next word.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoding Windows User Folder</title>
      <link>http://localhost:1313/dsblog/Decoding-Windows-User-Folder/</link>
      <pubDate>Sun, 30 Jun 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Decoding-Windows-User-Folder/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6119-Decoding-Windows-User-Folder.jpg&#34; alt=&#34;Decoding-Windows-User-Folder&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;decoding-windows-user-folder&#34;&gt;Decoding Windows User Folder&lt;/h1&gt;&#xA;&lt;h2 id=&#34;my-machine-cusers-folder-has-3-users-detault-harip-public-what-is-the-purpose-of-these-3-users&#34;&gt;My machine c:\users folder has 3 users Detault, harip, public. What is the purpose of these 3 users?&lt;/h2&gt;&#xA;&lt;p&gt;The &lt;code&gt;C:\Users&lt;/code&gt; folder on a Windows machine contains subfolders for each user profile on the system. Here&amp;rsquo;s an explanation of the purpose of the three users you mentioned: &lt;code&gt;Default&lt;/code&gt;, &lt;code&gt;hari&lt;/code&gt;, and &lt;code&gt;Public&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;h3 id=&#34;1-default&#34;&gt;1. Default&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: The &lt;code&gt;Default&lt;/code&gt; user profile is a template used by Windows when creating new user profiles. When a new user account is created on the system, Windows copies the contents of the &lt;code&gt;Default&lt;/code&gt; profile to set up the new user&amp;rsquo;s profile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Contents&lt;/strong&gt;: This folder typically contains the default settings and configuration files that new user profiles will inherit.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Location&lt;/strong&gt;: &lt;code&gt;C:\Users\Default&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;2-hari&#34;&gt;2. hari&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: This folder is the user profile for the account named &lt;code&gt;hari&lt;/code&gt;. It contains personal files, configuration settings, and application data specific to this user.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Contents&lt;/strong&gt;: It includes folders such as &lt;code&gt;Documents&lt;/code&gt;, &lt;code&gt;Downloads&lt;/code&gt;, &lt;code&gt;Pictures&lt;/code&gt;, &lt;code&gt;AppData&lt;/code&gt;, and others that store the user&amp;rsquo;s personal files and preferences.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Location&lt;/strong&gt;: &lt;code&gt;C:\Users\hari&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;3-public&#34;&gt;3. Public&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Purpose&lt;/strong&gt;: The &lt;code&gt;Public&lt;/code&gt; user profile is used to share files and folders among all users on the same computer. Any user account on the computer can access the files stored in the &lt;code&gt;Public&lt;/code&gt; profile.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Contents&lt;/strong&gt;: It typically contains folders such as &lt;code&gt;Public Documents&lt;/code&gt;, &lt;code&gt;Public Downloads&lt;/code&gt;, &lt;code&gt;Public Music&lt;/code&gt;, &lt;code&gt;Public Pictures&lt;/code&gt;, and &lt;code&gt;Public Videos&lt;/code&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Location&lt;/strong&gt;: &lt;code&gt;C:\Users\Public&lt;/code&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;summary&#34;&gt;Summary&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Default&lt;/strong&gt;: A template profile used to set up new user accounts.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;hari_&lt;/strong&gt;: A personal profile for the user named &lt;code&gt;hari_&lt;/code&gt;, containing their personal files and settings.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Public&lt;/strong&gt;: A shared profile accessible by all users on the computer, used for sharing files among users.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;These user profiles help manage and organize user-specific data and settings, ensuring that each user has a personalized experience while using the computer.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoding pip install operations</title>
      <link>http://localhost:1313/dsblog/Decoding-pip-install-operations/</link>
      <pubDate>Sat, 29 Jun 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Decoding-pip-install-operations/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6118-Decoding-pip-install-operations.jpg&#34; alt=&#34;Decoding-pip-install-operations&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;decoding-pip-install-operations&#34;&gt;Decoding pip install operations&lt;/h1&gt;&#xA;&lt;p&gt;Your draft provides useful insights into using &lt;code&gt;pip&lt;/code&gt; for Python package management. Here&amp;rsquo;s a refined version of your article with improved structure, grammar, and clarity:&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;managing-python-environments-and-packages-with-pip&#34;&gt;Managing Python Environments and Packages with &lt;code&gt;pip&lt;/code&gt;&lt;/h3&gt;&#xA;&lt;p&gt;In today&amp;rsquo;s technology landscape, where we deal with numerous programming languages, diverse hardware (CPU, GPU, TPU, etc.), various operating systems, and an extensive open-source community, building software from scratch can be quite challenging. Even when leveraging existing packages or solutions, there are still numerous challenges to consider, including security, safety, and privacy concerns.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Decoding docker commands</title>
      <link>http://localhost:1313/dsblog/Decoding-docker-commands/</link>
      <pubDate>Fri, 28 Jun 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Decoding-docker-commands/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6117-Decoding-docker-commands.jpg&#34; alt=&#34;Decoding-docker-commands&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;decoding-docker-commands&#34;&gt;Decoding docker commands&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are coming from IT Infrastructure background and have solid experience in containerization you can skip this. But if you are seeking to learn any of the following topic then keep reading.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;What is docker image, what is docker container, what is docker?&lt;/li&gt;&#xA;&lt;li&gt;How to create docker image and docker container?&lt;/li&gt;&#xA;&lt;li&gt;What is the use of docker compose?&lt;/li&gt;&#xA;&lt;li&gt;What is the meaning of code written inside Dockerfile?&lt;/li&gt;&#xA;&lt;li&gt;How to create a new python code and put inside the docker?&lt;/li&gt;&#xA;&lt;li&gt;How to ensure my docker uses my GPU?&lt;/li&gt;&#xA;&lt;li&gt;How to access my host machine&amp;rsquo;s local drive within the docker?&lt;/li&gt;&#xA;&lt;li&gt;How to send data out from docker to local host machine&amp;rsquo;s folder?&lt;/li&gt;&#xA;&lt;li&gt;How to execute command inside docker shell?&lt;/li&gt;&#xA;&lt;li&gt;How to install python packages inside docker?&lt;/li&gt;&#xA;&lt;li&gt;What are the common docker commands?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;introduction-why-this-article&#34;&gt;Introduction: Why this article?&lt;/h2&gt;&#xA;&lt;p&gt;Coming from a non-infrastructure background, I found working with Docker frustrating at first. The commands seemed cryptic, and complex environments often required downloading large images, creating custom ones, or modifying existing ones—only to face disappointing results. Investing so much time without clear success, or not knowing if Docker is the right solution from the start, can be disheartening. This article aims to demystify Docker, making it easier to understand and use effectively. After you learn the docker you will find that docker is the simplest thing in computer world to make development, testing and deployment more simple. Experts may be laughing at me. :)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Manamath Nath - Ramayana Corpus</title>
      <link>http://localhost:1313/dsblog/manamath-nath-ramayana-corpus/</link>
      <pubDate>Fri, 12 Jan 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/manamath-nath-ramayana-corpus/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6112-Manmath-Nath-Ramayana-Corpus.jpg&#34; alt=&#34;Manmath Nath - Ramayana Corpus&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;manmath-nath---ramayana-corpus&#34;&gt;Manmath Nath - Ramayana Corpus&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-corpus-intro&#34;&gt;Corpus Introduction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-text-license&#34;&gt;Corpus License&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-1&#34;&gt;Bala Kanda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-2&#34;&gt;Ayodhya Kanda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-3&#34;&gt;Aranyaka Kanda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-4&#34;&gt;Kishkinddha Kanda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-5&#34;&gt;Sunder Kanda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-6&#34;&gt;Lanka Kanda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/manmathnath-ramayana-7&#34;&gt;Utter Kanda&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>KM Ganguli Mahabharat Corpus</title>
      <link>http://localhost:1313/dsblog/KM-Ganguli-Mahabharat-Corpus/</link>
      <pubDate>Sun, 07 Jan 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/KM-Ganguli-Mahabharat-Corpus/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6111-KM-Ganguli-Mahabharata-Corpus.jpg&#34; alt=&#34;KM Ganguli Mahabharat Corpus&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;km-ganguli-mahabharat-corpus&#34;&gt;KM Ganguli Mahabharat Corpus&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_01&#34;&gt;Adi Parva (The Book of the Beginning)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_02&#34;&gt;Sabha Parva (The Book of the Assembly Hall)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_03&#34;&gt;Vana Parva or Aranyaka-Parva (The Book of the Forest)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_04&#34;&gt;Virata Parva (The Book of Virata)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_05&#34;&gt;Udyoga Parva (The Book of the Effort)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_06&#34;&gt;Bhishma Parva (The Book of Bhishma)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_07&#34;&gt;Drona Parva (The Book of Drona)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_08&#34;&gt;Karna Parva (The Book of Karna)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_09&#34;&gt;Shalya Parva (The Book of Shalya)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_10&#34;&gt;Sauptika Parva (The Book of the Sleeping Warriors)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_11&#34;&gt;Stri Parva (The Book of the Women)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_12&#34;&gt;Shanti Parva (The Book of Peace)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_13&#34;&gt;Anushasana Parva (The Book of the Instructions)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_14&#34;&gt;Ashvamedhika Parva (The Book of the Horse Sacrifice)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_15&#34;&gt;Ashramavasika Parva (The Book of the Hermitage)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_16&#34;&gt;Mausala Parva (The Book of the Clubs)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_17&#34;&gt;Mahaprasthanika Parva (The Book of the Great Journey)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://localhost:1313/mb-kmganguli-mahabharat_18&#34;&gt;Svargarohana Parva (The Book of the Ascent to Heaven)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>AI Usecases in Government</title>
      <link>http://localhost:1313/dsblog/AI-Usecases-in-Government/</link>
      <pubDate>Wed, 03 Jan 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Usecases-in-Government/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6110-AI-Usecases-in-Goverment.jpg&#34; alt=&#34;AI Usecases in Government&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-usecases-in-government&#34;&gt;AI Usecases in Government&lt;/h1&gt;&#xA;&lt;h2 id=&#34;preliminary-work-before-any-ai-project-with-government&#34;&gt;Preliminary Work before any AI Project with Government&lt;/h2&gt;&#xA;&lt;p&gt;Keeping technology evolution, cost of latest technologies, government expectations in mind one should do following steps.&lt;/p&gt;&#xA;&lt;h3 id=&#34;understanding&#34;&gt;Understanding&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Understand the mission, objective, goals of the portfolio or ministry. What is important for them like efficiency, public service enacting or enhancing, economic growth (jobs creation, agriculture production, food production, industrial production, startup etc)&lt;/li&gt;&#xA;&lt;li&gt;Understand AI policy of government, ministry, and department&lt;/li&gt;&#xA;&lt;li&gt;Understand their roadblocks/impediments in delivering the public service&lt;/li&gt;&#xA;&lt;li&gt;Understand the complete hierarchy from minister to peon and various departments under the portfolio&lt;/li&gt;&#xA;&lt;li&gt;Understand their metrics, formula to calculate the metric, frequency, data source, liveness of the source, reliability.&lt;/li&gt;&#xA;&lt;li&gt;Create stakholder power-interest grid, stakeholder and their metrics/KRA&lt;/li&gt;&#xA;&lt;li&gt;AI Awareness: Articulate clearly what are AI capabilities and what not. Given the avilable data and technology, articulate what is possible and what is not.&lt;/li&gt;&#xA;&lt;li&gt;Assess the infrastructre required and tentative cost.&lt;/li&gt;&#xA;&lt;li&gt;Understand regulatory framework involving compliance, approvals, audits etc.&lt;/li&gt;&#xA;&lt;li&gt;With examples understand how important is transparency, fairness, accountablity, public safety and trust is important them.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;solution-usecases-should-consider&#34;&gt;Solution Usecases should Consider&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Ethical Aspect&lt;/strong&gt;: Address the ethical implications of AI. How responsible AI can ensure this more efficiently.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Regulatory Framework&lt;/strong&gt;: Address regulatory framework and how AI can ensure higher compliance, more collaboration between the government, industry, and academia to create effective regulations.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Data Privacy and Security&lt;/strong&gt;: Address how data privacy and security measures can be taken care by AI systems.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h3 id=&#34;opportunities-to-engage-more&#34;&gt;Opportunities to Engage more&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;strong&gt;Education and Workforce Development&lt;/strong&gt;: Address how AI takes care of workforce training/skilling/upskilling need.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Public Perception and Awareness&lt;/strong&gt;: Address how AI can be effective in removing misconceptions or concerns about government policies prevalent in society.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Collaboration Opportunities&lt;/strong&gt;: Propose how AI opens new avenues for collaboration between the government, public and  public-private partnerships.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Case Studies and Success Stories&lt;/strong&gt;: Provide examples of successful AI implementations in other regions or sectors. Case&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;ai-usecases-in-government---across-sectors&#34;&gt;AI Usecases in Government - across sectors&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Healthcare&lt;/strong&gt;: AI can improve diagnostics, personalized medicine, and patient care through predictive analytics, image analysis, and disease prediction models. AI can reduce healthcare costs, improve treatment outcomes, and enhance accessibility to healthcare services. AI can assist in remote diagnostics or provide healthcare services in underserved areas&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI in School Education</title>
      <link>http://localhost:1313/dsblog/AI-in-School-Education/</link>
      <pubDate>Tue, 02 Jan 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-in-School-Education/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6109-AI-Usecases-in-Education.jpg&#34; alt=&#34;AI in School Education&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-in-school-education&#34;&gt;AI in School Education&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In the ever-evolving landscape of education, a technological revolution is quietly reshaping the way students learn, teachers instruct, and schools operate. At the heart of this transformation lies Artificial Intelligence (AI), an omnipresent force poised to revolutionize school education as we know it.&lt;/p&gt;&#xA;&lt;p&gt;AI&amp;rsquo;s emergence in education isn&amp;rsquo;t just a fleeting trend; it&amp;rsquo;s a paradigm shift with the potential to personalize learning experiences, empower educators, and reimagine the traditional classroom setup. From tailored lesson plans to administrative efficiency, AI is heralding a new era where education transcends boundaries and embraces innovation at its core.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Science and Basics of Astrology</title>
      <link>http://localhost:1313/dsblog/Basics-of-Astrology/</link>
      <pubDate>Wed, 27 Dec 2023 08:33:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Basics-of-Astrology/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6108-Basics-of-Astrology.jpg&#34; alt=&#34;Basics of Astrology&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;basics-of-jyotish&#34;&gt;Basics of Jyotish&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In this article I am going to discuss the basics of astrology and the data science aspect of astrology. I am defending here a big case of model retraining and without retraining if we are doing prediction from the old model that won&amp;rsquo;t be effective. Although in today&amp;rsquo;s time of data privacy, secrecy, getting personal data to create a prediction model is very costly or impossible for any corporation. As of today whatever data corporations are using to create the model of health care or public good or promoting a product for that anonymized data can be used but to create astrology models we need actual data. Only the government can get this data but the public doesn&amp;rsquo;t trust the government to create this model for predicting their life. What will be the future of Astrology and Jyotish in the coming time depends upon many factors, one of which is trust between governments and the public. The government can creates astrology models for the well being of the society. Without this, whatever astrology or Jyotish we are doing today it is becoming less trustworthy everyday.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Summary of Life Changing Selfhelp Books</title>
      <link>http://localhost:1313/dsblog/summary-of-life-changing-selfhelp-books/</link>
      <pubDate>Mon, 04 Dec 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/summary-of-life-changing-selfhelp-books/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6107-Summary-of-Life-Changing-Selfhelp-Books.jpg&#34; alt=&#34;Summary of Life Changing Selfhelp Books&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://localhost:1313/assets/docs/Summaries-of-Books.pdf&#34;&gt;Download Link to this Diary&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;object data=&#34;/assets/docs/Summaries-of-Books.pdf&#34; width=&#34;1000&#34; height=&#34;1000&#34; scroll=True type=&#39;application/pdf&#39;&gt;&lt;/object&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;The Inspirational Leader by Gifford Thomas&lt;/li&gt;&#xA;&lt;li&gt;The 5 Elements of Effective Thinking by Edward B. Burger&lt;/li&gt;&#xA;&lt;li&gt;How to Listen by Trimboli&lt;/li&gt;&#xA;&lt;li&gt;Self-discipline in 10 Days by Theodore Bryant&lt;/li&gt;&#xA;&lt;li&gt;Finish What You Start by Peter Hollis&lt;/li&gt;&#xA;&lt;li&gt;Do It Today by Darius Foroux&lt;/li&gt;&#xA;&lt;li&gt;Rest: Why You Get More Done When You Work Less by Alex&lt;/li&gt;&#xA;&lt;li&gt;Focus: The Hidden Driver of Excellence by Daniel Goleman&lt;/li&gt;&#xA;&lt;li&gt;The 4 Disciplines of Execution by Chris McChesney&lt;/li&gt;&#xA;&lt;li&gt;How To Develop The Leader Within You by John C. Maxwell&lt;/li&gt;&#xA;&lt;li&gt;Your Next Five Moves by Patrick Bet David&lt;/li&gt;&#xA;&lt;li&gt;The Power of Intention by Wayne W. Dyer&lt;/li&gt;&#xA;&lt;li&gt;The Power of Your Subconscious Mind by Joseph Murphy&lt;/li&gt;&#xA;&lt;li&gt;The Alchemist by Paulo Coelho&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Empowering Language with AI NLP Capabilities</title>
      <link>http://localhost:1313/dsblog/empowering-language-with-ainlp-capabilities/</link>
      <pubDate>Sat, 18 Nov 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/empowering-language-with-ainlp-capabilities/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6106-Empowering-Language-with-AI-NLP-Capabilities.jpg&#34; alt=&#34;Empowering-Language-with-AI-NLP-Capabilities&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;empowering-language-with-ai-nlp-capabilities&#34;&gt;Empowering-Language-with-AI-NLP-Capabilities&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;When envisioning artificial intelligence (AI), the initial images that often come to mind are humanoid robots. However, this perception oversimplifies the vast realm of AI, which is fundamentally distinct from natural intelligence—the inherent cognitive capacity found in living organisms shaped by Mother Nature. Life, in all its forms, from microscopic bacteria to complex human beings, possesses an innate intelligence derived from hydrocarbon-based living cells.&lt;/p&gt;&#xA;&lt;p&gt;The essence of life, intelligence, and consciousness transcends mere philosophical pondering; it&amp;rsquo;s a contentious debate within the scientific community. In the context of AI, the term refers to the intelligence embedded in machines crafted by human ingenuity. This synthetic intelligence is made possible through the integration of chips, predominantly fashioned from silicon—leading to their colloquial designation as silicon chips. Notably, the epicenter of many IT companies is aptly named Silicon Valley.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Topic Modeling with BERT</title>
      <link>http://localhost:1313/dsblog/topic-modeling-with-bert/</link>
      <pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/topic-modeling-with-bert/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6105-Topic-Modeling-with-BERT.jpg&#34; alt=&#34;Topic Modeling with BERT&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;topic-modeling-with-bert&#34;&gt;Topic Modeling with BERT&lt;/h1&gt;&#xA;&lt;p&gt;Key steps in BERTopic modelling are as following.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use &amp;ldquo;Sentence Embedding&amp;rdquo; models to embed the sentences of the article&lt;/li&gt;&#xA;&lt;li&gt;Reduce the dimensionality of embedding using UMAP&lt;/li&gt;&#xA;&lt;li&gt;Cluster these documents (reduced dimensions) using HDBSAN&lt;/li&gt;&#xA;&lt;li&gt;Use c-TF-IDF extract keywords, their frequency and IDF for each cluster.&lt;/li&gt;&#xA;&lt;li&gt;MMR: Maximize Candidate Relevance. How many words in a topic can represent the topic?&lt;/li&gt;&#xA;&lt;li&gt;Intertopic Distance Map&lt;/li&gt;&#xA;&lt;li&gt;Use similarity matrix (heatmap), dandogram (hierarchical map), to visualize the topics and key_words.&lt;/li&gt;&#xA;&lt;li&gt;Traction of topic over time period. Some may be irrelevant and for other traction may be increasing or decreasing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;installation&#34;&gt;Installation&lt;/h1&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Installation, with sentence-transformers, can be done using pypi:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install bertopic&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# If you want to install BERTopic with other embedding models, you can choose one of the following:&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Choose an embedding backend&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install bertopic[flair, gensim, spacy, use]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;# Topic modeling with images&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;pip install bertopic[vision]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h1 id=&#34;supported-topic-modelling-techniques&#34;&gt;Supported Topic Modelling Techniques&lt;/h1&gt;&#xA;&lt;p&gt;BERTopic supports all kinds of topic modeling techniques as below.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basics of Word Embedding</title>
      <link>http://localhost:1313/dsblog/basics-of-word-embedding/</link>
      <pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/basics-of-word-embedding/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6101-Basics-of-Word-Embedding.jpg&#34; alt=&#34;Basics of Word Embedding&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;basics-of-word-embedding&#34;&gt;Basics of Word Embedding&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-context-target-and-window&#34;&gt;What is Context, target and window?&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;The &amp;ldquo;context&amp;rdquo; word is the surrounding word.&lt;/li&gt;&#xA;&lt;li&gt;The &amp;ldquo;target&amp;rdquo; word is the middle word.&lt;/li&gt;&#xA;&lt;li&gt;The &amp;ldquo;window distance&amp;rdquo; is number of words (including) between context words and target word. Window distance 1 means, one word surronding the target, one left side context word, one right context word. Two window distance means 2 words left and 2 words right.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Let&amp;rsquo;s take a sentence&lt;/p&gt;</description>
    </item>
    <item>
      <title>Graph of Thoughts</title>
      <link>http://localhost:1313/dsblog/graph-of-thoughts/</link>
      <pubDate>Sat, 11 Nov 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/graph-of-thoughts/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6103-Graph-of-Thoughts.jpg&#34; alt=&#34;Graph of Thoughts&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;graph-of-thoughts&#34;&gt;Graph of Thoughts&lt;/h1&gt;&#xA;&lt;p&gt;This is a valuable resource for learning Graph of Thoughts (GoT) concepts. The YouTube video is from code_your_own_AI. I&amp;rsquo;m utilizing the comments made by @wesleychang2005 on the video, which provide an excellent summary of GoT. If you&amp;rsquo;re interested in this topic and find the summary below intriguing, I recommend watching the entire 41-minute video.&lt;/p&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=tCPA89n6NGQ&amp;amp;t=1562&#34;&gt;https://www.youtube.com/watch?v=tCPA89n6NGQ&amp;t=1562&lt;/a&gt;&lt;br&gt;&#xA;&lt;strong&gt;Take Aways from the video&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;00:26 🤯 Graph of Thoughts (GoT) is a non-linear approach to reasoning for AI agents, using interconnected nodes and edges to represent the thought process.&lt;/li&gt;&#xA;&lt;li&gt;01:18 📊 The Tree of Thoughts method suffers from inefficiency, requiring hundreds of queries to solve a single problem.&lt;/li&gt;&#xA;&lt;li&gt;02:36 🎯 An AI agent is defined as an entity that can perceive its environment, make decisions, and initiate actions based on a control cycle and a reward function.&lt;/li&gt;&#xA;&lt;li&gt;05:39 🌐 The latest research focuses on AI agents augmented by Large Language Models (LLMs) for more intelligent and autonomous behavior.&lt;/li&gt;&#xA;&lt;li&gt;08:43 🤖 LLM-augmented AI agents can interact with and learn from their environment, making them more adaptive and capable.&lt;/li&gt;&#xA;&lt;li&gt;12:45 📝 Explanation fine-tuning of LLMs (Large Language Models) is guided by GPT-4&amp;rsquo;s own reasoning explanation, serving as a blueprint for development.&lt;/li&gt;&#xA;&lt;li&gt;13:34 🕸️ The &amp;ldquo;Graph of Thoughts&amp;rdquo; allows for a flexible approach to reasoning, where multiple chains of thoughts can be pursued and evaluated simultaneously.&lt;/li&gt;&#xA;&lt;li&gt;16:50 🎛️ The application of graph theory in AI involves the use of graph attention networks and various encoding techniques to manage both visual and textual data.&lt;/li&gt;&#xA;&lt;li&gt;22:46 📊 A scoring mechanism is used to assess the LLM&amp;rsquo;s replies for accuracy and relevance, aiding in quality control of the model&amp;rsquo;s output.&lt;/li&gt;&#xA;&lt;li&gt;24:16 🎮 A &amp;ldquo;Controller&amp;rdquo; manages the entire reasoning process, using a &amp;ldquo;Graph of Operations&amp;rdquo; (GoO) to dictate the execution plan for tasks, making the reasoning adaptable and structured.&lt;/li&gt;&#xA;&lt;li&gt;25:35 🌍 Graph-of-Thoughts (GoT) can be used for planet classification tasks. The speaker uses a simple example where an AI system decides whether a planet is habitable based on attributes like distance from the sun and atmospheric conditions.&lt;/li&gt;&#xA;&lt;li&gt;27:32 🛠️ In GoT, each node in the &amp;lsquo;Graph of Operations&amp;rsquo; (GoO) represents a specific task (e.g., check distance from the sun). The &amp;lsquo;Graph Reasoning State&amp;rsquo; (GRS) records and updates the system&amp;rsquo;s understanding as nodes are executed.&lt;/li&gt;&#xA;&lt;li&gt;29:30 📝 The speaker describes a more complex example involving multiple types of planets and a list of features for classification. He emphasizes the need for a specialized Language Learning Model (LLM) trained in astrophysics.&lt;/li&gt;&#xA;&lt;li&gt;32:56 🎯 Scoring and validation are essential for assessing the reliability of the AI&amp;rsquo;s responses. The system assigns a confidence score to its classification decision.&lt;/li&gt;&#xA;&lt;li&gt;35:48 🔄 The GoT system can incorporate human feedback, iterating through multiple loops to refine its reasoning process and improve classification outcomes.&lt;/li&gt;&#xA;&lt;li&gt;36:57 🛠️ The Graph-of-Operation (GoO) framework lays out how AI operations interact and depend on each other in a sequence, from initial query to final output.&lt;/li&gt;&#xA;&lt;li&gt;38:18 🙋‍♂️ Human domain expertise is essential for designing the reasoning flow within the GoO, as it&amp;rsquo;s not automatically generated by the AI system itself.&lt;/li&gt;&#xA;&lt;li&gt;39:18 🤔 GPT-4 suggests that future AI systems like GPT-5 could potentially engage in meta-learning or self-improvement, opening the possibility for AI to design its own GoO structure.&lt;/li&gt;&#xA;&lt;li&gt;39:43 📊 Adequate training data is crucial for advanced AI systems to learn diverse tasks in multiple domains and potentially design complex GoO structures.&lt;/li&gt;&#xA;&lt;li&gt;40:07 📈 Mathematical graph theory could help in constructing multiple graphs for specific problems, setting the stage for training more advanced AI systems.&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>My Journey from Master to PhD in Data Science and AI</title>
      <link>http://localhost:1313/dsblog/journey-from-master-to-phd/</link>
      <pubDate>Wed, 08 Nov 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/journey-from-master-to-phd/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6100-Journey-from-MS-to-Phd.jpg&#34; alt=&#34;My Journey from Master to PhD in Data Science and AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;my-journey-from-master-to-phd-in-data-science-and-ai&#34;&gt;My Journey from Master to PhD in Data Science and AI&lt;/h1&gt;&#xA;&lt;p&gt;I have been in software development between 1993 to 2009. Some of these years were in senior leadership roles in delivery management, project management, CMMI, ISO, ISMS, PMO, etc. In 2010 I moved into project management training and consulting. In 2018, I was considering going back to technology but this time I wanted to pick up a completely new stack of technology. I decided I would move into Data Science and AI. I knew AI as much as any typical software development person in senior management knew about this. It means I was highly confident that I could pick this up quickly. On top of that lots of content is available on the internet, many YouTube channels, and many courses are available. I thought it should be a cakewalk for me. I started learning this technology in my own way in my committed free time. Within 5-6 months after lots of study I started realizing this was the way to get the knowledge but it could not help me get confident to solve the problem. The more I learned, the more I felt that I did not know how much I needed to learn or how far I needed to go.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Compressing Large Language Model</title>
      <link>http://localhost:1313/dsblog/compressing-llm/</link>
      <pubDate>Tue, 07 Nov 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/compressing-llm/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6099-Compressing-LLM.jpg&#34; alt=&#34;Compressing Large Language Model&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;compressing-large-language-model&#34;&gt;Compressing Large Language Model&lt;/h1&gt;&#xA;&lt;h2 id=&#34;is-this-article-for-me&#34;&gt;Is this article for me?&lt;/h2&gt;&#xA;&lt;p&gt;If you are looking answers to following question then &amp;ldquo;Yes&amp;rdquo;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is LLM compression?&lt;/li&gt;&#xA;&lt;li&gt;Why is LLM compression necessary?&lt;/li&gt;&#xA;&lt;li&gt;What are the different techniques for LLM compression?&lt;/li&gt;&#xA;&lt;li&gt;How does quantization work in LLM compression?&lt;/li&gt;&#xA;&lt;li&gt;What is pruning, and how does it help in compressing LLMs?&lt;/li&gt;&#xA;&lt;li&gt;Can you explain knowledge distillation in the context of LLMs?&lt;/li&gt;&#xA;&lt;li&gt;What is low-rank factorization and its role in LLM compression?&lt;/li&gt;&#xA;&lt;li&gt;How effective are weight sharing techniques in compressing LLMs?&lt;/li&gt;&#xA;&lt;li&gt;What are the trade-offs involved in LLM compression?&lt;/li&gt;&#xA;&lt;li&gt;How does fine-tuning work in the context of compressed LLMs?&lt;/li&gt;&#xA;&lt;li&gt;What are the benefits of fine-tuning in compressed LLMs?&lt;/li&gt;&#xA;&lt;li&gt;What role does hardware play in LLM compression?&lt;/li&gt;&#xA;&lt;li&gt;What are the ethical considerations in LLM compression?&lt;/li&gt;&#xA;&lt;li&gt;What are the future directions in LLM compression?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;1-what-is-llm-compression&#34;&gt;1. &lt;strong&gt;What is LLM Compression?&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;LLM (Large Language Model) compression refers to a set of techniques and methodologies aimed at reducing the size of large language models while maintaining their performance as much as possible. Large language models, such as GPT, BERT, and their variants, often contain hundreds of millions to billions of parameters, making them resource-intensive to deploy and run. The sheer size of these models poses challenges in terms of storage, computation, and real-time inference, especially when deploying on devices with limited hardware resources like mobile phones or edge devices.&lt;/p&gt;</description>
    </item>
    <item>
      <title>LaTeX Capabilities</title>
      <link>http://localhost:1313/dsblog/latex-capabilities/</link>
      <pubDate>Mon, 06 Nov 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/latex-capabilities/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6098-Latex-capabilities.jpg&#34; alt=&#34;LaTeX Capabilities&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;In the realm of document typesetting and preparation, LaTeX stands as a timeless giant, revered by professionals, researchers, students, and publishers alike. With its unmatched typographic quality, precision, and versatility, LaTeX empowers users to create documents that transcend the boundaries of conventional word processing. In this article, I am listing major capabilities that make LaTeX the tool of choice for those who demand perfection in their documents, ready to learn some coding and don&amp;rsquo;t want to pay for all this.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is Pinecone</title>
      <link>http://localhost:1313/dsblog/What-is-Pinecone/</link>
      <pubDate>Sun, 03 Sep 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-Pinecone/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6097-What-is-Pinecone.jpg&#34; alt=&#34;What is Pinecone&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-pinecone&#34;&gt;What is pinecone?&lt;/h2&gt;&#xA;&lt;p&gt;Pinecone is a managed vector database that provides vector search (or “similarity search”) for developers with a straightforward API and usage-based pricing. It’s free to try. &lt;a href=&#34;https://www.pinecone.io/learn/vector-search-basics/&#34;&gt;Introduction to Vector Search for Developers&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-a-vector-database&#34;&gt;What is a &lt;a href=&#34;https://www.pinecone.io/learn/vector-database/&#34;&gt;Vector Database&lt;/a&gt;?&lt;/h2&gt;&#xA;&lt;p&gt;Your must have heard about relational database, graph database, object datbase. But this article is about Vector Database.&lt;/p&gt;&#xA;&lt;p&gt;All AI Models need data for training and inference purposes. This data may be of different modalities like voice, image, text, tabular, etc. To train the model or to get the prediction from the model we need to input this data.  We need to devise a mechanism to convert this data into a format where we can perform mathematical operations on this data. This process of converting the original data into some floating point number, which represents the original object is called embedding. We create a vector embedding for each corresponding object. A database where you store these vectors of the objects is called a vector database. If you create the vector embedding for the objects during processing and do not store it for future reference then you waste compute resources to get the embedding and time to do this again and again. Therefore, it makes sense to compute the vector embedding of every object and store that in a vector database, and for doing our work like search, sorting, recommendation, summarisation etc. we use these embeddings from the vector database.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ML Model Development Framework</title>
      <link>http://localhost:1313/dsblog/ML-Model-Development-Framework/</link>
      <pubDate>Sat, 02 Sep 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ML-Model-Development-Framework/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6096-ML-Model-Development-Framework.jpg&#34; alt=&#34;ML Model Development Framework&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ml-model-development-framework--model-repositories&#34;&gt;ML Model Development Framework &amp;amp; Model Repositories&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;There are hundreds of &lt;a href=&#34;http://localhost:1313/dsblog/nlp-tasks&#34;&gt;machine learning tasks&lt;/a&gt;. To do these tasks there are &lt;a href=&#34;http://localhost:1313/dsblog/Type-of-Databases&#34;&gt;thousands of datasets&lt;/a&gt; created by individuals, governments, and corporations. We need to develop AI models using these datasets. There are thousands of models &lt;a href=&#34;dsblog/ML-Model-Repository-from-Pinto0309&#34;&gt;1&lt;/a&gt;, &lt;a href=&#34;http://localhost:1313/dsblog/paperwithcode-resources&#34;&gt;2&lt;/a&gt;, &lt;a href=&#34;http://localhost:1313/dsblog/What-Are-Transformers-in-AI&#34;&gt;3&lt;/a&gt; and many model development frameworks. It is practically mind-blowing to track this whole body of work and understand all this work in its entirety. But if you dive deeper into the following frameworks you will get a fair idea about the overall direction of the work. These frameworks are used to maintain pre-trained model repositories and download pre-trained models. You can develop your own finetuned model using those pre-trained models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ML Model Respository from Pinto0309</title>
      <link>http://localhost:1313/dsblog/ML-Model-Repository-from-Pinto0309/</link>
      <pubDate>Fri, 01 Sep 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ML-Model-Repository-from-Pinto0309/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6095-ML-Model-Repository-from-Pinto0309.jpg&#34; alt=&#34;ML Model Respository from Pinto0309&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ml-model-repository-from-pinto0309&#34;&gt;ML Model Repository from Pinto0309&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Using AI we can solve many kinds of tasks for this input can be text, structured data, image, video, audio, time-series, etc. To solve these problems we need to train model. These models may be computer vision, NLP, or traditional machine learning kind. There are hundreds of architectures and algorithms to solve business problems and create models. There a hundreds of different datasets that can be along with a particular architecture or algorithm to solve the problem. If you have any of these tasks then you can explore using these pre-trained models to solve your problem. There is a GitHub user &amp;ldquo;Katsuya Hyodo&amp;rdquo; with GitHub account &amp;ldquo;PINTO0309&amp;rdquo;. He has trained hundreds of models and created these pre-trained models for the community. You can scan and explore them from there. From there you can download the pre-trained models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python APIs for Data</title>
      <link>http://localhost:1313/dsblog/python-apis-for-data/</link>
      <pubDate>Mon, 28 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/python-apis-for-data/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6094-Python-APIs-for-Data.jpg&#34; alt=&#34;Python APIs for Data&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;python-apis-for-data&#34;&gt;Python APIs for Data&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.bing.com/&#34;&gt;Bing&lt;/a&gt; Bing is a search engine that brings together the best of search and people in your social networks to help you spend less time searching and more time doing.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.bing.com/dev/en-us/dev-center&#34;&gt;Api Documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://code.google.com/p/pybing/&#34;&gt;Python wrapper for the Bing search API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://www.bitly.com/&#34;&gt;Bitly&lt;/a&gt; URL shortening and bookmarking service&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;http://dev.bitly.com/get_started.html&#34;&gt;Api Documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://code.google.com/p/python-bitly/&#34;&gt;Python wrapper around the bit.ly API&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://blogger.com/&#34;&gt;Blogger&lt;/a&gt; Blog-publishing service&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developers.google.com/blogger/&#34;&gt;Api Documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://code.google.com/p/python-blogger/&#34;&gt;A python wrapper around the Blogger&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.box.com/&#34;&gt;Box&lt;/a&gt; Online file sharing and Cloud content management service for enterprise companies.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Distances in Machine Learning</title>
      <link>http://localhost:1313/dsblog/Distances-in-Machine-Learning/</link>
      <pubDate>Sun, 27 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Distances-in-Machine-Learning/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6093-Distances-in-Machine-Learning.jpg&#34; alt=&#34;Distances in Machine Learning&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;distances-in-machine-learning&#34;&gt;Distances in Machine Learning&lt;/h1&gt;&#xA;&lt;p&gt;Every sample, record, word, sentence, object, image etc in the Machine learning language is called vector. If we want to measure the similarity or dissimilarity between two data points then we need distance function.&lt;/p&gt;&#xA;&lt;p&gt;Distance metrics play a crucial role in various machine learning algorithms, including clustering, classification, and anomaly detection. Different distance measures capture different types of relationships between data points.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Important AI Paper List</title>
      <link>http://localhost:1313/dsblog/select-ai-papers/</link>
      <pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/select-ai-papers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6090-rps-Important-AI-Paper-List.jpg&#34; alt=&#34;Important AI Paper List&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;important-ai-paper-list&#34;&gt;Important AI Paper List&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduciton&#34;&gt;Introduciton&lt;/h2&gt;&#xA;&lt;p&gt;In almost all citations it becomes very difficult to read the title of research papers. Why? Because the contributors&amp;rsquo; information is first and most of the time, it is difficult to read the name other than native people. For example, if an Indian find a native name like &amp;ldquo;Vivek Ramaswami, Kartikeyan Karunanidhi&amp;rdquo; it is easy for them to read the name but the same name becomes difficult to read for non-Indian people, and vice-versa. Giving respect to the creator is very important but more than we need to know what have they done. I know from my experience, for almost every researcher, it becomes very difficult to track good AI research papers. For me, it is more difficult because I need to maintain this blog and I want to give references to the work across different webpages. Therefore I am creating a citation key, which includes the Last name of the first researcher + year of presenting that paper. Along with this, I am describing the title of the paper and where it was presented. If you find a particular title interesting for your work you can search that paper on &amp;ldquo;google scholar&amp;rdquo;, Mendeley, sci-hub or other places with which you are familiar and comfortable. Post that you can download and read that paper at your leisure. Hope you find this list of some use for your work.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Paper with Code Resources</title>
      <link>http://localhost:1313/dsblog/paperwithcode-resources/</link>
      <pubDate>Tue, 22 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/paperwithcode-resources/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6091-rps-Paperwithcode-Resources.jpg&#34; alt=&#34;Paper with Code Resources&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;paper-with-code-resources&#34;&gt;Paper with Code Resources&lt;/h1&gt;&#xA;&lt;h2 id=&#34;trending-papers-of-2021&#34;&gt;Trending Papers of 2021&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;ADOP: Approximate Differentiable One-Pixel Point Rendering — Rückert et al — &lt;a href=&#34;https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel&#34;&gt;https://paperswithcode.com/paper/adop-approximate-differentiable-one-pixel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;The Bayesian Learning Rule —Khan et al &lt;a href=&#34;https://paperswithcode.com/paper/the-bayesian-learning-rule&#34;&gt;https://paperswithcode.com/paper/the-bayesian-learning-rule&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Program Synthesis with Large Language Models — Austin et al &lt;a href=&#34;https://paperswithcode.com/paper/program-synthesis-with-large-language-models&#34;&gt;https://paperswithcode.com/paper/program-synthesis-with-large-language-models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Masked Autoencoders Are Scalable Vision Learners — He et al &lt;a href=&#34;https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision&#34;&gt;https://paperswithcode.com/paper/masked-autoencoders-are-scalable-vision&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;8-bit Optimizers via Block-wise Quantization — Dettmers et al &lt;a href=&#34;https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization&#34;&gt;https://paperswithcode.com/paper/8-bit-optimizers-via-block-wise-quantization&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Revisiting ResNets: Improved Training and Scaling Strategies — Bello et al &lt;a href=&#34;https://paperswithcode.com/paper/revisiting-resnets-improved-training-and&#34;&gt;https://paperswithcode.com/paper/revisiting-resnets-improved-training-and&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Image Super-Resolution via Iterative Refinement — Saharia et al &lt;a href=&#34;https://paperswithcode.com/paper/image-super-resolution-via-iterative&#34;&gt;https://paperswithcode.com/paper/image-super-resolution-via-iterative&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Perceiver IO: A General Architecture for Structured Inputs &amp;amp; Outputs — Jaegle et al &lt;a href=&#34;https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for&#34;&gt;https://paperswithcode.com/paper/perceiver-io-a-general-architecture-for&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Do Vision Transformers See Like Convolutional Neural Networks? — Raghu et al &lt;a href=&#34;https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional&#34;&gt;https://paperswithcode.com/paper/do-vision-transformers-see-like-convolutional&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Implicit MLE: Backpropagating Through Discrete Exponential Family Distributions — Niepert et al &lt;a href=&#34;https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete&#34;&gt;https://paperswithcode.com/paper/implicit-mle-backpropagating-through-discrete&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;trending-libaries-of-2021&#34;&gt;Trending Libaries of 2021&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;PyTorch Image Models — Ross Wightman — &lt;a href=&#34;https://github.com/rwightman/pytorch-image-models&#34;&gt;https://github.com/rwightman/pytorch-image-models&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Transformers — Hugging Face — &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;https://github.com/huggingface/transformers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;PyTorch-GAN — Erik Linder-Norén — &lt;a href=&#34;https://github.com/eriklindernoren/PyTorch-GAN&#34;&gt;https://github.com/eriklindernoren/PyTorch-GAN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;MMDetection — OpenMMLab — &lt;a href=&#34;https://github.com/open-mmlab/mmdetection&#34;&gt;https://github.com/open-mmlab/mmdetection&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Darknet — AlexeyAB — &lt;a href=&#34;https://github.com/AlexeyAB/darknet&#34;&gt;https://github.com/AlexeyAB/darknet&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Vision Transformer PyTorch — lucidrains — &lt;a href=&#34;https://github.com/lucidrains/vit-pytorch&#34;&gt;https://github.com/lucidrains/vit-pytorch&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;InsightFace — DeepInsight — &lt;a href=&#34;https://github.com/deepinsight/insightface&#34;&gt;https://github.com/deepinsight/insightface&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Detectron2 — Meta AI — &lt;a href=&#34;https://github.com/facebookresearch/detectron2&#34;&gt;https://github.com/facebookresearch/detectron2&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;PaddleOCR — PaddlePaddle — &lt;a href=&#34;https://github.com/PaddlePaddle/PaddleOCR&#34;&gt;https://github.com/PaddlePaddle/PaddleOCR&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;FairSeq — Meta AI — &lt;a href=&#34;https://github.com/pytorch/fairseq&#34;&gt;https://github.com/pytorch/fairseq&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;top-dataset---2021&#34;&gt;Top Dataset - 2021&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;MATH — Hendrycks et al &lt;a href=&#34;https://paperswithcode.com/dataset/math&#34;&gt;https://paperswithcode.com/dataset/math&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;UAV-Human — Li et al &lt;a href=&#34;https://paperswithcode.com/dataset/uav-human&#34;&gt;https://paperswithcode.com/dataset/uav-human&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;UPFD (User Preference-aware Fake News Detection) — Dou et al &lt;a href=&#34;https://paperswithcode.com/dataset/upfd&#34;&gt;https://paperswithcode.com/dataset/upfd&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;OGB-LSC (OGB Large-Scale Challenge) — Hu et al &lt;a href=&#34;https://paperswithcode.com/dataset/ogb-lsc&#34;&gt;https://paperswithcode.com/dataset/ogb-lsc&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;CodeXGLUE —Lu et al &lt;a href=&#34;https://paperswithcode.com/dataset/codexglue&#34;&gt;https://paperswithcode.com/dataset/codexglue&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;AGORA — Patel et al &lt;a href=&#34;https://paperswithcode.com/dataset/agora&#34;&gt;https://paperswithcode.com/dataset/agora&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;BEIR (Benchmarking IR) — Thakur et al &lt;a href=&#34;https://paperswithcode.com/dataset/beir&#34;&gt;https://paperswithcode.com/dataset/beir&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;WikiGraphs — Wang et al &lt;a href=&#34;https://paperswithcode.com/dataset/wikigraphs&#34;&gt;https://paperswithcode.com/dataset/wikigraphs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Few-NERD — Ding et al &lt;a href=&#34;https://paperswithcode.com/dataset/few-nerd&#34;&gt;https://paperswithcode.com/dataset/few-nerd&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;PASS (Pictures without humAns for Self-Supervision) —Asano et al &lt;a href=&#34;https://paperswithcode.com/dataset/pass&#34;&gt;https://paperswithcode.com/dataset/pass&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;papers-of-2022&#34;&gt;Papers of 2022&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Controllable Animation of Fluid Elements in Still Images&lt;/li&gt;&#xA;&lt;li&gt;F-SfT: Shape-From-Template With A Physics-Based Deformation Model&lt;/li&gt;&#xA;&lt;li&gt;TWIST: Two-Way Inter-Label Self-Training for Semi-Supervised 3D Instance Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Do Learned Representations Respect Causal Relationships?&lt;/li&gt;&#xA;&lt;li&gt;ZeroCap: Zero-Shot Image-to-Text Generation for Visual-Semantic Arithmetic&lt;/li&gt;&#xA;&lt;li&gt;3D Moments From Near-Duplicate Photos&lt;/li&gt;&#xA;&lt;li&gt;Exact Feature Distribution Matching for Arbitrary Style Transfer and Domain Generalization&lt;/li&gt;&#xA;&lt;li&gt;Blind2Unblind: Self-Supervised Image Denoising With Visible Blind Spots&lt;/li&gt;&#xA;&lt;li&gt;Balanced and Hierarchical Relation Learning for One-Shot Object Detection&lt;/li&gt;&#xA;&lt;li&gt;NICE-SLAM: Neural Implicit Scalable Encoding for SLAM&lt;/li&gt;&#xA;&lt;li&gt;Stochastic Trajectory Prediction Via Motion Indeterminacy Diffusion&lt;/li&gt;&#xA;&lt;li&gt;CLRNet: Cross Layer Refinement Network for Lane Detection&lt;/li&gt;&#xA;&lt;li&gt;Motion-Aware Contrastive Video Representation Learning Via Foreground-Background Merging&lt;/li&gt;&#xA;&lt;li&gt;DINE: Domain Adaptation From Single and Multiple Black-Box Predictors&lt;/li&gt;&#xA;&lt;li&gt;FaceFormer: Speech-Driven 3D Facial Animation With Transformers&lt;/li&gt;&#xA;&lt;li&gt;Rotationally Equivariant 3D Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Accelerating DETR Convergence Via Semantic-Aligned Matching&lt;/li&gt;&#xA;&lt;li&gt;Cloning Outfits From Real-World Images to 3D Characters for Generalizable Person Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;GeoNeRF: Generalizing NeRF With Geometry Priors&lt;/li&gt;&#xA;&lt;li&gt;ABPN: Adaptive Blend Pyramid Network for Real-Time Local Retouching of Ultra High-Resolution Photo&lt;/li&gt;&#xA;&lt;li&gt;Expanding Low-Density Latent Regions for Open-Set Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Uformer: A General U-Shaped Transformer for Image Restoration&lt;/li&gt;&#xA;&lt;li&gt;Exploring Dual-Task Correlation for Pose Guided Person Image Generation&lt;/li&gt;&#xA;&lt;li&gt;Portrait Eyeglasses and Shadow Removal By Leveraging 3D Synthetic Data&lt;/li&gt;&#xA;&lt;li&gt;Modeling 3D Layout for Group Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;Toward Fast, Flexible, and Robust Low-Light Image Enhancement&lt;/li&gt;&#xA;&lt;li&gt;Bridge-Prompt: Towards Ordinal Action Understanding in Instructional Videos&lt;/li&gt;&#xA;&lt;li&gt;HandOccNet: Occlusion-Robust 3D Hand Mesh Estimation Network&lt;/li&gt;&#xA;&lt;li&gt;Modular Action Concept Grounding in Semantic Video Prediction&lt;/li&gt;&#xA;&lt;li&gt;StyleSwin: Transformer-Based GAN for High-Resolution Image Generation&lt;/li&gt;&#xA;&lt;li&gt;Discrete Cosine Transform Network for Guided Depth Map Super-Resolution&lt;/li&gt;&#xA;&lt;li&gt;Cerberus Transformer: Joint Semantic, Affordance and Attribute Parsing&lt;/li&gt;&#xA;&lt;li&gt;TransGeo: Transformer Is All You Need for Cross-View Image Geo-Localization&lt;/li&gt;&#xA;&lt;li&gt;Contrastive Boundary Learning for Point Cloud Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Details or Artifacts: A Locally Discriminative Learning Approach to Realistic Image Super-Resolution&lt;/li&gt;&#xA;&lt;li&gt;CVNet: Contour Vibration Network for Building Extraction&lt;/li&gt;&#xA;&lt;li&gt;Swin Transformer V2: Scaling Up Capacity and Resolution&lt;/li&gt;&#xA;&lt;li&gt;Projective Manifold Gradient Layer for Deep Rotation Regression&lt;/li&gt;&#xA;&lt;li&gt;HCSC: Hierarchical Contrastive Selective Coding&lt;/li&gt;&#xA;&lt;li&gt;TransRank: Self-Supervised Video Representation Learning Via Ranking-Based Transformation Recognition&lt;/li&gt;&#xA;&lt;li&gt;DiSparse: Disentangled Sparsification for Multitask Model Compression&lt;/li&gt;&#xA;&lt;li&gt;Pushing The Limits of Simple Pipelines for Few-Shot Learning: External Data and Fine-Tuning Make A Difference&lt;/li&gt;&#xA;&lt;li&gt;Towards Efficient and Scalable Sharpness-Aware Minimization&lt;/li&gt;&#xA;&lt;li&gt;OSSO: Obtaining Skeletal Shape From Outside&lt;/li&gt;&#xA;&lt;li&gt;A Study on The Distribution of Social Biases in Self-Supervised Learning Visual Models&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Predictive Learning: A Negative-Free Method for Sound Source Localization in Visual Scenes&lt;/li&gt;&#xA;&lt;li&gt;Comparing Correspondences: Video Prediction With Correspondence-Wise Losses&lt;/li&gt;&#xA;&lt;li&gt;Towards Fewer Annotations: Active Learning Via Region Impurity and Prediction Uncertainty for Domain Adaptive Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;CrossPoint: Self-Supervised Cross-Modal Contrastive Learning for 3D Point Cloud Understanding&lt;/li&gt;&#xA;&lt;li&gt;Few Shot Generative Model Adaption Via Relaxed Spatial Structural Alignment&lt;/li&gt;&#xA;&lt;li&gt;Enhancing Adversarial Training With Second-Order Statistics of Weights&lt;/li&gt;&#xA;&lt;li&gt;Dual Temperature Helps Contrastive Learning Without Many Negative Samples: Towards Understanding and Simplifying MoCo&lt;/li&gt;&#xA;&lt;li&gt;Moving Window Regression: A Novel Approach to Ordinal Regression&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Predictive Convolutional Attentive Block for Anomaly Detection&lt;/li&gt;&#xA;&lt;li&gt;Robust Optimization As Data Augmentation for Large-Scale Graphs&lt;/li&gt;&#xA;&lt;li&gt;Robust Structured Declarative Classifiers for 3D Point Clouds: Defending Adversarial Attacks With Implicit Gradients&lt;/li&gt;&#xA;&lt;li&gt;Improving The Transferability of Targeted Adversarial Examples Through Object-Based Diverse Input&lt;/li&gt;&#xA;&lt;li&gt;ObjectFolder 2.0: A Multisensory Object Dataset for Sim2Real Transfer&lt;/li&gt;&#xA;&lt;li&gt;360MonoDepth: High-Resolution 360deg Monocular Depth Estimation&lt;/li&gt;&#xA;&lt;li&gt;POCO: Point Convolution for Surface Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;Neural Texture Extraction and Distribution for Controllable Person Image Synthesis&lt;/li&gt;&#xA;&lt;li&gt;Classification-Then-Grounding: Reformulating Video Scene Graphs As Temporal Bipartite Graphs&lt;/li&gt;&#xA;&lt;li&gt;DF-GAN: A Simple and Effective Baseline for Text-to-Image Synthesis&lt;/li&gt;&#xA;&lt;li&gt;ZeroWaste Dataset: Towards Deformable Object Segmentation in Cluttered Scenes&lt;/li&gt;&#xA;&lt;li&gt;UNIST: Unpaired Neural Implicit Shape Translation Network&lt;/li&gt;&#xA;&lt;li&gt;APES: Articulated Part Extraction From Sprite Sheets&lt;/li&gt;&#xA;&lt;li&gt;SPAct: Self-Supervised Privacy Preservation for Action Recognition&lt;/li&gt;&#xA;&lt;li&gt;De-Rendering 3D Objects in The Wild&lt;/li&gt;&#xA;&lt;li&gt;Global Sensing and Measurements Reuse for Image Compressed Sensing&lt;/li&gt;&#xA;&lt;li&gt;Practical Evaluation of Adversarial Robustness Via Adaptive Auto Attack&lt;/li&gt;&#xA;&lt;li&gt;Cross-View Transformers for Real-Time Map-View Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Controllable Dynamic Multi-Task Architectures&lt;/li&gt;&#xA;&lt;li&gt;FastDOG: Fast Discrete Optimization on GPU&lt;/li&gt;&#xA;&lt;li&gt;Focal and Global Knowledge Distillation for Detectors&lt;/li&gt;&#xA;&lt;li&gt;Learning To Prompt for Continual Learning&lt;/li&gt;&#xA;&lt;li&gt;Human Mesh Recovery From Multiple Shots&lt;/li&gt;&#xA;&lt;li&gt;Convolution of Convolution: Let Kernels Spatially Collaborate&lt;/li&gt;&#xA;&lt;li&gt;Make It Move: Controllable Image-to-Video Generation With Text Descriptions&lt;/li&gt;&#xA;&lt;li&gt;Neural Points: Point Cloud Representation With Neural Fields for Arbitrary Upsampling&lt;/li&gt;&#xA;&lt;li&gt;Video-Text Representation Learning Via Differentiable Weak Temporal Alignment&lt;/li&gt;&#xA;&lt;li&gt;Bi-Directional Object-Context Prioritization Learning for Saliency Ranking&lt;/li&gt;&#xA;&lt;li&gt;Vehicle Trajectory Prediction Works, But Not Everywhere&lt;/li&gt;&#xA;&lt;li&gt;MonoDTR: Monocular 3D Object Detection With Depth-Aware Transformer&lt;/li&gt;&#xA;&lt;li&gt;Attribute Surrogates Learning and Spectral Tokens Pooling in Transformers for Few-Shot Learning&lt;/li&gt;&#xA;&lt;li&gt;Generalized Category Discovery&lt;/li&gt;&#xA;&lt;li&gt;Contour-Hugging Heatmaps for Landmark Detection&lt;/li&gt;&#xA;&lt;li&gt;Voxel Field Fusion for 3D Object Detection&lt;/li&gt;&#xA;&lt;li&gt;DisARM: Displacement Aware Relation Module for 3D Detection&lt;/li&gt;&#xA;&lt;li&gt;MixFormer: Mixing Features Across Windows and Dimensions&lt;/li&gt;&#xA;&lt;li&gt;FineDiving: A Fine-Grained Dataset for Procedure-Aware Action Quality Assessment&lt;/li&gt;&#xA;&lt;li&gt;HEAT: Holistic Edge Attention Transformer for Structured Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;Mobile-Former: Bridging MobileNet and Transformer&lt;/li&gt;&#xA;&lt;li&gt;CycleMix: A Holistic Strategy for Medical Image Segmentation From Scribble Supervision&lt;/li&gt;&#xA;&lt;li&gt;VideoINR: Learning Video Implicit Neural Representation for Continuous Space-Time Super-Resolution&lt;/li&gt;&#xA;&lt;li&gt;Towards End-to-End Unified Scene Text Detection and Layout Analysis&lt;/li&gt;&#xA;&lt;li&gt;AutoSDF: Shape Priors for 3D Completion, Reconstruction and Generation&lt;/li&gt;&#xA;&lt;li&gt;ISNAS-DIP: Image-Specific Neural Architecture Search for Deep Image Prior&lt;/li&gt;&#xA;&lt;li&gt;End-to-End Referring Video Object Segmentation With Multimodal Transformers&lt;/li&gt;&#xA;&lt;li&gt;IterMVS: Iterative Probability Estimation for Efficient Multi-View Stereo&lt;/li&gt;&#xA;&lt;li&gt;Not All Points Are Equal: Learning Highly Efficient Point-Based Detectors for 3D LiDAR Point Clouds&lt;/li&gt;&#xA;&lt;li&gt;Detecting Camouflaged Object in Frequency Domain&lt;/li&gt;&#xA;&lt;li&gt;SelfRecon: Self Reconstruction Your Digital Avatar From Monocular Video&lt;/li&gt;&#xA;&lt;li&gt;Equivariant Point Cloud Analysis Via Learning Orientations for Message Passing&lt;/li&gt;&#xA;&lt;li&gt;Node Representation Learning in Graph Via Node-to-Neighbourhood Mutual Information Maximization&lt;/li&gt;&#xA;&lt;li&gt;Semi-Supervised Video Semantic Segmentation With Inter-Frame Feature Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;Amodal Segmentation Through Out-of-Task and Out-of-Distribution Generalization With A Bayesian Model&lt;/li&gt;&#xA;&lt;li&gt;How Well Do Sparse ImageNet Models Transfer?&lt;/li&gt;&#xA;&lt;li&gt;REX: Reasoning-Aware and Grounded Explanation&lt;/li&gt;&#xA;&lt;li&gt;Canonical Voting: Towards Robust Oriented Bounding Box Detection in 3D Scenes&lt;/li&gt;&#xA;&lt;li&gt;Object-Aware Video-Language Pre-Training for Retrieval&lt;/li&gt;&#xA;&lt;li&gt;MAT: Mask-Aware Transformer for Large Hole Image Inpainting&lt;/li&gt;&#xA;&lt;li&gt;Align and Prompt: Video-and-Language Pre-Training With Entity Prompts&lt;/li&gt;&#xA;&lt;li&gt;MSG-Transformer: Exchanging Local Spatial Information By Manipulating Messenger Tokens&lt;/li&gt;&#xA;&lt;li&gt;Cross Modal Retrieval With Querybank Normalisation&lt;/li&gt;&#xA;&lt;li&gt;Ray3D: Ray-Based 3D Human Pose Estimation for Monocular Absolute 3D Localization&lt;/li&gt;&#xA;&lt;li&gt;ASM-Loc: Action-Aware Segment Modeling for Weakly-Supervised Temporal Action Localization&lt;/li&gt;&#xA;&lt;li&gt;Scaling Up Your Kernels to 31×31: Revisiting Large Kernel Design in CNNs&lt;/li&gt;&#xA;&lt;li&gt;End-to-End Multi-Person Pose Estimation With Transformers&lt;/li&gt;&#xA;&lt;li&gt;REGTR: End-to-End Point Cloud Correspondences With Transformers&lt;/li&gt;&#xA;&lt;li&gt;Neural 3D Scene Reconstruction With The Manhattan-World Assumption&lt;/li&gt;&#xA;&lt;li&gt;V2C: Visual Voice Cloning&lt;/li&gt;&#xA;&lt;li&gt;Revisiting AP Loss for Dense Object Detection: Adaptive Ranking Pair Selection&lt;/li&gt;&#xA;&lt;li&gt;MAD: A Scalable Dataset for Language Grounding in Videos From Movie Audio Descriptions&lt;/li&gt;&#xA;&lt;li&gt;Gait Recognition in The Wild With Dense 3D Representations and A Benchmark&lt;/li&gt;&#xA;&lt;li&gt;ArtiBoost: Boosting Articulated 3D Hand-Object Pose Estimation Via Online Exploration and Synthesis&lt;/li&gt;&#xA;&lt;li&gt;QueryDet: Cascaded Sparse Query for Accelerating High-Resolution Small Object Detection&lt;/li&gt;&#xA;&lt;li&gt;IDEA-Net: Dynamic 3D Point Cloud Interpolation Via Deep Embedding Alignment&lt;/li&gt;&#xA;&lt;li&gt;BEHAVE: Dataset and Method for Tracking Human Object Interactions&lt;/li&gt;&#xA;&lt;li&gt;Revisiting Random Channel Pruning for Neural Network Compression&lt;/li&gt;&#xA;&lt;li&gt;Generating Diverse and Natural 3D Human Motions From Text&lt;/li&gt;&#xA;&lt;li&gt;E-CIR: Event-Enhanced Continuous Intensity Recovery&lt;/li&gt;&#xA;&lt;li&gt;Towards Robust Rain Removal Against Adversarial Attacks: A Comprehensive Benchmark Analysis and Beyond&lt;/li&gt;&#xA;&lt;li&gt;Symmetry and Uncertainty-Aware Object SLAM for 6DoF Object Pose Estimation&lt;/li&gt;&#xA;&lt;li&gt;AziNorm: Exploiting The Radial Symmetry of Point Cloud for Azimuth-Normalized 3D Perception&lt;/li&gt;&#xA;&lt;li&gt;Weakly Supervised Rotation-Invariant Aerial Object Detection Network&lt;/li&gt;&#xA;&lt;li&gt;Surface Reconstruction From Point Clouds By Learning Predictive Context Priors&lt;/li&gt;&#xA;&lt;li&gt;IRISformer: Dense Vision Transformers for Single-Image Inverse Rendering in Indoor Scenes&lt;/li&gt;&#xA;&lt;li&gt;DynamicEarthNet: Daily Multi-Spectral Satellite Dataset for Semantic Change Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Weakly Supervised Temporal Action Localization Via Representative Snippet Knowledge Propagation&lt;/li&gt;&#xA;&lt;li&gt;E2EC: An End-to-End Contour-Based Method for High-Quality High-Speed Instance Segmentation&lt;/li&gt;&#xA;&lt;li&gt;BatchFormer: Learning To Explore Sample Relationships for Robust Representation Learning&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Image-Specific Prototype Exploration for Weakly Supervised Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Learning Multi-View Aggregation in The Wild for Large-Scale 3D Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;PIE-Net: Photometric Invariant Edge Guided Network for Intrinsic Image Decomposition&lt;/li&gt;&#xA;&lt;li&gt;Clothes-Changing Person Re-Identification With RGB Modality Only&lt;/li&gt;&#xA;&lt;li&gt;Robust Image Forgery Detection Over Online Social Network Shared Images&lt;/li&gt;&#xA;&lt;li&gt;Representation Compensation Networks for Continual Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Tracking People By Predicting 3D Appearance, Location and Pose&lt;/li&gt;&#xA;&lt;li&gt;Text2Mesh: Text-Driven Neural Stylization for Meshes&lt;/li&gt;&#xA;&lt;li&gt;C-CAM: Causal CAM for Weakly Supervised Semantic Segmentation on Medical Image&lt;/li&gt;&#xA;&lt;li&gt;Forward Compatible Few-Shot Class-Incremental Learning&lt;/li&gt;&#xA;&lt;li&gt;Weakly Supervised Object Localization As Domain Adaption&lt;/li&gt;&#xA;&lt;li&gt;Tencent-MVSE: A Large-Scale Benchmark Dataset for Multi-Modal Video Similarity Evaluation&lt;/li&gt;&#xA;&lt;li&gt;Deep Orientation-Aware Functional Maps: Tackling Symmetry Issues in Shape Matching&lt;/li&gt;&#xA;&lt;li&gt;Tree Energy Loss: Towards Sparsely Annotated Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;MatteFormer: Transformer-Based Image Matting Via Prior-Tokens&lt;/li&gt;&#xA;&lt;li&gt;Video Shadow Detection Via Spatio-Temporal Interpolation Consistency Training&lt;/li&gt;&#xA;&lt;li&gt;Robust and Accurate Superquadric Recovery: A Probabilistic Approach&lt;/li&gt;&#xA;&lt;li&gt;Grounding Answers for Visual Questions Asked By Visually Impaired People&lt;/li&gt;&#xA;&lt;li&gt;Sparse Instance Activation for Real-Time Instance Segmentation&lt;/li&gt;&#xA;&lt;li&gt;VisualGPT: Data-Efficient Adaptation of Pretrained Language Models for Image Captioning&lt;/li&gt;&#xA;&lt;li&gt;MHFormer: Multi-Hypothesis Transformer for 3D Human Pose Estimation&lt;/li&gt;&#xA;&lt;li&gt;Surface-Aligned Neural Radiance Fields for Controllable 3D Human Synthesis&lt;/li&gt;&#xA;&lt;li&gt;Towards Implicit Text-Guided 3D Shape Generation&lt;/li&gt;&#xA;&lt;li&gt;SoftCollage: A Differentiable Probabilistic Tree Generator for Image Collage&lt;/li&gt;&#xA;&lt;li&gt;Query and Attention Augmentation for Knowledge-Based Explainable Reasoning&lt;/li&gt;&#xA;&lt;li&gt;Winoground: Probing Vision and Language Models for Visio-Linguistic Compositionality&lt;/li&gt;&#xA;&lt;li&gt;Progressive Attention on Multi-Level Dense Difference Maps for Generic Event Boundary Detection&lt;/li&gt;&#xA;&lt;li&gt;Fine-Grained Object Classification Via Self-Supervised Pose Alignment&lt;/li&gt;&#xA;&lt;li&gt;Animal Kingdom: A Large and Diverse Dataset for Animal Behavior Understanding&lt;/li&gt;&#xA;&lt;li&gt;Fine-Grained Temporal Contrastive Learning for Weakly-Supervised Temporal Action Localization&lt;/li&gt;&#xA;&lt;li&gt;Relieving Long-Tailed Instance Segmentation Via Pairwise Class Balance&lt;/li&gt;&#xA;&lt;li&gt;Online Convolutional Re-Parameterization&lt;/li&gt;&#xA;&lt;li&gt;Mimicking The Oracle: An Initial Phase Decorrelation Approach for Class Incremental Learning&lt;/li&gt;&#xA;&lt;li&gt;RelTransformer: A Transformer-Based Long-Tail Visual Relationship Recognition&lt;/li&gt;&#xA;&lt;li&gt;Personalized Image Aesthetics Assessment With Rich Attributes&lt;/li&gt;&#xA;&lt;li&gt;Part-Based Pseudo Label Refinement for Unsupervised Person Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;HDNet: High-Resolution Dual-Domain Learning for Spectral Compressive Imaging&lt;/li&gt;&#xA;&lt;li&gt;OW-DETR: Open-World Detection Transformer&lt;/li&gt;&#xA;&lt;li&gt;Learning Deep Implicit Functions for 3D Shapes With Dynamic Code Clouds&lt;/li&gt;&#xA;&lt;li&gt;Reversible Vision Transformers&lt;/li&gt;&#xA;&lt;li&gt;Amodal Panoptic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Correlation Verification for Image Retrieval&lt;/li&gt;&#xA;&lt;li&gt;Temporal Feature Alignment and Mutual Information Maximization for Video-Based Human Pose Estimation&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Transformers for Unsupervised Object Discovery Using Normalized Cut&lt;/li&gt;&#xA;&lt;li&gt;Exploring Structure-Aware Transformer Over Interaction Proposals for Human-Object Interaction Detection&lt;/li&gt;&#xA;&lt;li&gt;Decoupled Multi-Task Learning With Cyclical Self-Regulation for Face Parsing&lt;/li&gt;&#xA;&lt;li&gt;Glass: Geometric Latent Augmentation for Shape Spaces&lt;/li&gt;&#xA;&lt;li&gt;DPICT: Deep Progressive Image Compression Using Trit-Planes&lt;/li&gt;&#xA;&lt;li&gt;Text to Image Generation With Semantic-Spatial Aware GAN&lt;/li&gt;&#xA;&lt;li&gt;Generalizable Cross-Modality Medical Image Segmentation Via Style Augmentation and Dual Normalization&lt;/li&gt;&#xA;&lt;li&gt;Learning To Prompt for Open-Vocabulary Object Detection With Vision-Language Model&lt;/li&gt;&#xA;&lt;li&gt;Interactive Segmentation and Visualization for Tiny Objects in Multi-Megapixel Images&lt;/li&gt;&#xA;&lt;li&gt;Neural MoCon: Neural Motion Control for Physically Plausible Human Motion Capture&lt;/li&gt;&#xA;&lt;li&gt;Surface Representation for Point Clouds&lt;/li&gt;&#xA;&lt;li&gt;Implicit Motion Handling for Video Camouflaged Object Detection&lt;/li&gt;&#xA;&lt;li&gt;DeepLIIF: An Online Platform for Quantification of Clinical Pathology Slides&lt;/li&gt;&#xA;&lt;li&gt;Learning With Twin Noisy Labels for Visible-Infrared Person Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;Optical Flow Estimation for Spiking Camera&lt;/li&gt;&#xA;&lt;li&gt;GradViT: Gradient Inversion of Vision Transformers&lt;/li&gt;&#xA;&lt;li&gt;Spatial-Temporal Space Hand-in-Hand: Spatial-Temporal Video Super-Resolution Via Cycle-Projected Mutual Learning&lt;/li&gt;&#xA;&lt;li&gt;Joint Global and Local Hierarchical Priors for Learned Image Compression&lt;/li&gt;&#xA;&lt;li&gt;Knowledge Distillation Via The Target-Aware Transformer&lt;/li&gt;&#xA;&lt;li&gt;Subspace Adversarial Training&lt;/li&gt;&#xA;&lt;li&gt;3D-VField: Adversarial Augmentation of Point Clouds for Domain Generalization in 3D Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Image Segmentation Using Text and Image Prompts&lt;/li&gt;&#xA;&lt;li&gt;AutoMine: An Unmanned Mine Dataset&lt;/li&gt;&#xA;&lt;li&gt;Background Activation Suppression for Weakly Supervised Object Localization&lt;/li&gt;&#xA;&lt;li&gt;Synthetic Generation of Face Videos With Plethysmograph Physiology&lt;/li&gt;&#xA;&lt;li&gt;Hallucinated Neural Radiance Fields in The Wild&lt;/li&gt;&#xA;&lt;li&gt;Global Tracking Transformers&lt;/li&gt;&#xA;&lt;li&gt;Backdoor Attacks on Self-Supervised Learning&lt;/li&gt;&#xA;&lt;li&gt;GMFlow: Learning Optical Flow Via Global Matching&lt;/li&gt;&#xA;&lt;li&gt;Learning Hierarchical Cross-Modal Association for Co-Speech Gesture Generation&lt;/li&gt;&#xA;&lt;li&gt;Explore Spatio-Temporal Aggregation for Insubstantial Object Detection: Benchmark Dataset and Baseline&lt;/li&gt;&#xA;&lt;li&gt;Graph-Based Spatial Transformer With Memory Replay for Multi-Future Pedestrian Trajectory Prediction&lt;/li&gt;&#xA;&lt;li&gt;Scanline Homographies for Rolling-Shutter Plane Absolute Pose&lt;/li&gt;&#xA;&lt;li&gt;AdaInt: Learning Adaptive Intervals for 3D Lookup Tables on Real-Time Image Enhancement&lt;/li&gt;&#xA;&lt;li&gt;Recurrent Glimpse-Based Decoder for Detection With Transformer&lt;/li&gt;&#xA;&lt;li&gt;SimMIM: A Simple Framework for Masked Image Modeling&lt;/li&gt;&#xA;&lt;li&gt;Label Matching Semi-Supervised Object Detection&lt;/li&gt;&#xA;&lt;li&gt;RegionCLIP: Region-Based Language-Image Pretraining&lt;/li&gt;&#xA;&lt;li&gt;Video Frame Interpolation Transformer&lt;/li&gt;&#xA;&lt;li&gt;BCOT: A Markerless High-Precision 3D Object Tracking Benchmark&lt;/li&gt;&#xA;&lt;li&gt;Omni-DETR: Omni-Supervised Object Detection With Transformers&lt;/li&gt;&#xA;&lt;li&gt;Transferable Sparse Adversarial Attack&lt;/li&gt;&#xA;&lt;li&gt;CREAM: Weakly Supervised Object Localization Via Class RE-Activation Mapping&lt;/li&gt;&#xA;&lt;li&gt;VALHALLA: Visual Hallucination for Machine Translation&lt;/li&gt;&#xA;&lt;li&gt;HINT: Hierarchical Neuron Concept Explainer&lt;/li&gt;&#xA;&lt;li&gt;Neural Face Identification in A 2D Wireframe Projection of A Manifold Object&lt;/li&gt;&#xA;&lt;li&gt;Nonuniform-to-Uniform Quantization: Towards Accurate Quantization Via Generalized Straight-Through Estimation&lt;/li&gt;&#xA;&lt;li&gt;An Empirical Study of End-to-End Temporal Action Detection&lt;/li&gt;&#xA;&lt;li&gt;Object Localization Under Single Coarse Point Supervision&lt;/li&gt;&#xA;&lt;li&gt;Unsupervised Learning of Accurate Siamese Tracking&lt;/li&gt;&#xA;&lt;li&gt;Non-Parametric Depth Distribution Modelling Based Depth Inference for Multi-View Stereo&lt;/li&gt;&#xA;&lt;li&gt;Equalized Focal Loss for Dense Long-Tailed Object Detection&lt;/li&gt;&#xA;&lt;li&gt;DeepDPM: Deep Clustering With An Unknown Number of Clusters&lt;/li&gt;&#xA;&lt;li&gt;ISDNet: Integrating Shallow and Deep Networks for Efficient Ultra-High Resolution Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Unsupervised Domain Adaptation for Nighttime Aerial Tracking&lt;/li&gt;&#xA;&lt;li&gt;RestoreFormer: High-Quality Blind Face Restoration From Undegraded Key-Value Pairs&lt;/li&gt;&#xA;&lt;li&gt;Mask-Guided Spectral-Wise Transformer for Efficient Hyperspectral Image Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;A Variational Bayesian Method for Similarity Learning in Non-Rigid Image Registration&lt;/li&gt;&#xA;&lt;li&gt;Not Just Selection, But Exploration: Online Class-Incremental Continual Learning Via Dual View Consistency&lt;/li&gt;&#xA;&lt;li&gt;Coupling Vision and Proprioception for Navigation of Legged Robots&lt;/li&gt;&#xA;&lt;li&gt;Exploiting Rigidity Constraints for LiDAR Scene Flow Estimation&lt;/li&gt;&#xA;&lt;li&gt;EMOCA: Emotion Driven Monocular Face Capture and Animation&lt;/li&gt;&#xA;&lt;li&gt;Quarantine: Sparsity Can Uncover The Trojan Attack Trigger for Free&lt;/li&gt;&#xA;&lt;li&gt;AlignQ: Alignment Quantization With ADMM-Based Correlation Preservation&lt;/li&gt;&#xA;&lt;li&gt;Interactive Multi-Class Tiny-Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Learning From Pixel-Level Noisy Label: A New Perspective for Light Field Saliency Detection&lt;/li&gt;&#xA;&lt;li&gt;Multi-View Depth Estimation By Fusing Single-View Depth Probability With Multi-View Geometry&lt;/li&gt;&#xA;&lt;li&gt;Slimmable Domain Adaptation&lt;/li&gt;&#xA;&lt;li&gt;High-Resolution Image Harmonization Via Collaborative Dual Transformations&lt;/li&gt;&#xA;&lt;li&gt;MM-TTA: Multi-Modal Test-Time Adaptation for 3D Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Neural Articulated Shape and Appearance Models&lt;/li&gt;&#xA;&lt;li&gt;Topology Preserving Local Road Network Estimation From Single Onboard Camera Image&lt;/li&gt;&#xA;&lt;li&gt;Eigenlanes: Data-Driven Lane Descriptors for Structurally Diverse Lanes&lt;/li&gt;&#xA;&lt;li&gt;SwinTextSpotter: Scene Text Spotting Via Better Synergy Between Text Detection and Text Recognition&lt;/li&gt;&#xA;&lt;li&gt;Deblur-NeRF: Neural Radiance Fields From Blurry Images&lt;/li&gt;&#xA;&lt;li&gt;Whose Track Is It Anyway? Improving Robustness to Tracking Errors With Affinity-Based Trajectory Prediction&lt;/li&gt;&#xA;&lt;li&gt;Video K-Net: A Simple, Strong, and Unified Baseline for Video Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Local Learning Matters: Rethinking Data Heterogeneity in Federated Learning&lt;/li&gt;&#xA;&lt;li&gt;Blind Image Super-Resolution With Elaborate Degradation Modeling on Noise and Kernel&lt;/li&gt;&#xA;&lt;li&gt;Faithful Extreme Rescaling Via Generative Prior Reciprocated Invertible Representations&lt;/li&gt;&#xA;&lt;li&gt;Proto2Proto: Can You Recognize The Car, The Way I Do?&lt;/li&gt;&#xA;&lt;li&gt;TVConv: Efficient Translation Variant Convolution for Layout-Aware Visual Processing&lt;/li&gt;&#xA;&lt;li&gt;Dual Adversarial Adaptation for Cross-Device Real-World Image Super-Resolution&lt;/li&gt;&#xA;&lt;li&gt;Habitat-Web: Learning Embodied Object-Search Strategies From Human Demonstrations at Scale&lt;/li&gt;&#xA;&lt;li&gt;Simple But Effective: CLIP Embeddings for Embodied AI&lt;/li&gt;&#xA;&lt;li&gt;NomMer: Nominate Synergistic Context in Vision Transformer for Visual Recognition&lt;/li&gt;&#xA;&lt;li&gt;Collaborative Transformers for Grounded Situation Recognition&lt;/li&gt;&#xA;&lt;li&gt;CPPF: Towards Robust Category-Level 9D Pose Estimation in The Wild&lt;/li&gt;&#xA;&lt;li&gt;Continual Test-Time Domain Adaptation&lt;/li&gt;&#xA;&lt;li&gt;Dynamic MLP for Fine-Grained Image Classification By Leveraging Geographical and Temporal Information&lt;/li&gt;&#xA;&lt;li&gt;MuKEA: Multimodal Knowledge Extraction and Accumulation for Knowledge-Based Visual Question Answering&lt;/li&gt;&#xA;&lt;li&gt;Fair Contrastive Learning for Facial Attribute Classification&lt;/li&gt;&#xA;&lt;li&gt;Directional Self-Supervised Learning for Heavy Image Augmentations&lt;/li&gt;&#xA;&lt;li&gt;No-Reference Point Cloud Quality Assessment Via Domain Adaptation&lt;/li&gt;&#xA;&lt;li&gt;Comprehending and Ordering Semantics for Image Captioning&lt;/li&gt;&#xA;&lt;li&gt;A Large-Scale Comprehensive Dataset and Copy-Overlap Aware Evaluation Protocol for Segment-Level Video Copy Detection&lt;/li&gt;&#xA;&lt;li&gt;Label Relation Graphs Enhanced Hierarchical Residual Network for Hierarchical Multi-Granularity Classification&lt;/li&gt;&#xA;&lt;li&gt;HeadNeRF: A Real-Time NeRF-Based Parametric Head Model&lt;/li&gt;&#xA;&lt;li&gt;Occlusion-Robust Face Alignment Using A Viewpoint-Invariant Hierarchical Network Architecture&lt;/li&gt;&#xA;&lt;li&gt;IDR: Self-Supervised Image Denoising Via Iterative Data Refinement&lt;/li&gt;&#xA;&lt;li&gt;MogFace: Towards A Deeper Appreciation on Face Detection&lt;/li&gt;&#xA;&lt;li&gt;Learning Affinity From Attention: End-to-End Weakly-Supervised Semantic Segmentation With Transformers&lt;/li&gt;&#xA;&lt;li&gt;CamLiFlow: Bidirectional Camera-LiDAR Fusion for Joint Optical Flow and Scene Flow Estimation&lt;/li&gt;&#xA;&lt;li&gt;FERV39k: A Large-Scale Multi-Scene Dataset for Facial Expression Recognition in Videos&lt;/li&gt;&#xA;&lt;li&gt;Learning To Detect Mobile Objects From LiDAR Scans Without Labels&lt;/li&gt;&#xA;&lt;li&gt;WildNet: Learning Domain Generalized Semantic Segmentation From The Wild&lt;/li&gt;&#xA;&lt;li&gt;DAIR-V2X: A Large-Scale Dataset for Vehicle-Infrastructure Cooperative 3D Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Point-to-Voxel Knowledge Distillation for LiDAR Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Generating Diverse 3D Reconstructions From A Single Occluded Face Image&lt;/li&gt;&#xA;&lt;li&gt;Stand-Alone Inter-Frame Attention in Video Models&lt;/li&gt;&#xA;&lt;li&gt;Large-Scale Pre-Training for Person Re-Identification With Noisy Labels&lt;/li&gt;&#xA;&lt;li&gt;Semantic Segmentation By Early Region Proxy&lt;/li&gt;&#xA;&lt;li&gt;LD-ConGR: A Large RGB-D Video Dataset for Long-Distance Continuous Gesture Recognition&lt;/li&gt;&#xA;&lt;li&gt;HVH: Learning A Hybrid Neural Volumetric Representation for Dynamic Hair Performance Capture&lt;/li&gt;&#xA;&lt;li&gt;Rethinking Visual Geo-Localization for Large-Scale Applications&lt;/li&gt;&#xA;&lt;li&gt;The Principle of Diversity: Training Stronger Vision Transformers Calls for Reducing All Levels of Redundancy&lt;/li&gt;&#xA;&lt;li&gt;ViM: Out-of-Distribution With Virtual-Logit Matching&lt;/li&gt;&#xA;&lt;li&gt;Class-Aware Contrastive Semi-Supervised Learning&lt;/li&gt;&#xA;&lt;li&gt;Ditto: Building Digital Twins of Articulated Objects From Interaction&lt;/li&gt;&#xA;&lt;li&gt;Adaptive Early-Learning Correction for Segmentation From Noisy Annotations&lt;/li&gt;&#xA;&lt;li&gt;Cross-Domain Correlation Distillation for Unsupervised Domain Adaptation in Nighttime Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;RSTT: Real-Time Spatial Temporal Transformer for Space-Time Video Super-Resolution&lt;/li&gt;&#xA;&lt;li&gt;Partial Class Activation Attention for Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Multi-Scale Memory-Based Video Deblurring&lt;/li&gt;&#xA;&lt;li&gt;A Scalable Combinatorial Solver for Elastic Geometrically Consistent 3D Shape Matching&lt;/li&gt;&#xA;&lt;li&gt;Geometric Structure Preserving Warp for Natural Image Stitching&lt;/li&gt;&#xA;&lt;li&gt;GOAL: Generating 4D Whole-Body Motion for Hand-Object Grasping&lt;/li&gt;&#xA;&lt;li&gt;Conditional Prompt Learning for Vision-Language Models&lt;/li&gt;&#xA;&lt;li&gt;Graph Sampling Based Deep Metric Learning for Generalizable Person Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;Undoing The Damage of Label Shift for Cross-Domain Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;FisherMatch: Semi-Supervised Rotation Regression Via Entropy-Based Filtering&lt;/li&gt;&#xA;&lt;li&gt;Affine Medical Image Registration With Coarse-To-Fine Vision Transformer&lt;/li&gt;&#xA;&lt;li&gt;A Differentiable Two-Stage Alignment Scheme for Burst Image Reconstruction With Large Shift&lt;/li&gt;&#xA;&lt;li&gt;Deformable ProtoPNet: An Interpretable Image Classifier Using Deformable Prototypes&lt;/li&gt;&#xA;&lt;li&gt;Restormer: Efficient Transformer for High-Resolution Image Restoration&lt;/li&gt;&#xA;&lt;li&gt;IFRNet: Intermediate Feature Refine Network for Efficient Frame Interpolation&lt;/li&gt;&#xA;&lt;li&gt;Large Loss Matters in Weakly Supervised Multi-Label Classification&lt;/li&gt;&#xA;&lt;li&gt;Neural Inertial Localization&lt;/li&gt;&#xA;&lt;li&gt;GraftNet: Towards Domain Generalized Stereo Matching With A Broad-Spectrum and Task-Oriented Feature&lt;/li&gt;&#xA;&lt;li&gt;VGSE: Visually-Grounded Semantic Embeddings for Zero-Shot Learning&lt;/li&gt;&#xA;&lt;li&gt;Catching Both Gray and Black Swans: Open-Set Supervised Anomaly Detection&lt;/li&gt;&#xA;&lt;li&gt;MLSLT: Towards Multilingual Sign Language Translation&lt;/li&gt;&#xA;&lt;li&gt;Towards An End-to-End Framework for Flow-Guided Video Inpainting&lt;/li&gt;&#xA;&lt;li&gt;Contrastive Test-Time Adaptation&lt;/li&gt;&#xA;&lt;li&gt;MotionAug: Augmentation With Physical Correction for Human Motion Prediction&lt;/li&gt;&#xA;&lt;li&gt;Modeling Indirect Illumination for Inverse Rendering&lt;/li&gt;&#xA;&lt;li&gt;TransWeather: Transformer-Based Restoration of Images Degraded By Adverse Weather Conditions&lt;/li&gt;&#xA;&lt;li&gt;H2FA R-CNN: Holistic and Hierarchical Feature Alignment for Cross-Domain Weakly Supervised Object Detection&lt;/li&gt;&#xA;&lt;li&gt;P3Depth: Monocular Depth Estimation With A Piecewise Planarity Prior&lt;/li&gt;&#xA;&lt;li&gt;GEN-VLKT: Simplify Association and Enhance Interaction Understanding for HOI Detection&lt;/li&gt;&#xA;&lt;li&gt;Simple Multi-Dataset Detection&lt;/li&gt;&#xA;&lt;li&gt;Proactive Image Manipulation Detection&lt;/li&gt;&#xA;&lt;li&gt;StyTr2: Image Style Transfer With Transformers&lt;/li&gt;&#xA;&lt;li&gt;Global Matching With Overlapping Attention for Optical Flow Estimation&lt;/li&gt;&#xA;&lt;li&gt;Language As Queries for Referring Video Object Segmentation&lt;/li&gt;&#xA;&lt;li&gt;MViTv2: Improved Multiscale Vision Transformers for Classification and Detection&lt;/li&gt;&#xA;&lt;li&gt;Audio-Visual Generalised Zero-Shot Learning With Cross-Modal Attention and Language&lt;/li&gt;&#xA;&lt;li&gt;Rethinking Efficient Lane Detection Via Curve Modeling&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Arbitrary-Scale Point Clouds Upsampling Via Implicit Neural Representation&lt;/li&gt;&#xA;&lt;li&gt;Co-Advise: Cross Inductive Bias Distillation&lt;/li&gt;&#xA;&lt;li&gt;AdaMixer: A Fast-Converging Query-Based Object Detector&lt;/li&gt;&#xA;&lt;li&gt;DTFD-MIL: Double-Tier Feature Distillation Multiple Instance Learning for Histopathology Whole Slide Image Classification&lt;/li&gt;&#xA;&lt;li&gt;BEVT: BERT Pretraining of Video Transformers&lt;/li&gt;&#xA;&lt;li&gt;Deep Generalized Unfolding Networks for Image Restoration&lt;/li&gt;&#xA;&lt;li&gt;VISOLO: Grid-Based Space-Time Aggregation for Efficient Online Video Instance Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Deep Unlearning Via Randomized Conditionally Independent Hessians&lt;/li&gt;&#xA;&lt;li&gt;Revisiting Skeleton-Based Action Recognition&lt;/li&gt;&#xA;&lt;li&gt;Stereo Depth From Events Cameras: Concentrate and Focus on The Future&lt;/li&gt;&#xA;&lt;li&gt;A Simple Data Mixing Prior for Improving Self-Supervised Learning&lt;/li&gt;&#xA;&lt;li&gt;Knowledge Distillation As Efficient Pre-Training: Faster Convergence, Higher Data-Efficiency, and Better Transferability&lt;/li&gt;&#xA;&lt;li&gt;BigDL 2.0: Seamless Scaling of AI Pipelines From Laptops to Distributed Cluster&lt;/li&gt;&#xA;&lt;li&gt;Attentive Fine-Grained Structured Sparsity for Image Restoration&lt;/li&gt;&#xA;&lt;li&gt;Learning Fair Classifiers With Partially Annotated Group Labels&lt;/li&gt;&#xA;&lt;li&gt;NightLab: A Dual-Level Architecture With Hardness Detection for Segmentation at Night&lt;/li&gt;&#xA;&lt;li&gt;Constrained Few-Shot Class-Incremental Learning&lt;/li&gt;&#xA;&lt;li&gt;Threshold Matters in WSSS: Manipulating The Activation for The Robust and Accurate Segmentation Model Against Thresholds&lt;/li&gt;&#xA;&lt;li&gt;TransMVSNet: Global Context-Aware Multi-View Stereo Network With Transformers&lt;/li&gt;&#xA;&lt;li&gt;DPGEN: Differentially Private Generative Energy-Guided Network for Natural Image Synthesis&lt;/li&gt;&#xA;&lt;li&gt;The Majority Can Help The Minority: Context-Rich Minority Oversampling for Long-Tailed Classification&lt;/li&gt;&#xA;&lt;li&gt;IntentVizor: Towards Generic Query Guided Interactive Video Summarization&lt;/li&gt;&#xA;&lt;li&gt;Shape-Invariant 3D Adversarial Point Clouds&lt;/li&gt;&#xA;&lt;li&gt;Bootstrapping ViTs: Towards Liberating Vision Transformers From Pre-Training&lt;/li&gt;&#xA;&lt;li&gt;PubTables-1M: Towards Comprehensive Table Extraction From Unstructured Documents&lt;/li&gt;&#xA;&lt;li&gt;Meta-Attention for ViT-Backed Continual Learning&lt;/li&gt;&#xA;&lt;li&gt;DST: Dynamic Substitute Training for Data-Free Black-Box Attack&lt;/li&gt;&#xA;&lt;li&gt;Unified Contrastive Learning in Image-Text-Label Space&lt;/li&gt;&#xA;&lt;li&gt;Unsupervised Pre-Training for Temporal Action Localization Tasks&lt;/li&gt;&#xA;&lt;li&gt;Look Outside The Room: Synthesizing A Consistent Long-Term 3D Scene Video From A Single Image&lt;/li&gt;&#xA;&lt;li&gt;High-Fidelity Human Avatars From A Single RGB Camera&lt;/li&gt;&#xA;&lt;li&gt;Multiview Transformers for Video Recognition&lt;/li&gt;&#xA;&lt;li&gt;How Good Is Aesthetic Ability of A Fashion Model?&lt;/li&gt;&#xA;&lt;li&gt;Deformation and Correspondence Aware Unsupervised Synthetic-to-Real Scene Flow Estimation for Point Clouds&lt;/li&gt;&#xA;&lt;li&gt;Sequential Voting With Relational Box Fields for Active Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Semantic-Aware Auto-Encoders for Self-Supervised Representation Learning&lt;/li&gt;&#xA;&lt;li&gt;Consistency Learning Via Decoding Path Augmentation for Transformers in Human Object Interaction Detection&lt;/li&gt;&#xA;&lt;li&gt;Consistent Explanations By Contrastive Learning&lt;/li&gt;&#xA;&lt;li&gt;Hierarchical Modular Network for Video Captioning&lt;/li&gt;&#xA;&lt;li&gt;Depth Estimation By Combining Binocular Stereo and Monocular Structured-Light&lt;/li&gt;&#xA;&lt;li&gt;Salient-to-Broad Transition for Video Person Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;DeeCap: Dynamic Early Exiting for Efficient Image Captioning&lt;/li&gt;&#xA;&lt;li&gt;RepMLPNet: Hierarchical Vision MLP With Re-Parameterized Locality&lt;/li&gt;&#xA;&lt;li&gt;DR.VIC: Decomposition and Reasoning for Video Individual Counting&lt;/li&gt;&#xA;&lt;li&gt;ARCS: Accurate Rotation and Correspondence Search&lt;/li&gt;&#xA;&lt;li&gt;Learning To Anticipate Future With Dynamic Context Removal&lt;/li&gt;&#xA;&lt;li&gt;GCFSR: A Generative and Controllable Face Super Resolution Method Without Facial and GAN Priors&lt;/li&gt;&#xA;&lt;li&gt;On The Integration of Self-Attention and Convolution&lt;/li&gt;&#xA;&lt;li&gt;Domain Adaptation on Point Clouds Via Geometry-Aware Implicits&lt;/li&gt;&#xA;&lt;li&gt;GroupViT: Semantic Segmentation Emerges From Text Supervision&lt;/li&gt;&#xA;&lt;li&gt;DiffusionCLIP: Text-Guided Diffusion Models for Robust Image Manipulation&lt;/li&gt;&#xA;&lt;li&gt;BppAttack: Stealthy and Efficient Trojan Attacks Against Deep Neural Networks Via Image Quantization and Contrastive Adversarial Learning&lt;/li&gt;&#xA;&lt;li&gt;Stacked Hybrid-Attention and Group Collaborative Learning for Unbiased Scene Graph Generation&lt;/li&gt;&#xA;&lt;li&gt;Towards Better Plasticity-Stability Trade-Off in Incremental Learning: A Simple Linear Connector&lt;/li&gt;&#xA;&lt;li&gt;Topology-Preserving Shape Reconstruction and Registration Via Neural Diffeomorphic Flow&lt;/li&gt;&#xA;&lt;li&gt;Segment and Complete: Defending Object Detectors Against Adversarial Patch Attacks With Robust Patch Detection&lt;/li&gt;&#xA;&lt;li&gt;MAXIM: Multi-Axis MLP for Image Processing&lt;/li&gt;&#xA;&lt;li&gt;Learning Part Segmentation Through Unsupervised Domain Adaptation From Synthetic Vehicles&lt;/li&gt;&#xA;&lt;li&gt;PSTR: End-to-End One-Step Person Search With Transformers&lt;/li&gt;&#xA;&lt;li&gt;NFormer: Robust Person Re-Identification With Neighbor Transformer&lt;/li&gt;&#xA;&lt;li&gt;Bridging Global Context Interactions for High-Fidelity Image Completion&lt;/li&gt;&#xA;&lt;li&gt;SwinBERT: End-to-End Transformers With Sparse Attention for Video Captioning&lt;/li&gt;&#xA;&lt;li&gt;Not All Tokens Are Equal: Human-Centric Visual Analysis Via Token Clustering Transformer&lt;/li&gt;&#xA;&lt;li&gt;Temporally Efficient Vision Transformer for Video Instance Segmentation&lt;/li&gt;&#xA;&lt;li&gt;The Devil Is in The Margin: Margin-Based Label Smoothing for Network Calibration&lt;/li&gt;&#xA;&lt;li&gt;NLX-GPT: A Model for Natural Language Explanations in Vision and Vision-Language Tasks&lt;/li&gt;&#xA;&lt;li&gt;WarpingGAN: Warping Multiple Uniform Priors for Adversarial 3D Point Cloud Generation&lt;/li&gt;&#xA;&lt;li&gt;Pseudo-Q: Generating Pseudo Language Queries for Visual Grounding&lt;/li&gt;&#xA;&lt;li&gt;E2(GO)MOTION: Motion Augmented Event Stream for Egocentric Action Recognition&lt;/li&gt;&#xA;&lt;li&gt;OoD-Bench: Quantifying and Understanding Two Dimensions of Out-of-Distribution Generalization&lt;/li&gt;&#xA;&lt;li&gt;OnePose: One-Shot Object Pose Estimation Without CAD Models&lt;/li&gt;&#xA;&lt;li&gt;Rethinking Minimal Sufficient Representation in Contrastive Learning&lt;/li&gt;&#xA;&lt;li&gt;Scalable Penalized Regression for Noise Detection in Learning With Noisy Labels&lt;/li&gt;&#xA;&lt;li&gt;Federated Class-Incremental Learning&lt;/li&gt;&#xA;&lt;li&gt;Show, Deconfound and Tell: Image Captioning With Causal Inference&lt;/li&gt;&#xA;&lt;li&gt;MobRecon: Mobile-Friendly Hand Mesh Reconstruction From Monocular Image&lt;/li&gt;&#xA;&lt;li&gt;Parameter-Free Online Test-Time Adaptation&lt;/li&gt;&#xA;&lt;li&gt;SIGMA: Semantic-Complete Graph Matching for Domain Adaptive Object Detection&lt;/li&gt;&#xA;&lt;li&gt;No Pain, Big Gain: Classify Dynamic Point Cloud Sequences With Static Models By Fitting Feature-Level Space-Time Surfaces&lt;/li&gt;&#xA;&lt;li&gt;HerosNet: Hyperspectral Explicable Reconstruction and Optimal Sampling Deep Network for Snapshot Compressive Imaging&lt;/li&gt;&#xA;&lt;li&gt;Vision Transformer Slimming: Multi-Dimension Searching in Continuous Optimization Space&lt;/li&gt;&#xA;&lt;li&gt;Learning To Estimate Robust 3D Human Mesh From In-the-Wild Crowded Scenes&lt;/li&gt;&#xA;&lt;li&gt;Detecting Deepfakes With Self-Blended Images&lt;/li&gt;&#xA;&lt;li&gt;Implicit Sample Extension for Unsupervised Person Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;Energy-Based Latent Aligner for Incremental Learning&lt;/li&gt;&#xA;&lt;li&gt;Towards Semi-Supervised Deep Facial Expression Recognition With An Adaptive Confidence Margin&lt;/li&gt;&#xA;&lt;li&gt;Group R-CNN for Weakly Semi-Supervised Object Detection With Points&lt;/li&gt;&#xA;&lt;li&gt;Weakly-Supervised Action Transition Learning for Stochastic Human Motion Prediction&lt;/li&gt;&#xA;&lt;li&gt;Hybrid Relation Guided Set Matching for Few-Shot Action Recognition&lt;/li&gt;&#xA;&lt;li&gt;Cross-Patch Dense Contrastive Learning for Semi-Supervised Segmentation of Cellular Nuclei in Histopathologic Images&lt;/li&gt;&#xA;&lt;li&gt;Generalized Binary Search Network for Highly-Efficient Multi-View Stereo&lt;/li&gt;&#xA;&lt;li&gt;SHIFT: A Synthetic Driving Dataset for Continuous Multi-Task Domain Adaptation&lt;/li&gt;&#xA;&lt;li&gt;FlexIT: Towards Flexible Semantic Image Translation&lt;/li&gt;&#xA;&lt;li&gt;CRAFT: Cross-Attentional Flow Transformer for Robust Optical Flow&lt;/li&gt;&#xA;&lt;li&gt;BoxeR: Box-Attention for 2D and 3D Transformers&lt;/li&gt;&#xA;&lt;li&gt;Neural Architecture Search With Representation Mutual Information&lt;/li&gt;&#xA;&lt;li&gt;Can Neural Nets Learn The Same Model Twice? Investigating Reproducibility and Double Descent From The Decision Boundary Perspective&lt;/li&gt;&#xA;&lt;li&gt;Hierarchical Nearest Neighbor Graph Embedding for Efficient Dimensionality Reduction&lt;/li&gt;&#xA;&lt;li&gt;Multi-View Transformer for 3D Visual Grounding&lt;/li&gt;&#xA;&lt;li&gt;Structured Sparse R-CNN for Direct Scene Graph Generation&lt;/li&gt;&#xA;&lt;li&gt;BARC: Learning To Regress 3D Dog Shape From Images By Exploiting Breed Information&lt;/li&gt;&#xA;&lt;li&gt;PCA-Based Knowledge Distillation Towards Lightweight and Content-Style Balanced Photorealistic Style Transfer Models&lt;/li&gt;&#xA;&lt;li&gt;Towards Understanding Adversarial Robustness of Optical Flow Networks&lt;/li&gt;&#xA;&lt;li&gt;Lifelong Graph Learning&lt;/li&gt;&#xA;&lt;li&gt;Hypergraph-Induced Semantic Tuplet Loss for Deep Metric Learning&lt;/li&gt;&#xA;&lt;li&gt;Computing Wasserstein-p Distance Between Images With Linear Cost&lt;/li&gt;&#xA;&lt;li&gt;Unsupervised Representation Learning for Binary Networks By Joint Classifier Learning&lt;/li&gt;&#xA;&lt;li&gt;Large-Scale Video Panoptic Segmentation in The Wild: A Benchmark&lt;/li&gt;&#xA;&lt;li&gt;GrainSpace: A Large-Scale Dataset for Fine-Grained and Domain-Adaptive Recognition of Cereal Grains&lt;/li&gt;&#xA;&lt;li&gt;Learning Modal-Invariant and Temporal-Memory for Video-Based Visible-Infrared Person Re-Identification&lt;/li&gt;&#xA;&lt;li&gt;MSDN: Mutually Semantic Distillation Network for Zero-Shot Learning&lt;/li&gt;&#xA;&lt;li&gt;Oriented RepPoints for Aerial Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Weakly Supervised Temporal Sentence Grounding With Gaussian-Based Contrastive Proposal Learning&lt;/li&gt;&#xA;&lt;li&gt;Low-Resource Adaptation for Personalized Co-Speech Gesture Generation&lt;/li&gt;&#xA;&lt;li&gt;Task-Specific Inconsistency Alignment for Domain Adaptive Object Detection&lt;/li&gt;&#xA;&lt;li&gt;MS2DG-Net: Progressive Correspondence Learning Via Multiple Sparse Semantics Dynamic Graph&lt;/li&gt;&#xA;&lt;li&gt;Learning To Listen: Modeling Non-Deterministic Dyadic Facial Motion&lt;/li&gt;&#xA;&lt;li&gt;Capturing Humans in Motion: Temporal-Attentive 3D Human Pose and Shape Estimation From Monocular Video&lt;/li&gt;&#xA;&lt;li&gt;MixFormer: End-to-End Tracking With Iterative Mixed Attention&lt;/li&gt;&#xA;&lt;li&gt;Plenoxels: Radiance Fields Without Neural Networks&lt;/li&gt;&#xA;&lt;li&gt;Selective-Supervised Contrastive Learning With Noisy Labels&lt;/li&gt;&#xA;&lt;li&gt;SimT: Handling Open-Set Noise for Domain Adaptive Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Frequency-Driven Imperceptible Adversarial Attack on Semantic Similarity&lt;/li&gt;&#xA;&lt;li&gt;Video Demoireing With Relation-Based Temporal Consistency&lt;/li&gt;&#xA;&lt;li&gt;Industrial Style Transfer With Large-Scale Geometric Warping and Content Preservation&lt;/li&gt;&#xA;&lt;li&gt;Modeling Image Composition for Complex Scene Generation&lt;/li&gt;&#xA;&lt;li&gt;Decoupling Zero-Shot Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Templates for 3D Object Pose Estimation Revisited: Generalization to New Objects and Robustness to Occlusions&lt;/li&gt;&#xA;&lt;li&gt;Stochastic Variance Reduced Ensemble Adversarial Attack for Boosting The Adversarial Transferability&lt;/li&gt;&#xA;&lt;li&gt;IFOR: Iterative Flow Minimization for Robotic Object Rearrangement&lt;/li&gt;&#xA;&lt;li&gt;Zero Experience Required: Plug &amp;amp; Play Modular Transfer Learning for Semantic Visual Navigation&lt;/li&gt;&#xA;&lt;li&gt;TopFormer: Token Pyramid Transformer for Mobile Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;The Wanderings of Odysseus in 3D Scenes&lt;/li&gt;&#xA;&lt;li&gt;All-in-One Image Restoration for Unknown Corruption&lt;/li&gt;&#xA;&lt;li&gt;PUMP: Pyramidal and Uniqueness Matching Priors for Unsupervised Learning of Local Descriptors&lt;/li&gt;&#xA;&lt;li&gt;MixSTE: Seq2seq Mixed Spatio-Temporal Encoder for 3D Human Pose Estimation in Video&lt;/li&gt;&#xA;&lt;li&gt;RCP: Recurrent Closest Point for Point Cloud&lt;/li&gt;&#xA;&lt;li&gt;A Dual Weighting Label Assignment Scheme for Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Hyperbolic Vision Transformers: Combining Improvements in Metric Learning&lt;/li&gt;&#xA;&lt;li&gt;Instance-Aware Dynamic Neural Network Quantization&lt;/li&gt;&#xA;&lt;li&gt;Exploring Effective Data for Surrogate Training Towards Black-Box Attack&lt;/li&gt;&#xA;&lt;li&gt;JRDB-Act: A Large-Scale Dataset for Spatio-Temporal Action, Social Group and Activity Detection&lt;/li&gt;&#xA;&lt;li&gt;Investigating Top-k White-Box and Transferable Black-Box Attack&lt;/li&gt;&#xA;&lt;li&gt;Decoupling and Recoupling Spatiotemporal Representation for RGB-D-Based Motion Recognition&lt;/li&gt;&#xA;&lt;li&gt;A Self-Supervised Descriptor for Image Copy Detection&lt;/li&gt;&#xA;&lt;li&gt;Negative-Aware Attention Framework for Image-Text Matching&lt;/li&gt;&#xA;&lt;li&gt;An Image Patch Is A Wave: Phase-Aware Vision MLP&lt;/li&gt;&#xA;&lt;li&gt;Shunted Self-Attention Via Multi-Scale Token Aggregation&lt;/li&gt;&#xA;&lt;li&gt;Unified Multivariate Gaussian Mixture for Efficient Neural Image Compression&lt;/li&gt;&#xA;&lt;li&gt;Recurrent Variational Network: A Deep Learning Inverse Problem Solver Applied to The Task of Accelerated MRI Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;Surpassing The Human Accuracy: Detecting Gallbladder Cancer From USG Images With Curriculum Learning&lt;/li&gt;&#xA;&lt;li&gt;Appearance and Structure Aware Robust Deep Visual Graph Matching: Attack, Defense and Beyond&lt;/li&gt;&#xA;&lt;li&gt;TrackFormer: Multi-Object Tracking With Transformers&lt;/li&gt;&#xA;&lt;li&gt;3D Shape Reconstruction From 2D Images With Disentangled Attribute Flow&lt;/li&gt;&#xA;&lt;li&gt;Feature Statistics Mixing Regularization for Generative Adversarial Networks&lt;/li&gt;&#xA;&lt;li&gt;OpenTAL: Towards Open Set Temporal Action Localization&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Learning of Adversarial Example: Towards Good Generalizations for Deepfake Detection&lt;/li&gt;&#xA;&lt;li&gt;Ego4D: Around The World in 3,000 Hours of Egocentric Video&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Pre-Training of Swin Transformers for 3D Medical Image Analysis&lt;/li&gt;&#xA;&lt;li&gt;Weakly Supervised Semantic Segmentation Using Out-of-Distribution Data&lt;/li&gt;&#xA;&lt;li&gt;DAD-3DHeads: A Large-Scale Dense, Accurate and Diverse Dataset for 3D Head Alignment From A Single Image&lt;/li&gt;&#xA;&lt;li&gt;Reconstructing Surfaces for Sparse Point Clouds With On-Surface Priors&lt;/li&gt;&#xA;&lt;li&gt;VCLIMB: A Novel Video Class Incremental Learning Benchmark&lt;/li&gt;&#xA;&lt;li&gt;Robust Equivariant Imaging: A Fully Unsupervised Framework for Learning To Image From Noisy and Partial Measurements&lt;/li&gt;&#xA;&lt;li&gt;ST++: Make Self-Training Work Better for Semi-Supervised Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Interacting Attention Graph for Single Image Two-Hand Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;Rope3D: The Roadside Perception Dataset for Autonomous Driving and Monocular 3D Object Detection Task&lt;/li&gt;&#xA;&lt;li&gt;Cross-Image Relational Knowledge Distillation for Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Towards Layer-Wise Image Vectorization&lt;/li&gt;&#xA;&lt;li&gt;Scenic: A JAX Library for Computer Vision Research and Beyond&lt;/li&gt;&#xA;&lt;li&gt;Real-Time Object Detection for Streaming Perception&lt;/li&gt;&#xA;&lt;li&gt;VisualHow: Multimodal Problem Solving&lt;/li&gt;&#xA;&lt;li&gt;Spatial Commonsense Graph for Object Localisation in Partial Scenes&lt;/li&gt;&#xA;&lt;li&gt;OSSGAN: Open-Set Semi-Supervised Image Generation&lt;/li&gt;&#xA;&lt;li&gt;Bi-Level Alignment for Cross-Domain Crowd Counting&lt;/li&gt;&#xA;&lt;li&gt;ST-MFNet: A Spatio-Temporal Multi-Flow Network for Frame Interpolation&lt;/li&gt;&#xA;&lt;li&gt;Efficient Multi-View Stereo By Iterative Dynamic Cost Volume&lt;/li&gt;&#xA;&lt;li&gt;TransEditor: Transformer-Based Dual-Space GAN for Highly Controllable Facial Editing&lt;/li&gt;&#xA;&lt;li&gt;Use All The Labels: A Hierarchical Multi-Label Contrastive Learning Framework&lt;/li&gt;&#xA;&lt;li&gt;SGTR: End-to-End Scene Graph Generation With Transformer&lt;/li&gt;&#xA;&lt;li&gt;Decoupled Knowledge Distillation&lt;/li&gt;&#xA;&lt;li&gt;DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Reusing The Task-Specific Classifier As A Discriminator: Discriminator-Free Adversarial Domain Adaptation&lt;/li&gt;&#xA;&lt;li&gt;Show Me What and Tell Me How: Video Synthesis Via Multimodal Conditioning&lt;/li&gt;&#xA;&lt;li&gt;SIMBAR: Single Image-Based Scene Relighting for Effective Data Augmentation for Automated Driving Vision Tasks&lt;/li&gt;&#xA;&lt;li&gt;Multi-Label Classification With Partial Annotations Using Class-Aware Selective Loss&lt;/li&gt;&#xA;&lt;li&gt;CADTransformer: Panoptic Symbol Spotting Transformer for CAD Drawings&lt;/li&gt;&#xA;&lt;li&gt;IntraQ: Learning Synthetic Images With Intra-Class Heterogeneity for Zero-Shot Network Quantization&lt;/li&gt;&#xA;&lt;li&gt;I M Avatar: Implicit Morphable Head Avatars From Videos&lt;/li&gt;&#xA;&lt;li&gt;Weakly-Supervised Metric Learning With Cross-Module Communications for The Classification of Anterior Chamber Angle Images&lt;/li&gt;&#xA;&lt;li&gt;A Text Attention Network for Spatial Deformation Robust Scene Text Image Super-Resolution&lt;/li&gt;&#xA;&lt;li&gt;Multi-Modal Dynamic Graph Transformer for Visual Grounding&lt;/li&gt;&#xA;&lt;li&gt;Geometric Transformer for Fast and Robust Point Cloud Registration&lt;/li&gt;&#xA;&lt;li&gt;UMT: Unified Multi-Modal Transformers for Joint Video Moment Retrieval and Highlight Detection&lt;/li&gt;&#xA;&lt;li&gt;Demystifying The Neural Tangent Kernel From A Practical Perspective: Can It Be Trusted for Neural Architecture Search Without Training?&lt;/li&gt;&#xA;&lt;li&gt;The Devil Is in The Details: Window-Based Attention for Image Compression&lt;/li&gt;&#xA;&lt;li&gt;DiLiGenT102: A Photometric Stereo Benchmark Dataset With Controlled Shape and Material Variation&lt;/li&gt;&#xA;&lt;li&gt;PolyWorld: Polygonal Building Extraction With Graph Neural Networks in Satellite Images&lt;/li&gt;&#xA;&lt;li&gt;Lite Pose: Efficient Architecture Design for 2D Human Pose Estimation&lt;/li&gt;&#xA;&lt;li&gt;Spatio-Temporal Relation Modeling for Few-Shot Action Recognition&lt;/li&gt;&#xA;&lt;li&gt;Multi-Person Extreme Motion Prediction&lt;/li&gt;&#xA;&lt;li&gt;B-DARTS: Beta-Decay Regularization for Differentiable Architecture Search&lt;/li&gt;&#xA;&lt;li&gt;CMT: Convolutional Neural Networks Meet Vision Transformers&lt;/li&gt;&#xA;&lt;li&gt;KNN Local Attention for Image Restoration&lt;/li&gt;&#xA;&lt;li&gt;Predict, Prevent, and Evaluate: Disentangled Text-Driven Image Manipulation Empowered By Pre-Trained Vision-Language Model&lt;/li&gt;&#xA;&lt;li&gt;TransMix: Attend To Mix for Vision Transformers&lt;/li&gt;&#xA;&lt;li&gt;Inertia-Guided Flow Completion and Style Fusion for Video Inpainting&lt;/li&gt;&#xA;&lt;li&gt;Long-Tailed Visual Recognition Via Gaussian Clouded Logit Adjustment&lt;/li&gt;&#xA;&lt;li&gt;Image Animation With Perturbed Masks&lt;/li&gt;&#xA;&lt;li&gt;Domain Generalization Via Shuffled Style Assembly for Face Anti-Spoofing&lt;/li&gt;&#xA;&lt;li&gt;OcclusionFusion: Occlusion-Aware Motion Estimation for Real-Time Dynamic 3D Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;MonoScene: Monocular 3D Semantic Scene Completion&lt;/li&gt;&#xA;&lt;li&gt;AdaFocus V2: End-to-End Training of Spatial Dynamic Networks for Video Recognition&lt;/li&gt;&#xA;&lt;li&gt;Continuous Scene Representations for Embodied AI&lt;/li&gt;&#xA;&lt;li&gt;Beyond 3D Siamese Tracking: A Motion-Centric Paradigm for 3D Single Object Tracking in Point Clouds&lt;/li&gt;&#xA;&lt;li&gt;Non-Probability Sampling Network for Stochastic Human Trajectory Prediction&lt;/li&gt;&#xA;&lt;li&gt;ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning&lt;/li&gt;&#xA;&lt;li&gt;Human-Aware Object Placement for Visual Environment Reconstruction&lt;/li&gt;&#xA;&lt;li&gt;X-Pool: Cross-Modal Language-Video Attention for Text-Video Retrieval&lt;/li&gt;&#xA;&lt;li&gt;RAMA: A Rapid Multicut Algorithm on GPU&lt;/li&gt;&#xA;&lt;li&gt;Adversarial Parametric Pose Prior&lt;/li&gt;&#xA;&lt;li&gt;Mask Transfiner for High-Quality Instance Segmentation&lt;/li&gt;&#xA;&lt;li&gt;It Is Okay To Not Be Okay: Overcoming Emotional Bias in Affective Image Captioning By Contrastive Data Collection&lt;/li&gt;&#xA;&lt;li&gt;DiRA: Discriminative, Restorative, and Adversarial Learning for Self-Supervised Medical Image Analysis&lt;/li&gt;&#xA;&lt;li&gt;Event-Based Video Reconstruction Via Potential-Assisted Spiking Neural Network&lt;/li&gt;&#xA;&lt;li&gt;YouMVOS: An Actor-Centric Multi-Shot Video Object Segmentation Dataset&lt;/li&gt;&#xA;&lt;li&gt;DAFormer: Improving Network Architectures and Training Strategies for Domain-Adaptive Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Joint Distribution Matters: Deep Brownian Distance Covariance for Few-Shot Classification&lt;/li&gt;&#xA;&lt;li&gt;Self-Supervised Video Transformer&lt;/li&gt;&#xA;&lt;li&gt;AutoRF: Learning 3D Object Radiance Fields From Single View Observations&lt;/li&gt;&#xA;&lt;li&gt;Coopernaut: End-to-End Driving With Cooperative Perception for Networked Vehicles&lt;/li&gt;&#xA;&lt;li&gt;TubeR: Tubelet Transformer for Video Action Detection&lt;/li&gt;&#xA;&lt;li&gt;MUM: Mix Image Tiles and UnMix Feature Tiles for Semi-Supervised Object Detection&lt;/li&gt;&#xA;&lt;li&gt;Learning Non-Target Knowledge for Few-Shot Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;UKPGAN: A General Self-Supervised Keypoint Detector&lt;/li&gt;&#xA;&lt;li&gt;Raw High-Definition Radar for Multi-Task Learning&lt;/li&gt;&#xA;&lt;li&gt;Coarse-To-Fine Feature Mining for Video Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Compressing Models With Few Samples: Mimicking Then Replacing&lt;/li&gt;&#xA;&lt;li&gt;PokeBNN: A Binary Pursuit of Lightweight Accuracy&lt;/li&gt;&#xA;&lt;li&gt;Zoom in and Out: A Mixed-Scale Triplet Network for Camouflaged Object Detection&lt;/li&gt;&#xA;&lt;li&gt;SOMSI: Spherical Novel View Synthesis With Soft Occlusion Multi-Sphere Images&lt;/li&gt;&#xA;&lt;li&gt;EMScore: Evaluating Video Captioning Via Coarse-Grained and Fine-Grained Embedding Matching&lt;/li&gt;&#xA;&lt;li&gt;PoseTriplet: Co-Evolving 3D Human Pose Estimation, Imitation, and Hallucination Under Self-Supervision&lt;/li&gt;&#xA;&lt;li&gt;Group Contextualization for Video Recognition&lt;/li&gt;&#xA;&lt;li&gt;Single-Domain Generalized Object Detection in Urban Scene Via Cyclic-Disentangled Self-Distillation&lt;/li&gt;&#xA;&lt;li&gt;L2G: A Simple Local-to-Global Knowledge Transfer Framework for Weakly Supervised Semantic Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Self-Augmented Unpaired Image Dehazing Via Density and Depth Decomposition&lt;/li&gt;&#xA;&lt;li&gt;Neural 3D Video Synthesis From Multi-View Video&lt;/li&gt;&#xA;&lt;li&gt;SemAffiNet: Semantic-Affine Transformation for Point Cloud Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Shapley-NAS: Discovering Operation Contribution for Neural Architecture Search&lt;/li&gt;&#xA;&lt;li&gt;HyperTransformer: A Textural and Spectral Feature Fusion Transformer for Pansharpening&lt;/li&gt;&#xA;&lt;li&gt;Structure-Aware Flow Generation for Human Body Reshaping&lt;/li&gt;&#xA;&lt;li&gt;Learning To Answer Questions in Dynamic Audio-Visual Scenarios&lt;/li&gt;&#xA;&lt;li&gt;Synthetic Aperture Imaging With Events and Frames&lt;/li&gt;&#xA;&lt;li&gt;MonoGround: Detecting Monocular 3D Objects From The Ground&lt;/li&gt;&#xA;&lt;li&gt;Deep Visual Geo-Localization Benchmark&lt;/li&gt;&#xA;&lt;li&gt;StyleGAN-V: A Continuous Video Generator With The Price, Image Quality and Perks of StyleGAN2&lt;/li&gt;&#xA;&lt;li&gt;LISA: Learning Implicit Shape and Appearance of Hands&lt;/li&gt;&#xA;&lt;li&gt;Iterative Deep Homography Estimation&lt;/li&gt;&#xA;&lt;li&gt;Learned Queries for Efficient Local Attention&lt;/li&gt;&#xA;&lt;li&gt;Colar: Effective and Efficient Online Action Detection By Consulting Exemplars&lt;/li&gt;&#xA;&lt;li&gt;SoftGroup for 3D Instance Segmentation on Point Clouds&lt;/li&gt;&#xA;&lt;li&gt;MVS2D: Efficient Multi-View Stereo Via Attention-Driven 2D Convolutions&lt;/li&gt;&#xA;&lt;li&gt;Beyond Semantic to Instance Segmentation: Weakly-Supervised Instance Segmentation Via Semantic Knowledge Transfer and Self-Refinement&lt;/li&gt;&#xA;&lt;li&gt;Deep Constrained Least Squares for Blind Image Super-Resolution&lt;/li&gt;&#xA;&lt;li&gt;EDTER: Edge Detection With Transformer&lt;/li&gt;&#xA;&lt;li&gt;AirObject: A Temporally Evolving Graph Embedding for Object Identification&lt;/li&gt;&#xA;&lt;li&gt;From Representation to Reasoning: Towards Both Evidence and Commonsense Reasoning for Video Question-Answering&lt;/li&gt;&#xA;&lt;li&gt;Semantic-Aware Domain Generalized Segmentation&lt;/li&gt;&#xA;&lt;li&gt;DanceTrack: Multi-Object Tracking in Uniform Appearance and Diverse Motion&lt;/li&gt;&#xA;&lt;li&gt;UBnormal: New Benchmark for Supervised Open-Set Video Anomaly Detection&lt;/li&gt;&#xA;&lt;li&gt;AKB-48: A Real-World Articulated Object Knowledge Base&lt;/li&gt;&#xA;&lt;li&gt;Stratified Transformer for 3D Point Cloud Segmentation&lt;/li&gt;&#xA;&lt;li&gt;Aug-NeRF: Training Stronger Neural Radiance Fields With Triple-Level Physically-Grounded Augmentations&lt;/li&gt;&#xA;&lt;li&gt;Semantic-Shape Adaptive Feature Modulation for Semantic Image Synthesis&lt;/li&gt;&#xA;&lt;li&gt;Day-to-Night Image Synthesis for Training Nighttime Neural ISPs Literature ~Highlight: To address this problem, we propose a method that synthesizes nighttime images from daytime images.&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/&#34;&gt;https://www.paperdigest.org/2022/06/cvpr-2022-papers-with-code-data/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br&gt;&#xA;Dr Hari Thapliyaal&lt;br&gt;&#xA;dasarpai.com &lt;br&gt;&#xA;linkedin.com/in/harithapliyal&lt;/p&gt;</description>
    </item>
    <item>
      <title>Comprehensive Glossary of LLM, Deep Learning, NLP, and CV Terminology</title>
      <link>http://localhost:1313/dsblog/Comprehensive-Glossary-of-LLM/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Comprehensive-Glossary-of-LLM/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6089-Comprehensive-Glossary-of-LLM.jpg&#34; alt=&#34;Comprehensive Glossary of LLM&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;comprehensive-glossary-of-llm&#34;&gt;Comprehensive Glossary of LLM&lt;/h1&gt;&#xA;&lt;p&gt;I am developing this Glossary slowly at my own pace. Content on this page keep changing. Better definition, better explaination are part of my learing, my evolution and advancement in the field of Deep Learning and Machine Learning. As of Aug&#39;23 the terms are not in any order therefore if you are look for any specific term you can search on the page. When I will have 50+ terms on this page then I will try to sort them on some attribute of these terms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning Metrics</title>
      <link>http://localhost:1313/dsblog/Machine-Learning-Metrics/</link>
      <pubDate>Mon, 21 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Machine-Learning-Metrics/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6092-Machine-Learning-Metrics.jpg&#34; alt=&#34;Comprehensive Glossary of LLM&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;machine-learning-metrics&#34;&gt;Machine Learning Metrics&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In Machine Learning projects whether classical machine learning, deep learning, computer vision, speech processing, NLP, or any other ML project we keep building different models with different datasets. But how to know that for a particular problem model X is the best one? For that, we need to evaluate these models against certain metrics. What metrics we pick, depends upon the problem statement, data imbalance, type of data, etc. In this article, we will explore an exhaustive list of ML Metrics.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Paper-Summary- A Survey Paper# Pretrained Language Models for Text Generation</title>
      <link>http://localhost:1313/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</link>
      <pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/rps-Pretrained-Language-Models-for-Text-Generation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6088-rps-Pretrained-Language-Models-for-Text-Generation.jpg&#34; alt=&#34;Pretrained Language Models for Text Generation&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Paper Name :- Pretrained Language Models for Text Generation: A Survey&lt;/strong&gt;&lt;br&gt;&#xA;Typer of Paper:- Survey Paper  &lt;br&gt;&#xA;&lt;a href=&#34;https://arxiv.org/abs/2105.10311&#34;&gt;Paper URL&lt;/a&gt;&lt;br&gt;&#xA;Paper title of the citations mentioned can be found at &lt;a href=&#34;http://localhost:1313/dsblog/aip&#34;&gt;AI Papers with Heading&lt;/a&gt;. Use citation code to locate.&lt;/p&gt;&#xA;&lt;h1 id=&#34;paper-summary---pretrained-language-models-for-text-generation&#34;&gt;Paper Summary :- Pretrained Language Models for Text Generation&lt;/h1&gt;&#xA;&lt;h2 id=&#34;paper-outcome&#34;&gt;Paper Outcome&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;General task deﬁnition&lt;/li&gt;&#xA;&lt;li&gt;Describe the mainstream architectures of PLMs for text generation.&lt;/li&gt;&#xA;&lt;li&gt;How to adapt existing PLMs to model different input data and satisfy special properties in the generated text.&lt;/li&gt;&#xA;&lt;li&gt;Summarize several important ﬁne-tuning strategies for text generation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;ideas-from-the-paper&#34;&gt;Ideas from the Paper&lt;/h2&gt;&#xA;&lt;h3 id=&#34;main-ideas&#34;&gt;Main Ideas&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;This paper discusses &amp;ldquo;major advances achieved in the topic of PLMs for text generation&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;This survey aims to provide &amp;ldquo;text generation researchers a synthesis&amp;rdquo; and pointer to related research.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;general-ideas&#34;&gt;General Ideas&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Text generation has become one of the most important yet challenging tasks in natural language processing (NLP).&lt;/li&gt;&#xA;&lt;li&gt;Neural generation model are deep learning models&lt;/li&gt;&#xA;&lt;li&gt;Pretrained language models (PLMs) are neural generation model&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;task-types-and-typical-applications&#34;&gt;Task Types and Typical Applications&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;In most cases, text generation is conditioned on input data, such as attributes, text and structured data, which is denoted as X. Formally, the text generation task can be described as: P(YjX ) = P(y1; : : : ; yj ; : : : ; ynjX )&lt;/li&gt;&#xA;&lt;li&gt;If X is not provided or a random noise vector z, this task will degenerate into language modeling or unconditional&#xA;generation task(generate text without any constraint) &lt;a href=&#34;http://localhost:1313/dsblog/aip#radford2019&#34;&gt;Radford2019&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;If X is a set of discrete attributes (e.g., topic words, sentiment labels), the task becomes topic-to-text generation or&#xA;attribute-based generation.  X plays the role of guiding the text generation. &lt;a href=&#34;http://localhost:1313/dsblog/aip#Keskar2019&#34;&gt;Keskar2019&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;If X is structured data like knowledge graph or table, this task will be considered as KG-to-text or table-to-text generation (generate descriptive text about structured data), called data-to-text generation &lt;a href=&#34;http://localhost:1313/dsblog/aip#Li2021c&#34;&gt;Li2021c&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;If X is multimedia input such as image, the task becomes image caption &lt;a href=&#34;http://localhost:1313/dsblog/aip#Xia2020&#34;&gt;Xia2020&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;If X is multimedia input such as speech, the task become speech recognition &lt;a href=&#34;http://localhost:1313/dsblog/aip#Fan2019&#34;&gt;Fan2019&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;If X text sequence (most common form), there are several applications such as machine translation, summarization and dialogue system.&lt;/li&gt;&#xA;&lt;li&gt;Machine translation aims to translate text from one language into another language automatically &lt;a href=&#34;http://localhost:1313/dsblog/aip#Conneau2019&#34;&gt;Conneau2019&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Generating condensed summary of a long document &lt;a href=&#34;http://localhost:1313/dsblog/aip#Zhang2019b&#34;&gt;Zhang2019b&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Dialogue system to converse with humans using natural language. &lt;a href=&#34;http://localhost:1313/dsblog/aip#Wolf2019&#34;&gt;Wolf2019&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;architectures-for-text-generation&#34;&gt;Architectures for Text Generation&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Encoder-decoder Transformer. It is two stacks of Transformer blocks. The encoder is fed with an input sequence, while the decoder aims to generate the output sequence based on encoder-decoder self-attention mechanism.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;MASS &lt;a href=&#34;http://localhost:1313/dsblog/aip#song2019&#34;&gt;Song2019&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;T5 &lt;a href=&#34;http://localhost:1313/dsblog/aip#raffel2020&#34;&gt;Raffel2020&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;BART &lt;a href=&#34;http://localhost:1313/dsblog/aip#lewis2020&#34;&gt;Lewis2020&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Decoder-only Transformer. Employ a single Transformer decoder blocks. They apply unidirectional self-attention masking that each token can only attend to previous tokens.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;GPT &lt;a href=&#34;http://localhost:1313/dsblog/aip#radfordet2019&#34;&gt;Radfordet2019&lt;/a&gt;; &lt;a href=&#34;http://localhost:1313/dsblog/aip#brown2020&#34;&gt;Brown2020&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;CTRL [Keskar2019]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;modeling-different-data-types-from-input&#34;&gt;Modeling Different Data Types from Input&lt;/h2&gt;&#xA;&lt;h3 id=&#34;unstructured-input&#34;&gt;Unstructured Input&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hierarchical BERT to learn interactions between sentences with self-attention for document encoding. [Zhang2019b] and [Xu2020b]&lt;/li&gt;&#xA;&lt;li&gt;Capturing intersentential relations, DiscoBERT stacked graph convolutional network (GCN) on top of BERT to model structural discourse graphs. [Xu2020a]&lt;/li&gt;&#xA;&lt;li&gt;Cross-lingual language models (XLMs) for multilingual language understanding. [Conneau2019]&lt;/li&gt;&#xA;&lt;li&gt;Text generation models can obtain effective input word embeddings even in a low-resource language [Wada2018].&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;structured-input&#34;&gt;Structured Input&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PLMs are not designed for structured or tabular data but for sequential text/data.&lt;/li&gt;&#xA;&lt;li&gt;Incorporating PLMs for data-to text generation, especially in few-shot settings. [Chen2020b] and [Gong2020]&lt;/li&gt;&#xA;&lt;li&gt;To adapt to the sequential nature of PLMs linearized input knowledge graph (KG) and abstract meaning representation (AMR) graph into a sequence of triples. [Ribeiro2020] and [Mager2020]&lt;/li&gt;&#xA;&lt;li&gt;Introduced an additional graph encoder to encode the input KG. [Li2021b]&lt;/li&gt;&#xA;&lt;li&gt;Template based method to serialize input table into text sequence.  [Gong2020]&#xA;&lt;ul&gt;&#xA;&lt;li&gt;For example, the attribute-value pair “name: jack reynolds” will be serialized as a sentence “name is jack reynolds”. However, direct linearization will lose the structural information of original data, which may lead to generating unfaithful text about data.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Auxiliary reconstruction task for recovering the structural information of input data, which can enhance the capacity of modeling structural information. [Gong2020]&lt;/li&gt;&#xA;&lt;li&gt;The pointer generator mechanism is adopted to copy words from input knowledge data. [See2017] [Chen2020b].&lt;/li&gt;&#xA;&lt;li&gt;Content matching loss for measuring the distance between the information in input data and the output text. [Gong2020]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h3 id=&#34;multimedia-input&#34;&gt;Multimedia Input&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Conducted pretraining for the video caption task. VideoBERT [Sun2019b] and CBT [Sun2019a]&lt;/li&gt;&#xA;&lt;li&gt;Used a shared multi-layer Transformer network for both encoding and decoding. Unified VLP [Zhou2020]&lt;/li&gt;&#xA;&lt;li&gt;Pretrained the model on two masked language modeling (MLM) tasks, like cloze tasks designed for sequence-to-sequence LM. UniLM [Dong2019]&lt;/li&gt;&#xA;&lt;li&gt;Cross-modal pretrained model (XGPT) by taking images as inputs and using the image caption task as the basic generative task in the pretraining stage. Xia2020&lt;/li&gt;&#xA;&lt;li&gt;Image, video, speech recognition is hungry for human-transcripted supervised data.&lt;/li&gt;&#xA;&lt;li&gt;Integrate PLMs for weakly-supervised learning. For example,&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Unsupervised approach to pretraining encoder-decoder model with unpaired speech and transcripts. [Fan2019]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Two pretraining stages are used to extract acoustic and linguistic information with speech and transcripts, which is useful for downstream speech recognition task.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;satisfying-special-properties-for-output-text&#34;&gt;Satisfying Special Properties for Output Text&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Generated text should satisfy several key properties like. relevance, faithfulness, and order-preservation.&lt;/li&gt;&#xA;&lt;li&gt;Relevance. Relevance refers that the topics in output text is highly related to the input text. The generated responses should&#xA;also be relevant to the condition. RNN-based models still tend to generate irrelevant output text and lack consistency with input.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When applying PLMs to the task of dialogue systems, TransferTransfo  and DialoGPT were able to generate more relevant responses than  RNNbased models. [Wolf2019] [Zhang2020]&lt;/li&gt;&#xA;&lt;li&gt;Utilize elaborated condition blocks to incorporate external conditions. They used BERT for both encoder and decoder by utilizing different input&#xA;representations and self-attention masks to distinguish the source and target sides of dialogue. On the target (generation) side, a new attention routing mechanism is adopted to generate context-related words. [Zeng2020]&lt;/li&gt;&#xA;&lt;li&gt;Approach for non-conditioned dialogue [Bao2020].&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Faithfulness. Means the content in generated text should not contradict the facts in input text.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;PLMs are potentially beneficial to generate faithful text by utilizing background knowledge.&lt;/li&gt;&#xA;&lt;li&gt;Initialize the encoder and decoder with three outstanding PLMs, i.e., BERT, GPT and RoBERTa. [Rothe2020]&lt;/li&gt;&#xA;&lt;li&gt;With pretraining, the models are more aware of the domain characteristics and less prone to language model vulnerabilities.&lt;/li&gt;&#xA;&lt;li&gt;Decompose the decoder into a contextual network that retrieves relevant parts of the source document and a PLM that incorporates prior knowledge about language generation. [Kryscinski2018]&lt;/li&gt;&#xA;&lt;li&gt;Generate faithful text in different target domains, fine-tuned PLMs on target domains through theme modeling loss. [Yang2020b]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Order-preservation. Order-preservation denotes that the order of semantic units (word, phrase, etc.) in both input and output text is consistent.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When translating from source language to target language, keeping the order of phrases consistent in source language and target language will ensure the accuracy of the translation.&lt;/li&gt;&#xA;&lt;li&gt;Code-Switching Pre-training (CSP) for machine translation. [Yang2020a]&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Extracted the word-pair alignment information from the source and target language,&lt;/li&gt;&#xA;&lt;li&gt;Aplied the extracted alignment information to enhance order-preserving.&lt;/li&gt;&#xA;&lt;li&gt;Translation across multiple languages, called multilingual machine translation [Conneau2019].&lt;/li&gt;&#xA;&lt;li&gt;mRASP (technique of randomly aligned substitution), an approach to pretraining a universal multilingual machine translation model. [Lin2020]&lt;/li&gt;&#xA;&lt;li&gt;Aligning word representations of each language, making it possible to preserve the word order consistent cross multiple languages. Wada2018&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;summary-from-introduction&#34;&gt;Summary from Introduction&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Researchers have developed numerous techniques for a wide range of applications of text generation [Li2021a].&lt;/li&gt;&#xA;&lt;li&gt;Machine translation generates text in a different language based on the source text [Yang2020a];&lt;/li&gt;&#xA;&lt;li&gt;Summarization generates an abridged version of the source text to include salient information [Guan2020].&lt;/li&gt;&#xA;&lt;li&gt;Text generation tasks based on&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Recurrent neural networks (RNN) [Li2019],&lt;/li&gt;&#xA;&lt;li&gt;Convolutional neural networks (CNN) [Gehring2017],&lt;/li&gt;&#xA;&lt;li&gt;Graph neural networks (GNN) [Li2020],&lt;/li&gt;&#xA;&lt;li&gt;Attention mechanism [Bahdanau2015].&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;One of the advantages of these neural models is that they enable end-to-end learning of semantic mappings from input to output in text generation.&lt;/li&gt;&#xA;&lt;li&gt;Neural models are able to learn low-dimensional, dense vectors to implicitly represent linguistic features of text, which is also useful to alleviate data sparsity.&lt;/li&gt;&#xA;&lt;li&gt;Deep neural networks usually have a large number of parameters to learn, which are likely to overﬁt on these small datasets and do not generalize well in practice.&lt;/li&gt;&#xA;&lt;li&gt;The idea behind PLMs is to ﬁrst pretrain the models in large-scale corpus and then ﬁnetune these models in various downstream tasks to achieve&#xA;state-of-the-art results.&lt;/li&gt;&#xA;&lt;li&gt;PLMs can encode a large amount of linguistic knowledge from corpus and induce universal representations of language.&lt;/li&gt;&#xA;&lt;li&gt;PLMs are generally beneﬁcial for downstream tasks and can avoid training a new model from scratch [Brown2020].&lt;/li&gt;&#xA;&lt;li&gt;A synthesis to the research on some text generation subtasks. Zaib et al. [2020], and Guan et al. [2020]&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;conclusion--future-recommendations&#34;&gt;Conclusion &amp;amp; Future Recommendations&lt;/h2&gt;&#xA;&lt;p&gt;Model Extension.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is LLM</title>
      <link>http://localhost:1313/dsblog/what-is-llm/</link>
      <pubDate>Fri, 18 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/what-is-llm/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6087-What-is-LLM.jpg&#34; alt=&#34;What is LLM&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-large-language-model&#34;&gt;What is Large Language Model&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;LLM stands for &lt;strong&gt;Large Language Model&lt;/strong&gt;. It is a type of artificial intelligence (AI) model that is trained on a massive dataset of text and code. This allows LLMs to learn the statistical relationships between words and phrases, and to generate text that is similar to the text that they were trained on.&lt;/p&gt;&#xA;&lt;p&gt;LLMs are still under development, but they have already been shown to be capable of performing a wide variety of tasks:&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to do Literature Review</title>
      <link>http://localhost:1313/dsblog/How-To-Do-Literature-Review/</link>
      <pubDate>Thu, 17 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/How-To-Do-Literature-Review/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6086-How-To-Do-Literature-Review.jpg&#34; alt=&#34;How to do Literature Review&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;how-to-conduct-literature-review&#34;&gt;How to Conduct Literature Review?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Literature Review (LR) or Literature Survey (LS) is a process that helps you to browse the libraries, literature, articles, books, conference proceedings, etc. The objective of this process is to study the work of other researchers in the field and around the topic you are interested in. This is one of the heaviest work in any research work. If you are not on track or this process is taking unusually longer time, then it means you don&amp;rsquo;t have any guiding process or best practices in place. As per my experience during my MS in Data Science and Ph.D./DBA in AI-Natural Language Processing, I am writing my thoughts in this article. I am sure it will help you, especially if you are entering in the field of research.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NLP Tasks</title>
      <link>http://localhost:1313/dsblog/nlp-tasks/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/nlp-tasks/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6085-NLP-Tasks.jpg&#34; alt=&#34;NLP Tasks&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;nlp-tasks&#34;&gt;NLP Tasks&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Processing words of any language and driving some meaning from these is as old as the human language. Recently, AI momentum is taking on many of these language-processing tasks. Here is the summary of these NLP tasks, this list is continuously growing. Researchers keep creating a dataset for these tasks in different languages. Other researchers keep devising new ways to solve these tasks with better performance. They come up with a new architecture, a new set of hyperparameters, a new pipeline, etc. In summary, as of today, there are around 55 tasks. Hundreds of datasets and research papers exist around these. You can check on &lt;a href=&#34;https://paperswithcode.com/&#34;&gt;PaperWithCode&lt;/a&gt; or &lt;a href=&#34;https://huggingface.co/&#34;&gt;Hggingface&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>SQL and Relational Algebra</title>
      <link>http://localhost:1313/dsblog/relational-algebra/</link>
      <pubDate>Mon, 14 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/relational-algebra/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6084-Relational-Algebra.jpg&#34; alt=&#34;Relational Algebra&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;sql-and-relational-algebra&#34;&gt;SQL and Relational Algebra&lt;/h1&gt;&#xA;&lt;p&gt;Relational algebra (RA) is considered as a procedural query language where the user tells the system to carry out a set of operations to obtain the desired results. i.e. The user tells what data should be retrieved from the database and how to retrieve it.&lt;/p&gt;&#xA;&lt;p&gt;Relational algebra notions can be implemtned via any any SQL language like PL/SQL, TSQL, SQLite SQL, DB2 SQL, MariaDB SQL, FireBird SQL, PSQL, ANSI SQL commands in any databases like MySQL, PostgreSQL, Oracle, SQLServer SQL server.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Types of Questions</title>
      <link>http://localhost:1313/dsblog/types-of-questions/</link>
      <pubDate>Fri, 11 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/types-of-questions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6083-Types-of-Questions.jpg&#34; alt=&#34;Types of Questions&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;types-of-questions&#34;&gt;Types of Questions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Question-Answering task is one of the tasks in NLP-Task. To create a high-performing AI system that can understand the question correctly and answer appropriately, we need to train a model. And to train a model, we need to have a good-quality dataset in place. Without understanding what are the different formats of questions and answers, we cannot create a dataset. In our day-to-day life we never pay attention to this minute detail but to create an AI system that can perform QA tasks, we need to understand the different formats of questions. In this article, I am creating a list of these different types of questions. To create an AI system that can perform all these kinds of QA tasks, we need to craft the dataset very carefully. Although, we see lots of data around, but to create an NLP-Task specific dataset is tedious task.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google Cloud APIs</title>
      <link>http://localhost:1313/dsblog/Google-Cloud-APIS/</link>
      <pubDate>Fri, 28 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Google-Cloud-APIS/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6082-Google-API-Services.jpg&#34; alt=&#34;Google Cloud APIs&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;google-cloud-apis&#34;&gt;Google Cloud APIs&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Hundreds of services from Google are available to consumers as API. Every API has a specific purpose. Over a period of time, google keeps clubbing these API endpoints (a url/place where a service is available), cleaning their code and improving the capabilities of these services. Therefore, sometimes it looks endpoint or pip package is the same, but its API name is different. Recently when google clubbed their many AI APIs they are moved under VertexAI and API endpoint changed to aiplatform.googleapi.com. To bring some clarity for my own sake and some of you may like this, I wrote this article.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Prompt Engineering</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Prompt-Engineering/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Prompt-Engineering/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6080-Introduction-to-Prompt-Engineering.jpg&#34; alt=&#34;Introduction to Prompt Engineering&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction-to-prompt-best-engineering&#34;&gt;Introduction to Prompt Best Engineering&lt;/h1&gt;&#xA;&lt;p&gt;Prompts can contain questions, instructions, contextual information, examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more. Below are &lt;strong&gt;14 examples of good prompts&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;example-1-entity-input&#34;&gt;Example 1 (Entity input)&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Classify the following items as [large, small].&#xD;&#xA;Elephant&#xD;&#xA;Mouse&#xD;&#xA;Snail&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;example-2-completion-input&#34;&gt;Example 2 (completion input)&lt;/h2&gt;&#xA;&lt;p&gt;You can write a prompt like&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Tuning with VertexAI</title>
      <link>http://localhost:1313/dsblog/Model-Tuning-with-VertexAI/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Model-Tuning-with-VertexAI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6081-Model-Tuning-with-VertexAI.jpg&#34; alt=&#34;Model Tuning with VertexAI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;tuning-large-language-model-with-vertexai&#34;&gt;Tuning Large Language Model with VertexAI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;why-model-tuning&#34;&gt;Why Model Tuning?&lt;/h2&gt;&#xA;&lt;p&gt;Tuning is required when you want the model to learn something niche or specific that deviates from general language patterns.&lt;/p&gt;&#xA;&lt;h2 id=&#34;goal-of-tuning&#34;&gt;Goal of Tuning&lt;/h2&gt;&#xA;&lt;h3 id=&#34;classification&#34;&gt;Classification&lt;/h3&gt;&#xA;&lt;p&gt;prompt: &amp;ldquo;Classify the following text into one of the following classes: [business, entertainment].&amp;rdquo;&lt;/p&gt;&#xA;&lt;h3 id=&#34;summarization&#34;&gt;Summarization&lt;/h3&gt;&#xA;&lt;p&gt;prompt: &amp;ldquo;Summarize: Jessica: That sounds great! See you in Times Square! Alexander: See you at 10!&amp;rdquo;&lt;/p&gt;&#xA;&lt;p&gt;response: &amp;ldquo;#Person1 and #Person2 agree to meet at Times Square at 10:00 AM.&amp;rdquo;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Database and Analytics Product Services from Google Azure AWS</title>
      <link>http://localhost:1313/dsblog/Database-and-Analytics-Product-Services-from-Google-Azure-AWS/</link>
      <pubDate>Fri, 21 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Database-and-Analytics-Product-Services-from-Google-Azure-AWS/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6079-Database-and-Analytics-Product-Services-from-Google-Azure-AWS.jpg&#34; alt=&#34;Database and Analytics Product Services from Google Azure AWS&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;database-and-analytics-product-services-from-google-azure-aws&#34;&gt;Database and Analytics Product Services from Google Azure AWS&lt;/h1&gt;&#xA;&lt;h2 id=&#34;database-toolsservices&#34;&gt;Database Tools/Services&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno&lt;/th&gt;&#xA;          &lt;th&gt;Amazon&lt;/th&gt;&#xA;          &lt;th&gt;Azure&lt;/th&gt;&#xA;          &lt;th&gt;Microsoft&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/rds/aurora/?nc2=h_ql_prod_db_aa&#34;&gt;Amazon Aurora : High performance managed relational database with full MySQL and PostgreSQL compatibility&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/sql?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;SQL : Managed MySQL, PostgreSQL, SQL Server&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/azure-sql/&#34;&gt;Azure SQL : Migrate, modernize, and innovate on the modern SQL family of cloud databases&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/rds/aurora/serverless/?nc2=h_ql_prod_db_aav2&#34;&gt;Amazon Aurora Serverless V2 : Instantly scale to &amp;gt;100,000 transactions per second&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/datastore?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Datastore : NoSQL database for your web and mobile apps&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/cosmos-db/&#34;&gt;Azure Cosmos DB : Build or modernize scalable, high-performance apps&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/documentdb/?nc2=h_ql_prod_db_doc&#34;&gt;Amazon DocumentDB (with MongoDB compatibility) : Fully managed document database&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/firestore?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Firestore : Serverless NoSQL document DB&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/azure-sql/database/&#34;&gt;Azure SQL Database : Build apps that scale with managed and intelligent SQL database in the cloud&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/dynamodb/?nc2=h_ql_prod_db_ddb&#34;&gt;Amazon DynamoDB : Managed NoSQL database&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/spanner?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Spanner : Horizontally scalable relational DB&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/postgresql/&#34;&gt;Azure Database for PostgreSQL : Fully managed, intelligent, and scalable PostgreSQL&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/elasticache/?nc2=h_ql_prod_db_elc&#34;&gt;Amazon ElastiCache : In-memory caching service&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/bigtable?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Bigtable : Petabyte-scale, low-latency, non-relational&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/azure-sql/managed-instance/&#34;&gt;Azure SQL Managed Instance : Modernize SQL Server applications with a managed, always-up-to-date SQL instance in the cloud&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/keyspaces/?nc2=h_ql_prod_db_mcs&#34;&gt;Amazon Keyspaces (for Apache Cassandra) : Managed Cassandra-compatible database&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/memorystore?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Memorystore : Managed Redis and Memcached&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/services/mysql/&#34;&gt;Azure Database for MySQL : Fully managed, scalable MySQL Database&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/memorydb/?nc2=h_ql_prod_db_memdb&#34;&gt;Amazon MemoryDB for Redis : Redis-compatible, durable, in-memory database that delivers ultra-fast performance&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/dbmigration?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Database Migration : Cloud SQL migrations simplified&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/virtual-machines/sql-server/&#34;&gt;SQL Server on Azure Virtual Machines : Migrate SQL Server workloads to the cloud at lower total cost of ownership (TCO)&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/neptune/?nc2=h_ql_prod_db_nep&#34;&gt;Amazon Neptune : Fully managed graph database service&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/marketplace/product/mongodb/mdb-atlas-self-service?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;MongoDB Atlas : JSON-like data models, querying, &amp;amp; scaling&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/cache/&#34;&gt;Azure Cache for Redis : Accelerate apps with high-throughput, low-latency data caching&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/qldb/?nc2=h_ql_prod_db_qldb&#34;&gt;Amazon Quantum Ledger Database (QLDB) : Fully managed ledger database&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/marketplace/product/endpoints/prod.n4gcp.neo4j.io?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Neo4j Aura : Integrated, fully managed graph databases&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/database-migration/&#34;&gt;Azure Database Migration Service : Accelerate your data migration to Azure&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/rds/?nc2=h_ql_prod_db_rds&#34;&gt;Amazon RDS : Managed relational database service for MySQL, PostgreSQL, Oracle, SQL Server, and MariaDB&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/marketplace/product/redis-marketplace-isaas/redis-enterprise-cloud-flexible-plan?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Redis Enterprise : Robust in-memory database platform&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/services/managed-instance-apache-cassandra/&#34;&gt;Azure Managed Instance for Apache Cassandra : Modernize Cassandra data clusters with a managed instance in the cloud&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/rds/outposts/?nc2=h_ql_prod_db_rdsvm&#34;&gt;Amazon RDS on Outposts : Automate on-premises database management&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;AlloyDB : Enterprise-grade, PostgreSQL-compatible databases&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/services/mariadb/&#34;&gt;Azure Database for MariaDB : Deploy applications to the cloud with enterprise-ready, fully managed community MariaDB&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/redshift/?nc2=h_ql_prod_db_rs&#34;&gt;Amazon Redshift : Fast, simple, cost-effective data warehousing&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/timestream/?nc2=h_ql_prod_db_ts&#34;&gt;Amazon Timestream : Fully managed time series database&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/dms/?nc2=h_ql_prod_db_dbm&#34;&gt;AWS Database Migration Service : Migrate databases with minimal downtime&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;data-analytics-toolsservices&#34;&gt;Data Analytics Tools/Services&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno&lt;/th&gt;&#xA;          &lt;th&gt;Amazon&lt;/th&gt;&#xA;          &lt;th&gt;Azure&lt;/th&gt;&#xA;          &lt;th&gt;Microsoft&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/athena/?nc2=h_ql_prod_an_ath&#34;&gt;Amazon Athena : Query data in S3 using SQL&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;BigQuery : Data warehouse for business agility and insights.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/synapse-analytics/&#34;&gt;Azure Synapse Analytics : Limitless analytics with unmatched time to insight&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/cloudsearch/?nc2=h_ql_prod_an_cs&#34;&gt;Amazon Cloud : SearchManaged search service&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Looker : Platform for BI, data applications, and embedded analytics.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/databricks/&#34;&gt;Azure Databricks : Design AI with Apache Spark™-based analytics&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/datazone/?nc2=h_ql_prod_an_dz&#34;&gt;Amazon DataZone (Preview) : Unlock data across organizational boundaries with built-in governance&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Dataflow : Streaming analytics for stream and batch processing.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/purview/&#34;&gt;Microsoft Purview : Govern, protect, and manage your data estate&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/opensearch-service/?nc2=h_ql_prod_an_es&#34;&gt;Amazon OpenSearch Service : Search, visualize, and analyze up to petabytes of text and unstructured data&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Pub/Sub : Messaging service for event ingestion and delivery.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/data-factory/&#34;&gt;Azure Data Factory : Hybrid data integration at enterprise scale, made easy&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/emr/?nc2=h_ql_prod_an_emr&#34;&gt;Amazon EMR : Easily run big data frameworks&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Dataproc : Service for running Apache Spark and Apache Hadoop clusters.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/hdinsight/&#34;&gt;HDInsight : Provision cloud Hadoop, Spark, R Server, HBase, and Storm clusters&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/finspace/?nc2=h_ql_prod_an_fs&#34;&gt;Amazon FinSpace : Analytics for the financial services industry&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Cloud Data Fusion : Data integration for building and managing data pipelines.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/stream-analytics/&#34;&gt;Azure Stream Analytics : Real-time analytics on fast-moving streaming data&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/kinesis/?nc2=h_ql_prod_an_kin&#34;&gt;Amazon Kinesis : Analyze real-time video and data streams&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Cloud Composer : Workflow orchestration service built on Apache Airflow.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/machine-learning/&#34;&gt;Azure Machine Learning : Build, train, and deploy models from the cloud to the edge&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/msk/?nc2=h_ql_prod_an_msak&#34;&gt;Amazon Managed Streaming for Apache Kafka : Fully managed Apache Kafka service&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Dataprep : Service to prepare data for analysis and machine learning.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/analysis-services/&#34;&gt;Azure Analysis Services : Enterprise-grade analytics engine as a service&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/redshift/?nc2=h_ql_prod_an_rs&#34;&gt;Amazon Redshift : Fast, simple, cost-effective data warehousing&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Dataplex : Intelligent data fabric for unifying data management across silos.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/storage/data-lake-storage/&#34;&gt;Azure Data Lake Storage : Scalable, secure data lake for high-performance analytics&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/quicksight/?nc2=h_ql_prod_an_qs&#34;&gt;Amazon QuickSight : Fast business analytics service&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Looker Studio : Interactive data suite for dashboarding, reporting, and analytics.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-us/products/data-explorer/&#34;&gt;Azure Data Explorer : Fast and highly scalable data exploration service&lt;/a&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/clean-rooms/?nc2=h_ql_prod_an_cr&#34;&gt;AWS Clean Rooms : Match, analyze, and collaborate on datasets–without sharing or revealing underlying data&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://console.cloud.google.com/alloydb?authuser=3&amp;amp;project=test-project-gcp-360004&#34;&gt;Analytics Hub : Service for securely and efficiently exchanging data analytics assets.&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/data-exchange/?nc2=h_ql_prod_an_dex&#34;&gt;AWS Data Exchange : Find, subscribe to, and use third-party data in the cloud&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/datapipeline/?nc2=h_ql_prod_an_dp&#34;&gt;AWS Data Pipeline : Orchestration service for periodic, data-driven workflows&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/glue/?nc2=h_ql_prod_an_glu&#34;&gt;AWS Glue : Simple, scalable, and serverless data integration&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aws.amazon.com/lake-formation/?nc2=h_ql_prod_an_lkf&#34;&gt;AWS Lake Formation : Build, manage, and secure your data lake&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br&gt;&#xA;Dr Hari Thapliyaal&lt;br&gt;&#xA;dasarpai.com &lt;br&gt;&#xA;linkedin.com/in/harithapliyal&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Product and Services from Google, Azure and AWS</title>
      <link>http://localhost:1313/dsblog/AI-Product-and-Services-from-Google-Azure-and-AWS/</link>
      <pubDate>Thu, 20 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Product-and-Services-from-Google-Azure-and-AWS/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6078-AI-Product-and-Services-from-Google-Azure-and-AWS.jpg&#34; alt=&#34;AI Product and Services from Google, Azure and AWS&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-product-and-services-from-google-azure-and-aws&#34;&gt;AI Product and Services from Google, Azure and AWS&lt;/h1&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno&lt;/th&gt;&#xA;          &lt;th&gt;Azure&lt;/th&gt;&#xA;          &lt;th&gt;Google&lt;/th&gt;&#xA;          &lt;th&gt;AWS&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/anomaly-detector/&#34;&gt;Anomaly Detector:&lt;/a&gt; Easily add anomaly detection capabilities to your apps.&lt;/td&gt;&#xA;          &lt;td&gt;AutoML: Custom low-code models &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/training/training&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/a2i/home?region=us-east-1&#34;&gt;Amazon Augmented AI&lt;/a&gt; : Easily implement human review of machine learning predictions&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/bot-services/&#34;&gt;Azure Bot Service:&lt;/a&gt; Build conversational AI experiences for your customers&lt;/td&gt;&#xA;          &lt;td&gt;Cloud TPU: Hardware acceleration for ML &lt;a href=&#34;https://cloud.google.com/tpu/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/tpu/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/bedrock/home?region=us-east-1&#34;&gt;Amazon Bedrock&lt;/a&gt; : The easiest way to build and scale generative AI applications with foundation models (FMs).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/search/&#34;&gt;Azure Cognitive Search:&lt;/a&gt; Enterprise scale search for app development&lt;/td&gt;&#xA;          &lt;td&gt;Cloud Translation: Language detection and translation &lt;a href=&#34;https://cloud.google.com/translate/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/translate/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/codeguru/home?region=us-east-1&#34;&gt;Amazon CodeGuru&lt;/a&gt; : Intelligent recommendations for building and running modern applications&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/databricks/&#34;&gt;Azure Databricks:&lt;/a&gt; Design AI with Apache Spark™-based analytics&lt;/td&gt;&#xA;          &lt;td&gt;Cloud Vision: Image recognition and classification &lt;a href=&#34;https://cloud.google.com/vision/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vision/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/comprehendmedical/home?region=us-east-1&#34;&gt;Amazon Comprehend Medical&lt;/a&gt; : Amazon Comprehend Medical uses machine learning to extract insights and relationships from medical text.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/machine-learning/&#34;&gt;Azure Machine Learning:&lt;/a&gt; Enterprise-grade machine learning service to build and deploy models faster&lt;/td&gt;&#xA;          &lt;td&gt;Contact Center AI: AI in your contact center &lt;a href=&#34;https://cloud.google.com/solutions/contact-center/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/solutions/contact-center/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/comprehend/home?region=us-east-1&#34;&gt;Amazon Comprehend&lt;/a&gt; : Analyze Unstructured Text&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/open-datasets/&#34;&gt;Azure Open Datasets:&lt;/a&gt; Cloud platform to host and share curated open datasets to accelerate development of machine learning models&lt;/td&gt;&#xA;          &lt;td&gt;Deep Learning Containers: Preconfigured containers for deep learning &lt;a href=&#34;https://cloud.google.com/ai-platform/deep-learning-containers/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/ai-platform/deep-learning-containers/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/deepcomposer/home?region=us-east-1&#34;&gt;AWS DeepComposer&lt;/a&gt; : AWS DeepComposer allows developers of all skill levels to get started with Generative AI.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/&#34;&gt;Azure Cognitive Services:&lt;/a&gt; Deploy high-quality AI models as APIs&lt;/td&gt;&#xA;          &lt;td&gt;Deep Learning VM Images: Preconfigured VMs for deep learning &lt;a href=&#34;https://cloud.google.com/deep-learning-vm/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/deep-learning-vm/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/deeplens/home?region=us-east-1&#34;&gt;AWS DeepLens&lt;/a&gt; : Deep Learning Enabled Video Camera&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/video-indexer/&#34;&gt;Azure Video Analyzer for Media:&lt;/a&gt; Unlock video insights&lt;/td&gt;&#xA;          &lt;td&gt;Dialogflow: Create conversational interfaces &lt;a href=&#34;https://cloud.google.com/dialogflow-enterprise/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/dialogflow-enterprise/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/deepracer/home?region=us-east-1&#34;&gt;AWS DeepRacer&lt;/a&gt; : Fully autonomous 1/18th scale race car, driven by machine learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/content-safety/&#34;&gt;Content Moderator GA:&lt;/a&gt; Automated image, text and video moderation&lt;/td&gt;&#xA;          &lt;td&gt;Document AI: Analyze, classify, search documents &lt;a href=&#34;https://cloud.google.com/solutions/document-understanding/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/document-understanding/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/devops-guru/home?region=us-east-1&#34;&gt;Amazon DevOps Guru&lt;/a&gt; : ML-powered cloud operations service to improve application availability.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/custom-vision-service/&#34;&gt;Custom Vision:&lt;/a&gt; Easily customise your own state-of-the-art computer vision models for your unique use case&lt;/td&gt;&#xA;          &lt;td&gt;Recommendations AI: Create custom recommendations &lt;a href=&#34;https://cloud.google.com/recommendations/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/recommendations-ai/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/forecast/home?region=us-east-1&#34;&gt;Amazon Forecast&lt;/a&gt; : Amazon Forecast is a fully-managed service for accurate time-series forecasting&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/virtual-machines/data-science-virtual-machines/&#34;&gt;Data Science Virtual Machines:&lt;/a&gt; Rich pre-configured environment for AI development&lt;/td&gt;&#xA;          &lt;td&gt;Speech-To-Text: Convert audio to text &lt;a href=&#34;https://cloud.google.com/speech/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/speech/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/frauddetector/home?region=us-east-1&#34;&gt;Amazon Fraud Detector&lt;/a&gt; : Detect more online fraud faster using machine learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/form-recognizer/&#34;&gt;Azure Form Recogniser:&lt;/a&gt; Accelerate information extraction from documents&lt;/td&gt;&#xA;          &lt;td&gt;Talent Solutions: Job search with ML &lt;a href=&#34;https://cloud.google.com/job-discovery/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/job-discovery/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/healthlake/home?region=us-east-1&#34;&gt;Amazon HealthLake&lt;/a&gt; : Making sense of health data&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/immersive-reader/&#34;&gt;Azure Immersive Reader:&lt;/a&gt; Empower users of all ages and abilities to read and comprehend text&lt;/td&gt;&#xA;          &lt;td&gt;Text-To-Speech: Convert text to audio &lt;a href=&#34;https://cloud.google.com/text-to-speech/&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/text-to-speech/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/kendra/home?region=us-east-1&#34;&gt;Amazon Kendra&lt;/a&gt; : Highly accurate enterprise search service powered by machine learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/kinect-dk/&#34;&gt;Kinect DK:&lt;/a&gt; Build computer vision and speech models using a developer kit with advanced AI sensors&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Data Labeling: Data labeling by humans &lt;a href=&#34;https://cloud.google.com/data-labeling/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lexv2/home?region=us-east-1&#34;&gt;Amazon Lex&lt;/a&gt; : Build Voice and Text Chatbots&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/conversational-language-understanding/&#34;&gt;Language Understanding:&lt;/a&gt; Teach your apps to understand commands from your users&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Edge Manager: Deploy monitor edge inferences &lt;a href=&#34;https://https://cloud.google.com/vertex-ai/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lookoutequipment/home?region=us-east-1&#34;&gt;Amazon Lookout for Equipment&lt;/a&gt; : Detect abnormal equipment behavior by analyzing sensor data&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/genomics/&#34;&gt;Microsoft Genomics:&lt;/a&gt; Power genome sequencing and research insights&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Feature Store: Managed ML feature repository &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/featurestore&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/featurestore/overview&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lookoutmetrics/home?region=us-east-1&#34;&gt;Amazon Lookout for Metrics&lt;/a&gt; : Accurately detect anomalies in your business metrics and quickly understand why&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;17.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/personalizer/&#34;&gt;Personaliser:&lt;/a&gt; An AI service that delivers a personalised user experience&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Matching Engine: Vector similarity searches &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/matching-engine&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/matching-engine&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/lookoutvision/home?region=us-east-1&#34;&gt;Amazon Lookout for Vision&lt;/a&gt; : Identify defects using computer vision to automate quality inspection.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;18.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/project-bonsai/&#34;&gt;Project Bonsai:&lt;/a&gt; Create intelligent industrial control systems using simulations&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Model Monitoring: Monitor models for skew/drift &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/model-monitoring&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/model-monitoring/overview&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/monitron/home?region=us-east-1&#34;&gt;Amazon Monitron&lt;/a&gt; : End-to-end system for equipment monitoring&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;19.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://docs.microsoft.com/en-in/azure/cognitive-services/QnAMaker/Overview/overview&#34;&gt;QnA Maker:&lt;/a&gt; Distill information into conversational, easy-to-navigate answers&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Pipelines: Hosted ML workflows &lt;a href=&#34;https://cloud.google.com/ai-platform/pipelines/&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/omics/home?region=us-east-1&#34;&gt;Amazon Omics&lt;/a&gt; : Transform omics data into insights.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;20.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/speaker-recognition/&#34;&gt;Speaker Recognition:&lt;/a&gt; A Speech service feature that verifies and identifies speakers&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Predictions: Autoscaled model serving &lt;a href=&#34;https://cloud.google.com/ai-platform/prediction/docs/overview&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/panorama/home?region=us-east-1&#34;&gt;AWS Panorama&lt;/a&gt; : Enabling computer vision applications at the edge&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;21.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/speech-to-text/&#34;&gt;Speech to Text:&lt;/a&gt; A Speech service feature that accurately converts spoken audio to text&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Tensorboard: Managed TensorBoard for ML-experiment Visualization &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/experiments&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/personalize/home?region=us-east-1&#34;&gt;Amazon Personalize&lt;/a&gt; : Amazon Personalize helps you easily add real-time recommendations to your apps&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;22.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/speech-translation/&#34;&gt;Speech Translation:&lt;/a&gt; Easily integrate real-time speech translation to your app&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Training: Distributed AI training &lt;a href=&#34;https://cloud.google.com/ai-platform/training/docs/overview&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/polly/home?region=us-east-1&#34;&gt;Amazon Polly&lt;/a&gt; : Turn Text into Lifelike Speech&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;23.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/language-service/&#34;&gt;Cognitive Service for Language:&lt;/a&gt; Add natural language capabilities with a single API call&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Vizier: black-box hyperparameter tuning &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vizier/overview&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/vizier&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/rekognition/home?region=us-east-1&#34;&gt;Amazon Rekognition&lt;/a&gt; : Search and Analyze Images&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;24.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/cognitive-services/text-to-speech/&#34;&gt;Text to Speech:&lt;/a&gt; A Speech service feature that converts text to lifelike speech&lt;/td&gt;&#xA;          &lt;td&gt;Vertex AI Workbench:Jupyter-based environment for Data Science &lt;a href=&#34;https://cloud.google.com/vertex-ai-workbench&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/workbench&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/sagemaker/home?region=us-east-1&#34;&gt;Amazon SageMaker&lt;/a&gt; : Build, Train, and Deploy Machine Learning Models&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;25.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/services/cognitive-services/translator/&#34;&gt;Translator:&lt;/a&gt; Easily conduct machine translation with a simple REST API call&lt;/td&gt;&#xA;          &lt;td&gt;Vertex Explainable AI: Understand ML model predictions &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/explainable-ai/overview&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/explainable-ai&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/textract/home?region=us-east-1&#34;&gt;Amazon Textract&lt;/a&gt; : Easily extract text and data from virtually any document&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;26.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/metrics-advisor/&#34;&gt;Azure Metrics Advisor:&lt;/a&gt; An AI service that monitors metrics and diagnoses issues&lt;/td&gt;&#xA;          &lt;td&gt;Vertex ML Metadata: Artifact, lineage, and execution tracking &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/ml-metadata&#34;&gt;Link&lt;/a&gt; &lt;a href=&#34;https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/transcribe/home?region=us-east-1&#34;&gt;Amazon Transcribe&lt;/a&gt; : Powerful Speech Recognition&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;27.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/bot-services/health-bot/&#34;&gt;Health Bot:&lt;/a&gt; A managed service purpose-built for development of virtual healthcare assistants&lt;/td&gt;&#xA;          &lt;td&gt;Vision Product Search: Visual search for products &lt;a href=&#34;https://cloud.google.com/vision/product-search/docs/&#34;&gt;Doc&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://us-east-1.console.aws.amazon.com/translate/home?region=us-east-1&#34;&gt;Amazon Translate&lt;/a&gt; : Powerful Neural Machine Translation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;28.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://aka.ms/ScalerHomepage&#34;&gt;Azure Applied AI Services:&lt;/a&gt; Specialised services that enable organisations to accelerate time to value in applying AI to solve common scenarios&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;29.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/openai-service/&#34;&gt;Azure OpenAI Service:&lt;/a&gt; Apply advanced coding and language models to a variety of use cases&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;30.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://azure.microsoft.com/en-in/products/cognitive-services/vision-services/&#34;&gt;Azure Cognitive Services for Vision:&lt;/a&gt; Unlock insights from image and video content with AI&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br&gt;&#xA;Dr Hari Thapliyaal&lt;br&gt;&#xA;dasarpai.com &lt;br&gt;&#xA;linkedin.com/in/harithapliyal&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to ML Model Deployment</title>
      <link>http://localhost:1313/dsblog/Introduction-to-ML-Model-deployment/</link>
      <pubDate>Wed, 19 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-ML-Model-deployment/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6077-Introduction-to-ML-Model-deployment.jpg&#34; alt=&#34;Introduction to AI Model Deployement&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction-to-ai-model-deployment&#34;&gt;Introduction to AI Model deployment&lt;/h1&gt;&#xA;&lt;h2 id=&#34;big-players&#34;&gt;Big Players&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Amazon&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Amazon has many products and one of their product is &lt;strong&gt;AWS Cloud&lt;/strong&gt;. Under this product they sell IT infrastructure (storage, memory, network, VM, webhosting etc.)&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Amazon SageMaker&lt;/strong&gt; is Cloud based Machine Learning Platform, and this is one of the product under AWS Cloud.&lt;/li&gt;&#xA;&lt;li&gt;Amazon SageMaker can be used to train AI model, host AI model, monitor the model and hosts many other services which any Data Science project need from data gathering to model serving.&lt;/li&gt;&#xA;&lt;li&gt;AWS is oldest cloud service provider in the market.&lt;/li&gt;&#xA;&lt;li&gt;AWS Sagemaker was launched in Nov&#39;17.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Google&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Google has hundreds of products like gmail, youtube, google drive etc. One of their product is called &lt;strong&gt;Google Cloud&lt;/strong&gt;. Under this product they sell IT infrastrcture like Amazon sells under AWS.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;VertexAI&lt;/strong&gt; is Cloud based Machine Learning platform of Google. VertexAI is part of Google Cloud.&lt;/li&gt;&#xA;&lt;li&gt;VertexAI can be used to train AI Model,host AI model, monitor the model etc.&lt;/li&gt;&#xA;&lt;li&gt;VertexAI was launched in Jun&#39;21&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Microsoft&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Like Amazon&amp;rsquo;s cloud platform which is called AWS Cloud, Microsoft&amp;rsquo;s cloud plateform is called &lt;strong&gt;Azure&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Microsoft&amp;rsquo;s AI product is called &lt;strong&gt;Azure Machine Learning&lt;/strong&gt;.&lt;/li&gt;&#xA;&lt;li&gt;Today (Jul&#39;23) Azure Machine Learning has has most of the capabilites than any other player&amp;rsquo;s AI product.&lt;/li&gt;&#xA;&lt;li&gt;Azure Machine Learning was launched Feb&#39;14&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-is-genai&#34;&gt;What is GenAI?&lt;/h2&gt;&#xA;&lt;p&gt;There are many kinds of AI models like classifier models, regressor models, clustering models, reinforcement models, etc. An AI model which has the ability to generate text, images, video, and music is called GenAI. They all take inspiration from the human brain, therefore they all have neural network (NN) architecture. There are dozens (if not hundreds) types of NN architecture that can be used to create different kinds of AI models. The type of NN architecture depends upon the data which is used for developing the model and the problem which we want to solve using AI model. Researchers in universities or big corporations like Google, Facebook, Amazon, and Microsoft keep developing new architecture, and using these architectures they develop the foundational models. Once foundational models are developed, they release a research paper. In this, they inform the world what architecture they used, what data they used, what parameters (weights &amp;amp; biases) the model has learned, what are the results of their product and compare that with other existing models. They can develop these foundational models with one set of hyperparameters, and they can release these foundational models of different sizes (it depends upon the number of parameters used). AI product builders pick up these foundational models and fine-tune these based on the exact business problem in their hands. Which foundational model do they choose, it also depends upon the size of the model, the kind of data it has used to create those foundational models, and what was the performance of the model on a similar task which the product developer want to solve.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS SageMaker Jumpstart Models</title>
      <link>http://localhost:1313/dsblog/AWS-SageMaker-Jumpstart-Models/</link>
      <pubDate>Tue, 18 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AWS-SageMaker-Jumpstart-Models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6076-AWS-SageMaker-Jumpstart-Models.jpg&#34; alt=&#34;AWS SageMaker Jumpstart Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;aws-sagemaker-jumpstart-models&#34;&gt;AWS SageMaker Jumpstart Models&lt;/h1&gt;&#xA;&lt;p&gt;As of 17-Jul-23, AWS Sagemaker has 463 models in its Model Zoo. They call these models as Jumstart Models. What are the capabilities of these models, who are the developer of these models, where these models are hosted in given in the table below.&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;SNo.&lt;/th&gt;&#xA;          &lt;th&gt;Task Type&lt;/th&gt;&#xA;          &lt;th&gt;Company&lt;/th&gt;&#xA;          &lt;th&gt;Model Description&lt;/th&gt;&#xA;          &lt;th&gt;Model ID&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Falcon-40B-Instruct is a 40B parameters causal decoder-only model built by TII based on Falcon-40B and finetuned on a mixture of Baize  It is ready-to-use chat/instruct model based on Falcon 40B&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration-falcon-40b-instruct-bf16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Generation model built upon a Transformer model from Hugging Face&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration-open-llama&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3.&lt;/td&gt;&#xA;          &lt;td&gt;Text to Image&lt;/td&gt;&#xA;          &lt;td&gt;StabilityAI&lt;/td&gt;&#xA;          &lt;td&gt;Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Cohere&lt;/td&gt;&#xA;          &lt;td&gt;Generative model that responds well with instruction-like prompts. This model provides businesses and enterprises with best quality, performance and accuracy in all generative tasks. And with our intuitive SDK, unlocking the full potential of LLMs for your applications has never been easier.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;AI21 Labs&lt;/td&gt;&#xA;          &lt;td&gt;Jurassic-2 Ultra is optimized to follow natural language instructions and context, so there is no need to provide it with any examples.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;AI21 Labs&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;AI21 Labs&lt;/td&gt;&#xA;          &lt;td&gt;Condense lengthy texts into short, easy-to-read bites that remain factually consistent with the source. No prompting needed – simply input the text that needs to be summarized. The model is specifically trained to generate summaries that capture the essence and key ideas of the original text.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;AI21 Labs&lt;/td&gt;&#xA;          &lt;td&gt;Get the AI21 Paraphrase model, the top-of-the-line paraphrasing engine, and deploy it in your private environment. The model aims to generate 10 alternative suggestions with every activation. It may return fewer suggestions when rewriting very short texts for which it cannot produce as many as 10 sensible paraphrases.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;AI21 Labs&lt;/td&gt;&#xA;          &lt;td&gt;Jurassic-2 Mid is optimized to follow natural language instructions and context, so there is no need to provide it with any examples. Pre-trained language model trained by AI21 Labs on a corpus of web text including natural language and computer programs with recent data - updated to mid 2022. This model has a 8192 token context window (i.e. the length of the prompt + completion should be at most 8192 tokens).&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;AI21 Labs&lt;/td&gt;&#xA;          &lt;td&gt;Detects and suggests corrections for Grammar, Spelling, Punctuation mistakes, as well as word misuse, and accidental repetition or omission.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11.&lt;/td&gt;&#xA;          &lt;td&gt;Text to Image&lt;/td&gt;&#xA;          &lt;td&gt;StabilityAI&lt;/td&gt;&#xA;          &lt;td&gt;Extend beyond just text-to-image prompting. Stable Diffusion XL offers several ways to modify the images: Inpainting - edit inside the image, Outpainting - extend the image outside of the original image, Image-to-image - prompt a new image using a sourced image.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12.&lt;/td&gt;&#xA;          &lt;td&gt;Text to Image&lt;/td&gt;&#xA;          &lt;td&gt;Stabilityai&lt;/td&gt;&#xA;          &lt;td&gt;This is a text-to-image model from Stability AI and downloaded from HuggingFace  It takes a textual description as input and returns a generated image from the description&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: model-txt2img-stabilityai-stable-diffusion-v2-1-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text2Text Generation model built upon a T5 model from Hugging Face  The deployed model can be used for running inference on any input text&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-text2text-flan-t5-xl&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Generation model built upon a Transformer model from Hugging Face  It takes a text string as input and predicts next words in the sequence&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration1-gpt-j-6b&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text2Text Generation model built upon a T5 model from Hugging Face  The deployed model can be used for running inference on any input text&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-text2text-flan-ul2-bf16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;AlexaTM 20B is a multitask, multilingual, large-scale sequence-to-sequence (seq2seq) model, trained on a mixture of Common Crawl (mC4) and Wikipedia data across 12 languages, using denoising and Causal Language Modeling (CLM) tasks&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-textgeneration1-alexa20b&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;17.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Generation model built upon a Transformer model from Hugging Face  It takes a text string as input and predicts next words in the sequence&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration-bloom-1b7&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;18.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Classification model from TensorFlow Hub  It takes an image as input and classifies the image to one of the 1001 classes&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v2-100-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;19.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from Tensorflow  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-resnet50-v1-fpn-640x640-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;20.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from PyTorch Hub  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-od1-fasterrcnn-resnet50-fpn&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;21.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub  It takes a text string as input and classifies the input text as either a positive or negative movie review&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-bert-en-uncased-L-12-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;22.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is an Extractive Question Answering model built on a Transformer model from Hugging Face  It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-distilbert-base-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;23.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is Zero Shot Text Classification model built on a Transformer model from Hugging Face  It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-facebook-bart-large-mnli&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;24.&lt;/td&gt;&#xA;          &lt;td&gt;Semantic Segmentation&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is an Semantic Segmentation model from Gluon CV  It takes an image as input and returns class label for each pixel in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-semseg-fcn-resnet101-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;25.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Sentence Pair Classification model built upon a Text Embedding model from Hugging Face  It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&#39;&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-distilbert-base-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;26.&lt;/td&gt;&#xA;          &lt;td&gt;Named Entity Recognition&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Named Entity Generation model built upon a Transformer model from Hugging Face  It takes a text string as input and predicts named entities in the input text&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-ner-distilbert-base-cased-finetuned-conll03-english&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;27.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Summarization model built upon a Transformer model from Hugging Face  It takes a text string as input and returns a summary of the text&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-distilbart-xsum-1-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;28.&lt;/td&gt;&#xA;          &lt;td&gt;Machine Translation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Machine Translation model built upon a Transformer model from Hugging Face  It takes a text string as input and predicts its translation&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-translation-t5-small&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;29.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Embedding model from TensorFlow Hub  It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-2-H-128-A-2-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;30.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Embedding model from GluonNLP pre-trained on the decade (2010-2019) of S&amp;amp;P 500 10-K/10-Q reports  It takes a text string as input and outputs an embedding vector For pre-training, the entire text of the 10K/Q filing was used, not just the MD&amp;amp;A (Management Discussion and Analysis) section, so as to ensure that a broader context of financial language is captured Embeddings from the pre-trained modelare then used for fine-tuning specific classifiers&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-tcembedding-robertafin-base-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;31.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub  It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&#39;&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-bert-en-uncased-L-12-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;32.&lt;/td&gt;&#xA;          &lt;td&gt;Instance Segmentation&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is an Instance Segmentation model from Gluon CV  It detects and delineates each distinct object in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-is-mask-rcnn-fpn-resnet101-v1d-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;33.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Feature Vector model from TensorFlow Hub  It takes an image as input and returns a feature vector (embedding) of the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v2-100-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;34.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Classification model from PyTorch Hub  It takes an image as input and classifies the image to one of the 1000 classes&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-mobilenet-v2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;35.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from Gluon CV  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-512-mobilenet1-0-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;36.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from TensorFlow Hub  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-ssd-mobilenet-v2-fpnlite-320x320-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;37.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from PyTorch Hub  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-od-nvidia-ssd&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;38.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Classification model from TensorFlow Hub  It takes an image as input and classifies the image to one of the 1001 classes&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v2-075-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;39.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v2-050-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;40.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v2-035-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;41.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v2-140-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;42.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v2-130-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;43.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from PyTorch Hub  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-od1-fasterrcnn-mobilenet-v3-large-320-fpn&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;44.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-od1-fasterrcnn-mobilenet-v3-large-fpn&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;45.&lt;/td&gt;&#xA;          &lt;td&gt;Semantic Segmentation&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is an Semantic Segmentation model from Gluon CV  It takes an image as input and returns class label for each pixel in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-semseg-fcn-resnet101-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;46.&lt;/td&gt;&#xA;          &lt;td&gt;Semantic Segmentation&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-semseg-fcn-resnet101-ade&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;47.&lt;/td&gt;&#xA;          &lt;td&gt;Instance Segmentation&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-semseg-fcn-resnet50-ade&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;48.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Classification model from PyTorch Hub  It takes an image as input and classifies the image to one of the 1000 classes&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-resnet18&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;49.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-resnet34&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;50.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-resnet50&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;51.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-resnet101&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;52.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-resnet152&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;53.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from Gluon CV  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-512-mobilenet1-0-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;54.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-512-resnet50-v1-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;55.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-512-resnet50-v1-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;56.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-300-vgg16-atrous-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;57.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-300-vgg16-atrous-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;58.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-efficientdet-d0-512x512-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;59.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-efficientdet-d1-640x640-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;60.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-efficientdet-d2-768x768-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;61.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-efficientdet-d3-896x896-coco17-tpu-32&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;62.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-mobilenet-v1-fpn-640x640-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;63.&lt;/td&gt;&#xA;          &lt;td&gt;Instance Segmentation&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is an Instance Segmentation model from Gluon CV  It detects and delineates each distinct object in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-is-mask-rcnn-fpn-resnet50-v1b-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;64.&lt;/td&gt;&#xA;          &lt;td&gt;Instance Segmentation&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-is-mask-rcnn-fpn-resnet18-v1b-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;65.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-is-mask-rcnn-resnet18-v1b-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;66.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Feature Vector model from TensorFlow Hub  It takes an image as input and returns a feature vector (embedding) of the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v2-075-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;67.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v2-050-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;68.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v2-035-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;69.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v2-140-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;70.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v2-130-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;71.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from TensorFlow Hub  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-ssd-mobilenet-v2-fpnlite-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;72.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-ssd-mobilenet-v2-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;73.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-ssd-mobilenet-v1-fpn-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;74.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet50-v1-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;75.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet50-v1-800x1333-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;76.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is Zero Shot Text Classification model built on a Transformer model from Hugging Face  It can classify sentences in English language It takes a sequence and a list of candidate labels as inputs and predicts score that the sequence is associated with the particular label&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-narsil-deberta-large-mnli-zero-cls&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;77.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-moritzlaurer-deberta-v3-large-mnli-fever-anli-ling-wanli&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;78.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-cross-encoder-nli-distilroberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;79.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-recognai-bert-base-spanish-wwm-cased-xnli&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;80.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-moritzlaurer-mdeberta-v3-base-xnli-multilingual-nli-2mil7&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;81.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-cross-encoder-nli-roberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;82.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-cross-encoder-nli-deberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;83.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-cross-encoder-nli-minilm2-l6-h768&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;84.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-recognai-zeroshot-selectra-medium&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;85.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-navteca-bart-large-mnli&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;86.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-jiva-xlm-roberta-large-it-mnli&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;87.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-digitalepidemiologylab-covid-twitter-bert-v2-mnli&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;88.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-recognai-zeroshot-selectra-small&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;89.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-snli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;90.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-bert-base-turkish-cased-allnli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;91.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-bert-base-turkish-cased-snli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;92.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-bert-base-multilingual-cased-allnli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;93.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-narsil-bart-large-mnli-opti&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;94.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-allnli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;95.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-lighteternal-nli-xlm-r-greek&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;96.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-allnli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;97.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-bert-base-multilingual-cased-multinli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;98.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-eleldar-theme-classification&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;99.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-bert-base-turkish-cased-multinli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;100.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-bert-base-multilingual-cased-snli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;101.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-multinli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;102.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-distilbert-base-turkish-cased-multinli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;103.&lt;/td&gt;&#xA;          &lt;td&gt;Zero-Shot Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-zstc-emrecan-convbert-base-turkish-mc4-cased-snli-tr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;104.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Classification model from TensorFlow Hub  It takes an image as input and classifies the image to one of the 1001 classes&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-tf2-preview-mobilenet-v2-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;105.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-inception-v3-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;106.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-inception-v2-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;107.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-inception-v1-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;108.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-tf2-preview-inception-v3-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;109.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-inception-resnet-v2-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;110.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-resnet-v2-50-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;111.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-resnet-v2-101-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;112.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-resnet-v2-152-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;113.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-resnet-v1-50-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;114.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-resnet-v1-101-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;115.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-resnet-v1-152-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;116.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-resnet-50-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;117.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b0-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;118.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b1-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;119.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b2-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;120.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b3-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;121.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b4-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;122.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b5-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;123.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b6-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;124.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-b7-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;125.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-lite0-classification-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;126.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-lite1-classification-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;127.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-lite2-classification-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;128.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-lite3-classification-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;129.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-efficientnet-lite4-classification-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;130.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-100-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;131.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-100-192-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;132.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-100-160-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;133.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-100-128-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;134.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-075-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;135.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-075-192-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;136.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-075-160-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;137.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-075-128-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;138.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-050-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;139.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-050-192-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;140.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-050-160-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;141.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-050-128-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;142.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-025-224-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;143.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-025-192-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;144.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-025-160-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;145.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-imagenet-mobilenet-v1-025-128-classification-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;146.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-s-r50x1-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;147.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-s-r50x3-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;148.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-s-r101x1-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;149.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-s-r101x3-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;150.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r50x1-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;151.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r50x3-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;152.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r101x1-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;153.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r101x3-ilsvrc2012-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;154.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r50x1-imagenet21k-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;155.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r50x3-imagenet21k-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;156.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r101x1-imagenet21k-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;157.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-ic-bit-m-r101x3-imagenet21k-classification-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;158.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-alexnet&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;159.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-densenet121&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;160.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-densenet169&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;161.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-densenet201&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;162.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-densenet161&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;163.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-resnext50-32x4d&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;164.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-resnext101-32x8d&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;165.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-shufflenet-v2-x1-0&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;166.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-squeezenet1-0&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;167.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-squeezenet1-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;168.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg11&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;169.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg11-bn&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;170.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg13&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;171.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg13-bn&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;172.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;173.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg16-bn&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;174.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg19&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;175.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-vgg19-bn&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;176.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-wide-resnet50-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;177.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-wide-resnet101-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;178.&lt;/td&gt;&#xA;          &lt;td&gt;Image Classification&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-ic-googlenet&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;179.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from Gluon CV  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-512-vgg16-atrous-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;180.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-ssd-512-vgg16-atrous-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;181.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-yolo3-darknet53-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;182.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-yolo3-mobilenet1-0-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;183.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-yolo3-darknet53-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;184.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-yolo3-mobilenet1-0-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;185.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-faster-rcnn-resnet50-v1b-voc&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;186.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-faster-rcnn-resnet50-v1b-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;187.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-faster-rcnn-resnet101-v1d-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;188.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-faster-rcnn-fpn-resnet50-v1b-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;189.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-od-faster-rcnn-fpn-resnet101-v1d-coco&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;190.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-320x320-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;191.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-mobilenet-v2-fpnlite-640x640-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;192.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-resnet50-v1-fpn-1024x1024-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;193.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-resnet101-v1-fpn-640x640-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;194.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-resnet101-v1-fpn-1024x1024-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;195.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-resnet152-v1-fpn-640x640-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;196.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od1-ssd-resnet152-v1-fpn-1024x1024-coco17-tpu-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;197.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an Image Feature Vector model from TensorFlow Hub  It takes an image as input and returns a feature vector (embedding) of the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-inception-v3-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;198.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-inception-v2-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;199.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-inception-v1-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;200.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-tf2-preview-inception-v3-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;201.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-tf2-preview-mobilenet-v2-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;202.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-resnet-v2-50-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;203.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-resnet-v2-101-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;204.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-resnet-v2-152-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;205.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-resnet-v1-50-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;206.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-resnet-v1-101-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;207.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-resnet-v1-152-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;208.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-resnet-50-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;209.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-b0-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;210.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-b1-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;211.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-b2-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;212.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-b3-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;213.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-b6-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;214.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-lite0-featurevector-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;215.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-lite1-featurevector-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;216.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-lite2-featurevector-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;217.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-lite3-featurevector-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;218.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-efficientnet-lite4-featurevector-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;219.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-100-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;220.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-100-192-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;221.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-100-160-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;222.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-100-128-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;223.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-075-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;224.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-075-192-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;225.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-075-160-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;226.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-075-128-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;227.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-050-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;228.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-050-192-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;229.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-050-160-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;230.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-050-128-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;231.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-025-224-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;232.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-025-192-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;233.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-025-160-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;234.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-imagenet-mobilenet-v1-025-128-featurevector-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;235.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-s-r50x1-ilsvrc2012-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;236.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-s-r50x3-ilsvrc2012-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;237.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-s-r101x1-ilsvrc2012-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;238.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-s-r101x3-ilsvrc2012-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;239.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-m-r50x1-ilsvrc2012-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;240.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-m-r50x3-imagenet21k-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;241.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-m-r101x1-ilsvrc2012-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;242.&lt;/td&gt;&#xA;          &lt;td&gt;Image Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-icembedding-bit-m-r101x3-imagenet21k-featurevector-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;243.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an object detection model from TensorFlow Hub  It takes an image as input and returns bounding boxes for the objects in the image&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet50-v1-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;244.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet101-v1-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;245.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet101-v1-800x1333-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;246.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet101-v1-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;247.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet152-v1-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;248.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet152-v1-800x1333-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;249.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-resnet152-v1-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;250.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-inception-resnet-v2-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;251.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-faster-rcnn-inception-resnet-v2-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;252.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-efficientdet-d0-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;253.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-efficientdet-d1-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;254.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-efficientdet-d2-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;255.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-efficientdet-d3-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;256.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-efficientdet-d4-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;257.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-efficientdet-d5-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;258.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-retinanet-resnet50-v1-fpn-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;259.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-retinanet-resnet50-v1-fpn-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;260.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-retinanet-resnet101-v1-fpn-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;261.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-retinanet-resnet101-v1-fpn-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;262.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-retinanet-resnet152-v1-fpn-640x640-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;263.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-retinanet-resnet152-v1-fpn-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;264.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-hourglass-512x512-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;265.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-hourglass-512x512-kpts-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;266.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-hourglass-1024x1024-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;267.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-hourglass-1024x1024-kpts-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;268.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-resnet50v1-fpn-512x512-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;269.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-resnet50v1-fpn-512x512-kpts-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;270.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-resnet50v2-512x512-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;271.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-resnet50v2-512x512-kpts-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;272.&lt;/td&gt;&#xA;          &lt;td&gt;Object Detection&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-od-centernet-resnet101v1-fpn-512x512-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;273.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub  It takes a text string as input and classifies the input text as either a positive or negative movie review&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-bert-en-cased-L-12-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;274.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-bert-multi-cased-L-12-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;275.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-128-A-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;276.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;277.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-512-A-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;278.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is an Extractive Question Answering model built on a Transformer model from Hugging Face  It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-distilbert-base-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;279.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-distilbert-base-multilingual-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;280.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-base-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;281.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-base-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;282.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-base-multilingual-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;283.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub  It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&#39;&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-bert-en-cased-L-12-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;284.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-bert-multi-cased-L-12-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;285.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-bert-en-uncased-L-24-H-1024-A-16-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;286.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-electra-small-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;287.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-electra-base-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;288.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-distilbert-base-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;289.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-distilbert-base-multilingual-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;290.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-base-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;291.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-base-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;292.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-base-multilingual-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;293.&lt;/td&gt;&#xA;          &lt;td&gt;Named Entity Recognition&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Named Entity Generation model built upon a Transformer model from Hugging Face  It takes a text string as input and predicts named entities in the input text&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-ner-distilbert-base-uncased-finetuned-conll03-english&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;294.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration-bloom-1b1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;295.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration-bloom-560m&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;296.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration-gpt2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;297.&lt;/td&gt;&#xA;          &lt;td&gt;Text Generation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-textgeneration-distilgpt2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;298.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Summarization model built upon a Transformer model from Hugging Face  It takes a text string as input and returns a summary of the text&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-bert-small2bert-small-finetuned-cnn-daily-mail-summarization&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;299.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-distilbart-cnn-6-6&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;300.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-distilbart-xsum-12-3&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;301.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-distilbart-cnn-12-6&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;302.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-bart-large-cnn-samsum&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;303.&lt;/td&gt;&#xA;          &lt;td&gt;Machine Translation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Machine Translation model built upon a Transformer model from Hugging Face  It takes a text string as input and predicts its translation&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-translation-t5-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;304.&lt;/td&gt;&#xA;          &lt;td&gt;Machine Translation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-translation-t5-large&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;305.&lt;/td&gt;&#xA;          &lt;td&gt;Machine Translation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-translation-opus-mt-en-es&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;306.&lt;/td&gt;&#xA;          &lt;td&gt;Machine Translation&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-translation-opus-mt-en-vi&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;307.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Embedding model from TensorFlow Hub  It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-2-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;308.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-2-H-512-A-8-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;309.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-2-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;310.&lt;/td&gt;&#xA;          &lt;td&gt;Text to Image&lt;/td&gt;&#xA;          &lt;td&gt;Stabilityai&lt;/td&gt;&#xA;          &lt;td&gt;This is a text-to-image model from Stability AI and downloaded from HuggingFace  It takes a textual description as input and returns a generated image from the description&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: model-txt2img-stabilityai-stable-diffusion-v2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;311.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Embedding model from TensorFlow Hub  It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-4-H-128-A-2-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;312.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-4-H-256-A-4-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;313.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-tcembedding-robertafin-base-wiki-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;314.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-tcembedding-robertafin-large-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;315.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Mxnet&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: mxnet-tcembedding-robertafin-large-wiki-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;316.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Classification model built upon a Text Embedding model from TensorFlow Hub  It takes a text string as input and classifies the input text as either a positive or negative movie review&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-2-H-768-A-12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;317.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-128-A-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;318.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;319.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-512-A-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;320.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-4-H-768-A-12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;321.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-128-A-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;322.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;323.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-512-A-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;324.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-6-H-768-A-12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;325.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-128-A-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;326.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;327.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-512-A-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;328.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-8-H-768-A-12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;329.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-128-A-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;330.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;331.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-512-A-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;332.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-10-H-768-A-12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;333.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-128-A-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;334.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;335.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-512-A-8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;336.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-small-bert-bert-en-uncased-L-12-H-768-A-12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;337.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-bert-en-uncased-L-24-H-1024-A-16-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;338.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-bert-en-cased-L-24-H-1024-A-16-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;339.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-bert-en-wwm-uncased-L-24-H-1024-A-16-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;340.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-bert-en-wwm-cased-L-24-H-1024-A-16-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;341.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-albert-en-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;342.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-electra-small-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;343.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-electra-base-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;344.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-experts-bert-wiki-books-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;345.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-experts-bert-pubmed-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;346.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-talking-heads-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;347.&lt;/td&gt;&#xA;          &lt;td&gt;Text Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tc-talking-heads-large&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;348.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is an Extractive Question Answering model built on a Transformer model from Hugging Face  It takes two strings as inputs: the first string is a question and the second string is the context or any text you want to use to find the answer of the question, and it returns a sub-string from the context as an answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-base-multilingual-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;349.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-large-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;350.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-large-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;351.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-large-uncased-whole-word-masking&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;352.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-bert-large-cased-whole-word-masking&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;353.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-distilroberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;354.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-roberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;355.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-roberta-base-openai-detector&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;356.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-eqa-roberta-large&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;357.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Sentence Pair Classification model built upon a Text Embedding model from TensorFlow Hub  It takes a pair of sentences as input and classifies the input pair to &amp;rsquo;entailment&amp;rsquo; or &amp;rsquo;no-entailment&#39;&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-bert-en-wwm-uncased-L-24-H-1024-A-16-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;358.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-bert-en-wwm-cased-L-24-H-1024-A-16-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;359.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-experts-bert-wiki-books-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;360.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-spc-experts-bert-pubmed-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;361.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-base-multilingual-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;362.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-large-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;363.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-large-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;364.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-large-uncased-whole-word-masking&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;365.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-bert-large-cased-whole-word-masking&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;366.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-distilroberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;367.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-roberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;368.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-roberta-base-openai-detector&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;369.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-roberta-large&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;370.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-roberta-large-openai-detector&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;371.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-xlm-mlm-ende-1024&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;372.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-xlm-mlm-enro-1024&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;373.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-xlm-mlm-xnli15-1024&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;374.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-xlm-mlm-tlm-xnli15-1024&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;375.&lt;/td&gt;&#xA;          &lt;td&gt;Sentence Pair Classification&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-spc-xlm-clm-ende-1024&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;376.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Summarization model built upon a Transformer model from Hugging Face  It takes a text string as input and returns a summary of the text&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-bigbird-pegasus-large-arxiv&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;377.&lt;/td&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;Huggingface&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: huggingface-summarization-bigbird-pegasus-large-pubmed&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;378.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is a Text Embedding model from TensorFlow Hub  It takes a text string as input and outputs an embedding vector The Text Embedding model is pre-trained on Wikipedia and BookCorpus datasets&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-4-H-512-A-8-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;379.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-4-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;380.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-6-H-128-A-2-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;381.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-6-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;382.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-6-H-512-A-8-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;383.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-6-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;384.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-8-H-256-A-4-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;385.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-8-H-512-A-8-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;386.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-8-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;387.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-10-H-128-A-2-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;388.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-10-H-256-A-4-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;389.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-10-H-512-A-8-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;390.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-10-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;391.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-12-H-128-A-2-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;392.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-12-H-256-A-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;393.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-12-H-512-A-8-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;394.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;395.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-en-uncased-L-12-H-768-A-12-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;396.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-wiki-books-sst2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;397.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-bert-wiki-books-mnli-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;398.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-large-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;399.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-universal-sentence-encoder-cmlm-en-base-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;400.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-talkheads-ggelu-bert-en-base-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;401.&lt;/td&gt;&#xA;          &lt;td&gt;Text Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-tcembedding-talkheads-ggelu-bert-en-large-2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;402.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Classification&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is the LightGBM algorithm for tabular classification task  LightGBM is a gradient boosting framework that uses tree based learning algorithms&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: lightgbm-classification-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;403.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Classification&lt;/td&gt;&#xA;          &lt;td&gt;Catboost&lt;/td&gt;&#xA;          &lt;td&gt;This is the CatBoost algorithm for tabular classification task  CatBoost is a machine learning algorithm that uses gradient boosting on decision trees&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: catboost-classification-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;404.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Classification&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is the AutoGluon-Tabular algorithm for tabular classification task  AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: autogluon-classification-ensemble&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;405.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Classification&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is the TabTransformer algorithm for tabular classification task  TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-tabtransformerclassification-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;406.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Classification&lt;/td&gt;&#xA;          &lt;td&gt;Sklearn&lt;/td&gt;&#xA;          &lt;td&gt;This is the scikit-learn linear algorithm for tabular classification task  Linear Classification is a linear approach to classify data into labels (targets) based on a linear combination of its input features (predictors)&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: sklearn-classification-linear&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;407.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Classification&lt;/td&gt;&#xA;          &lt;td&gt;Xgboost&lt;/td&gt;&#xA;          &lt;td&gt;This is the XGBoost algorithm for tabular classification task  XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: xgboost-classification-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;408.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Regression&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is the LightGBM algorithm for tabular regression task  LightGBM is a gradient boosting framework that uses tree based learning algorithms&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: lightgbm-regression-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;409.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Regression&lt;/td&gt;&#xA;          &lt;td&gt;Catboost&lt;/td&gt;&#xA;          &lt;td&gt;This is the CatBoost algorithm for tabular regression task  CatBoost is a machine learning algorithm that uses gradient boosting on decision trees&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: catboost-regression-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;410.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Regression&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is the AutoGluon-Tabular algorithm for tabular regression task  AutoGluon-Tabular is an open-source AutoML framework that trains highly accurate machine learning models on an unprocessed tabular dataset Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection, AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: autogluon-regression-ensemble&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;411.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Regression&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is the TabTransformer algorithm for tabular regression task  TabTransformer is a deep tabular data modeling architecture that built upon self-attention based Transformers&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-tabtransformerregression-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;412.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Regression&lt;/td&gt;&#xA;          &lt;td&gt;Sklearn&lt;/td&gt;&#xA;          &lt;td&gt;This is the scikit-learn linear algorithm for tabular regression task  Linear Regression is a linear approach for modelling the relationship between a scalar response and one or more explanatory variables&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: sklearn-regression-linear&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;413.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular Regression&lt;/td&gt;&#xA;          &lt;td&gt;Xgboost&lt;/td&gt;&#xA;          &lt;td&gt;This is the XGBoost algorithm for tabular regression task  XGBoost is an optimized distributed gradient boosting library designed to be highly efficient, flexible and portable It implements machine learning algorithms under the Gradient Boosting framework&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: xgboost-regression-model&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;414.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-distilbert-base-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;415.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-large-uncased-whole-word-masking&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;416.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-large-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;417.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-large-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;418.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-roberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;419.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same as above&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-distilbert-base-multilingual-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;420.&lt;/td&gt;&#xA;          &lt;td&gt;Object detection&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Identify birds species in a scene using a SageMaker object detection model.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;421.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-distilroberta-base&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;422.&lt;/td&gt;&#xA;          &lt;td&gt;Audio Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an audio embedding model from Tensorflow Hub  It takes a wav (audio file format) file as input and outputs an embedding vector&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-audioembedding-trill-distilled-3&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;423.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-roberta-large-openai-detector&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;424.&lt;/td&gt;&#xA;          &lt;td&gt;Object detection&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Identify defective regions in product images either by training an object detection model from scratch or fine-tuning pretrained SageMaker models.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;425.&lt;/td&gt;&#xA;          &lt;td&gt;Audio Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an audio embedding model from Tensorflow Hub  It takes a wav (audio file format) file as input and outputs an embedding vector&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-audioembedding-trillsson2-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;426.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Automatically detect potentially fraudulent activity in transactions using SageMaker XGBoost with the over-sampling technique Synthetic Minority Over-sampling (SMOTE).&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;427.&lt;/td&gt;&#xA;          &lt;td&gt;Feature importance using shap&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;428.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-distilbert-base-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;429.&lt;/td&gt;&#xA;          &lt;td&gt;Graph neural network classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Detect fraud in financial transactions by training a graph convolutional network with the deep graph library and a SageMaker XGBoost model.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;430.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Classify financial payments based on transaction information using SageMaker XGBoost. Use this solution template as an intermediate step in fraud detection, personalization, or anomaly detection.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;431.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Identify unhappy mobile phone customers using SageMaker XGBoost.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;432.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-base-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;433.&lt;/td&gt;&#xA;          &lt;td&gt;RL&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Distributed reinforcement learning starter kit for NeurIPS 2020 Procgen Reinforcement learning challenge.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;434.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-large-cased-whole-word-masking-finetuned-squad&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;435.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;436.&lt;/td&gt;&#xA;          &lt;td&gt;RL&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;437.&lt;/td&gt;&#xA;          &lt;td&gt;Entity resolution&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;438.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;439.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular and text classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;440.&lt;/td&gt;&#xA;          &lt;td&gt;Text classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Anonymize text to better preserve user privacy in sentiment classification.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;441.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular, image, and text classification.&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;442.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;443.&lt;/td&gt;&#xA;          &lt;td&gt;Text to Image&lt;/td&gt;&#xA;          &lt;td&gt;Stabilityai&lt;/td&gt;&#xA;          &lt;td&gt;This is a text-to-image model from Stability AI and downloaded from HuggingFace  It takes a textual description as input and returns a generated image from the description&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: model-txt2img-stabilityai-stable-diffusion-v2-fp16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;444.&lt;/td&gt;&#xA;          &lt;td&gt;Text to Image&lt;/td&gt;&#xA;          &lt;td&gt;Stabilityai&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: model-txt2img-stabilityai-stable-diffusion-v1-4-fp16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;445.&lt;/td&gt;&#xA;          &lt;td&gt;ext to Image&lt;/td&gt;&#xA;          &lt;td&gt;Stabilityai&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: model-txt2img-stabilityai-stable-diffusion-v1-4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;446.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-base-multilingual-cased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;447.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-roberta-large&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;448.&lt;/td&gt;&#xA;          &lt;td&gt;Audio Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an audio embedding model from Tensorflow Hub  It takes a wav (audio file format) file as input and outputs an embedding vector&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-audioembedding-frill-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;449.&lt;/td&gt;&#xA;          &lt;td&gt;Audio Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-audioembedding-trillsson3-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;450.&lt;/td&gt;&#xA;          &lt;td&gt;Audio Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-audioembedding-trill-3&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;451.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular and text classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;452.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-roberta-base-openai-detector&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;453.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-large-cased-whole-word-masking&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;454.&lt;/td&gt;&#xA;          &lt;td&gt;Time series&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Demand forecasting for multivariate time series data using three state-of-the-art time series forecasting algorithms: LSTNet, Prophet, and SageMaker DeepAR.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;455.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;This is a Extractive Question Answering model built upon a Text Embedding model from PyTorch Hub  It takes as input a pair of question-context strings, and returns a sub-string from the context as a answer to the question&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-large-uncased-whole-word-masking-finetuned-squad&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;456.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-base-multilingual-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;457.&lt;/td&gt;&#xA;          &lt;td&gt;Question Answering&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Same&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: pytorch-eqa-bert-base-uncased&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;458.&lt;/td&gt;&#xA;          &lt;td&gt;Audio Embedding&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;          &lt;td&gt;This is an audio embedding model from Tensorflow Hub  It takes a wav (audio file format) file as input and outputs an embedding vector&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: tensorflow-audioembedding-trillsson1-1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;459.&lt;/td&gt;&#xA;          &lt;td&gt;Object detection&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;460.&lt;/td&gt;&#xA;          &lt;td&gt;Causal inference&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Generate a counterfactual analysis of corn response to nitrogen. This solution learns the crop phenology cycle in its entirety using multi-spectral satellite imagery and ground-level observations.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;461.&lt;/td&gt;&#xA;          &lt;td&gt;Price optimization&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Estimate price elasticity using Double Machine Learning (ML) for causal inference and the Prophet forecasting procedure. Use these estimates to optimize daily prices.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;462.&lt;/td&gt;&#xA;          &lt;td&gt;Tabular and text classification&lt;/td&gt;&#xA;          &lt;td&gt;SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;463.&lt;/td&gt;&#xA;          &lt;td&gt;Upscaling&lt;/td&gt;&#xA;          &lt;td&gt;Stabilityai&lt;/td&gt;&#xA;          &lt;td&gt;This is a upscaling model from Stability AI downloaded from HuggingFace with FP16 precision  Given a low resolution image and a textual prompt, it generates a higher resolution image with size up to four times the original image size&lt;/td&gt;&#xA;          &lt;td&gt;Model draft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: model-upscaling-stabilityai-stable-diffusion-x4-upscaler-fp16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aws.amazon.com/sagemaker/jumpstart/getting-started/&#34;&gt;https://aws.amazon.com/sagemaker/jumpstart/getting-started/&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;strong&gt;Author&lt;/strong&gt;&lt;br&gt;&#xA;Dr. Hari Thapliyaal&lt;br&gt;&#xA;dasarpai.com &lt;br&gt;&#xA;linkedin.com/in/harithapliyal&lt;/p&gt;</description>
    </item>
    <item>
      <title>Embedding with FastText</title>
      <link>http://localhost:1313/dsblog/Embedding-with-FastText/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Embedding-with-FastText/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6073-Embedding-with-FastText.jpg&#34; alt=&#34;Embedding with FastText&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;embedding-with-fasttext&#34;&gt;Embedding with FastText&lt;/h1&gt;&#xA;&lt;p&gt;&lt;a href=&#34;http://localhost:1313/dsblog/what-is-nlp#what-is-embedding&#34;&gt;What is Embedding?&lt;/a&gt; &lt;br&gt;&#xA;&lt;a href=&#34;http://localhost:1313/dsblog/what-is-nlp#what-are-different-embedding-types&#34;&gt;What are Different Types of Embedding&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-fasttext&#34;&gt;What is FastText?&lt;/h2&gt;&#xA;&lt;p&gt;FastText is an open-source library for efficient learning of word representations and sentence classification developed by Facebook AI Research. It is designed to handle large-scale text data and provides tools for &lt;strong&gt;training&lt;/strong&gt; and &lt;strong&gt;using word embeddings&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;p&gt;FastText is an extension of the popular Word2Vec model that not only learns word embeddings but also &lt;strong&gt;considers subword&lt;/strong&gt; information. It represents each word as a bag of character n-grams (subword units), which allows it to capture morphological variations and &lt;strong&gt;handle out-of-vocabulary&lt;/strong&gt; words more effectively.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Major LLM Developers Shaping the AI Landscape</title>
      <link>http://localhost:1313/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Major-LLM-Developers-Reshaping-NLP-Advancements/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6075-Major-LLM-Developers-Reshaping-NLP-Advancements.jpg&#34; alt=&#34;Major LLM Developers Shaping the AI Landscape&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;major-llm-developers-shaping-the-ai-landscape&#34;&gt;Major LLM Developers Shaping the AI Landscape&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;From Text to Intelligence: Major LLM Developers Shaping the AI Landscape&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction:&lt;/h2&gt;&#xA;&lt;p&gt;The world of Artificial Intelligence (AI) has experienced an exponential growth, fueled by groundbreaking research and the efforts of innovative developers. Among the key players, Large Language Model (LLM) developers have taken center stage, creating powerful language models that have revolutionized natural language processing and understanding. In this article, we delve into the major LLM developers, their key contributions.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Decorator Function</title>
      <link>http://localhost:1313/dsblog/Python-Decorator-Function/</link>
      <pubDate>Sat, 15 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Decorator-Function/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6074-Python-Decorator-Function.jpg&#34; alt=&#34;Python Decorator Function&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;python-decorator-function&#34;&gt;Python Decorator Function&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-decorator-function-in-python&#34;&gt;What is Decorator Function in Python&lt;/h2&gt;&#xA;&lt;p&gt;In Python, a decorator is a special type of function that allows you to modify or extend the behavior of other functions or methods. Decorators provide a convenient way to add functionality to functions without modifying their code directly. They are commonly used for tasks such as logging, authorization, caching, and more.&lt;/p&gt;&#xA;&lt;p&gt;A decorator function takes *&lt;em&gt;another function as an argument&lt;/em&gt;, adds some functionality to it, and returns a new function that includes the original function&amp;rsquo;s behavior along with the additional functionality.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Naming Convention</title>
      <link>http://localhost:1313/dsblog/Python-Naming-Convention/</link>
      <pubDate>Tue, 11 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Naming-Convention/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6072-Python-Naming-Convention.jpg&#34; alt=&#34;Python Naming Convention&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;python-naming-convention&#34;&gt;Python Naming Convention&lt;/h1&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;UPPERCASE / UPPER_CASE_WITH_UNDERSCORES =&amp;gt; module-level constants&lt;/li&gt;&#xA;&lt;li&gt;lowercase / lower_case_with_underscores =&amp;gt; for variable and function name.&lt;/li&gt;&#xA;&lt;li&gt;CapitalizedWords (or CapWords, or CamelCase – so named because of the bumpy look of its letters [4]). This is also sometimes known as StudlyCaps. =&amp;gt; CamelCase =&amp;gt; Class&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Note: When using acronyms in CapWords, capitalize all the letters of the acronym. Thus HTTPServerError is better than HttpServerError.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;mixedCase (differs from CapitalizedWords by initial lowercase character!)&lt;/li&gt;&#xA;&lt;li&gt;Capitalized_Words_With_Underscores (ugly!)&lt;/li&gt;&#xA;&lt;li&gt;_single_leading_underscore: weak “internal use” indicator. E.g. from M import * does not import objects whose names start with an underscore.&lt;/li&gt;&#xA;&lt;li&gt;single_trailing_underscore_: used by convention to avoid conflicts with Python keyword, e.g.&#xA;tkinter.Toplevel(master, class_=&amp;lsquo;ClassName&amp;rsquo;)&lt;/li&gt;&#xA;&lt;li&gt;__double_leading_underscore: when naming a class attribute, invokes name mangling (inside class FooBar, __boo becomes _FooBar__boo; see below).&lt;/li&gt;&#xA;&lt;li&gt;_&lt;em&gt;double_leading_and_trailing_underscore&lt;/em&gt;_: “magic” objects or attributes that live in user-controlled namespaces. E.g. _&lt;em&gt;init&lt;/em&gt;_, _&lt;em&gt;import&lt;/em&gt;_ or _&lt;em&gt;file&lt;/em&gt;_. Never invent such names; only use them as documented.&lt;/li&gt;&#xA;&lt;li&gt;Never use the characters ‘l’ (lowercase letter el), ‘O’ (uppercase letter oh), or ‘I’ (uppercase letter eye) as single character variable names.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h1 id=&#34;programming-recommendations&#34;&gt;Programming Recommendations&lt;/h1&gt;&#xA;&lt;h2 id=&#34;use-is-not-operator&#34;&gt;Use &amp;ldquo;is not&amp;rdquo; operator&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correct:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; foo &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Wrong:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; &lt;span style=&#34;color:#f92672&#34;&gt;not&lt;/span&gt; foo &lt;span style=&#34;color:#f92672&#34;&gt;is&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;always-use-a-def-statement&#34;&gt;Always use a def statement&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correct:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;f&lt;/span&gt;(x): &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Wrong:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;f &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;lambda&lt;/span&gt; x: &lt;span style=&#34;color:#ae81ff&#34;&gt;2&lt;/span&gt;&lt;span style=&#34;color:#f92672&#34;&gt;*&lt;/span&gt;x&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;all-tryexcept-clauses&#34;&gt;all try/except clauses&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correct:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    value &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; collection[key]&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;KeyError&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; key_not_found(key)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; handle_value(value)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Wrong:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;try&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Too broad!&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; handle_value(collection[key])&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;except&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;KeyError&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#75715e&#34;&gt;# Will also catch KeyError raised by handle_value()&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; key_not_found(key)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;context-managers-should-be-invoked-through-separate-functions-or-methods&#34;&gt;Context managers should be invoked through separate functions or methods&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correct:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; conn&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;begin_transaction():&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    do_stuff_in_transaction(conn)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Wrong:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;with&lt;/span&gt; conn:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    do_stuff_in_transaction(conn)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;be-consistent-in-return-statements&#34;&gt;Be consistent in return statements&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correct:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foo&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(x)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;else&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; &lt;span style=&#34;color:#66d9ef&#34;&gt;None&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(x)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;ul&gt;&#xA;&lt;li&gt;Wrong:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-python&#34; data-lang=&#34;python&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;foo&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;=&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(x)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;def&lt;/span&gt; &lt;span style=&#34;color:#a6e22e&#34;&gt;bar&lt;/span&gt;(x):&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;if&lt;/span&gt; x &lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt; &lt;span style=&#34;color:#ae81ff&#34;&gt;0&lt;/span&gt;:&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;        &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt;&#xA;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;    &lt;span style=&#34;color:#66d9ef&#34;&gt;return&lt;/span&gt; math&lt;span style=&#34;color:#f92672&#34;&gt;.&lt;/span&gt;sqrt(x)&#xA;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id=&#34;startswith-endswith&#34;&gt;startswith, endswith&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Use &amp;lsquo;&amp;rsquo;.startswith() and &amp;lsquo;&amp;rsquo;.endswith() instead of string slicing to check for prefixes or suffixes.&lt;/li&gt;&#xA;&lt;li&gt;Correct:&#xA;if foo.startswith(&amp;lsquo;bar&amp;rsquo;):&lt;/li&gt;&#xA;&lt;li&gt;Wrong:&#xA;if foo[:3] == &amp;lsquo;bar&amp;rsquo;:&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;object-type-comparisons&#34;&gt;Object type comparisons&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Correct:&#xA;if isinstance(obj, int):&lt;/li&gt;&#xA;&lt;li&gt;Wrong:&#xA;if type(obj) is type(1):&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;sequences-strings-lists-tuples&#34;&gt;Sequences, (strings, lists, tuples)&lt;/h2&gt;&#xA;&lt;p&gt;-For sequences, (strings, lists, tuples), use the fact that empty sequences are false:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Sorting Algorithm A Summary</title>
      <link>http://localhost:1313/dsblog/Sorting-Algorithm-A-Summary/</link>
      <pubDate>Mon, 10 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Sorting-Algorithm-A-Summary/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6071-Sorting-Algorithm-A-Summary.jpg&#34; alt=&#34;Sorting Algorithm A Summary&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;sorting-algorithm-a-summary&#34;&gt;Sorting Algorithm A Summary&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Sorting is a fundamental operation in computer science and plays a vital role in various applications. Whether it&amp;rsquo;s organizing data, searching for specific elements efficiently, or preparing data for further processing, sorting algorithms provide the necessary tools to bring order to chaos. With a wide range of sorting techniques available, each with its own strengths and weaknesses, it is essential to understand their principles, time complexities, and trade-offs.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is CAPTCHA?</title>
      <link>http://localhost:1313/dsblog/What-is-Captcha/</link>
      <pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-Captcha/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6070-What-is-Captcha.jpg&#34; alt=&#34;What is CAPTCHA?&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-captcha&#34;&gt;What is CAPTCHA?&lt;/h1&gt;&#xA;&lt;p&gt;CAPTCHA stands for &amp;ldquo;Completely Automated Public Turing test to tell Computers and Humans Apart.&amp;rdquo; It is a security mechanism used by websites to determine whether the user is a human or a computer program (bot). CAPTCHAs are typically implemented as tests or challenges presented to the user, which are easy for humans to solve but difficult for bots.&lt;/p&gt;&#xA;&lt;p&gt;The purpose of CAPTCHA is to prevent automated bots from performing actions that are intended for human users, such as &lt;strong&gt;creating accounts, submitting forms, or accessing restricted content&lt;/strong&gt;. By requiring users to complete a CAPTCHA, websites can verify their humanity and protect against &lt;strong&gt;spam, brute-force attacks, data scraping, and other malicious activities&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is GAN Architecture?</title>
      <link>http://localhost:1313/dsblog/What-is-GAN-Architecture/</link>
      <pubDate>Mon, 03 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-GAN-Architecture/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6069-What-is-GAN-Architecture.jpg&#34; alt=&#34;What is GAN Architecture?&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-gan-architecture&#34;&gt;What is GAN Architecture?&lt;/h1&gt;&#xA;&lt;p&gt;Generative Adversarial Networks (GANs) are a powerful class of neural networks that are used for unsupervised learning. It was developed and introduced by Ian J. Goodfellow in 2014. It is a type of artificial intelligence (AI) model that consists of two neural networks: a generator and a discriminator. GANs are used for generative tasks, such as creating realistic images, videos, or even audio.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Guide to Model Fine Tuning with OpenAI API</title>
      <link>http://localhost:1313/dsblog/Model-Fine-Tuning-with-OpenAI-API/</link>
      <pubDate>Sun, 02 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Model-Fine-Tuning-with-OpenAI-API/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6068-A-Guide-to-Model-Fine-Tuning-with-OpenAI-API.jpg&#34; alt=&#34;A Guide to Model Fine Tuning with OpenAI API&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;a-guide-to-model-fine-tuning-with-openai-api&#34;&gt;A Guide to Model Fine Tuning with OpenAI API&lt;/h1&gt;&#xA;&lt;h2 id=&#34;account-setup-and-api-key-generation&#34;&gt;Account Setup and API Key Generation&lt;/h2&gt;&#xA;&lt;p&gt;Go to &lt;a href=&#34;https://platform.openai.com/&#34;&gt;openai&lt;/a&gt;, sign up there and create your account. After than you need to create an API using &lt;a href=&#34;https://platform.openai.com/account/api-keys&#34;&gt;API Key Link&lt;/a&gt;. You need to copy the api key and you replace the text below &amp;lt;OPENAI_API_KEY&amp;gt;. Being string the key should be within &amp;ldquo;&amp;rdquo;. Keeping security in mind it is highly recommended that you do not put the API in the code file. Keep it at some secured place and read that file to fetch the API key. OpenAI gives you USD 5 free usage. After that you need to pay. For that you need to setup your credit card details on their system. They are very fair on the charges, just keep track of your usage. If you don&amp;rsquo;t use any of their service they won&amp;rsquo;t charge anything for just having account with them. While doing any model finetuning or prediction openai tells you how much they will charge you for that particular command. My suggestion is if you are just experimenting then keep your dataset small so that you can manage your learning with USD 10-20.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Capabilities of AI Transformers</title>
      <link>http://localhost:1313/dsblog/Capabilities-of-AI-Transformers/</link>
      <pubDate>Sat, 01 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Capabilities-of-AI-Transformers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6067-Capabilities-of-AI-Transformers.jpg&#34; alt=&#34;Capabilities of AI Transformers&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;capabilities-of-ai-transformers&#34;&gt;Capabilities of AI Transformers&lt;/h1&gt;&#xA;&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;&#xA;&lt;p&gt;Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Model Garden of VertexAI</title>
      <link>http://localhost:1313/dsblog/Model-Garden-of-VertexAI/</link>
      <pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Model-Garden-of-VertexAI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6065-Model-Garden-of-VertexAI.jpg&#34; alt=&#34;All Resources to Learn Data Science&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;model-garden-of-vertexai&#34;&gt;Model Garden of VertexAI:&lt;/h1&gt;&#xA;&lt;h2 id=&#34;unlocking-the-power-of-googles-vertexai-exploring-the-world-of-pre-built-models-for-ai-tasks&#34;&gt;Unlocking the Power of Google&amp;rsquo;s VertexAI: Exploring the World of Pre-Built Models for AI Tasks&lt;/h2&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction:&lt;/h2&gt;&#xA;&lt;p&gt;Artificial Intelligence (AI) has transformed numerous industries, from healthcare and finance to e-commerce, logistic, eduction and entertainment. But the complexity of developing machine learning models often poses a challenge. As the demand for AI-powered solutions continues to rise, data scientists seek efficient ways to leverage pre-trained models or build custom models to address specific tasks. In this regard, Google&amp;rsquo;s VertexAI emerges as a robust platform that offers an extensive selection of pre-built models for a wide range of AI tasks. VertexAI platform has revolutionized the landscape by seamlessly leveraging LLM (Large Language Models) and Prompt Engineering techniques to perform complex machine learning tasks effortlessly. With VertexAI, data scientists can harness the power of state-of-the-art language models, such as LLM, to accelerate their ML development process. Additionally, the innovative concept of Prompt Engineering enables users to effectively communicate with the models, guiding them to deliver precise and accurate results. From computer vision and natural language processing to speech processing and structured tabular data analysis, Vertex AI&amp;rsquo;s repertoire includes over 100 models catering to diverse application domains. This article explores how Vertex AI, through its integration of LLM and Prompt Engineering, empowers users to effortlessly tackle intricate machine learning tasks across diverse domains, revolutionizing the AI development experience.&lt;/p&gt;</description>
    </item>
    <item>
      <title>All Resources to Learn Data Science</title>
      <link>http://localhost:1313/dsblog/all-resources-to-learn-data-science/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/all-resources-to-learn-data-science/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6064-Resources-to-Learn-Everything-About-AI.jpg&#34; alt=&#34;All Resources to Learn Data Science&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;all-resources-to-learn-data-science&#34;&gt;All Resources to Learn Data Science&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Welcome to the AI ML Resources category page, where you&amp;rsquo;ll find a wealth of knowledge on various topics related to Artificial Intelligence (AI), Machine Learning (ML), Deep Learning (DL), Natural Language Processing (NLP), Mathematics and statistics required to learn Data Science. Each of the pages mentioned below brings together a wide range of articles, tutorials, and guides that delve into the fascinating world of AI and ML. Whether you&amp;rsquo;re a beginner seeking foundational knowledge or an experienced practitioner looking to expand your skills, these resources offer valuable insights and practical guidance. You need to go through these links one at time. As a master page you can book mark this page.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Demystifying DevOps, MLOps, and DataOps</title>
      <link>http://localhost:1313/dsblog/Demystifying-DevOps-MLOps-and-DataOps/</link>
      <pubDate>Thu, 08 Jun 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Demystifying-DevOps-MLOps-and-DataOps/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6066-Demystifying-DevOps-MLOps-and-DataOps.jpg&#34; alt=&#34;All Resources to Learn Data Science&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;demystifying-devops-mlops-and-dataops&#34;&gt;Demystifying DevOps, MLOps, and DataOps:&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Bridging the Gap between Software Development, Machine Learning, and Data Managemen&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h2 id=&#34;what-is-devops&#34;&gt;What is DevOps&lt;/h2&gt;&#xA;&lt;p&gt;DevOps, short for Development and Operations, is a set of practices, principles, and cultural philosophies that aim to improve collaboration and efficiency between software development teams and IT operations teams. It emphasizes the integration of software development and IT operations, breaking down traditional silos and fostering a collaborative approach throughout the entire software delivery lifecycle.&lt;/p&gt;</description>
    </item>
    <item>
      <title>A Comprehensive Guide to 210&#43; AWS Services</title>
      <link>http://localhost:1313/dsblog/AWS-Cloud-Service-Catalog/</link>
      <pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AWS-Cloud-Service-Catalog/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6063-AWS-Cloud-Service-Catalog.jpg&#34; alt=&#34;AWS Cloud Service Catalog&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;a-comprehensive-guide-to-210-aws-services&#34;&gt;A Comprehensive Guide to 210+ AWS Services&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Exploring 210+ Cloud Services and Their Purposes&lt;/strong&gt;&lt;br&gt;&#xA;All these services are availalbe at &lt;a href=&#34;https://us-east-1.console.aws.amazon.com/console/services?region=us-east-1&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Amazon Web Services (AWS) is a suite of cloud computing services that runs on the same infrastructure that Amazon uses for its e-commerce website. AWS offers a broad set of global compute, storage, database, AI, analytics, application, and deployment services that help organizations move faster, lower IT costs, and scale applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unlocking the Power of Azure- Exploring 300&#43; Cloud Services and Their Purposes</title>
      <link>http://localhost:1313/dsblog/Azure-Cloud-Service-Catalog/</link>
      <pubDate>Tue, 06 Jun 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Azure-Cloud-Service-Catalog/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6062-Azure-Cloud-Service-Catalog.jpg&#34; alt=&#34;Azure Cloud Service Catalog:&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;unlocking-the-power-of-azure&#34;&gt;Unlocking the Power of Azure&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Exploring 300+ Cloud Services and Their Purposes&lt;/strong&gt;&lt;br&gt;&#xA;All these services are availalbe at &lt;a href=&#34;https://azure.microsoft.com/en-in/products/&#34;&gt;Link:&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Embracing the cloud has become an integral part of modern businesses, and Microsoft Azure stands out as a leading player in the realm of cloud computing. With a staggering portfolio of over 300+ cloud services, Azure offers a rich and diverse ecosystem to meet the ever-evolving needs of organizations across the globe. However, navigating through this extensive array of services can be a daunting task, as it is often challenging to grasp the purpose and potential of each offering. In this comprehensive guide, we aim to unravel the mysteries of Azure and shed light on the vast landscape of its cloud services. Join me on a journey of discovery as we explore, demystify, and showcase the range of Azure&amp;rsquo;s offerings, empowering you to make informed decisions and harness the full power of the Azure.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google Cloud Service Catalog - A Comprehensive Overview of 250&#43; Google Cloud Services</title>
      <link>http://localhost:1313/dsblog/Google-Cloud-Service-Catalog/</link>
      <pubDate>Mon, 05 Jun 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Google-Cloud-Service-Catalog/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6061-Google-Cloud-Service-Catalog.jpg&#34; alt=&#34;Google Cloud Service Catalog&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;google-cloud-service-catalog&#34;&gt;Google Cloud Service Catalog&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;A Comprehensive Overview of 250+ Google Cloud Services&lt;/strong&gt;&lt;br&gt;&#xA;All these services are availalbe at &lt;a href=&#34;https://cloud.google.com&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In the ever-evolving landscape of cloud computing, Google Cloud entered recently compare to AWS and Azure. But it stands out as a prominent player, offering a vast array of services and solutions to empower businesses and developers. With over 250+ services available, navigating the expansive Google Cloud ecosystem can be a daunting task. However, understanding these services and their functionalities is crucial for harnessing the full potential of the platform and provide the right technical solution of any business problem. In this comprehensive guide, I will take you through the diverse landscape of Google Cloud services, shedding light on their purposes. Whether you are a seasoned cloud professional or new to the Google Cloud environment, this article aims to demystify the complexity and provide you with valuable insights into the extensive toolkit Google Cloud has to offer. You can bookmark this page for future reference.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Unraveling the Google Web - Exploring the Purpose of Google&#39;s Websites</title>
      <link>http://localhost:1313/dsblog/Unraveling-the-Google-Web/</link>
      <pubDate>Sun, 04 Jun 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Unraveling-the-Google-Web/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6060-Unraveling-the-Google-Web.jpg&#34; alt=&#34;Unraveling the Google Web Exploring the Purpose of Google’s Websites&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;unraveling-the-google-web-exploring-the-purpose-of-googles-websites&#34;&gt;Unraveling the Google Web Exploring the Purpose of Google&amp;rsquo;s Websites&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;introduction&lt;/h2&gt;&#xA;&lt;p&gt;Google has become synonym of search. Therefore when you want to search something you say google it. But, we need to keep in mind google is not only about search. It offers hundreds of other products and services. In today&amp;rsquo;s digital era, Google has become an integral part of our lives, serving as a gateway to vast amounts of information and a wide array of products and services. As we navigate the vast expanse of the internet, we encounter numerous websites under the Google umbrella, each with its unique purpose and role. From search engines to productivity tools, advertising platforms to educational resources, Google offers a diverse range of websites that cater to different needs and interests. In this article, we embark on a journey to unravel the Google web and delve into the purpose of its various websites. Whether you&amp;rsquo;re a curious user seeking to understand the different facets of Google or a digital enthusiast looking to explore new horizons, join us as we uncover the hidden gems and shed light on the myriad of Google websites that shape our online experiences.&lt;/p&gt;</description>
    </item>
    <item>
      <title>God Fathers of AI</title>
      <link>http://localhost:1313/dsblog/God-Fathers-of-AI/</link>
      <pubDate>Fri, 05 May 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/God-Fathers-of-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6058-God-Fathers-of-AI.jpg&#34; alt=&#34;God Fathers of AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;god-fathers-of-ai&#34;&gt;God Fathers of AI&lt;/h1&gt;&#xA;&lt;p&gt;In other fields of studies or in religion, there is only one god or only one godfather. But in the field of AI, that is not the case. There are many pioneers or Godfathers who have done significant work in this field. Recently, the resignation of Dr. Geoffrey Hinton from Google raised eyebrows in the business world and in Governments the world over. Technology is good or bad, it depends upon whose hand it is. Geoffrey raised that concern and for that, he wants better controls in place. What will happen, we need to follow the progress and raise our voices around. In this article, I am mentioning some godfathers of AI, their workplaces, and their contributions. I am sure this will inspire many young minds.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Business Usecases of GPT</title>
      <link>http://localhost:1313/dsblog/Business-Usecases-of-GPT/</link>
      <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Business-Usecases-of-GPT/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6059-Business-Usecases-of-GPT.jpg&#34; alt=&#34;Application of GPT&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;business-usecases-of-gpt&#34;&gt;Business-Usecases-of-GPT&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;You will not lose your job because of AI, but you may lose it because you didn&amp;rsquo;t learn how to use AI in your job.&lt;/p&gt;&#xA;&lt;p&gt;Artificial Intelligence (AI) has become increasingly prevalent in the modern workplace, and one of the most promising applications of AI is the use of Generative Pre-trained Transformer (GPT) models. GPT is a type of deep learning model that is capable of generating human-like text based on a given prompt. It has been used in a wide range of applications, from language translation and sentiment analysis to chatbots and content generation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Interconnectedness of Life and Data</title>
      <link>http://localhost:1313/dsblog/File-Formats-in-Machine-Learning/</link>
      <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/File-Formats-in-Machine-Learning/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6057-The-Interconnectedness-of-Life-and-Data.jpg&#34; alt=&#34;The Interconnectedness of Life and Data&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;the-interconnectedness-of-life-and-data&#34;&gt;The Interconnectedness of Life and Data&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;While reading below keep your mind open. If you can keep your religious or even scientific information aside it would help you understand my thoughts. For many of you these may be hard ideas to digest, therefore reading multiple times and thinking over again and again will help.&lt;/p&gt;&#xA;&lt;p&gt;Life, consciousness, intelligence, force, energy, work, power, information, data, and time are highly interconnected ideas. They are so much connected, sometimes it looks difficult to define one without the other.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Types of Machine Learning</title>
      <link>http://localhost:1313/dsblog/Types-of-Machine-Learning/</link>
      <pubDate>Thu, 27 Apr 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Types-of-Machine-Learning/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6056-Types-of-Machine-Learning.jpg&#34; alt=&#34;Types of Machine Learning&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;types-of-machine-learning&#34;&gt;Types of Machine Learning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Machine learning is a field of artificial intelligence that focuses on developing algorithms that can learn from data and make predictions or decisions. There are several types of machine learning techniques, each with its strengths and weaknesses. In this post, we will explore some of the most commonly used machine learning techniques, including supervised learning, unsupervised learning, reinforcement learning, and more. This post is not about deep diving into these topics but to give you a oneliner understanding and the difference between these different techniques.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linux OS Directories</title>
      <link>http://localhost:1313/dsblog/Linux-OS-Directories/</link>
      <pubDate>Wed, 26 Apr 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Linux-OS-Directories/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6055-Linux-OS-Directories.jpg&#34; alt=&#34;Linux OS Directories&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;linux-os-directories&#34;&gt;Linux OS Directories&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Linux OS Folders and the purpose.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction:&lt;/h2&gt;&#xA;&lt;p&gt;Linux is a widely used operating system that is known for its flexibility and versatility. One of the unique features of Linux is its file system hierarchy, which is organized into a many directories that serve specific purposes. Folder structure of Unix OS and all distributions of Linux is same. Each directory has its own set of files and subdirectories that are used to manage various aspects of the operating system and data folders.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Types of Technologies</title>
      <link>http://localhost:1313/dsblog/Types-of-Technologies/</link>
      <pubDate>Fri, 24 Feb 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Types-of-Technologies/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6052-Types-of-Technologies.jpg&#34; alt=&#34;Types of Technologies&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;how-many-types-of-technologies&#34;&gt;How Many Types of Technologies?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Often we hear various jargon of different types of technologies and sometimes during the discussion, it becomes a mouthful of technologies to digest the meaning of these. Many times these technologies are overlapping each other but the speaker mentions that in a certain context. Today I thought let me list the possible technologies which we hear about very frequently. Nowadays AI balloon is flying everywhere and all over, it is impacting our society, business, government, social behavior, lifestyle, and whatnot. In light of this, we find many new technologies are popping up or modifying the way of doing existing businesses. In the interest of brevity, I am keeping a one-liner kind of definition. In the coming time, based on the need I will expand on each topic. Each technology mentioned below deserves a full-length article to understand the possibilities around that and its impact on our businesses, societies, etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cognitive Biases</title>
      <link>http://localhost:1313/dsblog/cognitive-biases/</link>
      <pubDate>Wed, 22 Feb 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/cognitive-biases/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6051-Cognitive-Biases.jpg&#34; alt=&#34;Cognitive Bias&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;cognitive-biases&#34;&gt;Cognitive Biases&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Cognitive biases are the systematic errors that occur when individuals deviate from rational decision-making. These biases are a result of our brain&amp;rsquo;s ability to process information, which can sometimes lead to irrational thinking and decision-making. As data science continues to advance, it is critical to understand how cognitive biases can impact AI, ML, NLP, deep learning, and robotics. Cognitive biases can lead to biased data collection, modeling, and decision-making processes, which can ultimately impact the accuracy and effectiveness of these technologies.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Podcast Lex Fridman Sam Harris Consciousness Free Will Psychedelics</title>
      <link>http://localhost:1313/dsblog/Podcast-LexFridman-SamHarris-Consciousness-FreeWill-Psychedelics/</link>
      <pubDate>Tue, 07 Feb 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Podcast-LexFridman-SamHarris-Consciousness-FreeWill-Psychedelics/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6050-Podcast-LexFridman-SamHarris-Consciousness-FreeWill-Psychedelics.jpg&#34; alt=&#34;Postcast Lex Fridman Sam Harris Consciousness FreeWill Psychedelics&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;podcast-summary-lex-fridman-sam-harris-consciousness-free-will-psychedelics&#34;&gt;Podcast Summary: Lex Fridman Sam Harris Consciousness Free Will Psychedelics&lt;/h1&gt;&#xA;&lt;p&gt;This is an interesting and deepdive discussion between &lt;a href=&#34;https://en.wikipedia.org/wiki/Lex_Fridman&#34;&gt;Lex Fridman&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Sam_Harris&#34;&gt;Sam Harris&lt;/a&gt;. In 3 hours 20 minute enchanting discussion they explore various topics like Consciousness, Free Will, Psychedelics, AI, UFOs etc.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Title: Sam Harris-: Consciousness, Free Will, Psychedelics, AI, UFOs, and Meaning / Lex Fridman Podcast #185&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;If you have time and you are intersted in this kind of deep discussion you can watch the video at the following link. &lt;a href=&#34;https://www.youtube.com/watch?v=4dC_nRYIDZU&#34;&gt;3 Hours 19 Minutes Full Podcast&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Books on Consciousness</title>
      <link>http://localhost:1313/dsblog/Books-on-Conciousness/</link>
      <pubDate>Mon, 06 Feb 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Books-on-Conciousness/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6049-Books-on-Conciousness.jpg&#34; alt=&#34;Books-on-Conciousness&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;books-on-consciousness&#34;&gt;Books on Consciousness&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;If you are from the software industry and especially in a data scientist role on day to day basis. Then there are high chances you ask questions like&lt;/p&gt;&#xA;&lt;p&gt;What is life?&lt;br&gt;&#xA;What is consciousness?&lt;br&gt;&#xA;What is the reality of existence?&lt;br&gt;&#xA;What is the final definition of God?&lt;br&gt;&#xA;What is the ultimate reality of this world?&lt;/p&gt;&#xA;&lt;p&gt;I am not saying you ask these questions because you are fed up or puzzled with your life. But because of different reasons. You are creating artificial intelligence systems.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Responsible AI</title>
      <link>http://localhost:1313/dsblog/Responsible-AI/</link>
      <pubDate>Fri, 03 Feb 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Responsible-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6047-Responsible-AI.jpg&#34; alt=&#34;Responsible-AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;responsible-ai&#34;&gt;Responsible AI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction:&lt;/h2&gt;&#xA;&lt;p&gt;Artificial Intelligence (AI) is rapidly transforming the way we live, work, and interact with the world around us. As AI systems become increasingly sophisticated and ubiquitous, it is more important than ever to ensure that they are developed and deployed in a responsible and ethical manner. Responsible AI refers to the principles and practices of developing and using AI in a way that is safe, transparent, accountable, and aligned with human values. In this blog post, we will explore the different aspects of responsible AI, including ethics, safety, transparency, accountability, and societal impact.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Cost Functions and Optimizers in Machine Learning</title>
      <link>http://localhost:1313/dsblog/Cost-Functions-and-Optimizers-in-Machine-Learning/</link>
      <pubDate>Wed, 01 Feb 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Cost-Functions-and-Optimizers-in-Machine-Learning/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6045-Cost-Functions-and-Optimizers-in-Machine-Learning.jpg&#34; alt=&#34;Cost-Functions-and-Optimizers-in-Machine-Learning&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;cost-functions-and-optimizers-in-machine-learning&#34;&gt;Cost-Functions-and-Optimizers-in-Machine-Learning&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-machine-learning&#34;&gt;What is machine learning?&lt;/h2&gt;&#xA;&lt;p&gt;Machine learning is a subfield of artificial intelligence that focuses on the &lt;strong&gt;development of algorithms and statistical models&lt;/strong&gt; that enable computers to improve their performance on a specific task through experience.&lt;/p&gt;&#xA;&lt;p&gt;In machine learning, the goal is to develop models that can &lt;strong&gt;automatically learn patterns and relationships in data, and use that knowledge to make predictions or take actions&lt;/strong&gt;. The models are trained on a large dataset, and the learning process involves &lt;strong&gt;optimizing the parameters of the model to minimize the prediction error&lt;/strong&gt;. For this purpose every algorithms uses some &lt;strong&gt;cost function or loss function&lt;/strong&gt;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Application of AI in BFSI</title>
      <link>http://localhost:1313/dsblog/Application-of-AI-in-BFSI/</link>
      <pubDate>Sat, 28 Jan 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Application-of-AI-in-BFSI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6048-Application-of-AI-in-BFSI.jpg&#34; alt=&#34;Application-of-AI-in-BFSI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;application-of-ai-in-banking-finance-security-and-insurance-bfsi&#34;&gt;Application of AI in Banking, Finance, Security and Insurance (BFSI)&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The banking, financial services, and insurance (BFSI) sector has been at the forefront of adopting cutting-edge technology to streamline operations, improve customer experience, and reduce costs. Machine learning (ML) has been one of the most promising technologies in this regard, offering numerous opportunities to automate manual processes, make accurate predictions, and provide real-time insights. ML algorithms can be used to analyze vast amounts of customer and transactional data, providing insights into customer behavior, fraud detection, and more. The implementation of ML in BFSI has been helping organizations to drive operational efficiency, reduce costs, and stay ahead of the competition.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPU for Data Science Work</title>
      <link>http://localhost:1313/dsblog/GPU-for-Data-Science-Work/</link>
      <pubDate>Thu, 26 Jan 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/GPU-for-Data-Science-Work/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6042-GPU-for-Data-Science-Work.jpg&#34; alt=&#34;GPU for Data Science Work&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;gpu-for-data-science-work&#34;&gt;GPU for Data Science Work&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-the-difference-between-microprocessor-cpu-and-gpu&#34;&gt;What is the difference between microprocessor (CPU) and GPU?&lt;/h2&gt;&#xA;&lt;p&gt;A microprocessor and a GPU (graphics processing unit) are both types of processors, but they are designed for different purposes and have different architectures.&lt;/p&gt;&#xA;&lt;p&gt;A microprocessor, also known as a CPU (central processing unit), is the &amp;ldquo;brain&amp;rdquo; of a computer. It is responsible for executing instructions for the operating system and software applications. A microprocessor typically has a small number of cores (1-16) that are optimized for sequential processing, and it is designed to handle a wide variety of tasks, from simple mathematical calculations to complex algorithms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Lake vs Data Warehouse vs Data Mart</title>
      <link>http://localhost:1313/dsblog/Datalake-vs-Data-Warehouse/</link>
      <pubDate>Wed, 25 Jan 2023 08:33:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Datalake-vs-Data-Warehouse/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6040-Datalake-vs-Data-Warehouse.jpg&#34; alt=&#34;Datalake vs Data Warehouse&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-the-difference-between-data-lake-and-data-warehouse&#34;&gt;What is the difference between Data Lake and Data Warehouse?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A data warehouse is a system used for reporting and data analysis, and is considered a &amp;ldquo;single version of the truth.&amp;rdquo; It typically includes a subset of an organization&amp;rsquo;s data that is specifically structured for querying and reporting. A data lake, on the other hand, is a more flexible and general-purpose system for storing raw, unstructured data. Data in a lake can be stored in its original format and can be used for a variety of purposes, including reporting and analysis. Data warehouse is more structured while data lake is unstructured. Data warehouse is optimized for reporting and analytics while data lake is optimized for storing and processing large amount of raw data.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Type of Databases</title>
      <link>http://localhost:1313/dsblog/Type-of-Databases/</link>
      <pubDate>Wed, 25 Jan 2023 08:33:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Type-of-Databases/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6041-Type-of-Databases.jpg&#34; alt=&#34;Type of Databases&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-are-the-various-types-of-databases&#34;&gt;What are the various types of databases?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In the 21st Century, Data is the real oil of machines. There are different kinds of oils and there are different kinds of containers. Similarly, there are different kinds of data and there are different kinds of database software to manage these databases. Broadly we call them SQL and NoSQL databases. But In the NoSQL, there are some other finer groups for specific purposes. Let&amp;rsquo;s look into these.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Usecases in Agriculture Industry</title>
      <link>http://localhost:1313/dsblog/AI-usecases-in-Agriculture-Industry/</link>
      <pubDate>Mon, 23 Jan 2023 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-usecases-in-Agriculture-Industry/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6037-AI-usecases-in-Agriculture-Industry.jpg&#34; alt=&#34;AI Usecases in Agriculture Industry&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-usecases-in-agriculture-industry&#34;&gt;AI Usecases in Agriculture Industry&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In the today world where energy saving, climate change, cost and process optimization, effectiveness is the philosophy of all business activities. With ever-increasing demand of food, the agriculture industry is looking for ways to improve crop yields and optimize farming practices. The use of Artificial Intelligence (AI) in agriculture is proving to be a game-changer, providing farmers with new and innovative tools to improve efficiency and productivity. From precision farming to autonomous tractors, AI is revolutionizing the way we think about farming and agriculture.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Use Cases in Food Processing</title>
      <link>http://localhost:1313/dsblog/AI-Use-Cases-in-Food-Processing/</link>
      <pubDate>Sun, 22 Jan 2023 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Use-Cases-in-Food-Processing/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6036-AI-Use-Cases-in-Food-Processing.jpg&#34; alt=&#34;“AI Use Cases in Food Processing&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-use-cases-in-food-processing&#34;&gt;AI Use Cases in Food Processing&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The food processing industry is a vital sector in the global economy, responsible for providing safe and nutritious food to millions of people around the world. Artificial intelligence (AI) is being increasingly used in the food processing industry to improve efficiency, reduce costs, and enhance the quality and safety of food products. From automated sorting and grading of fruits and vegetables to intelligent vending machines, AI is being used in a wide range of applications across the food processing industry.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Will AI Replace Human?</title>
      <link>http://localhost:1313/dsblog/Will-AI-Replace-Human/</link>
      <pubDate>Thu, 19 Jan 2023 08:33:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Will-AI-Replace-Human/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6038-Will-AI-Replace-Human.jpg&#34; alt=&#34;Will AI Replace Human&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;artificial-intelligence-can-replace-human&#34;&gt;Artificial Intelligence can Replace Human?&lt;/h1&gt;&#xA;&lt;p&gt;The Success of ChatGPT has taken the world by storm. Unless you are not living in some cave you already know what is happening. People are asking questions like will AI replace humans? What will happen to our jobs? What are the challenges? I thought let me write my thought on this. There was significant overlap between these phases, so don&amp;rsquo;t assume that when one phase was over then only the second started.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Neural Network</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Neural-Network/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Neural-Network/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6034-Introduction-to-Neural-Network.jpg&#34; alt=&#34;Introduction to Neural Network&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction-to-neural-network&#34;&gt;Introduction to Neural Network&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction-to-a-perceptron&#34;&gt;Introduction to a Perceptron&lt;/h2&gt;&#xA;&lt;p&gt;A perceptron is a type of artificial neural network that can be used for binary classification. It is a simple model that consists of a single layer of artificial neurons and is used to classify input data into one of two categories. The perceptron algorithm learns the weights of the artificial neurons by adjusting them based on the input data and the desired output. The perceptron is considered a basic building block for more complex neural networks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is GAN?</title>
      <link>http://localhost:1313/dsblog/What-is-GAN/</link>
      <pubDate>Tue, 17 Jan 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-GAN/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6043-gan.jpg&#34; alt=&#34;Partial Dependence Plots&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-gan&#34;&gt;What is GAN?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-gan-generative-adversarial-network&#34;&gt;What is GAN (Generative Adversarial Network)?&lt;/h2&gt;&#xA;&lt;p&gt;Generative adversarial networks (GANs) are besing used to generate images, videos, text, audio and music. GAN is a class of machine-learning models introduced by Ian Goodfellow and his colleagues in 2014. The GANs became popular among researchers quickly because of their property to generate new data with the same statistics as the input training set. It can be applied to images, videos, textual data, tabular data and more, proving useful for semi-supervised, fully supervised, and reinforcement learning.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Timeseries Interview Questions</title>
      <link>http://localhost:1313/dsblog/Timeseries-Interview-Questions/</link>
      <pubDate>Sun, 08 Jan 2023 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Timeseries-Interview-Questions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6023-Timeseries-Interview-Questions.jpg&#34; alt=&#34;Timeseries Interview Questions&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;timeseries-interview-questions&#34;&gt;Timeseries Interview Questions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-are-the-characterstics-of--time-series-data&#34;&gt;What are the characterstics of  time series data?&lt;/h2&gt;&#xA;&lt;p&gt;Time series data is a series of data points collected over time. Some characteristics of time series data include:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Time dependence: Time series data is typically collected at regular time intervals, and the values of the time series are often dependent on the time at which they were collected.&lt;/li&gt;&#xA;&lt;li&gt;Equal duration gap between samples/ records&lt;/li&gt;&#xA;&lt;li&gt;No missing record in between&lt;/li&gt;&#xA;&lt;li&gt;Trend: Many time series exhibit a long-term trend, either upward or downward. This trend may be influenced by a variety of factors such as economic conditions, population growth, or technological changes.&lt;/li&gt;&#xA;&lt;li&gt;Seasonality: Many time series exhibit regular fluctuations due to seasonal factors such as weather, holidays, or other events. For example, retail sales may be higher in the months leading up to Christmas due to holiday shopping.&lt;/li&gt;&#xA;&lt;li&gt;Cyclicity: Time series may exhibit cyclical pattern. Like sales is highest in month start, body temprature is high at 6am, traffic is least on weekends etc.&lt;/li&gt;&#xA;&lt;li&gt;Noise: Time series data may also be affected by random noise or error, which can make it difficult to accurately forecast future values.&lt;/li&gt;&#xA;&lt;li&gt;Autocorrelation: Time series data may exhibit autocorrelation, which is the phenomenon of a value at a particular time being correlated with values at nearby times. This can make it challenging to model the time series, as the value at a given time may depend on the values at nearby times.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;example-of-time-series-data&#34;&gt;Example of time series data&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Date&lt;/th&gt;&#xA;          &lt;th&gt;Sales (y)&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-01-01&lt;/td&gt;&#xA;          &lt;td&gt;1000&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-02-01&lt;/td&gt;&#xA;          &lt;td&gt;1100&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-03-01&lt;/td&gt;&#xA;          &lt;td&gt;1200&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-04-01&lt;/td&gt;&#xA;          &lt;td&gt;1100&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-05-01&lt;/td&gt;&#xA;          &lt;td&gt;1000&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-06-01&lt;/td&gt;&#xA;          &lt;td&gt;900&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-07-01&lt;/td&gt;&#xA;          &lt;td&gt;1200&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-08-01&lt;/td&gt;&#xA;          &lt;td&gt;1400&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-09-01&lt;/td&gt;&#xA;          &lt;td&gt;1300&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2020-10-01&lt;/td&gt;&#xA;          &lt;td&gt;1500&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;This first column can be date or date or datetime. Interval between two rows must be equal. The unit of date or time or datetime may be milliosecond, or second, or minute, or hour, or day, week, month, quarter, year or dacade. This should be continuous without any gap.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Linear Regression Interview Questions</title>
      <link>http://localhost:1313/dsblog/Linear-Regression-Interview-Questions/</link>
      <pubDate>Sat, 07 Jan 2023 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Linear-Regression-Interview-Questions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6022-Linear-Regression-Interview-Questions.jpg&#34; alt=&#34;Prompt Engineering for GPT4&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;linear-regression-interview-questions-and-answers&#34;&gt;Linear Regression Interview Questions and Answers&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;In this question-answer article, I will try that the start of every answer from example rather than theory (some unavoidable variation may be possible). I firmly believe if examples are clear, human mind is smart enough in generlization and creating theories.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;h2 id=&#34;question-1-what-is-linear-regression-what-is-the-difference-between-simple-linear-regression-and-multiple-linear-regression&#34;&gt;Question 1: What is linear regression? What is the difference between simple linear regression and multiple linear regression?&lt;/h2&gt;&#xA;&lt;p&gt;Linear regression is a statistical method used to model the linear relationship between a dependent variable and one or more independent variables. It is used to predict the value of the dependent variable based on the values of the independent variables.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Statistics Interview Question for Data Scientist</title>
      <link>http://localhost:1313/dsblog/Statistics-Interview-Question-for-Data-Scientist/</link>
      <pubDate>Fri, 06 Jan 2023 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Statistics-Interview-Question-for-Data-Scientist/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6025-Statistics-Interview-Question-for-Data-Scientist.jpg&#34; alt=&#34;Statistics Interview Question for Data Scientist&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;statistics-interview-question-for-data-scientist&#34;&gt;Statistics Interview Question for Data Scientist&lt;/h1&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;In this question-answer blog, I will try to answer that every question starts with an example rather than a theory or definition (some unavoidable variation may be possible). I firmly believe if examples are clear, then a human mind is smart enough in generalizing, creating theories and definitions.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The purpose of this blog is not to give you clear-cut definitions of important concepts of statistics but help you in visualizing the ideas in your mind. So that even without the definitions you understand what a particular idea means.&lt;/p&gt;</description>
    </item>
    <item>
      <title>GPT Usecases</title>
      <link>http://localhost:1313/dsblog/gpt-usecases/</link>
      <pubDate>Thu, 05 Jan 2023 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/gpt-usecases/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6020-GPT-Usecases.jpg&#34; alt=&#34;GPT Usecases&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-gpt&#34;&gt;What is GPT?&lt;/h1&gt;&#xA;&lt;p&gt;GPT is a transformer. Don&amp;rsquo;t confuse it with your electricity transformer! In Artificial Intelligence there are different kinds of neural network architectures to perform various tasks like classification, translation, segmentation, regression, etc. One of those architectures is transformer architecture. The Foundation of this architecture is based on another two architectures called encoder architecture and decoder architecture. There are lots of other technical complexity but for the business readers I am hiding that for that the time being, we will discuss that at some other place. In nutshell, GPT is a Transformer technology developed by OpenAI and it can perform several NLP tasks. NLP stands for natural language preprocessing. NLP tasks mean tasks like sentiment analysis of the text, text classification, topic modeling, translation, named entity recognition, and dozens of other tasks.&lt;/p&gt;</description>
    </item>
    <item>
      <title>ChatGPT Usecases</title>
      <link>http://localhost:1313/dsblog/chatgpt-usecases/</link>
      <pubDate>Wed, 04 Jan 2023 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/chatgpt-usecases/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6019-ChatGPT-Usecases.jpg&#34; alt=&#34;ChatGPT Usecases&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-chatgpt&#34;&gt;What is ChatGPT?&lt;/h1&gt;&#xA;&lt;p&gt;ChatGPT is &lt;strong&gt;general purpose&lt;/strong&gt; - &amp;ldquo;chat model&amp;rdquo; from OpenAI. It is a &lt;strong&gt;language model&lt;/strong&gt;, which means if you type some text then it can understand and respond to you appropriately. At this point in time, it is not accepting voice commands, neither able to process images or videos. A &lt;strong&gt;general-purpose model&lt;/strong&gt; means it can understand the question coming from any domain of life. A domain may be vertical or horizontal. A vertical domain means where a vendor is supplying a product or service for a specific type of customer. A horizontal domain is where a vendor supplies products or services for all types of customer.  Healthcare, banking, logistic, insurance, agriculture, philosophy, history, and economics are one kind of verticals whereas&#xA;BPO, Quality Management, Software Development, Taxation, HR, IT Security, Accounting, Office Administration, Catering, and Entertainment are other kind of domains. A &lt;strong&gt;general-purpose model&lt;/strong&gt; can understand the questions from all aspects of life whether business vertical or horizontal or normal daily family or conflicts with other group members, family members, etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI in Energy Management</title>
      <link>http://localhost:1313/dsblog/AI-in-Energy-Management/</link>
      <pubDate>Mon, 02 Jan 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-in-Energy-Management/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6046-AI-Usecases-in-Energy-Management.jpg&#34; alt=&#34;AI in Energy Management&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-in-energy-management&#34;&gt;AI in Energy Management&lt;/h1&gt;&#xA;&lt;h3 id=&#34;introduction&#34;&gt;Introduction&lt;/h3&gt;&#xA;&lt;p&gt;The application of AI in energy management is aimed at optimizing energy consumption and reducing waste in the energy sector. AI can help in Energy Demand management, Energy Optimization, Energy Equipment Maintenance and Repair, Renewable energy integration and smart grid management. Some of the specific usecases in Energy sector can be as following.&lt;/p&gt;&#xA;&lt;h2 id=&#34;important-specific-usecases-of-ai-in-energy-management&#34;&gt;Important specific usecases of AI in Energy Management&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Real-time monitoring: AI can be used to monitor energy consumption in real-time, providing real-time feedback on energy usage patterns and allowing for immediate adjustments to improve energy efficiency.&lt;/li&gt;&#xA;&lt;li&gt;Predictive maintenance: AI algorithms can be used to predict when equipment is likely to fail, reducing downtime and improving the reliability of energy systems.&lt;/li&gt;&#xA;&lt;li&gt;Energy trading: AI algorithms can be used to optimize energy trading by predicting energy prices and enabling the buying and selling of energy at optimal times.&lt;/li&gt;&#xA;&lt;li&gt;Grid balancing: AI can be used to balance energy supply and demand in real-time, reducing energy waste and improving the reliability of energy grids.&lt;/li&gt;&#xA;&lt;li&gt;Carbon emissions reduction: AI algorithms can be used to analyze energy consumption patterns and identify ways to reduce carbon emissions, helping to mitigate the impact of energy consumption on the environment.&lt;/li&gt;&#xA;&lt;li&gt;Energy storage optimization: AI algorithms can be used to optimize the use of energy storage systems, reducing energy waste and improving energy efficiency.&lt;/li&gt;&#xA;&lt;li&gt;Energy efficiency assessment: AI can be used to assess the energy efficiency of buildings, factories, and other energy-intensive environments, providing recommendations for improvement.&lt;/li&gt;&#xA;&lt;li&gt;Renewable energy forecasting: AI can be used to forecast renewable energy generation, helping energy providers to better match supply and demand and reduce energy waste.&lt;/li&gt;&#xA;&lt;li&gt;Smart meter data analysis: AI algorithms can be used to analyze data from smart meters, providing insights into energy consumption patterns and enabling better energy management.&lt;/li&gt;&#xA;&lt;li&gt;Energy-saving behavior analysis: AI algorithms can be used to analyze energy-saving behaviors of consumers, providing insights into ways to reduce energy waste and improve efficiency.&lt;/li&gt;&#xA;&lt;li&gt;Energy market analysis: AI algorithms can be used to analyze energy markets, providing insights into energy prices and enabling better energy trading.&lt;/li&gt;&#xA;&lt;li&gt;Energy fraud detection: AI algorithms can be used to detect energy fraud, reducing energy waste and improving the reliability of energy systems.&lt;/li&gt;&#xA;&lt;li&gt;Energy efficiency incentives: AI algorithms can be used to analyze energy consumption patterns and determine appropriate incentives for consumers to reduce energy waste and improve efficiency.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;&#xA;&lt;p&gt;In conclusion, the application of AI in energy management is a promising solution for improving energy efficiency and reducing energy waste. By using AI algorithms to analyze data and predict energy consumption patterns, energy providers can better match supply and demand, reduce energy waste, and lower costs. Furthermore, the use of AI in energy management has the potential to mitigate the impact of energy consumption on the environment, improve reliability, and provide insights into ways to reduce energy waste and increase efficiency. The future of AI in energy management is bright, and as AI technologies continue to advance, it is likely that new and innovative applications will emerge that will further transform the energy sector and benefit consumers and the environment alike&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is Computer Vision</title>
      <link>http://localhost:1313/dsblog/what-is-computer-vision/</link>
      <pubDate>Wed, 28 Dec 2022 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/what-is-computer-vision/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6018-What-is-Computer-Vision.jpg&#34; alt=&#34;What is Computer Vision&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-computer-vision&#34;&gt;What is Computer vision?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;&#xA;&lt;p&gt;In the digital world, scientists are working hard to create machines and robots that can interact with humans the way humans interact with each other. You cannot interact with another human being around if you are not aware of the objects and background around you. There are many ways to know the things around us. We can know them through smell; without looking anything around we can tell, here is a rose flower or samosa or sugar factory around. Without looking we can tell whether a train is coming or going, a person is going or coming, this is a song sung by Lata Mangeshkar. Without looking I can tell this is smooth or rough, hard or soft, cold or hot. In all these cases we could identify the objects and things around us without using our eyes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Science of Reasoning</title>
      <link>http://localhost:1313/dsblog/The-Science-of-Reasoning/</link>
      <pubDate>Wed, 21 Dec 2022 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/The-Science-of-Reasoning/</guid>
      <description>&lt;h1 id=&#34;the-science-of-reasoning&#34;&gt;The Science of Reasoning&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6017-The-Science-of-Reasoning.jpg&#34; alt=&#34;The Science of Reasoning&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;about-reasoning&#34;&gt;About Reasoning&lt;/h2&gt;&#xA;&lt;p&gt;Reasoning is a unique ability in humans. Whatever civilizational advancement we see, it is because of our ability to think, imagine and reason. We all give reasons and ask for reasons but most humans don&amp;rsquo;t understand the fallacies of reasoning. Due to this sometimes we are putting forward a correct point but we are using the wrong reasoning.&lt;/p&gt;&#xA;&lt;p&gt;In Sanskrit, we have a subject called Tarka Shastra, which deals with reasoning. My purpose of writing this article is neither to guide you for some career exam nor to make you a TV debater, but to summarize the importance of correct reasoning. If you know what is the correct way of reasoning then nobody can confuse you and the most important thing, you will not confuse yourself and feel a victim of society.&lt;/p&gt;</description>
    </item>
    <item>
      <title>What is NLP?</title>
      <link>http://localhost:1313/dsblog/what-is-nlp/</link>
      <pubDate>Mon, 19 Dec 2022 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/what-is-nlp/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6016-What-is-NLP.jpg&#34; alt=&#34;What is NLP?&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-nlp&#34;&gt;What is NLP?&lt;/h2&gt;&#xA;&lt;p&gt;Humans interact with their surroundings using different kinds of inputs. Eyes deal with inputs of color, shape, and size. Ear deals with inputs of sound, voice, and noise. Similarly, the other 3 senses also deal with other kinds of inputs. When you write something you may be drawing some art or you may be drawing letters of some language. Language is what we use to speak, for example, English, Hindi, Kannada, Tamil, and French are languages. The script is a tool to write what we speak. There are many kinds of scripts and you can use those scripts to write words of the languages. Some scripts are good for some languages. You cannot write all the words of all the languages of the world using one script (without modifying the original letters of the script). The Roman script is good to write English languages but when you want to write any Indian language using Roman then you will make many mistakes when reading the scripts. Because you won&amp;rsquo;t be able to produce the same sound as the original language was producing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Book Review - Data Science in Marketing Analysis</title>
      <link>http://localhost:1313/dsblog/bookreview-data-science-for-marketing-analytics/</link>
      <pubDate>Wed, 26 Oct 2022 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/bookreview-data-science-for-marketing-analytics/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://localhost:1313/assets/images/dspost/dsp6014-BookReview-Data-Science-for-Marketing-Analytics.jpg&#34;&gt;Book Review - Data Science in Marketing Analysis&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;book-review&#34;&gt;BOOK REVIEW&lt;/h1&gt;&#xA;&lt;h2 id=&#34;title-of-the-book-data-science-in-marketing-analysis&#34;&gt;TITLE OF THE BOOK: Data Science in Marketing Analysis&lt;/h2&gt;&#xA;&lt;h2 id=&#34;author-mirza-rahim-baig-gururajan-govindan-and-vishwesh-ravi-shrimali&#34;&gt;AUTHOR: Mirza Rahim Baig, Gururajan Govindan, and Vishwesh Ravi Shrimali&lt;/h2&gt;&#xA;&lt;h2 id=&#34;publisher-packt-publishing&#34;&gt;PUBLISHER: Packt Publishing&lt;/h2&gt;&#xA;&lt;h2 id=&#34;year-2021&#34;&gt;YEAR: 2021&lt;/h2&gt;&#xA;&lt;h2 id=&#34;reviewer-hari-thapliyal-ai-educationist--consultant-founder-dasarpai&#34;&gt;Reviewer: Hari Thapliyal, AI Educationist &amp;amp; Consultant, Founder, dasarpAI&lt;/h2&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;INTRODUCTION&lt;/h2&gt;&#xA;&lt;p&gt;Before writing this book, three authors of this books has written 3 books separately. Mirza Rahim Baig has authored “The Deep Learning Workshop”, Gururajan Govindan authored “The Data Analysis Workshop” and Vishwesh Ravi Shrimali has written a book “The Computer Vision Workshop”. The individual’s experience of writing book on Data Science has made this book easy understandable and lucid book. I am doing this review on the second edition of this book. The first edition was published in 2019 and the second edition is published in 2021. This book contains 637 pages, and it looks heavy on your table but most the content is code example and screenshots of graphs and data tables. This is normal for any good programming book, which wants their reader to understand what code was written and how the output looks like. This book is written in simple English. In the book, authors trying to explain how to work with python, pandas, seaborn and other important python libraries. This book goes beyond the title of this book. It is not only about marketing analysis but also how to develop model using scikit-learn and other machine learning libraries. Copyright of this book is with Packt Publishing.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Domain Knowledge in Machine Learning</title>
      <link>http://localhost:1313/dsblog/Domain-Knowledge-in-Machine-Learning/</link>
      <pubDate>Sat, 15 Oct 2022 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Domain-Knowledge-in-Machine-Learning/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6015-domain-knowledge-in-machine-learning.jpg&#34; alt=&#34;Domain Knowledge in Machine Learning&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;domain-knowledge-in-machine-learning&#34;&gt;Domain Knowledge in Machine Learning&lt;/h1&gt;&#xA;&lt;p&gt;Let’s say the domain is a restaurant kitchen. A dataset with 3 variables. Two predictors and one predicted. Predictor variables are flour in kilograms and water in liters.  A predicted variable is the number of roti/ bread. You know the model will be something like this.&lt;/p&gt;&#xA;&lt;p&gt;Number of roti (y). = b1 * flour in kg (x1) + b2 * water in liter (x2)&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Science/AI Projects Project Ideas</title>
      <link>http://localhost:1313/dsblog/DS-AI-Projects-Project-Ideas/</link>
      <pubDate>Thu, 06 Oct 2022 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/DS-AI-Projects-Project-Ideas/</guid>
      <description>&lt;p&gt;&lt;a href=&#34;http://localhost:1313/assets/images/dspost/dsp6013-Data-Science-Project-Ideas.jpg&#34;&gt;AI Projects Project Ideas&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;ai-data-science-machine-learning-deep-learning-nlp-project-ideas&#34;&gt;AI, Data Science, Machine Learning, Deep Learning, NLP Project Ideas&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Project Name/Idea&lt;/th&gt;&#xA;          &lt;th&gt;Type of Project&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;IPL 2022 Analysis using Python&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Uber Trips Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Waiter Tips Analysis &amp;amp; Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Time Series Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Stock Market Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Movie Rating Analysis for Beginners&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Unemployment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Water Quality Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Google Search Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;WhatsApp Chats Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Smartwatch Data Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Instagram Reach Analysis and Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Smartwatch Data Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Covid-19 Vaccine Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Financial Budget Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Worldwide Billionaires Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Best Streaming Service Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Virat Kohli Performance Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Covid-19 Spread and Impacts Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Data Science Project on Birth Rate Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Analysis&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Twitter Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Real-time Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Squid Game Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Hotel Reviews Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Tinder Reviews Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Tiktok Reviews Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Pfizer Vaccine Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;WhatsApp Chats Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Omicron Variant Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Flipkart Reviews Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Google Play Store Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Amazon Alexa Reviews Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Amazon Product Reviews Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Ukraine vs Russia Twitter Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Adding Labels to a Dataset for Sentiment Analysis&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Classification Model Evaluation&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;MNIST Digits Classification&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Classification with Neural Networks&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;News Classification&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Iris Flower Classification&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Comparison of Classification Algorithms&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Insurance Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Spam Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Sarcasm Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Hate Speech Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;End-to-end Hate Speech Detection System&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;End-to-end Fake News Detection System&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;End-to-end Spam Detection System&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Real-time Gender Detection System&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Social Media Ads Classification&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Fake News Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Gender Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Mobile Price Classification&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Password Strength Checker with Machine Learning&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Spam Comments Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Online Payments Fraud Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Breast Cancer Survival Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Stress Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Language Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Language Detection&lt;/td&gt;&#xA;          &lt;td&gt;Classification&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Clustering Music Genres with Machine Learning&lt;/td&gt;&#xA;          &lt;td&gt;Clustering&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;AlexNet Neural Network Architecture&lt;/td&gt;&#xA;          &lt;td&gt;CV&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Count Objects in Image&lt;/td&gt;&#xA;          &lt;td&gt;CV-Object Detection&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;End-to-End Machine Learning Model&lt;/td&gt;&#xA;          &lt;td&gt;ML&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;End-to-end Machine Learning Project&lt;/td&gt;&#xA;          &lt;td&gt;ML&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Complete Process of NLP with Python&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Interactive Language Translator&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Create a Chatbot with Python&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Text Summarization&lt;/td&gt;&#xA;          &lt;td&gt;NLP-IE&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Keyword Extraction&lt;/td&gt;&#xA;          &lt;td&gt;NLP-IE&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Netflix Recommendation System&lt;/td&gt;&#xA;          &lt;td&gt;Recommendation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Restaurant Recommendation System&lt;/td&gt;&#xA;          &lt;td&gt;Recommendation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Book Recommendation System&lt;/td&gt;&#xA;          &lt;td&gt;Recommendation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Instagram Recommendation System&lt;/td&gt;&#xA;          &lt;td&gt;Recommendation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Article Recommendation System&lt;/td&gt;&#xA;          &lt;td&gt;Recommendation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Amazon Recommendation System&lt;/td&gt;&#xA;          &lt;td&gt;Recommendation&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;House Rent Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Website Traffic Forecasting&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Online Food Order Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Student Marks Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Netflix Stock Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Health Insurance Premium Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Car Price Prediction Model&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Video Game Sales Prediction Model&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Student Grades Prediction Model&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Click-Through Rate Prediction Model&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Data Science Project on Area and Population&lt;/td&gt;&#xA;          &lt;td&gt;Regression&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Apple Stock Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Tesla Stock Price Prediction Model&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Data Science Project on Time Series&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Social Media Followers Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Dogecoin Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Sales Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Currency Exchange Rate Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Automatic Time Series Forecasting&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Future Sales Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Time Series Forecasting with ARIMA&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Cryptocurrency Price Prediction for the next 30 days&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Stock Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Covid-19 Deaths Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Stock Price Prediction with LSTM Neural Network&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Future Sales Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Product Demand Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Electricity Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Cryptocurrency Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Tata Motors Stock Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Number of Orders Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;Microsoft Stock Price Prediction&lt;/td&gt;&#xA;          &lt;td&gt;Time Series&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>Confusion Matrix Bayesian Theorem</title>
      <link>http://localhost:1313/dsblog/Confusion-Matrix-Bayesian-Theorem/</link>
      <pubDate>Mon, 22 Aug 2022 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Confusion-Matrix-Bayesian-Theorem/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6006-Confusion-Matrix-Bayesian-Theorem.jpg&#34; alt=&#34;Confusion Matrix&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;If you are like me then you must have struggled enough to understand the confusion matrix or still struggling to understand the metrics of this confusion matrix. A simple 2×2 actual vs predicted values matrix can be looked at and analyzed from different angles and hence we can have all different metrics from this. The beauty of all these metrics is different metrics are important for evaluating different kinds of models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Science, AI, ML, eBooks, PDF Books</title>
      <link>http://localhost:1313/dsblog/ds-ai-ml-books/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ds-ai-ml-books/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr120-Data-Science-AI-ML-eBooks-PDF-Books.jpg&#34; alt=&#34;DS, AI, ML, Books Available&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;online-data-science-ai-ml-content&#34;&gt;Online Data Science, AI, ML Content&lt;/h1&gt;&#xA;&lt;p&gt;Data Science, AI, Machine Learning, Books/ Guide/ Reports/ Presentations / Jupyter Notebook Available.&lt;/p&gt;&#xA;&lt;p&gt;All these books are available in pdf format at &lt;a href=&#34;https://drive.google.com/drive/folders/14wS6JWWDsZ2TEXCD9A7jgLVCEVEd1Mpb?usp=sharing&#34; target=&#34;_blank&#34;&gt; this link&lt;/a&gt;. I update this page less frequently but keep adding books in the repo. The list below may not contain the name you are looking for. Therefore, it is suggested to visit the link mentioned earlier. This link contains excellent presentations Book, (PPT), Handbook, Report, Articles (ARTC), Book, Booklet, eBook, Notebook, Notes, PAPER, GUIDE, TOC, Syllabus, LINKS, Handbook, Chapter, Tool, BROC – Broacher on Machine Learning, Deep Learning, NLP, Statistics, Reinforcement Learning, GAN. Approx 800 pdf files which inclues 350+ books.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Science Cheatsheets</title>
      <link>http://localhost:1313/dsblog/data-science-cheatsheets/</link>
      <pubDate>Sun, 03 Jul 2022 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/data-science-cheatsheets/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr103-Data-Science-Cheatsheets.jpg&#34; alt=&#34;Data Science Cheatsheets&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;data-science-cheatsheets&#34;&gt;Data Science Cheatsheets&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;All these cheat sheets are kept at &lt;a href=&#34;https://drive.google.com/drive/folders/1dCHf52OYqbB17rXzJODYiBnM8JNneb2_?usp=sharing&#34;&gt;my google drive link&lt;/a&gt;. 180+ cheatsheet on ML, DL, DE, DA, NLP, Algorithms, Pandas, Numpy, Dask, Bigdata, Statistics, Python, SQL, Docker, sklearn, git, GNN etc.&lt;/p&gt;&#xA;&lt;h2 id=&#34;list-of-cheatsheets&#34;&gt;List of Cheatsheets&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;21 Types of SQL joins-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;5W1H-DataScience-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Acceptance Criteria Checklist.pdf&lt;/li&gt;&#xA;&lt;li&gt;Activation Functions-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Advanced R-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;AI4All-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;AI-Cheatsheet+NN+ML+DL+BD.pdf&lt;/li&gt;&#xA;&lt;li&gt;AIML_Fundamental-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;AIML-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;AI-ML-DS Cheatsheets .pdf&lt;/li&gt;&#xA;&lt;li&gt;AI-NeuralNetworks.pdf&lt;/li&gt;&#xA;&lt;li&gt;All in One Mathematics Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;An Introduction to Convolutional Neural Networks-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Artificial Intelligence _ Super VIP Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Azure-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Beginners Python-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Behavioral Interview-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Best_Machine_Learning_Algorithms-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;BI versus DS-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Bias-Variance-Tradeoff-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Big Data Hadoop+Mapreduce-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Big Data-Hadoop-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Bigdata-Hadoop-hdfs-commands-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Bigdata-Hortonworks SQLtoHive-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Bigdata-Pig-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;BrainMapping-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Calculus Cheat Sheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;CalculusA_All-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;CalculusB_All-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Chart-Suggestion-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Cloud Comparison AWS AZURE GCP-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Cloud Computing Cheatsheet .pdf&lt;/li&gt;&#xA;&lt;li&gt;Combined Cheat Sheets of ML+DL Probability and LLMs-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Complete Collection of Data Science Cheatsheets.pdf&lt;/li&gt;&#xA;&lt;li&gt;Comprehensive Python -CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Computing Neural Network Gradients-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;CS229 - Machine Learning-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Dask-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Engineering _ Analytics Use Case Architecture on AWS-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Engineering Cookbook-GUIDE.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Science -CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Science -Data Prep with SQL -Quick Reference-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Science Regular Python Expressions-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Science with Python Workflow-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Visualization with ggplot2-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Data VisualizationA-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data Wrangling with Pandas-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data_engineering_infographic-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Data_Wrangling_with_dplyr_and_tidyr-RStudio-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;DataScience1-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;DataScience2-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;DataScience3-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;DataScience4-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;DataScience-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Deep Learning Course Notes-Coursera-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Deep Learning-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Deep_Learning_Cheat_Sheet-Hacker Noon-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Deeplearning-Definitions-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Docker-Cheatsheet-2016.pdf&lt;/li&gt;&#xA;&lt;li&gt;Docker-The Ultimate CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Ensemble Learning-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Financial Formulas-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;ggplot2&amp;ndash;CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;GitA-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Git-atlassian-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;GitB-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;GitC-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Google-Data Engineering CheatSheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Google-Data-Engineering-Cheatsheets.pdf&lt;/li&gt;&#xA;&lt;li&gt;Graph4NLP-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Graphics-Principles-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Great Python Cheatsheet by Dummies-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Handling Data Imbalance-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Keras-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Liner_Algebra-in-4Pages-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;LinkedIn-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;LinkedInGuide-Ultimate-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine learning algorithms with Python _ R code examples-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning Algorithms-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning Algorithms-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning Best Practices-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning Interview-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning_Data Science Interview Cheatsheets-InterviewQ.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine Learning-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine-Learnign-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine-Learning1-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Machine-Learning-Algorithm&amp;ndash;CHEATSHEET.svg&lt;/li&gt;&#xA;&lt;li&gt;Machine-learning-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Matplotlib-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Merlion timeseries library-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Metrics and more-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Microservices-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Microsoft-Machine-Learning-Algorithm&amp;ndash;CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Microsoft-Office-Cheatsheets.pdf&lt;/li&gt;&#xA;&lt;li&gt;ML Algorithm Learning-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;ML dataset-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;ML-Algorithms-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;MySql-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Nested Queries And Aggregation-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Neural Network Architecture Types-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Neural networks-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Neural_Network_Cells-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Neural_Network_Graphs-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Neural_Networks_Zoo-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;NeuralNetwork-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;NLP-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Numpy_Python_-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;NumpyA-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;NumpyB-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;NumpyC-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Open CV-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Pandas Data analysis-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Pandas Python-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Pandas_Cheatsheet-Pandas Basics-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Pandas1-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Pandas2-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Pandas-Basics-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Pandas-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;PandasOne-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Postman Cheatsheet .pdf&lt;/li&gt;&#xA;&lt;li&gt;Probability-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Pros Cons of commonly used machine learning algorithms-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;PySpark Quick Reference Guide.pdf&lt;/li&gt;&#xA;&lt;li&gt;PySpark-RDD-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;PySpark-SQL-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Python BasicsA-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Python BasicsB-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Python Security Best Practices-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Python_CheatSheet-by-WebsiteSetup.pdf&lt;/li&gt;&#xA;&lt;li&gt;Python_Matplotlib-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Python_SciPy_Linear_Algebra-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Python3A-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Python3B-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Python3C-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;PythonA-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;PythonB-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;PythonC-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Python-CheatSheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;PythonD-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;PythonD-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Python-for-DS-All-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Pytorch-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Quantitative Aptitude-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Query-Optimization-Techniques-SQL-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;R programming cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;R Programming-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Reading and Writing Data with Pandas-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Regression-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Rest API Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Risk Assessment Example-CheatSheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Roadmap of mathematics for Deep Learning-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Scikit_Learn_Python-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Scikit_Learn-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Scikit-Learn1-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Seaborn-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Sklearn-Algo-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;SQL &amp;amp; NoSQL-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;SQL API with Python-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;SQL for MLI FAM-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;SQL Window Functions.pdf&lt;/li&gt;&#xA;&lt;li&gt;SQL-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Statistics Test Decision-CHEATSHEET.png&lt;/li&gt;&#xA;&lt;li&gt;Statistics1-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Statistics2-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Statistics-A-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Statistics-Cheatsheet.pdf&lt;/li&gt;&#xA;&lt;li&gt;Statistics-Harvard-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Super VIP ML , DL , AI-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Super-VIP-Deep-learning-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Tableau-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;The Super Duper NLP Repo-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Theoretical Computer Science-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Top 56 Job Interview Questions.pdf&lt;/li&gt;&#xA;&lt;li&gt;Top Data Science Interview Question.pdf&lt;/li&gt;&#xA;&lt;li&gt;Top Data Science Libraries-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;Top Machine Learning Models Guides.pdf&lt;/li&gt;&#xA;&lt;li&gt;Top Prediction Algorithms-CHEATSHEET.jpg&lt;/li&gt;&#xA;&lt;li&gt;Ultimate Guide to AI, Data Science _ Machine Learning-LINKS.pdf&lt;/li&gt;&#xA;&lt;li&gt;VIP Cheatsheet-Recurrent Neural Networks-CHEATSHEET.pdf&lt;/li&gt;&#xA;&lt;li&gt;VIS-Know your data with ggplot2-NOTEBOOK.pdf&lt;/li&gt;&#xA;&lt;li&gt;Visualizing-Percentages-20-Ways-InfoNewt.pdf&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Python Software Development and Distribution</title>
      <link>http://localhost:1313/dsblog/Python-Software-Development-and-Distribution/</link>
      <pubDate>Thu, 30 Sep 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Python-Software-Development-and-Distribution/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6012-Python-Software-Development-and-Distribution.jpg&#34; alt=&#34;Software Distribution&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;software-distribution&#34;&gt;Software Distribution&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;We don’t develop any good and valuable piece of software from scratch. We use pieces of code written by others. This piece of code can be a service running on another machine or software written but kept in a repository. This service may be created by some other company, individual, our company, our team, or ourselves. So any software has two components, one, which is created by us, and we are responsible for the maintenance of that. Another component is a piece of software that is created by someone else, and we are not responsible for the maintenance of that.&lt;/p&gt;</description>
    </item>
    <item>
      <title>300 Important Statistical Terms</title>
      <link>http://localhost:1313/dsblog/300-Important-Statistical-Terms/</link>
      <pubDate>Wed, 29 Sep 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/300-Important-Statistical-Terms/</guid>
      <description>&lt;h1 id=&#34;important-statistical-terms&#34;&gt;Important Statistical Terms&lt;/h1&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6011-300&amp;#43;Important-Statitical-Terms.jpg&#34; alt=&#34;300 Important Statistical Terms&#34;&gt;&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno&lt;/th&gt;&#xA;          &lt;th&gt;Term&lt;/th&gt;&#xA;          &lt;th&gt;Definition&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;Affine transformation.&lt;/td&gt;&#xA;          &lt;td&gt;See transformation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;Affirming the antecedent.&lt;/td&gt;&#xA;          &lt;td&gt;A valid logical argument that concludes from the premise A → B and the premise A that therefore, B is true. The name comes from the fact that the argument affirms (i.e., asserts as true) the antecedent (A) in the conditional.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;Affirming the consequent.&lt;/td&gt;&#xA;          &lt;td&gt;A logical fallacy that argues from the premise A → B and the premise B that therefore, A is true. The name comes from the fact that the argument affirms (i.e., asserts as true) the consequent (B) in the conditional.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;Alternative Hypothesis.&lt;/td&gt;&#xA;          &lt;td&gt;In hypothesis testing, a null hypothesis (typically that there is no effect) is compared with an alternative hypothesis (typically that there is an effect, or that there is an effect of a particular sign). For example, in evaluating whether a new cancer remedy works, the null hypothesis typically would be that the remedy does not work, while the alternative hypothesis would be that the remedy does work. When the data are sufficiently improbable under the assumption that the null hypothesis is true, the null hypothesis is rejected in favor of the alternative hypothesis. (This does not imply that the data are probable under the assumption that the alternative hypothesis is true, nor that the null hypothesis is false, nor that the alternative hypothesis is true. Confused? Take a course in Statistics!)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;Ante.&lt;/td&gt;&#xA;          &lt;td&gt;The up-front cost of a bet: the money you must pay to play the game. From Latin for “before.”&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;Antecedent.&lt;/td&gt;&#xA;          &lt;td&gt;In a conditional p → q, the antecedent is p.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;Appeal to Ignorance.&lt;/td&gt;&#xA;          &lt;td&gt;A logical fallacy: taking the absence of evidence to be evidence of absence. If something is not known to be false, assume that it is true; or if something is not known to be true, assume that it is false. For example, if I have no reason to think that anyone in Tajikistan wish me well, that is not evidence that nobody in Tajikistan wishes me well.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;Association.&lt;/td&gt;&#xA;          &lt;td&gt;Two variables are associated if some of the variability of one can be accounted for by the other. In a scatterplot of the two variables, if the scatter in the values of the variable plotted on the vertical axis is smaller in narrow ranges of the variable plotted on the horizontal axis (i.e., in vertical “slices”) than it is overall, the two variables are associated. The correlation coefficient is a measure of linear association, which is a special case of association in which large values of one variable tend to occur with large values of the other, and small values of one tend to occur with small values of the other (positive association), or in which large values of one tend to occur with small values of the other, and vice versa (negative association).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;Average.&lt;/td&gt;&#xA;          &lt;td&gt;An ambiguous term. It often denotes the arithmetic mean, but it can also denote the median, the mode, the geometric mean, and weighted means, among other things. Beware if something reports “the average” without making it clear which average.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;          &lt;td&gt;Axioms of Probability.&lt;/td&gt;&#xA;          &lt;td&gt;There are three axioms of probability: (1) Chances are always at least zero. (2) The chance that something happens is 100%. (3) If two events cannot both occur at the same time (if they are disjoint or mutually exclusive), the chance that either one occurs is the sum of the chances that each occurs. For example, consider an experiment that consists of tossing a coin once. The first axiom says that the chance that the coin lands heads, for instance, must be at least zero. The second axiom says that the chance that the coin either lands heads or lands tails or lands on its edge or doesn’t land at all is 100%. The third axiom says that the chance that the coin either lands heads or lands tails is the sum of the chance that the coin lands heads and the chance that the coin lands tails, because both cannot occur in the same coin toss. All other mathematical facts about probability can be derived from these three axioms. For example, it is true that the chance that an event does not occur is (100% − the chance that the event occurs). This is a consequence of the second and third axioms.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;Base rate fallacy.&lt;/td&gt;&#xA;          &lt;td&gt;The base rate fallacy consists of failing to take into account prior probabilities (base rates) when computing conditional probabilities from other conditional probabilities. It is related to the Prosecutor’s Fallacy. For instance, suppose that a test for the presence of some condition has a 1% chance of a false positive result (the test says the condition is present when it is not) and a 1% chance of a false negative result (the test says the condition is absent when the condition is present), so the exam is 99% accurate. What is the chance that an item that tests positive really has the condition? The intuitive answer is 99%, but that is not necessarily true: the correct answer depends on the fraction f of items in the population that have the condition (and on whether the item tested is selected at random from the population). The chance that a randomly selected item tests positive is 0.99×f/(0.99×f + 0.01×(1−f)), which could be much smaller than 99% if f is small. See Bayes’ Rule.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;Bayes’ Rule.&lt;/td&gt;&#xA;          &lt;td&gt;Bayes’ rule expresses the conditional probability of the event A given the event B in terms of the conditional probability of the event B given the event A and the unconditional probability of A: P(A/B) = P(B/A) ×P(A)/( P(B/A)×P(A) + P(B/Ac) ×P(Ac) ). In this expression, the unconditional probability of A is also called the prior probability of A, because it is the probability assigned to A prior to observing any data. Similarly, in this context, P(A/B) is called the posterior probability of A given B, because it is the probability of A updated to reflect (i.e., to condition on) the fact that B was observed to occur.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;Bernoulli’s Inequality.&lt;/td&gt;&#xA;          &lt;td&gt;The Bernoulli Inequality says that if x ≥ −1 then (1+x)n ≥ 1 + nx for every integer n ≥ 0. If n is even, the inequality holds for all x.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;Bias.&lt;/td&gt;&#xA;          &lt;td&gt;A measurement procedure or estimator is said to be biased if, on the average, it gives an answer that differs from the truth. The bias is the average (expected) difference between the measurement and the truth. For example, if you get on the scale with clothes on, that biases the measurement to be larger than your true weight (this would be a positive bias). The design of an experiment or of a survey can also lead to bias. Bias can be deliberate, but it is not necessarily so. See also nonresponse bias.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;Bimodal.&lt;/td&gt;&#xA;          &lt;td&gt;Having two modes.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;Bin.&lt;/td&gt;&#xA;          &lt;td&gt;See class interval.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;17&lt;/td&gt;&#xA;          &lt;td&gt;Binomial Coefficient.&lt;/td&gt;&#xA;          &lt;td&gt;See combinations.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;18&lt;/td&gt;&#xA;          &lt;td&gt;Binomial Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;A random variable has a binomial distribution (with parameters n and p) if it is the number of “successes” in a fixed number n of independent random trials, all of which have the same probability p of resulting in “success.” Under these assumptions, the probability of k successes (and n−k failures) is nCk pk(1−p)n−k, where nCk is the number of combinations of n objects taken k at a time: nCk = n!/(k!(n−k)!). The expected value of a random variable with the Binomial distribution is n×p, and the standard error of a random variable with the Binomial distribution is (n×p×(1 − p))½. This page shows the probability histogram of the binomial distribution.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;Binomial Theorem.&lt;/td&gt;&#xA;          &lt;td&gt;The Binomial theorem says that (x+y)n = xn + nxn−1y + … + nCkxn−kyk + … + yn.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;          &lt;td&gt;Bivariate.&lt;/td&gt;&#xA;          &lt;td&gt;Having or having to do with two variables. For example, bivariate data are data where we have two measurements of each “individual.” These measurements might be the heights and weights of a group of people (an “individual” is a person), the heights of fathers and sons (an “individual” is a father-son pair), the pressure and temperature of a fixed volume of gas (an “individual” is the volume of gas under a certain set of experimental conditions), etc. Scatterplots, the correlation coefficient, and regression make sense for bivariate data but not univariate data. C.f. univariate.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;Blind, Blind Experiment.&lt;/td&gt;&#xA;          &lt;td&gt;In a blind experiment, the subjects do not know whether they are in the treatment group or the control group. In order to have a blind experiment with human subjects, it is usually necessary to administer a placebo to the control group.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;Bootstrap estimate of Standard Error.&lt;/td&gt;&#xA;          &lt;td&gt;The name for this idea comes from the idiom “to pull oneself up by one’s bootstraps,” which connotes getting out of a hole without anything to stand on. The idea of the bootstrap is to assume, for the purposes of estimating uncertainties, that the sample is the population, then use the SE for sampling from the sample to estimate the SE of sampling from the population. For sampling from a box of numbers, the SD of the sample is the bootstrap estimate of the SD of the box from which the sample is drawn. For sample percentages, this takes a particularly simple form: the SE of the sample percentage of n draws from a box, with replacement, is SD(box)/n½, where for a box that contains only zeros and ones, SD(box) = ((fraction of ones in box)×(fraction of zeros in box) )½. The bootstrap estimate of the SE of the sample percentage consists of estimating SD(box) by ((fraction of ones in sample)×(fraction of zeros in sample))½. When the sample size is large, this approximation is likely to be good.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;Box model.&lt;/td&gt;&#xA;          &lt;td&gt;An analogy between an experiment and drawing numbered tickets “at random” from a box with replacement. For example, suppose we are trying to evaluate a cold remedy by giving it or a placebo to a group of n individuals, randomly choosing half the individuals to receive the remedy and half to receive the placebo. Consider the median time to recovery for all the individuals (we assume everyone recovers from the cold eventually; to simplify things, we also assume that no one recovered in exactly the median time, and that n is even). By definition, half the individuals got better in less than the median time, and half in more than the median time. The individuals who received the treatment are a random sample of size n/2 from the set of n subjects, half of whom got better in less than median time, and half in longer than median time. If the remedy is ineffective, the number of subjects who received the remedy and who recovered in less than median time is like the sum of n/2 draws with replacement from a box with two tickets in it: one with a “1” on it, and one with a “0” on it. This page illustrates the sampling distribution of random draws with or without from a box of numbered tickets.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;24&lt;/td&gt;&#xA;          &lt;td&gt;Breakdown Point.&lt;/td&gt;&#xA;          &lt;td&gt;The breakdown point of an estimator is the smallest fraction of observations one must corrupt to make the estimator take any value one wants.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;25&lt;/td&gt;&#xA;          &lt;td&gt;Categorical Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A variable whose value ranges over categories, such as {red, green, blue}, {male, female}, {Arizona, California, Montana, New York}, {short, tall}, {Asian, African-American, Caucasian, Hispanic, Native American, Polynesian}, {straight, curly}, etc. Some categorical variables are ordinal. The distinction between categorical variables and qualitative variables is a bit blurry. C.f. quantitative variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;26&lt;/td&gt;&#xA;          &lt;td&gt;Causation, causal relation.&lt;/td&gt;&#xA;          &lt;td&gt;Two variables are causally related if changes in the value of one cause the other to change. For example, if one heats a rigid container filled with a gas, that causes the pressure of the gas in the container to increase. Two variables can be associated without having any causal relation, and even if two variables have a causal relation, their correlation can be small or zero.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;          &lt;td&gt;Central Limit Theorem.&lt;/td&gt;&#xA;          &lt;td&gt;The central limit theorem states that the probability histograms of the sample mean and sample sum of n draws with replacement from a box of labeled tickets converge to a normal curve as the sample size n grows, in the following sense: As n grows, the area of the probability histogram for any range of values approaches the area under the normal curve for the same range of values, converted to standard units. See also the normal approximation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;Certain Event.&lt;/td&gt;&#xA;          &lt;td&gt;An event is certain if its probability is 100%. Even if an event is certain, it might not occur. However, by the complement rule, the chance that it does not occur is 0%.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;29&lt;/td&gt;&#xA;          &lt;td&gt;Chance variation, chance error.&lt;/td&gt;&#xA;          &lt;td&gt;A random variable can be decomposed into a sum of its expected value and chance variation around its expected value. The expected value of the chance variation is zero; the standard error of the chance variation is the same as the standard error of the random variable—the size of a “typical” difference between the random variable and its expected value. See also sampling error.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;30&lt;/td&gt;&#xA;          &lt;td&gt;Change of Units or Variables.&lt;/td&gt;&#xA;          &lt;td&gt;See also transformation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;31&lt;/td&gt;&#xA;          &lt;td&gt;Chebychev’s Inequality.&lt;/td&gt;&#xA;          &lt;td&gt;For lists: For every number k&amp;gt;0, the fraction of elements in a list that are k SD’s or further from the arithmetic mean of the list is at most 1/k2. For random variables: For every number k&amp;gt;0, the probability that a random variable X is k SEs or further from its expected value is at most 1/k2.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;32&lt;/td&gt;&#xA;          &lt;td&gt;Chi-square curve.&lt;/td&gt;&#xA;          &lt;td&gt;The chi-square curve is a family of curves that depend on a parameter called degrees of freedom (d.f.). The chi-square curve is an approximation to the probability histogram of the chi-square statistic for multinomial model if the expected number of outcomes in each category is large. The chi-square curve is positive, and its total area is 100%, so we can think of it as the probability histogram of a random variable. The balance point of the curve is d.f., so the expected value of the corresponding random variable would equal d.f.. The standard error of the corresponding random variable would be (2×d.f.)½. As d.f. grows, the shape of the chi-square curve approaches the shape of the normal curve. This page shows the chi-square curve.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;33&lt;/td&gt;&#xA;          &lt;td&gt;Chi-square Statistic.&lt;/td&gt;&#xA;          &lt;td&gt;The chi-square statistic is used to measure the agreement between categorical data and a multinomial model that predicts the relative frequency of outcomes in each possible category. Suppose there are n independent trials, each of which can result in one of k possible outcomes. Suppose that in each trial, the probability that outcome i occurs is pi, for i = 1, 2, … , k, and that these probabilities are the same in every trial. The expected number of times outcome 1 occurs in the n trials is n×p1; more generally, the expected number of times outcome i occurs is expectedi = n×pi. If the model be correct, we would expect the n trials to result in outcome i about n×pi times, give or take a bit. Let observedi denote the number of times an outcome of type i occurs in the n trials, for i = 1, 2, … , k. The chi-squared statistic summarizes the discrepancies between the expected number of times each outcome occurs (assuming that the model is true) and the observed number of times each outcome occurs, by summing the squares of the discrepancies, normalized by the expected numbers, over all the categories: chi-squared = (observed1 − expected1)2/expected1 + (observed2 − expected2)2/expected2 + … + (observedk − expectedk)2/expectedk. As the sample size n increases, if the model is correct, the sampling distribution of the chi-squared statistic is approximated increasingly well by the chi-squared curve with (#categories − 1) = k − 1 degrees of freedom (d.f.), in the sense that the chance that the chi-squared statistic is in any given range grows closer and closer to the area under the Chi-Squared curve over the same range. This page illustrates the sampling distribution of the chi-square statistic.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;Class Boundary.&lt;/td&gt;&#xA;          &lt;td&gt;A point that is the left endpoint of one class interval, and the right endpoint of another class interval.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;35&lt;/td&gt;&#xA;          &lt;td&gt;Class Interval.&lt;/td&gt;&#xA;          &lt;td&gt;In plotting a histogram, one starts by dividing the range of values into a set of non-overlapping intervals, called class intervals, in such a way that every datum is contained in some class interval. See the related entries class boundary and endpoint convention.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;36&lt;/td&gt;&#xA;          &lt;td&gt;Cluster Sample.&lt;/td&gt;&#xA;          &lt;td&gt;In a cluster sample, the sampling unit is a collection of population units, not single population units. For example, techniques for adjusting the U.S. census start with a sample of geographic blocks, then (try to) enumerate all inhabitants of the blocks in the sample to obtain a sample of people. This is an example of a cluster sample. (The blocks are chosen separately from different strata, so the overall design is a stratified cluster sample.)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;Combinations.&lt;/td&gt;&#xA;          &lt;td&gt;The number of combinations of n things taken k at a time is the number of ways of picking a subset of k of the n things, without replacement, and without regard to the order in which the elements of the subset are picked. The number of such combinations is nCk = n!/(k!(n−k)!), where k! (pronounced “k factorial”) is k×(k−1)×(k−2)× … × 1. The numbers nCk are also called the Binomial coefficients. From a set that has n elements one can form a total of 2n subsets of all sizes. For example, from the set {a, b, c}, which has 3 elements, one can form the 23 = 8 subsets {}, {a}, {b}, {c}, {a,b}, {a,c}, {b,c}, {a,b,c}. Because the number of subsets with k elements one can form from a set with n elements is nCk, and the total number of subsets of a set is the sum of the numbers of possible subsets of each size, it follows that nC0+nC1+nC2+ … +nCn = 2n. The calculator has a button (nCm) that lets you compute the number of combinations of m things chosen from a set of n things. To use the button, first type the value of n, then push the nCm button, then type the value of m, then press the “=” button.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;38&lt;/td&gt;&#xA;          &lt;td&gt;Complement.&lt;/td&gt;&#xA;          &lt;td&gt;The complement of a subset of a given set is the collection of all elements of the set that are not elements of the subset.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;Complement rule.&lt;/td&gt;&#xA;          &lt;td&gt;The probability of the complement of an event is 100% minus the probability of the event: P(Ac) = 100% − P(A).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;40&lt;/td&gt;&#xA;          &lt;td&gt;Compound proposition.&lt;/td&gt;&#xA;          &lt;td&gt;A logical proposition formed from other propositions using logical operations such as !, /, XOR, &amp;amp;, → and ↔.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;Conditional Probability.&lt;/td&gt;&#xA;          &lt;td&gt;Suppose we are interested in the probability that some event A occurs, and we learn that the event B occurred. How should we update the probability of A to reflect this new knowledge? This is what the conditional probability does: it says how the additional knowledge that B occurred should affect the probability that A occurred quantitatively. For example, suppose that A and B are mutually exclusive. Then if B occurred, A did not, so the conditional probability that A occurred given that B occurred is zero. At the other extreme, suppose that B is a subset of A, so that A must occur whenever B does. Then if we learn that B occurred, A must have occurred too, so the conditional probability that A occurred given that B occurred is 100%. For in-between cases, where A and B intersect, but B is not a subset of A, the conditional probability of A given B is a number between zero and 100%. Basically, one “restricts” the outcome space S to consider only the part of S that is in B, because we know that B occurred. For A to have happened given that B happened requires that AB happened, so we are interested in the event AB. To have a legitimate probability requires that P(S) = 100%, so if we are restricting the outcome space to B, we need to divide by the probability of B to make the probability of this new S be 100%. On this scale, the probability that AB happened is P(AB)/P(B). This is the definition of the conditional probability of A given B, provided P(B) is not zero (division by zero is undefined). Note that the special cases AB = {} (A and B are mutually exclusive) and AB = B (B is a subset of A) agree with our intuition as described at the top of this paragraph. Conditional probabilities satisfy the axioms of probability, just as ordinary probabilities do.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;42&lt;/td&gt;&#xA;          &lt;td&gt;Confidence Interval.&lt;/td&gt;&#xA;          &lt;td&gt;A confidence interval for a parameter is a random interval constructed from data in such a way that the probability that the interval contains the true value of the parameter can be specified before the data are collected. Confidence intervals are demonstrated in this page.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;          &lt;td&gt;Confidence Level.&lt;/td&gt;&#xA;          &lt;td&gt;The confidence level of a confidence interval is the chance that the interval that will result once data are collected will contain the corresponding parameter. If one computes confidence intervals again and again from independent data, the long-term limit of the fraction of intervals that contain the parameter is the confidence level.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;44&lt;/td&gt;&#xA;          &lt;td&gt;Confounding.&lt;/td&gt;&#xA;          &lt;td&gt;When the differences between the treatment and control groups other than the treatment produce differences in response that are not distinguishable from the effect of the treatment, those differences between the groups are said to be confounded with the effect of the treatment (if any). For example, prominent statisticians questioned whether differences between individuals that led some to smoke and others not to (rather than the act of smoking itself) were responsible for the observed difference in the frequencies with which smokers and non-smokers contract various illnesses. If that were the case, those factors would be confounded with the effect of smoking. Confounding is quite likely to affect observational studies and experiments that are not randomized. Confounding tends to be decreased by randomization. See also Simpson’s Paradox.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;Continuity Correction.&lt;/td&gt;&#xA;          &lt;td&gt;In using the normal approximation to the binomial probability histogram, one can get more accurate answers by finding the area under the normal curve corresponding to half-integers, transformed to standard units. This is clearest if we are seeking the chance of a particular number of successes. For example, suppose we seek to approximate the chance of 10 successes in 25 independent trials, each with probability p = 40% of success. The number of successes in this scenario has a binomial distribution with parameters n = 25 and p = 40%. The expected number of successes is np = 10, and the standard error is (np(1−p))½ = 6½ = 2.45. If we consider the area under the normal curve at the point 10 successes, transformed to standard units, we get zero: the area under a point is always zero. We get a better approximation by considering 10 successes to be the range from 9 1/2 to 10 1/2 successes. The only possible number of successes between 9 1/2 and 10 1/2 is 10, so this is exactly right for the binomial distribution. Because the normal curve is continuous and a binomial random variable is discrete, we need to “smear out” the binomial probability over an appropriate range. The lower endpoint of the range, 9 1/2 successes, is (9.5 − 10)/2.45 = −0.20 standard units. The upper endpoint of the range, 10 1/2 successes, is (10.5 − 10)/2.45 = +0.20 standard units. The area under the normal curve between −0.20 and +0.20 is about 15.8%. The true binomial probability is 25C10×(0.4)10×(0.6)15 = 16%. In a similar way, if we seek the normal approximation to the probability that a binomial random variable is in the range from i successes to k successes, inclusive, we should find the area under the normal curve from i−1/2 to k+1/2 successes, transformed to standard units. If we seek the probability of more than i successes and fewer than k successes, we should find the area under the normal curve corresponding to the range i+1/2 to k−1/2 successes, transformed to standard units. If we seek the probability of more than i but no more than k successes, we should find the area under the normal curve corresponding to the range i+1/2 to k+1/2 successes, transformed to standard units. If we seek the probability of at least i but fewer than k successes, we should find the area under the normal curve corresponding to the range i−1/2 to k−1/2 successes, transformed to standard units. Including or excluding the half-integer ranges at the ends of the interval in this manner is called the continuity correction.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;46&lt;/td&gt;&#xA;          &lt;td&gt;Consequent.&lt;/td&gt;&#xA;          &lt;td&gt;In a conditional p → q, the consequent is q.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;Continuous Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A quantitative variable is continuous if its set of possible values is uncountable. Examples include temperature, exact height, exact age (including parts of a second). In practice, one can never measure a continuous variable to infinite precision, so continuous variables are sometimes approximated by discrete variables. A random variable X is also called continuous if its set of possible values is uncountable, and the chance that it takes any particular value is zero (in symbols, if P(X = x) = 0 for every real number x). A random variable is continuous if and only if its cumulative probability distribution function is a continuous function (a function with no jumps).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;48&lt;/td&gt;&#xA;          &lt;td&gt;Contrapositive.&lt;/td&gt;&#xA;          &lt;td&gt;If p and q are two logical propositions, then the contrapositive of the proposition (p → q) is the proposition ((! q) → (!p) ). The contrapositive is logically equivalent to the original proposition.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;49&lt;/td&gt;&#xA;          &lt;td&gt;Control.&lt;/td&gt;&#xA;          &lt;td&gt;There are at least three senses of “control” in statistics: a member of the control group, to whom no treatment is given; a controlled experiment, and to control for a possible confounding variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;Controlled experiment.&lt;/td&gt;&#xA;          &lt;td&gt;An experiment that uses the method of comparison to evaluate the effect of a treatment by comparing treated subjects with a control group, who do not receive the treatment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;51&lt;/td&gt;&#xA;          &lt;td&gt;Controlled, randomized experiment.&lt;/td&gt;&#xA;          &lt;td&gt;A controlled experiment in which the assignment of subjects to the treatment group or control group is done at random, for example, by tossing a coin.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;52&lt;/td&gt;&#xA;          &lt;td&gt;Control for a variable.&lt;/td&gt;&#xA;          &lt;td&gt;To control for a variable is to try to separate its effect from the treatment effect, so it will not confound with the treatment. There are many methods that try to control for variables. Some are based on matching individuals between treatment and control; others use assumptions about the nature of the effects of the variables to try to model the effect mathematically, for example, using regression.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;53&lt;/td&gt;&#xA;          &lt;td&gt;Control group.&lt;/td&gt;&#xA;          &lt;td&gt;The subjects in a controlled experiment who do not receive the treatment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;54&lt;/td&gt;&#xA;          &lt;td&gt;Convenience Sample.&lt;/td&gt;&#xA;          &lt;td&gt;A sample drawn because of its convenience; it is not a probability sample. For example, I might take a sample of opinions in Berkeley (where I live) by just asking my 10 nearest neighbors. That would be a sample of convenience, and would be unlikely to be representative of all of Berkeley. Samples of convenience are not typically representative, and it is not possible to quantify how unrepresentative results based on samples of convenience are likely to be. Convenience samples are to be avoided, and results based on convenience samples are to be viewed with suspicion. See also quota sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;55&lt;/td&gt;&#xA;          &lt;td&gt;Converge, convergence.&lt;/td&gt;&#xA;          &lt;td&gt;A sequence of numbers x1, x2, x3 … converges if there is a number x such that for any number E&amp;gt;0, there is a number k (which can depend on E) such that /xj − x/ &amp;lt; E whenever j &amp;gt; k. If such a number x exists, it is called the limit of the sequence x1, x2, x3 … .&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;56&lt;/td&gt;&#xA;          &lt;td&gt;Convergence in probability.&lt;/td&gt;&#xA;          &lt;td&gt;A sequence of random variables X1, X2, X3 … converges in probability if there is a random variable X such that for any number E&amp;gt;0, the sequence of numbers P(/X1 − X/ &amp;lt; e), P(/X2 − X/ &amp;lt; e), P(/X3 − X/ &amp;lt; e), … converges to 100%.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;57&lt;/td&gt;&#xA;          &lt;td&gt;Converse.&lt;/td&gt;&#xA;          &lt;td&gt;If p and q are two logical propositions, then the converse of the proposition (p → q) is the proposition (q → p).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;58&lt;/td&gt;&#xA;          &lt;td&gt;Correlation.&lt;/td&gt;&#xA;          &lt;td&gt;A measure of linear association between two (ordered) lists. Two variables can be strongly correlated without having any causal relationship, and two variables can have a causal relationship and yet be uncorrelated.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;59&lt;/td&gt;&#xA;          &lt;td&gt;Correlation coefficient.&lt;/td&gt;&#xA;          &lt;td&gt;The correlation coefficient r is a measure of how nearly a scatterplot falls on a straight line. The correlation coefficient is always between −1 and +1. To compute the correlation coefficient of a list of pairs of measurements (X,Y), first transform X and Y individually into standard units. Multiply corresponding elements of the transformed pairs to get a single list of numbers. The correlation coefficient is the mean of that list of products. This page contains a tool that lets you generate bivariate data with any correlation coefficient you want.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;60&lt;/td&gt;&#xA;          &lt;td&gt;Counting.&lt;/td&gt;&#xA;          &lt;td&gt;To count a set of things is to put it in one to one correspondence with a consecutive subset of the positive integers (counting numbers).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;61&lt;/td&gt;&#xA;          &lt;td&gt;Counting numbers, natural numbers.&lt;/td&gt;&#xA;          &lt;td&gt;The counting numbers are the strictly positive integers ({1, 2, 3, … }). (Some authorities include (0) among the counting numbers.)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;62&lt;/td&gt;&#xA;          &lt;td&gt;Countable Set.&lt;/td&gt;&#xA;          &lt;td&gt;A set is countable if its elements can be put in one-to-one correspondence with a subset of the counting numbers. For example, the sets {0, 1, 7, −3}, {red, green, blue}, {…,−2, −1, 0, 1, 2, …}, {straight, curly}, and the set of all fractions, are countable. If a set is not countable, it is uncountable. The set of all real numbers is uncountable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;63&lt;/td&gt;&#xA;          &lt;td&gt;Cover.&lt;/td&gt;&#xA;          &lt;td&gt;A confidence interval is said to cover if the interval contains the true value of the parameter. Before the data are collected, the chance that the confidence interval will contain the parameter value is the coverage probability, which equals the confidence level after the data are collected and the confidence interval is actually computed.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;64&lt;/td&gt;&#xA;          &lt;td&gt;Coverage probability.&lt;/td&gt;&#xA;          &lt;td&gt;The coverage probability of a procedure for making confidence intervals is the chance that the procedure produces an interval that covers the truth.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;65&lt;/td&gt;&#xA;          &lt;td&gt;Critical value&lt;/td&gt;&#xA;          &lt;td&gt;The critical value in an hypothesis test is the value of the test statistic beyond which we would reject the null hypothesis. The critical value is set so that the probability that the test statistic is beyond the critical value is at most equal to the significance level if the null hypothesis be true.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;66&lt;/td&gt;&#xA;          &lt;td&gt;Cross-sectional study.&lt;/td&gt;&#xA;          &lt;td&gt;A cross-sectional study compares different individuals to each other at the same time—it looks at a cross-section of a population. The differences between those individuals can confound with the effect being explored. For example, in trying to determine the effect of age on sexual promiscuity, a cross-sectional study would be likely to confound the effect of age with the effect of the mores the subjects were taught as children: the older individuals were probably raised with a very different attitude towards promiscuity than the younger subjects. Thus it would be imprudent to attribute differences in promiscuity to the aging process. C.f. longitudinal study.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;67&lt;/td&gt;&#xA;          &lt;td&gt;Cumulative Probability Distribution Function (cdf).&lt;/td&gt;&#xA;          &lt;td&gt;The cumulative distribution function of a random variable is the chance that the random variable is less than or equal to x, as a function of x. In symbols, if F is the cdf of the random variable X, then F(x) = P( X ≤ x). The cumulative distribution function must tend to zero as x approaches minus infinity, and must tend to unity as x approaches infinity. It is a positive function, and increases monotonically: if y &amp;gt; x, then F(y) ≥ F(x). The cumulative distribution function completely characterizes the probability distribution of a random variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;68&lt;/td&gt;&#xA;          &lt;td&gt;de Morgan’s Laws&lt;/td&gt;&#xA;          &lt;td&gt;de Morgan’s Laws are identities involving logical operations: the negation of a conjunction is logically equivalent to the disjunction of the negations, and the negation of a disjunction is logically equivalent to the conjunction of the negations. In symbols, !(p &amp;amp; q) = !p / !q and !(p / q) = !p &amp;amp; !q.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;69&lt;/td&gt;&#xA;          &lt;td&gt;Deck of Cards.&lt;/td&gt;&#xA;          &lt;td&gt;A standard deck of playing cards contains 52 cards, 13 each of four suits: spades, hearts, diamonds, and clubs. The thirteen cards of each suit are {ace, 2, 3, 4, 5, 6, 7, 8, 9, 10, jack, queen, king}. The face cards are {jack, queen, king}. It is typically assumed that if a deck of cards is shuffled well, it is equally likely to be in each possible ordering. There are 52! (52 factorial) possible orderings.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;70&lt;/td&gt;&#xA;          &lt;td&gt;Dependent Events, Dependent Random Variables.&lt;/td&gt;&#xA;          &lt;td&gt;Two events or random variables are dependent if they are not independent.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;71&lt;/td&gt;&#xA;          &lt;td&gt;Dependent Variable.&lt;/td&gt;&#xA;          &lt;td&gt;In regression, the variable whose values are supposed to be explained by changes in the other variable (the the independent or explanatory variable). Usually one regresses the dependent variable on the independent variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;72&lt;/td&gt;&#xA;          &lt;td&gt;Density, Density Scale.&lt;/td&gt;&#xA;          &lt;td&gt;The vertical axis of a histogram has units of percent per unit of the horizontal axis. This is called a density scale; it measures how “dense” the observations are in each bin. See also probability density.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;73&lt;/td&gt;&#xA;          &lt;td&gt;Denying the antecedent.&lt;/td&gt;&#xA;          &lt;td&gt;A logical fallacy that argues from the premise A → B and the premise !A that therefore, !B. The name comes from the fact that the operation denies (i.e., asserts the negation of) the antecedent (A) in the conditional.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;74&lt;/td&gt;&#xA;          &lt;td&gt;Denying the consequent.&lt;/td&gt;&#xA;          &lt;td&gt;A valid logical argument that concludes from the premise A → B and the premise !B that therefore, !A. The name comes from the fact that the operation denies (i.e., asserts the logical negation) the consequent (B) in the conditional.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;75&lt;/td&gt;&#xA;          &lt;td&gt;Deviation.&lt;/td&gt;&#xA;          &lt;td&gt;A deviation is the difference between a datum and some reference value, typically the mean of the data. In computing the SD, one finds the rms of the deviations from the mean, the differences between the individual data and the mean of the data.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;76&lt;/td&gt;&#xA;          &lt;td&gt;Discrete Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A quantitative variable whose set of possible values is countable. Typical examples of discrete variables are variables whose possible values are a subset of the integers, such as Social Security numbers, the number of people in a family, ages rounded to the nearest year, etc. Discrete variables are “chunky.” C.f. continuous variable. A discrete random variable is one whose set of possible values is countable. A random variable is discrete if and only if its cumulative probability distribution function is a stair-step function; i.e., if it is piecewise constant and only increases by jumps.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;77&lt;/td&gt;&#xA;          &lt;td&gt;Disjoint or Mutually Exclusive Events.&lt;/td&gt;&#xA;          &lt;td&gt;Two events are disjoint or mutually exclusive if the occurrence of one is incompatible with the occurrence of the other; that is, if they can’t both happen at once (if they have no outcome in common). Equivalently, two events are disjoint if their intersection is the empty set.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;78&lt;/td&gt;&#xA;          &lt;td&gt;Disjoint or Mutually Exclusive Sets.&lt;/td&gt;&#xA;          &lt;td&gt;Two sets are disjoint or mutually exclusive if they have no element in common. Equivalently, two sets are disjoint if their intersection is the empty set.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;79&lt;/td&gt;&#xA;          &lt;td&gt;Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The distribution of a set of numerical data is how their values are distributed over the real numbers. It is completely characterized by the empirical distribution function. Similarly, the probability distribution of a random variable is completely characterized by its probability distribution function. Sometimes the word “distribution” is used as a synonym for the empirical distribution function or the probability distribution function. If two or more random variables are defined for the same experiment, they have a joint probability distribution.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;80&lt;/td&gt;&#xA;          &lt;td&gt;Distribution Function, Empirical.&lt;/td&gt;&#xA;          &lt;td&gt;The empirical (cumulative) distribution function of a set of numerical data is, for each real value of x, the fraction of observations that are less than or equal to x. A plot of the empirical distribution function is an uneven set of stairs. The width of the stairs is the spacing between adjacent data; the height of the stairs depends on how many data have exactly the same value. The distribution function is zero for small enough (negative) values of x, and is unity for large enough values of x. It increases monotonically: if y &amp;gt; x, the empirical distribution function evaluated at y is at least as large as the empirical distribution function evaluated at x.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;81&lt;/td&gt;&#xA;          &lt;td&gt;Double-Blind, Double-Blind Experiment.&lt;/td&gt;&#xA;          &lt;td&gt;In a double-blind experiment, neither the subjects nor the people evaluating the subjects knows who is in the treatment group and who is in the control group. This mitigates the placebo effect and guards against conscious and unconscious prejudice for or against the treatment on the part of the evaluators.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;82&lt;/td&gt;&#xA;          &lt;td&gt;Ecological Correlation.&lt;/td&gt;&#xA;          &lt;td&gt;The correlation between averages of groups of individuals, instead of individuals. Ecological correlation can be misleading about the association of individuals.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;83&lt;/td&gt;&#xA;          &lt;td&gt;Element of a Set.&lt;/td&gt;&#xA;          &lt;td&gt;See member.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;84&lt;/td&gt;&#xA;          &lt;td&gt;Empirical Law of Averages.&lt;/td&gt;&#xA;          &lt;td&gt;The Empirical Law of Averages lies at the base of the frequency theory of probability. This law, which is, in fact, an assumption about how the world works, rather than a mathematical or physical law, states that if one repeats a random experiment over and over, independently and under “identical” conditions, the fraction of trials that result in a given outcome converges to a limit as the number of trials grows without bound.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;85&lt;/td&gt;&#xA;          &lt;td&gt;Empty Set.&lt;/td&gt;&#xA;          &lt;td&gt;The empty set, denoted {} or ∅, is the set that has no members.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;86&lt;/td&gt;&#xA;          &lt;td&gt;Endpoint Convention.&lt;/td&gt;&#xA;          &lt;td&gt;In plotting a histogram, one must decide whether to include a datum that lies at a class boundary with the class interval to the left or the right of the boundary. The rule for making this assignment is called an endpoint convention. The two standard endpoint conventions are (1) to include the left endpoint of all class intervals and exclude the right, except for the rightmost class interval, which includes both of its endpoints, and (2) to include the right endpoint of all class intervals and exclude the left, except for the leftmost interval, which includes both of its endpoints.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;87&lt;/td&gt;&#xA;          &lt;td&gt;Equally Likely Outcomes.&lt;/td&gt;&#xA;          &lt;td&gt;According to the equally likely outcome Theory of Probability, if an experiment has a finite number possible outcomes and there is no reason Nature should prefer any of those outcomes over any other (e.g., because the outcome is the result of rolling a symmetric die or tossing a perfectly balanced coin or thoroughly shuffling a deck of cards), then each of those possible outcomes has the same probability. See also Laplace’s Principle of Insufficient Reason.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;88&lt;/td&gt;&#xA;          &lt;td&gt;Estimator.&lt;/td&gt;&#xA;          &lt;td&gt;An estimator is a rule for “guessing” the value of a population parameter based on a random sample from the population. An estimator is a random variable, because its value depends on which particular sample is obtained, which is random. A canonical example of an estimator is the sample mean, which is an estimator of the population mean.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;89&lt;/td&gt;&#xA;          &lt;td&gt;Event.&lt;/td&gt;&#xA;          &lt;td&gt;An event is a subset of outcome space. An event determined by a random variable is an event of the form A=(X is in A). When the random variable X is observed, that determines whether or not A occurs: if the value of X happens to be in A, A occurs; if not, A does not occur.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;90&lt;/td&gt;&#xA;          &lt;td&gt;Exhaustive.&lt;/td&gt;&#xA;          &lt;td&gt;A collection of events {A1, A2, A3, … } exhausts the set A if, for the event A to occur, at least one of those sets must also occur; that is, if S ⊂ A1 ∪ A2 ∪ A3 ∪ … If the event A is not specified, it is assumed to be the entire outcome space S.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;91&lt;/td&gt;&#xA;          &lt;td&gt;Expectation, Expected Value.&lt;/td&gt;&#xA;          &lt;td&gt;The expected value of a random variable is the long-term limiting average of its values in independent repeated experiments. The expected value of the random variable X is denoted EX or E(X). For a discrete random variable (one that has a countable number of possible values) the expected value is the weighted average of its possible values, where the weight assigned to each possible value is the chance that the random variable takes that value. One can think of the expected value of a random variable as the point at which its probability histogram would balance, if it were cut out of a uniform material. Taking the expected value is a linear operation: if X and Y are two random variables, the expected value of their sum is the sum of their expected values (E(X+Y) = E(X) + E(Y)), and the expected value of a constant a times a random variable X is the constant times the expected value of X (E(a×X ) = a× E(X)).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;92&lt;/td&gt;&#xA;          &lt;td&gt;Experiment.&lt;/td&gt;&#xA;          &lt;td&gt;What distinguishes an experiment from an observational study is that in an experiment, the experimenter chooses who receives the treatment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;93&lt;/td&gt;&#xA;          &lt;td&gt;Explanatory Variable.&lt;/td&gt;&#xA;          &lt;td&gt;In regression, the explanatory or independent variable is the one that is supposed to “explain” the other. For example, in examining crop yield versus quantity of fertilizer applied, the quantity of fertilizer would be the explanatory or independent variable, and the crop yield would be the dependent variable. In experiments, the explanatory variable is the one that is manipulated; the one that is observed is the dependent variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;94&lt;/td&gt;&#xA;          &lt;td&gt;Extrapolation.&lt;/td&gt;&#xA;          &lt;td&gt;See interpolation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;95&lt;/td&gt;&#xA;          &lt;td&gt;Factorial.&lt;/td&gt;&#xA;          &lt;td&gt;For an integer k that is greater than or equal to 1, k! (pronounced “k factorial”) is k×(k−1)×(k−2)× …×1. By convention, 0! = 1. There are k! ways of ordering k distinct objects. For example, 9! is the number of batting orders of 9 baseball players, and 52! is the number of different ways a standard deck of playing cards can be ordered. The calculator above has a button to compute the factorial of a number. To compute k!, first type the value of k, then press the button labeled “!”.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;96&lt;/td&gt;&#xA;          &lt;td&gt;Fair Bet.&lt;/td&gt;&#xA;          &lt;td&gt;A fair bet is one for which the expected value of the payoff is zero, after accounting for the cost of the bet. For example, suppose I offer to pay you $2 if a fair coin lands heads, but you must ante up $1 to play. Your expected payoff is −$1+ $0×P(tails) + $2×P(heads) = −$1 + $2×50% = $0. This is a fair bet—in the long run, if you made this bet over and over again, you would expect to break even.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;97&lt;/td&gt;&#xA;          &lt;td&gt;False Discovery Rate.&lt;/td&gt;&#xA;          &lt;td&gt;In testing a collection of hypotheses, the false discovery rate is the fraction of rejected null hypotheses that are rejected erroneously (the number of Type I errors divided by the number of rejected null hypotheses), with the convention that if no hypothesis is rejected, the false discovery rate is zero.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;98&lt;/td&gt;&#xA;          &lt;td&gt;Finite, finite set.&lt;/td&gt;&#xA;          &lt;td&gt;A set is finite if it has a finite number of elements, that is, if for some natural number n, the elements can be put in one-to-one correspondence with the set {1, 2, … n}.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;99&lt;/td&gt;&#xA;          &lt;td&gt;Finite Population Correction.&lt;/td&gt;&#xA;          &lt;td&gt;When sampling without replacement, as in a simple random sample, the SE of sample sums and sample means depends on the fraction of the population that is in the sample: the greater the fraction, the smaller the SE. Sampling with replacement is like sampling from an infinitely large population. The adjustment to the SE for sampling without replacement is called the finite population correction. The SE for sampling without replacement is smaller than the SE for sampling with replacement by the finite population correction factor ((N −n)/(N − 1))½. Note that for sample size n=1, there is no difference between sampling with and without replacement; the finite population correction is then unity. If the sample size is the entire population of N units, there is no variability in the result of sampling without replacement (every member of the population is in the sample exactly once), and the SE should be zero. This is indeed what the finite population correction gives (the numerator vanishes).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;100&lt;/td&gt;&#xA;          &lt;td&gt;Fisher’s exact test (for the equality of two percentages)&lt;/td&gt;&#xA;          &lt;td&gt;Consider two populations of zeros and ones. Let p1 be the proportion of ones in the first population, and let p2 be the proportion of ones in the second population. We would like to test the null hypothesis that p1 = p2 on the basis of a simple random sample from each population. Let n1 be the size of the sample from population 1, and let n2 be the size of the sample from population 2. Let G be the total number of ones in both samples. If the null hypothesis be true, the two samples are like one larger sample from a single population of zeros and ones. The allocation of ones between the two samples would be expected to be proportional to the relative sizes of the samples, but would have some chance variability. Conditional on G and the two sample sizes, under the null hypothesis, the tickets in the first sample are like a random sample of size n1 without replacement from a collection of N = n1 + n2 units of which G are labeled with ones. Thus, under the null hypothesis, the number of tickets labeled with ones in the first sample has (conditional on G) an hypergeometric distribution with parameters N, G, and n1. Fisher’s exact test uses this distribution to set the ranges of observed values of the number of ones in the first sample for which we would reject the null hypothesis.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;101&lt;/td&gt;&#xA;          &lt;td&gt;Football-Shaped Scatterplot.&lt;/td&gt;&#xA;          &lt;td&gt;In a football-shaped scatterplot, most of the points lie within a tilted oval, shaped more-or-less like a football. A football-shaped scatterplot is one in which the data are homoscedastically scattered about a straight line.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;102&lt;/td&gt;&#xA;          &lt;td&gt;Frame, sampling frame.&lt;/td&gt;&#xA;          &lt;td&gt;A sampling frame is a collection of units from which a sample will be drawn. Ideally, the frame is identical to the population we want to learn about; more typically, the frame is only a subset of the population of interest. The difference between the frame and the population can be a source of bias in sampling design, if the parameter of interest has a different value for the frame than it does for the population. For example, one might desire to estimate the current annual average income of 1998 graduates of the University of California at Berkeley. I propose to use the sample mean income of a sample of graduates drawn at random. To facilitate taking the sample and contacting the graduates to obtain income information from them, I might draw names at random from the list of 1998 graduates for whom the alumni association has an accurate current address. The population is the collection of 1998 graduates; the frame is those graduates who have current addresses on file with the alumni association. If there is a tendency for graduates with higher incomes to have up-to-date addresses on file with the alumni association, that would introduce a positive bias into the annual average income estimated from the sample by the sample mean.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;103&lt;/td&gt;&#xA;          &lt;td&gt;FPP.&lt;/td&gt;&#xA;          &lt;td&gt;Statistics, third edition, by Freedman, Pisani, and Purves, published by W.W. Norton, 1997.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;104&lt;/td&gt;&#xA;          &lt;td&gt;Frequency theory of probability.&lt;/td&gt;&#xA;          &lt;td&gt;See Probability, Theories of.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;105&lt;/td&gt;&#xA;          &lt;td&gt;Frequency table.&lt;/td&gt;&#xA;          &lt;td&gt;A table listing the frequency (number) or relative frequency (fraction or percentage) of observations in different ranges, called class intervals.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;106&lt;/td&gt;&#xA;          &lt;td&gt;Fundamental Rule of Counting.&lt;/td&gt;&#xA;          &lt;td&gt;If a sequence of experiments or trials T1, T2, T3, …, Tk could result, respectively, in n1, n2 n3, …, nk possible outcomes, and the numbers n1, n2 n3, …, nk do not depend on which outcomes actually occurred, the entire sequence of k experiments has n1× n2 × n3× …× nk possible outcomes.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;107&lt;/td&gt;&#xA;          &lt;td&gt;Game Theory.&lt;/td&gt;&#xA;          &lt;td&gt;A field of study that bridges mathematics, statistics, economics, and psychology. It is used to study economic behavior, and to model conflict between nations, for example, “nuclear stalemate” during the Cold War.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;108&lt;/td&gt;&#xA;          &lt;td&gt;Geometric Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The geometric distribution describes the number of trials up to and including the first success, in independent trials with the same probability of success. The geometric distribution depends only on the single parameter p, the probability of success in each trial. For example, the number of times one must toss a fair coin until the first time the coin lands heads has a geometric distribution with parameter p = 50%. The geometric distribution assigns probability p×(1 − p)k−1to the event that it takes k trials to the first success. The expected value of the geometric distribution is 1/p, and its SE is (1−p)½/p.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;109&lt;/td&gt;&#xA;          &lt;td&gt;Geometric Mean.&lt;/td&gt;&#xA;          &lt;td&gt;The geometric mean of n numbers {x1, x2, x3, …, xn} is the nth root of their product: (x1×x2×x3× … ×xn)1/n.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;110&lt;/td&gt;&#xA;          &lt;td&gt;Graph of Averages.&lt;/td&gt;&#xA;          &lt;td&gt;For bivariate data, a graph of averages is a plot of the average values of one variable (say y) for small ranges of values of the other variable (say x), against the value of the second variable (x) at the midpoints of the ranges.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;111&lt;/td&gt;&#xA;          &lt;td&gt;Heteroscedasticity.&lt;/td&gt;&#xA;          &lt;td&gt;“Mixed scatter.” A scatterplot or residual plot shows heteroscedasticity if the scatter in vertical slices through the plot depends on where you take the slice. Linear regression is not usually a good idea if the data are heteroscedastic.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;112&lt;/td&gt;&#xA;          &lt;td&gt;Histogram.&lt;/td&gt;&#xA;          &lt;td&gt;A histogram is a kind of plot that summarizes how data are distributed. Starting with a set of class intervals, the histogram is a set of rectangles (“bins”) sitting on the horizontal axis. The bases of the rectangles are the class intervals, and their heights are such that their areas are proportional to the fraction of observations in the corresponding class intervals. That is, the height of a given rectangle is the fraction of observations in the corresponding class interval, divided by the length of the corresponding class interval. A histogram does not need a vertical scale, because the total area of the histogram must equal 100%. The units of the vertical axis are percent per unit of the horizontal axis. This is called the density scale. The horizontal axis of a histogram needs a scale. If any observations coincide with the endpoints of class intervals, the endpoint convention is important. This page contains a histogram tool, with controls to highlight ranges of values and read their areas.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;113&lt;/td&gt;&#xA;          &lt;td&gt;Historical Controls.&lt;/td&gt;&#xA;          &lt;td&gt;Sometimes, the a treatment group is compared with individuals from another epoch who did not receive the treatment; for example, in studying the possible effect of fluoridated water on childhood cancer, we might compare cancer rates in a community before and after fluorine was added to the water supply. Those individuals who were children before fluoridation started would comprise an historical control group. Experiments and studies with historical controls tend to be more susceptible to confounding than those with contemporary controls, because many factors that might affect the outcome other than the treatment tend to change over time as well. (In this example, the level of other potential carcinogens in the environment also could have changed.)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;114&lt;/td&gt;&#xA;          &lt;td&gt;Homoscedasticity.&lt;/td&gt;&#xA;          &lt;td&gt;“Same scatter.” A scatterplot or residual plot shows homoscedasticity if the scatter in vertical slices through the plot does not depend much on where you take the slice. C.f. heteroscedasticity.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;115&lt;/td&gt;&#xA;          &lt;td&gt;House Edge.&lt;/td&gt;&#xA;          &lt;td&gt;In casino games, the expected payoff to the bettor is negative: the house (casino) tends to win money in the long run. The amount of money the house would expect to win for each $1 wagered on a particular bet (such as a bet on “red” in roulette) is called the house edge for that bet.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;116&lt;/td&gt;&#xA;          &lt;td&gt;HTLWS.&lt;/td&gt;&#xA;          &lt;td&gt;The book How to lie with Statistics by D. Huff.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;117&lt;/td&gt;&#xA;          &lt;td&gt;Hypergeometric Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The hypergeometric distribution with parameters N, G and n is the distribution of the number of “good” objects in a simple random sample of size n (i.e., a random sample without replacement in which every subset of size n has the same chance of occurring) from a population of N objects of which G are “good.” The chance of getting exactly g good objects in such a sample is GCg × N−GCn−g/NCn, provided g ≤ n, g ≤ G, and n − g ≤ N − G. (The probability is zero otherwise.) The expected value of the hypergeometric distribution is n×G/N, and its standard error is ((N−n)/(N−1))½ × (n × G/N × (1−G/N) )½.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;118&lt;/td&gt;&#xA;          &lt;td&gt;Hypothesis testing.&lt;/td&gt;&#xA;          &lt;td&gt;Statistical hypothesis testing is formalized as making a decision between rejecting or not rejecting a null hypothesis, on the basis of a set of observations. Two types of errors can result from any decision rule (test): rejecting the null hypothesis when it is true (a Type I error), and failing to reject the null hypothesis when it is false (a Type II error). For any hypothesis, it is possible to develop many different decision rules (tests). Typically, one specifies ahead of time the chance of a Type I error one is willing to allow. That chance is called the significance level of the test or decision rule. For a given significance level, one way of deciding which decision rule is best is to pick the one that has the smallest chance of a Type II error when a given alternative hypothesis is true. The chance of correctly rejecting the null hypothesis when a given alternative hypothesis is true is called the power of the test against that alternative.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;119&lt;/td&gt;&#xA;          &lt;td&gt;iff, if and only if, ↔&lt;/td&gt;&#xA;          &lt;td&gt;If p and q are two logical propositions, then(p ↔ q) is a proposition that is true when both p and q are true, and when both p and q are false. It is logically equivalent to the proposition ( (p → q) &amp;amp; (q → p) ) and to the proposition ( (p &amp;amp; q)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;120&lt;/td&gt;&#xA;          &lt;td&gt;Implies, logical implication, → , conditional, if-then&lt;/td&gt;&#xA;          &lt;td&gt;Logical implication is an operation on two logical propositions. If p and q are two logical propositions, (p → q), pronounced “p implies q” or “if p then q” is a logical proposition that is true if p is false, or if both p and q are true. The proposition (p → q) is logically equivalent to the proposition ((!p) / q). In the conditional p → q, the antecedent is p and the consequent is q.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;121&lt;/td&gt;&#xA;          &lt;td&gt;Independent, independence.&lt;/td&gt;&#xA;          &lt;td&gt;Two events A and B are (statistically) independent if the chance that they both happen simultaneously is the product of the chances that each occurs individually; i.e., if P(AB) = P(A)P(B). This is essentially equivalent to saying that learning that one event occurs does not give any information about whether the other event occurred too: the conditional probability of A given B is the same as the unconditional probability of A, i.e., P(A/B) = P(A). Two random variables X and Y are independent if all events they determine are independent, for example, if the event {a &amp;lt; X ≤ b} is independent of the event {c &amp;lt; Y ≤ d} for all choices of a, b, c, and d. A collection of more than two random variables is independent if for every proper subset of the variables, every event determined by that subset of the variables is independent of every event determined by the variables in the complement of the subset. For example, the three random variables X, Y, and Z are independent if every event determined by X is independent of every event determined by Y and every event determined by X is independent of every event determined by Y and Z and every event determined by Y is independent of every event determined by X and Z and every event determined by Z is independent of every event determined by X and Y.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;122&lt;/td&gt;&#xA;          &lt;td&gt;Independent and identically distributed (iid).&lt;/td&gt;&#xA;          &lt;td&gt;A collection of two or more random variables {X1, X2, … , } is independent and identically distributed if the variables have the same probability distribution, and are independent.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;123&lt;/td&gt;&#xA;          &lt;td&gt;Independent Variable.&lt;/td&gt;&#xA;          &lt;td&gt;In regression, the independent variable is the one that is supposed to explain the other; the term is a synonym for “explanatory variable.” Usually, one regresses the “dependent variable” on the “independent variable.” There is not always a clear choice of the independent variable. The independent variable is usually plotted on the horizontal axis. Independent in this context does not mean the same thing as statistically independent.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;124&lt;/td&gt;&#xA;          &lt;td&gt;Indicator Random Variable.&lt;/td&gt;&#xA;          &lt;td&gt;The indicator [random variable] of the event A, often written 1A, is the random variable that equals unity if A occurs, and zero if A does not occur. The expected value of the indicator of A is the probability of A, P(A), and the standard error of the indicator of A is (P(A)×(1−P(A))½. The sum 1A + 1B + 1C + … of the indicators of a collection of events {A, B, C, …} counts how many of the events {A, B, C, …} occur in a given trial. The product of the indicators of a collection of events is the indicator of the intersection of the events (the product equals one if and only if all of indicators equal one). The maximum of the indicators of a collection of events is the indicator of the union of the events (the maximum equals one if any of the indicators equals one).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;125&lt;/td&gt;&#xA;          &lt;td&gt;Inter-quartile Range (IQR).&lt;/td&gt;&#xA;          &lt;td&gt;The inter-quartile range of a list of numbers is the upper quartile minus the lower quartile.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;126&lt;/td&gt;&#xA;          &lt;td&gt;Interpolation.&lt;/td&gt;&#xA;          &lt;td&gt;Given a set of bivariate data (x, y), to impute a value of y corresponding to some value of x at which there is no measurement of y is called interpolation, if the value of x is within the range of the measured values of x. If the value of x is outside the range of measured values, imputing a corresponding value of y is called extrapolation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;127&lt;/td&gt;&#xA;          &lt;td&gt;Intersection.&lt;/td&gt;&#xA;          &lt;td&gt;The intersection of two or more sets is the set of elements that all the sets have in common; the elements contained in every one of the sets. The intersection of the events A and B is written “A∩B,” “A and B,” and “AB.” C.f. union. See also Venn diagrams.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;128&lt;/td&gt;&#xA;          &lt;td&gt;Invalid (logical) argument.&lt;/td&gt;&#xA;          &lt;td&gt;An invalid logical argument is one in which the truth of the premises does not guarantee the truth of the conclusion. For example, the following logical argument is invaldraft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: If the forecast calls for rain, I will not wear sandals. The forecast does not call for rain. Therefore, I will wear sandals. See also valid argument.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;129&lt;/td&gt;&#xA;          &lt;td&gt;Joint Probability Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;If X1, X2, … , Xk are random variables defined for the same experiment, their joint probability distribution gives the probability of events determined by the collection of random variables: for any collection of sets of numbers {A1, … , Ak}, the joint probability distribution determines P( (X1 is in A1) and (X2 is in A2) and … and (Xk is in Ak) ). For example, suppose we roll two fair dice independently. Let X1 be the number of spots that show on the first die, and let X2 be the total number of spots that show on both dice. Then the joint distribution of X1 and X2 is as follows: P(X1 = 1, X2 = 2) = P(X1 = 1, X2 = 3) = P(X1 = 1, X2 = 4) = P(X1 = 1, X2 = 5) = P(X1 = 1, X2 = 6) = P(X1 = 1, X2 = 7) = P(X1 = 2, X2 = 3) = P(X1 = 2, X2 = 4) = P(X1 = 2, X2 = 5) = P(X1 = 2, X2 = 6) = P(X1 = 2, X2 = 7) = P(X1 = 2, X2 = 8) = … … P(X1 = 6, X2 = 7) = P(X1 = 6, X2 = 8) = P(X1 = 6, X2 = 9) = P(X1 = 6, X2 = 10) = P(X1 = 6, X2 = 11) = P(X1 = 6, X2 = 12) = 1/36. If a collection of random variables is independent, their joint probability distribution is the product of their marginal probability distributions, their individual probability distributions without regard for the value of the other variables. In this example, the marginal probability distribution of X1 is P(X1 = 1) = P(X1 = 2) = P(X1 = 3) = P(X1 = 4) = P(X1 = 5) = P(X1 = 6) = 1/6, and the marginal probability distribution of X2 is P(X2 = 2) = P(X2 = 12) = 1/36 P(X2 = 3) = P(X2 = 11) = 1/18 P(X2 = 4) = P(X2 = 10) = 3/36 P(X2 = 5) = P(X2 = 9) = 1/9 P(X2 = 6) = P(X2 = 8) = 5/36 P(X2 = 7) = 1/6. Note that P(X1 = 1, X2 = 10) = 0, while P(X1 = 1)×P(X2 = 10) = (1/6)(3/36) = 1/72. The joint probability is not equal to the product of the marginal probabilities: X1 and X2 are dependent random variables.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;130&lt;/td&gt;&#xA;          &lt;td&gt;Law of Averages.&lt;/td&gt;&#xA;          &lt;td&gt;The Law of Averages says that the average of independent observations of random variables that have the same probability distribution is increasingly likely to be close to the expected value of the random variables as the number of observations grows. More precisely, if X1, X2, X3, …, are independent random variables with the same probability distribution, and E(X) is their common expected value, then for every number ε &amp;gt; 0, P{/(X1 + X2 + … + Xn)/n − E(X) / &amp;lt; ε} converges to 100% as n grows. This is equivalent to saying that the sequence of sample means X1, (X1+X2)/2, (X1+X2+X3)/3, … converges in probability to E(X).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;131&lt;/td&gt;&#xA;          &lt;td&gt;Law of Large Numbers.&lt;/td&gt;&#xA;          &lt;td&gt;The Law of Large Numbers says that in repeated, independent trials with the same probability p of success in each trial, the percentage of successes is increasingly likely to be close to the chance of success as the number of trials increases. More precisely, the chance that the percentage of successes differs from the probability p by more than a fixed positive amount, e &amp;gt; 0, converges to zero as the number of trials n goes to infinity, for every number e &amp;gt; 0. Note that in contrast to the difference between the percentage of successes and the probability of success, the difference between the number of successes and the expected number of successes, n×p, tends to grow as n grows. The following tool illustrates the law of large numbers; the button toggles between displaying the difference between the number of successes and the expected number of successes, and the difference between the percentage of successes and the expected percentage of successes. The tool on this page illustrates the law of large numbers.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;132&lt;/td&gt;&#xA;          &lt;td&gt;Limit.&lt;/td&gt;&#xA;          &lt;td&gt;See converge.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;133&lt;/td&gt;&#xA;          &lt;td&gt;Linear Operation.&lt;/td&gt;&#xA;          &lt;td&gt;Suppose f is a function or operation that acts on things we shall denote generically by the lower-case Roman letters x and y. Suppose it makes sense to multiply x and y by numbers (which we denote by a), and that it makes sense to add things like x and y together. We say that f is linear if for every number a and every value of x and y for which f(x) and f(y) are defined, (i) f( a×x ) is defined and equals a×f(x), and (ii) f( x + y ) is defined and equals f(x) + f(y). C.f. affine.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;134&lt;/td&gt;&#xA;          &lt;td&gt;Linear association.&lt;/td&gt;&#xA;          &lt;td&gt;Two variables are linearly associated if a change in one is associated with a proportional change in the other, with the same constant of proportionality throughout the range of measurement. The correlation coefficient measures the degree of linear association on a scale of −1 to 1.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;135&lt;/td&gt;&#xA;          &lt;td&gt;List.&lt;/td&gt;&#xA;          &lt;td&gt;I use the term list to mean two things: either a multiset or (more often) an tuple. Lists are countable collections (multisets) in some order (like a tuple). That is, it makes sense to talk about the 1st (or 7th, or nth) element of a list, and the nth and mth elements of a list can be equal, even if n ≠ m (the elements of a list need not be distinct).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;136&lt;/td&gt;&#xA;          &lt;td&gt;Location, Measure of.&lt;/td&gt;&#xA;          &lt;td&gt;A measure of location is a way of summarizing what a “typical” element of a list is—it is a one-number summary of a distribution. See also arithmetic mean, median, and mode.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;137&lt;/td&gt;&#xA;          &lt;td&gt;Logical argument.&lt;/td&gt;&#xA;          &lt;td&gt;A logical argument consists of one or more premises, propositions that are assumed to be true, and a conclusion, a proposition that is supposed to be guaranteed to be true (as a matter of pure logic) if the premises are true. For example, the following is a logical argument: p → q Therefore, q. This argument has two premises: p → q, and p. The conclusion of the argument is q. If a logical argument is valid if the truth of the premises guarantees the truth of the conclusion; otherwise, the argument is invalid. That is, an argument with premises p1, p1, … pn and conclusion q is valid if the compound proposition (p1 &amp;amp; p2 &amp;amp; … &amp;amp; pn) → q is logically equivalent to TRUE. The argument given above is valid because if it is true that p → q and that p is true (the two premises), then q (the conclusion of the argument) must also be true.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;138&lt;/td&gt;&#xA;          &lt;td&gt;Logically equivalent, logical equivalence.&lt;/td&gt;&#xA;          &lt;td&gt;Two propositions are logically equivalent if they always have the same truth value. That is, the propositions p and q are logically equivalent if p is true whenever q is true and p is false whenever q is false. The proposition (p ↔ q) is always true if and only if p and q are logically equivalent. For example, p is logically equivalent to p, to (p &amp;amp; p), and to (p / p); (p / (!p)) is logically equivalent to TRUE; (p &amp;amp; !p) is logically equivalent to FALSE; (p ↔ p) is logically equivalent to TRUE; and (p → q) is logically equivalent to (!p / q).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;139&lt;/td&gt;&#xA;          &lt;td&gt;Longitudinal study.&lt;/td&gt;&#xA;          &lt;td&gt;A study in which individuals are followed over time, and compared with themselves at different times, to determine, for example, the effect of aging on some measured variable. Longitudinal studies provide much more persuasive evidence about the effect of aging than do cross-sectional studies.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;140&lt;/td&gt;&#xA;          &lt;td&gt;Lower Quartile (LQ).&lt;/td&gt;&#xA;          &lt;td&gt;See quartiles.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;141&lt;/td&gt;&#xA;          &lt;td&gt;Margin of error.&lt;/td&gt;&#xA;          &lt;td&gt;A measure of the uncertainty in an estimate of a parameter; unfortunately, not everyone agrees what it should mean. The margin of error of an estimate is typically one or two times the estimated standard error of the estimate.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;142&lt;/td&gt;&#xA;          &lt;td&gt;Marginal probability distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The marginal probability distribution of a random variable that has a joint probability distribution with some other random variables is the probability distribution of that random variable without regard for the values that the other random variables take. The marginal distribution of a discrete random variable X1 that has a joint distribution with other discrete random variables can be found from the joint distribution by summing over all possible values of the other variables. For example, suppose we roll two fair dice independently. Let X1 be the number of spots that show on the first die, and let X2 be the total number of spots that show on both dice. Then the joint distribution of X1 and X2 is as follows: P(X1 = 1, X2 = 2) = P(X1 = 1, X2 = 3) = P(X1 = 1, X2 = 4) = P(X1 = 1, X2 = 5) = P(X1 = 1, X2 = 6) = P(X1 = 1, X2 = 7) = P(X1 = 2, X2 = 3) = P(X1 = 2, X2 = 4) = P(X1 = 2, X2 = 5) = P(X1 = 2, X2 = 6) = P(X1 = 2, X2 = 7) = P(X1 = 2, X2 = 8) = … … P(X1 = 6, X2 = 7) = P(X1 = 6, X2 = 8) = P(X1 = 6, X2 = 9) = P(X1 = 6, X2 = 10) = P(X1 = 6, X2 = 11) = P(X1 = 6, X2 = 12) = 1/36. The marginal probability distribution of X1 is P(X1 = 1) = P(X1 = 2) = P(X1 = 3) = P(X1 = 4) = P(X1 = 5) = P(X1 = 6) = 1/6. We can verify that the marginal probability that X1 = 1 is indeed the sum of the joint probability distribution over all possible values of X2 for which X1 = 1: P(X1 = 1) = P(X1 = 1, X2 = 2) + P(X1 = 1, X2 = 3) + P(X1 = 1, X2 = 4) + P(X1 = 1, X2 = 5) + P(X1 = 1, X2 = 6) + P(X1 = 1, X2 = 7) = 6/36 = 1/6. Similarly, the marginal probability distribution of X2 is P(X2 = 2) = P(X2 = 12) = 1/36 P(X2 = 3) = P(X2 = 11) = 1/18 P(X2 = 4) = P(X2 = 10) = 3/36 P(X2 = 5) = P(X2 = 9) = 1/9 P(X2 = 6) = P(X2 = 8) = 5/36 P(X2 = 7) = 1/6. Again, we can verify that the marginal probability that X2 = 4 is 3/36 by adding the joint probabilities for all possible values of X1 for which X2 = 4: P(X2 = 4) = P(X1 = 1, X2 = 4) + P(X1 = 2, X2 = 4) + P(X1 = 3, X2 = 4) = 3/36.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;143&lt;/td&gt;&#xA;          &lt;td&gt;Markov’s Inequality.&lt;/td&gt;&#xA;          &lt;td&gt;For lists: If a list contains no negative numbers, the fraction of numbers in the list at least as large as any given constant a&amp;gt;0 is no larger than the arithmetic mean of the list, divided by a. For random variables: if a random variable X must be nonnegative, the chance that X exceeds any given constant a&amp;gt;0 is no larger than the expected value of X, divided by a.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;144&lt;/td&gt;&#xA;          &lt;td&gt;Maximum Likelihood Estimate (MLE).&lt;/td&gt;&#xA;          &lt;td&gt;The maximum likelihood estimate of a parameter from data is the possible value of the parameter for which the chance of observing the data largest. That is, suppose that the parameter is p, and that we observe data x. Then the maximum likelihood estimate of p is estimate p by the value q that makes P(observing x when the value of p is q) as large as possible. For example, suppose we are trying to estimate the chance that a (possibly biased) coin lands heads when it is tossed. Our data will be the number of times x the coin lands heads in n independent tosses of the coin. The distribution of the number of times the coin lands heads is binomial with parameters n (known) and p (unknown). The chance of observing x heads in n trials if the chance of heads in a given trial is q is nCx qx(1−q)n−x. The maximum likelihood estimate of p would be the value of q that makes that chance largest. We can find that value of q explicitly using calculus; it turns out to be q = x/n, the fraction of times the coin is observed to land heads in the n tosses. Thus the maximum likelihood estimate of the chance of heads from the number of heads in n independent tosses of the coin is the observed fraction of tosses in which the coin lands heads.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;145&lt;/td&gt;&#xA;          &lt;td&gt;Mean, Arithmetic mean.&lt;/td&gt;&#xA;          &lt;td&gt;The sum of a list of numbers, divided by the number of elements in the list. See also average.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;146&lt;/td&gt;&#xA;          &lt;td&gt;Mean Squared Error (MSE).&lt;/td&gt;&#xA;          &lt;td&gt;The mean squared error of an estimator of a parameter is the expected value of the square of the difference between the estimator and the parameter. In symbols, if X is an estimator of the parameter t, then MSE(X) = E( (X−t)2 ). The MSE measures how far the estimator is off from what it is trying to estimate, on the average in repeated experiments. It is a summary measure of the accuracy of the estimator. It combines any tendency of the estimator to overshoot or undershoot the truth (bias), and the variability of the estimator (SE). The MSE can be written in terms of the bias and SE of the estimator: MSE(X) = (bias(X))2 + (SE(X))2.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;147&lt;/td&gt;&#xA;          &lt;td&gt;Median.&lt;/td&gt;&#xA;          &lt;td&gt;“Middle value” of a list. The smallest number such that at least half the numbers in the list are no greater than it. If the list has an odd number of entries, the median is the middle entry in the list after sorting the list into increasing order. If the list has an even number of entries, the median is the smaller of the two middle numbers after sorting. The median can be estimated from a histogram by finding the smallest number such that the area under the histogram to the left of that number is 50%.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;148&lt;/td&gt;&#xA;          &lt;td&gt;Member of a set.&lt;/td&gt;&#xA;          &lt;td&gt;Something is a member (or element) of a set if it is one of the things in the set.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;149&lt;/td&gt;&#xA;          &lt;td&gt;Method of Comparison.&lt;/td&gt;&#xA;          &lt;td&gt;The most basic and important method of determining whether a treatment has an effect: compare what happens to individuals who are treated (the treatment group) with what happens to individuals who are not treated (the control group).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;150&lt;/td&gt;&#xA;          &lt;td&gt;Minimax Strategy.&lt;/td&gt;&#xA;          &lt;td&gt;In game theory, a minimax strategy is one that minimizes one’s maximum loss, whatever the opponent might do (whatever strategy the opponent might choose).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;151&lt;/td&gt;&#xA;          &lt;td&gt;Mode.&lt;/td&gt;&#xA;          &lt;td&gt;For lists, the mode is a most common (frequent) value. A list can have more than one mode. For histograms, a mode is a relative maximum (“bump”).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;152&lt;/td&gt;&#xA;          &lt;td&gt;Moment.&lt;/td&gt;&#xA;          &lt;td&gt;The kth moment of a list is the average value of the elements raised to the kth power; that is, if the list consists of the N elements x1, x2, … , xN, the kth moment of the list is ( x1k + x2k + xNk )/N. The kth moment of a random variable X is the expected value of Xk, E(Xk).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;153&lt;/td&gt;&#xA;          &lt;td&gt;Monotone, monotonic function.&lt;/td&gt;&#xA;          &lt;td&gt;A function is monotone if it only increases or only decreases: f increases monotonically (is monotonic increasing) if x &amp;gt; y, implies thatf(x) ≥ f(y). A function f decreases monotonically (is monotonic decreasing) if x &amp;gt; y, implies thatf(x) ≤ f(y). A function f is strictly monotonically increasing if x &amp;gt; y, implies thatf(x) &amp;gt; f(y), and strictly monotonically decreasing if if x &amp;gt; y, implies thatf(x) &amp;lt; f(y).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;154&lt;/td&gt;&#xA;          &lt;td&gt;Multimodal Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;A distribution with more than one mode. The histogram of a multimodal distribution has more than one “bump.”&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;155&lt;/td&gt;&#xA;          &lt;td&gt;Multinomial Distribution&lt;/td&gt;&#xA;          &lt;td&gt;Consider a sequence of n independent trials, each of which can result in an outcome in any of k categories. Let pj be the probability that each trial results in an outcome in category j, j = 1, 2, … , k, so p1 + p2 + … + pk = 100%. The number of outcomes of each type has a multinomial distribution. In particular, the probability that the n trials result in n1 outcomes of type 1, n2 outcomes of type 2, … , and nk outcomes of type k is n!/(n1! × n2! × … × nk!) × p1n1 × p2n2 × … × pknk, if n1, … , nk are nonnegative integers that sum to n; the chance is zero otherwise.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;156&lt;/td&gt;&#xA;          &lt;td&gt;Multiplication rule.&lt;/td&gt;&#xA;          &lt;td&gt;The chance that events A and B both occur (i.e., that event AB occurs), is the conditional probability that A occurs given that B occurs, times the unconditional probability that B occurs.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;157&lt;/td&gt;&#xA;          &lt;td&gt;Multiplicity in hypothesis tests.&lt;/td&gt;&#xA;          &lt;td&gt;In hypothesis testing, if more than one hypothesis is tested, the actual significance level of the combined tests is not equal to the nominal significance level of the individual tests. See also false discovery rate.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;158&lt;/td&gt;&#xA;          &lt;td&gt;Multivariate Data.&lt;/td&gt;&#xA;          &lt;td&gt;A set of measurements of two or more variables per individual. See bivariate.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;159&lt;/td&gt;&#xA;          &lt;td&gt;Multiset.&lt;/td&gt;&#xA;          &lt;td&gt;A multiset, also known as a bag is a collection of things, but—unlike a set, which is also a collection of things—the same object can occur in a multiset more than once. For instance, the sets {1, 2}, {1, 2, 2}, and {1, 1, 1, 1, 1, 2, 2} are all equal, while the multisets [1, 2], [1, 2, 2], and [1, 1, 1, 1, 1, 2, 2] are all different. However, order does not matter for sets or for multisets, so, for instance {1, 2} = {2, 1} and [1, 1, 1, 1, 1, 2, 2] = [2, 1, 1, 2, 1, 1, 1].&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;160&lt;/td&gt;&#xA;          &lt;td&gt;Mutually Exclusive.&lt;/td&gt;&#xA;          &lt;td&gt;See disjoint events or disjoint sets.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;161&lt;/td&gt;&#xA;          &lt;td&gt;Nearly normal distribution.&lt;/td&gt;&#xA;          &lt;td&gt;A population of numbers (a list of numbers) is said to have a nearly normal distribution if the histogram of its values in standard units nearly follows a normal curve. More precisely, suppose that the mean of the list is μ and the standard deviation of the list is SD. Then the list is nearly normally distributed if, for every two numbers a &amp;lt; b, the fraction of numbers in the list that are between a and b is approximately equal to the area under the normal curve between (a − μ)/SD and (a − μ)/SD.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;162&lt;/td&gt;&#xA;          &lt;td&gt;Negative Binomial Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;Consider a sequence of independent trials with the same probability p of success in each trial. The number of trials up to and including the rth success has the negative Binomial distribution with parameters n and r. If the random variable N has the negative binomial distribution with parameters n and r, then P(N=k) = k−1Cr−1 × pr × (1−p)k−r, for k = r, r+1, r+2, …, and zero for k &amp;lt; r, because there must be at least r trials to have r successes. The negative binomial distribution is derived as follows: for the rth success to occur on the kth trial, there must have been r−1 successes in the first k−1 trials, and the kth trial must result in success. The chance of the former is the chance of r−1 successes in k−1 independent trials with the same probability of success in each trial, which, according to the Binomial distribution with parameters n=k−1 and p, has probability k−1Cr−1 × pr−1 × (1−p)k−r. The chance of the latter event is p, by assumption. Because the trials are independent, we can find the chance that both events occur by multiplying their chances together, which gives the expression for P(N=k) above.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;163&lt;/td&gt;&#xA;          &lt;td&gt;No causation without manipulation.&lt;/td&gt;&#xA;          &lt;td&gt;A slogan attributed to Paul Holland. If the conditions were not deliberately manipulated (for example, if the situation is an observational study rather than an experiment), it is unwise to conclude that there is any causal relationship between the outcome and the conditions. See post hoc ergo propter hoc and cum hoc ergo propter hoc.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;164&lt;/td&gt;&#xA;          &lt;td&gt;Nonlinear Association.&lt;/td&gt;&#xA;          &lt;td&gt;The relationship between two variables is nonlinear if a change in one is associated with a change in the other that is depends on the value of the first; that is, if the change in the second is not simply proportional to the change in the first, independent of the value of the first variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;165&lt;/td&gt;&#xA;          &lt;td&gt;Nonresponse.&lt;/td&gt;&#xA;          &lt;td&gt;In surveys, it is rare that everyone who is “invited” to participate (everyone whose phone number is called, everyone who is mailed a questionnaire, everyone an interviewer tries to stop on the street…) in fact responds. The difference between the “invited” sample sought, and that obtained, is the nonresponse.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;166&lt;/td&gt;&#xA;          &lt;td&gt;Nonresponse bias.&lt;/td&gt;&#xA;          &lt;td&gt;In a survey, those who respond may differ from those who do not, in ways that are related to the effect one is trying to measure. For example, a telephone survey of how many hours people work is likely to miss people who are working late, and are therefore not at home to answer the phone. When that happens, the survey may suffer from nonresponse bias. Nonresponse bias makes the result of a survey differ systematically from the truth.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;167&lt;/td&gt;&#xA;          &lt;td&gt;Nonresponse rate.&lt;/td&gt;&#xA;          &lt;td&gt;The fraction of nonresponders in a survey: the number of nonresponders divided by the number of people invited to participate (the number sent questionnaires, the number of interview attempts, etc.) If the nonresponse rate is appreciable, the survey suffer from large nonresponse bias.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;168&lt;/td&gt;&#xA;          &lt;td&gt;Normal approximation.&lt;/td&gt;&#xA;          &lt;td&gt;The normal approximation to data is to approximate areas under the histogram of data, transformed into standard units, by the corresponding areas under the normal curve. Many probability distributions can be approximated by a normal distribution, in the sense that the area under the probability histogram is close to the area under a corresponding part of the normal curve. To find the corresponding part of the normal curve, the range must be converted to standard units, by subtracting the expected value and dividing by the standard error. For example, the area under the binomial probability histogram for n = 50 and p = 30% between 9.5 and 17.5 is 74.2%. To use the normal approximation, we transform the endpoints to standard units, by subtracting the expected value (for the Binomial random variable, n×p = 15 for these values of n and p) and dividing the result by the standard error (for a Binomial, (n × p × (1−p))1/2 = 3.24 for these values of n and p). The area normal approximation is the area under the normal curve between (9.5 − 15)/3.24 = −1.697 and (17.5 − 15)/3.24 = 0.772; that area is 73.5%, slightly smaller than the corresponding area under the binomial histogram. See also the continuity correction. The tool on this page illustrates the normal approximation to the binomial probability histogram. Note that the approximation gets worse when p gets close to 0 or 1, and that the approximation improves as n increases.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;169&lt;/td&gt;&#xA;          &lt;td&gt;Normal curve.&lt;/td&gt;&#xA;          &lt;td&gt;The normal curve is the familiar “bell curve:,” illustrated on this page. The mathematical expression for the normal curve is y = (2×pi)−½e−x2/2, where pi is the ratio of the circumference of a circle to its diameter (3.14159265…), and e is the base of the natural logarithm (2.71828…). The normal curve is symmetric around the point x=0, and positive for every value of x. The area under the normal curve is unity, and the SD of the normal curve, suitably defined, is also unity. Many (but not most) histograms, converted into standard units, approximately follow the normal curve.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;170&lt;/td&gt;&#xA;          &lt;td&gt;Normal distribution.&lt;/td&gt;&#xA;          &lt;td&gt;A random variable X has a normal distribution with mean m and standard error s if for every pair of numbers a ≤ b, the chance that a &amp;lt; (X−m)/s &amp;lt; b is P(a &amp;lt; (X−m)/s &amp;lt; b) = area under the normal curve between a and b. If there are numbers m and s such that X has a normal distribution with mean m and standard error s, then X is said to have a normal distribution or to be normally distributed. If X has a normal distribution with mean m=0 and standard error s=1, then X is said to have a standard normal distribution. The notation X&lt;del&gt;N(m,s2) means that X has a normal distribution with mean m and standard error s; for example, X&lt;/del&gt;N(0,1), means X has a standard normal distribution.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;171&lt;/td&gt;&#xA;          &lt;td&gt;NOT, !, Negation, Logical Negation.&lt;/td&gt;&#xA;          &lt;td&gt;The negation of a logical proposition p, !p, is a proposition that is the logical opposite of p. That is, if p is true, !p is false, and if p is false, !p is true. Negation takes precedence over other logical operations. Other common symbols for the negation operator include ¬, − and ˜.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;172&lt;/td&gt;&#xA;          &lt;td&gt;Null hypothesis.&lt;/td&gt;&#xA;          &lt;td&gt;In hypothesis testing, the hypothesis we wish to falsify on the basis of the data. The null hypothesis is typically that something is not present, that there is no effect, or that there is no difference between treatment and control.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;173&lt;/td&gt;&#xA;          &lt;td&gt;Observational Study.&lt;/td&gt;&#xA;          &lt;td&gt;Controlled experiment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;174&lt;/td&gt;&#xA;          &lt;td&gt;Odds.&lt;/td&gt;&#xA;          &lt;td&gt;The odds in favor of an event is the ratio of the probability that the event occurs to the probability that the event does not occur. For example, suppose an experiment can result in any of n possible outcomes, all equally likely, and that k of the outcomes result in a “win” and n−k result in a “loss.” Then the chance of winning is k/n; the chance of not winning is (n−k)/n; and the odds in favor of winning are (k/n)/((n−k)/n) = k/(n−k), which is the number of favorable outcomes divided by the number of unfavorable outcomes. Note that odds are not synonymous with probability, but the two can be converted back and forth. If the odds in favor of an event are q, then the probability of the event is q/(1+q). If the probability of an event is p, the odds in favor of the event are p/(1−p) and the odds against the event are (1−p)/p.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;175&lt;/td&gt;&#xA;          &lt;td&gt;One-sided Test.&lt;/td&gt;&#xA;          &lt;td&gt;C.f. two-sided test. An hypothesis test of the null hypothesis that the value of a parameter, μ, is equal to a null value, μ0, designed to have power against either the alternative hypothesis that μ &amp;lt; μ0 or the alternative μ &amp;gt; μ0 (but not both). For example, a significance level 5%, one-sided z test of the null hypothesis that the mean of a population equals zero against the alternative that it is greater than zero, would reject the null hypothesis for values of&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;176&lt;/td&gt;&#xA;          &lt;td&gt;or, /, Disjunction, Logical Disjunction, ∨&lt;/td&gt;&#xA;          &lt;td&gt;An operation on two logical propositions. If p and q are two propositions, (p / q) is a proposition that is true if p is true or if q is true (or both); otherwise, it is false. That is, (p / q) is true unless both p and q are false. The operation / is sometimes represented by the symbol ∨ and sometimes by the word or. C.f. exclusive disjunction, XOR.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;177&lt;/td&gt;&#xA;          &lt;td&gt;Ordinal Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A variable whose possible values have a natural order, such as {short, medium, long}, {cold, warm, hot}, or {0, 1, 2, 3, …}. In contrast, a variable whose possible values are {straight, curly} or {Arizona, California, Montana, New York} would not naturally be ordinal. Arithmetic with the possible values of an ordinal variable does not necessarily make sense, but it does make sense to say that one possible value is larger than another.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;178&lt;/td&gt;&#xA;          &lt;td&gt;Outcome Space.&lt;/td&gt;&#xA;          &lt;td&gt;The outcome space is the set of all possible outcomes of a given random experiment. The outcome space is often denoted by the capital letter S.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;179&lt;/td&gt;&#xA;          &lt;td&gt;Outlier.&lt;/td&gt;&#xA;          &lt;td&gt;An outlier is an observation that is many SD’s from the mean. It is sometimes tempting to discard outliers, but this is imprudent unless the cause of the outlier can be identified, and the outlier is determined to be spurious. Otherwise, discarding outliers can cause one to underestimate the true variability of the measurement process.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;180&lt;/td&gt;&#xA;          &lt;td&gt;P-value.&lt;/td&gt;&#xA;          &lt;td&gt;Suppose we have a family of hypothesis tests of a null hypothesis that let us test the hypothesis at any significance level p between 0 and 100% we choose. The P value of the null hypothesis given the data is the smallest significance level p for which any of the tests would have rejected the null hypothesis. For example, let X be a test statistic, and for p between 0 and 100%, let xp be the smallest number such that, under the null hypothesis, P( X ≤ x ) ≥ p. Then for any p between 0 and 100%, the rule reject the null hypothesis if X &amp;lt; xp tests the null hypothesis at significance level p. If we observed X = x, the P-value of the null hypothesis given the data would be the smallest p such that x &amp;lt; xp.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;181&lt;/td&gt;&#xA;          &lt;td&gt;Parameter.&lt;/td&gt;&#xA;          &lt;td&gt;A numerical property of a population, such as its mean.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;182&lt;/td&gt;&#xA;          &lt;td&gt;Partition.&lt;/td&gt;&#xA;          &lt;td&gt;A partition of an event A is a collection of events {A1, A2, A3, … } such that the events in the collection are disjoint, and their union is A. That is, AjAk = {} unless j = k, and A = A1 ∪ A2 ∪ A3 ∪ … . If the event A is not specified, it is assumed to be the entire outcome space S.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;183&lt;/td&gt;&#xA;          &lt;td&gt;Payoff Matrix.&lt;/td&gt;&#xA;          &lt;td&gt;A way of representing what each player in a game wins or loses, as a function of his and his opponent’s strategies.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;184&lt;/td&gt;&#xA;          &lt;td&gt;Percentile.&lt;/td&gt;&#xA;          &lt;td&gt;The pth percentile of a list is the smallest number such that at least p% of the numbers in the list are no larger than it. The pth percentile of a random variable is the smallest number such that the chance that the random variable is no larger than it is at least p%. C.f. quantile.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;185&lt;/td&gt;&#xA;          &lt;td&gt;Permutation.&lt;/td&gt;&#xA;          &lt;td&gt;A permutation of a set is an arrangement of the elements of the set in some order. If the set has n things in it, there are n! different orderings of its elements. For the first element in an ordering, there are n possible choices, for the second, there remain n−1 possible choices, for the third, there are n−2, etc., and for the nth element of the ordering, there is a single choice remaining. By the fundamental rule of counting, the total number of sequences is thus n×(n−1)×(n−2)×…×1. Similarly, the number of orderings of length k one can form from n≥k things is n×(n−1)×(n−2)×…×(n−k+1) = n!/(n−k)!. This is denoted nPk, the number of permutations of n things taken k at a time. C.f. combinations.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;186&lt;/td&gt;&#xA;          &lt;td&gt;Placebo.&lt;/td&gt;&#xA;          &lt;td&gt;A “dummy” treatment that has no pharmacological effect; e.g., a sugar pill.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;187&lt;/td&gt;&#xA;          &lt;td&gt;Placebo effect.&lt;/td&gt;&#xA;          &lt;td&gt;The belief or knowledge that one is being treated can itself have an effect that confounds with the real effect of the treatment. Subjects given a placebo as a pain-killer report statistically significant reductions in pain in randomized experiments that compare them with subjects who receive no treatment at all. This very real psychological effect of a placebo, which has no direct biochemical effect, is called the placebo effect. Administering a placebo to the control group is thus important in experiments with human subjects; this is the essence of a blind experiment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;188&lt;/td&gt;&#xA;          &lt;td&gt;Point of Averages.&lt;/td&gt;&#xA;          &lt;td&gt;In a scatterplot, the point whose coordinates are the arithmetic means of the corresponding variables. For example, if the variable X is plotted on the horizontal axis and the variable Y is plotted on the vertical axis, the point of averages has coordinates (mean of X, mean of Y).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;189&lt;/td&gt;&#xA;          &lt;td&gt;Poisson Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The Poisson distribution is a discrete probability distribution that depends on one parameter, m. If X is a random variable with the Poisson distribution with parameter m, then the probability that X = k is E−m × mk/k!, k = 0, 1, 2, … , where E is the base of the natural logarithm and ! is the factorial function. For all other values of k, the probability is zero. The expected value the Poisson distribution with parameter m is m, and the standard error of the Poisson distribution with parameter m is m½.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;190&lt;/td&gt;&#xA;          &lt;td&gt;Population.&lt;/td&gt;&#xA;          &lt;td&gt;A collection of units being studied. Units can be people, places, objects, epochs, drugs, procedures, or many other things. Much of statistics is concerned with estimating numerical properties (parameters) of an entire population from a random sample of units from the population.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;191&lt;/td&gt;&#xA;          &lt;td&gt;Population Mean.&lt;/td&gt;&#xA;          &lt;td&gt;The mean of the numbers in a numerical population. For example, the population mean of a box of numbered tickets is the mean of the list comprised of all the numbers on all the tickets. The population mean is a parameter. C.f. sample mean.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;192&lt;/td&gt;&#xA;          &lt;td&gt;Population Percentage.&lt;/td&gt;&#xA;          &lt;td&gt;The percentage of units in a population that possess a specified property. For example, the percentage of a given collection of registered voters who are registered as Republicans. If each unit that possesses the property is labeled with “1,” and each unit that does not possess the property is labeled with “0,” the population percentage is the same as the mean of that list of zeros and ones; that is, the population percentage is the population mean for a population of zeros and ones. The population percentage is a parameter. C.f. sample percentage.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;193&lt;/td&gt;&#xA;          &lt;td&gt;Population Standard Deviation.&lt;/td&gt;&#xA;          &lt;td&gt;The standard deviation of the values of a variable for a population. This is a parameter, not a statistic. C.f. sample standard deviation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;194&lt;/td&gt;&#xA;          &lt;td&gt;Post hoc ergo propter hoc.&lt;/td&gt;&#xA;          &lt;td&gt;“After this, therefore because of this.” A fallacy of logic known since classical times: inferring a causal relation from correlation. Don’t do this at home!&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;195&lt;/td&gt;&#xA;          &lt;td&gt;Power.&lt;/td&gt;&#xA;          &lt;td&gt;Refers to an hypothesis test. The power of a test against a specific alternative hypothesis is the chance that the test correctly rejects the null hypothesis when the alternative hypothesis is true.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;196&lt;/td&gt;&#xA;          &lt;td&gt;Premise, logical premise.&lt;/td&gt;&#xA;          &lt;td&gt;A premise is a proposition that is assumed to be true as part of a logical argument.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;197&lt;/td&gt;&#xA;          &lt;td&gt;Prima facie.&lt;/td&gt;&#xA;          &lt;td&gt;Latin for “at first glance.” “On the face of it.” Prima facie evidence for something is information that at first glance supports the conclusion. On closer examination, that might not be true; there could be another explanation for the evidence.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;198&lt;/td&gt;&#xA;          &lt;td&gt;Principle of insufficient reason (Laplace)&lt;/td&gt;&#xA;          &lt;td&gt;Laplace’s principle of insufficient reason says that if there is no reason to believe that the possible outcomes of an experiment are not equally likely, one should assume that the outcomes are equally likely. This is an example of a fallacy called appeal to ignorance.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;199&lt;/td&gt;&#xA;          &lt;td&gt;Probability.&lt;/td&gt;&#xA;          &lt;td&gt;The probability of an event is a number between zero and 100%. The meaning (interpretation) of probability is the subject of theories of probability, which differ in their interpretations. However, any rule for assigning probabilities to events has to satisfy the axioms of probability.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;200&lt;/td&gt;&#xA;          &lt;td&gt;Probability density function.&lt;/td&gt;&#xA;          &lt;td&gt;The chance that a continuous random variable is in any range of values can be calculated as the area under a curve over that range of values. The curve is the probability density function of the random variable. That is, if X is a continuous random variable, there is a function f(x) such that for every pair of numbers a≤b, P(a≤ X ≤b) = (area under f between a and b); f is the probability density function of X. For example, the probability density function of a random variable with a standard normal distribution is the normal curve. Only continuous random variables have probability density functions.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;201&lt;/td&gt;&#xA;          &lt;td&gt;Probability Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The probability distribution of a random variable specifies the chance that the variable takes a value in any subset of the real numbers. (The subsets have to satisfy some technical conditions that are not important for this course.) The probability distribution of a random variable is completely characterized by the cumulative probability distribution function; the terms sometimes are used synonymously. The probability distribution of a discrete random variable can be characterized by the chance that the random variable takes each of its possible values. For example, the probability distribution of the total number of spots S showing on the roll of two fair dice can be written as a table: The probability distribution of a continuous random variable can be characterized by its probability density function.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;202&lt;/td&gt;&#xA;          &lt;td&gt;Probability Histogram.&lt;/td&gt;&#xA;          &lt;td&gt;A probability histogram for a random variable is analogous to a histogram of data, but instead of plotting the area of the bins proportional to the relative frequency of observations in the class interval, one plots the area of the bins proportional to the probability that the random variable is in the class interval.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;203&lt;/td&gt;&#xA;          &lt;td&gt;Probability Sample.&lt;/td&gt;&#xA;          &lt;td&gt;A sample drawn from a population using a random mechanism so that every element of the population has a known chance of ending up in the sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;204&lt;/td&gt;&#xA;          &lt;td&gt;Probability, Theories of.&lt;/td&gt;&#xA;          &lt;td&gt;A theory of probability is a way of assigning meaning to probability statements such as “the chance that a thumbtack lands point-up is 2/3.” That is, a theory of probability connects the mathematics of probability, which is the set of consequences of the axioms of probability, with the real world of observation and experiment. There are several common theories of probability. According to the frequency theory of probability, the probability of an event is the limit of the percentage of times that the event occurs in repeated, independent trials under essentially the same circumstances. According to the subjective theory of probability, a probability is a number that measures how strongly we believe an event will occur. The number is on a scale of 0% to 100%, with 0% indicating that we are completely sure it won’t occur, and 100% indicating that we are completely sure that it will occur. According to the theory of equally likely outcomes, if an experiment has n possible outcomes, and (for example, by symmetry) there is no reason that any of the n possible outcomes should occur preferentially to any of the others, then the chance of each outcome is 100%/n. Each of these theories has its limitations, its proponents, and its detractors.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;205&lt;/td&gt;&#xA;          &lt;td&gt;Proposition, logical proposition.&lt;/td&gt;&#xA;          &lt;td&gt;A logical proposition is a statement that can be either true or false. For example, “the sun is shining in Berkeley right now” is a proposition. See also &amp;amp;, ↔, →, /, XOR, converse, contrapositive and logical argument.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;206&lt;/td&gt;&#xA;          &lt;td&gt;Prosecutor’s Fallacy.&lt;/td&gt;&#xA;          &lt;td&gt;The prosecutor’s fallacy consists of confusing two conditional probabilities: P(A/B) and P(B/A). For instance, P(A/B) could be the chance of observing the evidence if the accused is guilty, while P(B/A) is the chance that the accused is guilty given the evidence. The latter might not make sense at all, but even when it does, the two numbers need not be equal. This fallacy is related to a common misinterpretation of P-values.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;207&lt;/td&gt;&#xA;          &lt;td&gt;Qualitative Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A qualitative variable is one whose values are adjectives, such as colors, genders, nationalities, etc. C.f. quantitative variable and categorical variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;208&lt;/td&gt;&#xA;          &lt;td&gt;Quantile.&lt;/td&gt;&#xA;          &lt;td&gt;The qth quantile of a list (0 &amp;lt; q ≤ 1) is the smallest number such that the fraction q or more of the elements of the list are less than or equal to it. I.e., if the list contains n numbers, the qth quantile, is the smallest number Q such that at least n×q elements of the list are less than or equal to Q.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;209&lt;/td&gt;&#xA;          &lt;td&gt;Quantitative Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A variable that takes numerical values for which arithmetic makes sense, for example, counts, temperatures, weights, amounts of money, etc. For some variables that take numerical values, arithmetic with those values does not make sense; such variables are not quantitative. For example, adding and subtracting social security numbers does not make sense. Quantitative variables typically have units of measurement, such as inches, people, or pounds.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;210&lt;/td&gt;&#xA;          &lt;td&gt;Quartiles.&lt;/td&gt;&#xA;          &lt;td&gt;There are three quartiles. The first or lower quartile (LQ) of a list is a number (not necessarily a number in the list) such that at least 1/4 of the numbers in the list are no larger than it, and at least 3/4 of the numbers in the list are no smaller than it. The second quartile is the median. The third or upper quartile (UQ) is a number such that at least 3/4 of the entries in the list are no larger than it, and at least 1/4 of the numbers in the list are no smaller than it. To find the quartiles, first sort the list into increasing order. Find the smallest integer that is at least as big as the number of entries in the list divided by four. Call that integer k. The kth element of the sorted list is the lower quartile. Find the smallest integer that is at least as big as the number of entries in the list divided by two. Call that integer l. The lth element of the sorted list is the median. Find the smallest integer that is at least as large as the number of entries in the list times 3/4. Call that integer m. The mth element of the sorted list is the upper quartile.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;211&lt;/td&gt;&#xA;          &lt;td&gt;Quota Sample.&lt;/td&gt;&#xA;          &lt;td&gt;A quota sample is a sample picked to match the population with respect to some summary characteristics. It is not a random sample. For example, in an opinion poll, one might select a sample so that the proportions of various ethnicities in the sample match the proportions of ethnicities in the overall population from which the sample is drawn. Matching on summary statistics does not guarantee that the sample comes close to matching the population with respect to the quantity of interest. As a result, quota samples are typically biased, and the size of the bias is generally impossible to determine unless the result can be compared with a known result for the whole population or for a random sample. Moreover, with a quota sample, it is impossible to quantify how representative of the population a quota sample is likely to be—quota sampling does not allow one to quantify the likely size of sampling error. Quota samples are to be avoided, and results based on quota samples are to be viewed with suspicion. See also convenience sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;212&lt;/td&gt;&#xA;          &lt;td&gt;Random Error.&lt;/td&gt;&#xA;          &lt;td&gt;All measurements are subject to error, which can often be broken down into two components: a bias or systematic error, which affects all measurements the same way; and a random error, which is in general different each time a measurement is made, and behaves like a number drawn with replacement from a box of numbered tickets whose average is zero.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;213&lt;/td&gt;&#xA;          &lt;td&gt;Random Event.&lt;/td&gt;&#xA;          &lt;td&gt;See random experiment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;214&lt;/td&gt;&#xA;          &lt;td&gt;Random Experiment.&lt;/td&gt;&#xA;          &lt;td&gt;An experiment or trial whose outcome is not perfectly predictable, but for which the long-run relative frequency of outcomes of different types in repeated trials is predictable. Note that “random” is different from “haphazard,” which does not necessarily imply long-term regularity.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;215&lt;/td&gt;&#xA;          &lt;td&gt;Random Sample.&lt;/td&gt;&#xA;          &lt;td&gt;A random sample is a sample whose members are chosen at random from a given population in such a way that the chance of obtaining any particular sample can be computed. The number of units in the sample is called the sample size, often denoted n. The number of units in the population often is denoted N. Random samples can be drawn with or without replacing objects between draws; that is, drawing all n objects in the sample at once (a random sample without replacement), or drawing the objects one at a time, replacing them in the population between draws (a random sample with replacement). In a random sample with replacement, any given member of the population can occur in the sample more than once. In a random sample without replacement, any given member of the population can be in the sample at most once. A random sample without replacement in which every subset of n of the N units in the population is equally likely is also called a simple random sample. The term random sample with replacement denotes a random sample drawn in such a way that every multiset of n units in the population is equally likely. See also probability sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;216&lt;/td&gt;&#xA;          &lt;td&gt;Random Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A random variable is an assignment of numbers to possible outcomes of a random experiment. For example, consider tossing three coins. The number of heads showing when the coins land is a random variable: it assigns the number 0 to the outcome {T, T, T}, the number 1 to the outcome {T, T, H}, the number 2 to the outcome {T, H, H}, and the number 3 to the outcome {H, H, H}.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;217&lt;/td&gt;&#xA;          &lt;td&gt;Randomized Controlled Experiment.&lt;/td&gt;&#xA;          &lt;td&gt;An experiment in which chance is deliberately introduced in assigning subjects to the treatment and control groups. For example, we could write an identifying number for each subject on a slip of paper, stir up the slips of paper, and draw slips without replacement until we have drawn half of them. The subjects identified on the slips drawn could then be assigned to treatment, and the rest to control. Randomizing the assignment tends to decrease confounding of the treatment effect with other factors, by making the treatment and control groups roughly comparable in all respects but the treatment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;218&lt;/td&gt;&#xA;          &lt;td&gt;Range.&lt;/td&gt;&#xA;          &lt;td&gt;The range of a set of numbers is the largest value in the set minus the smallest value in the set. Note that as a statistical term, the range is a single number, not a range of numbers.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;219&lt;/td&gt;&#xA;          &lt;td&gt;Real number.&lt;/td&gt;&#xA;          &lt;td&gt;Loosely speaking, the real numbers are all numbers that can be represented as fractions (rational numbers), whether proper or improper—and all numbers in between the rational numbers. That is, the real numbers comprise the rational numbers and all limits of Cauchy sequences of rational numbers, where the Cauchy sequence is with respect to the absolute value metric. (More formally, the real numbers are the completion of the set of rational numbers in the topology induced by the absolute value function.) The real numbers contain all integers, all fractions, and all irrational (and transcendental) numbers, such as π, e, and 2½. There are uncountably many real numbers between 0 and 1; in contrast, there are only countably many rational numbers between 0 and 1.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;220&lt;/td&gt;&#xA;          &lt;td&gt;Regression, Linear Regression.&lt;/td&gt;&#xA;          &lt;td&gt;Linear regression fits a line to a scatterplot in such a way as to minimize the sum of the squares of the residuals. The resulting regression line, together with the standard deviations of the two variables or their correlation coefficient, can be a reasonable summary of a scatterplot if the scatterplot is roughly football-shaped. In other cases, it is a poor summary. If we are regressing the variable Y on the variable X, and if Y is plotted on the vertical axis and X is plotted on the horizontal axis, the regression line passes through the point of averages, and has slope equal to the correlation coefficient times the SD of Y divided by the SD of X. This page shows a scatterplot, with a button to plot the regression line.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;221&lt;/td&gt;&#xA;          &lt;td&gt;Regression Fallacy.&lt;/td&gt;&#xA;          &lt;td&gt;The regression fallacy is to attribute the regression effect to an external cause.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;222&lt;/td&gt;&#xA;          &lt;td&gt;Regression Toward the Mean, Regression Effect.&lt;/td&gt;&#xA;          &lt;td&gt;Suppose one measures two variables for each member of a group of individuals, and that the correlation coefficient of the variables is positive (negative). If the value of the first variable for that individual is above average, the value of the second variable for that individual is likely to be above (below) average, but by fewer standard deviations than the first variable is. That is, the second observation is likely to be closer to the mean in standard units. For example, suppose one measures the heights of fathers and sons. Each individual is a (father, son) pair; the two variables measured are the height of the father and the height of the son. These two variables will tend to have a positive correlation coefficient: fathers who are taller than average tend to have sons who are taller than average. Consider a (father, son) pair chosen at random from this group. Suppose the father’s height is 3SD above the average of all the fathers’ heights. (The SD is the standard deviation of the fathers’ heights.) Then the son’s height is also likely to be above the average of the sons’ heights, but by fewer than 3SD (here the SD is the standard deviation of the sons’ heights).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;223&lt;/td&gt;&#xA;          &lt;td&gt;Rejection region.&lt;/td&gt;&#xA;          &lt;td&gt;In an hypothesis test using a test statistic, the rejection region is the set of values of the test statistic for which we reject the null hypothesis.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;224&lt;/td&gt;&#xA;          &lt;td&gt;Residual.&lt;/td&gt;&#xA;          &lt;td&gt;The difference between a datum and the value predicted for it by a model. In linear regression of a variable plotted on the vertical axis onto a variable plotted on the horizontal axis, a residual is the “vertical” distance from a datum to the line. Residuals can be positive (if the datum is above the line) or negative (if the datum is below the line). Plots of residuals can reveal computational errors in linear regression, as well as conditions under which linear regression is inappropriate, such as nonlinearity and heteroscedasticity. If linear regression is performed properly, the sum of the residuals from the regression line must be zero; otherwise, there is a computational error somewhere.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;225&lt;/td&gt;&#xA;          &lt;td&gt;Residual Plot.&lt;/td&gt;&#xA;          &lt;td&gt;A residual plot for a regression is a plot of the residuals from the regression against the explanatory variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;226&lt;/td&gt;&#xA;          &lt;td&gt;Resistant.&lt;/td&gt;&#xA;          &lt;td&gt;A statistic is said to be resistant if corrupting a datum cannot change the statistic much. The mean is not resistant; the median is. See also breakdown point.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;227&lt;/td&gt;&#xA;          &lt;td&gt;Root-mean-square (RMS).&lt;/td&gt;&#xA;          &lt;td&gt;The RMS of a list is the square-root of the mean of the squares of the elements in the list. It is a measure of the average “size” of the elements of the list. To compute the RMS of a list, you square all the entries, average the numbers you get, and take the square-root of that average.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;228&lt;/td&gt;&#xA;          &lt;td&gt;Root-mean-square error (RMSE).&lt;/td&gt;&#xA;          &lt;td&gt;The RMSE of an an estimator of a parameter is the square-root of the mean squared error (MSE) of the estimator. In symbols, if X is an estimator of the parameter t, then RMSE(X) = ( E( (X−t)2 ) )½. The RMSE of an estimator is a measure of the expected error of the estimator. The units of RMSE are the same as the units of the estimator. See also mean squared error.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;229&lt;/td&gt;&#xA;          &lt;td&gt;rms Error of Regression&lt;/td&gt;&#xA;          &lt;td&gt;The rms error of regression is the rms of the vertical residuals from the regression line. For regressing Y on X, the rms error of regression is equal to (1 − r2)½×SDY, where r is the correlation coefficient between X and Y and SDY is the standard deviation of the values of Y.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;230&lt;/td&gt;&#xA;          &lt;td&gt;Sample.&lt;/td&gt;&#xA;          &lt;td&gt;A sample is a collection of units from a population. See also random sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;231&lt;/td&gt;&#xA;          &lt;td&gt;Sample Mean.&lt;/td&gt;&#xA;          &lt;td&gt;The arithmetic mean of a random sample from a population. It is a statistic commonly used to estimate the population mean. Suppose there are n data, {x1, x2, … , xn}. The sample mean is (x1 + x2 + … + xn)/n. The expected value of the sample mean is the population mean. For sampling with replacement, the SE of the sample mean is the population standard deviation, divided by the square-root of the sample size. For sampling without replacement, the SE of the sample mean is the finite-population correction ((N−n)/(N−1))½ times the SE of the sample mean for sampling with replacement, with N the size of the population and n the size of the sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;232&lt;/td&gt;&#xA;          &lt;td&gt;Sample Percentage.&lt;/td&gt;&#xA;          &lt;td&gt;The percentage of a random sample with a certain property, such as the percentage of voters registered as Democrats in a simple random sample of voters. The sample mean is a statistic commonly used to estimate the population percentage. The expected value of the sample percentage from a simple random sample or a random sample with replacement is the population percentage. The SE of the sample percentage for sampling with replacement is (p(1−p)/n )½, where p is the population percentage and n is the sample size. The SE of the sample percentage for sampling without replacement is the finite-population correction ((N−n)/(N−1))½ times the SE of the sample percentage for sampling with replacement, with N the size of the population and n the size of the sample. The SE of the sample percentage is often estimated by the bootstrap.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;233&lt;/td&gt;&#xA;          &lt;td&gt;Sample Size.&lt;/td&gt;&#xA;          &lt;td&gt;The number of elements in a sample from a population.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;234&lt;/td&gt;&#xA;          &lt;td&gt;Sound argument.&lt;/td&gt;&#xA;          &lt;td&gt;A logical argument is sound if it is logically valid and its premises are in fact true. An argument can be logically valid and yet not sound—if its premises are false.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;235&lt;/td&gt;&#xA;          &lt;td&gt;Sample Standard Deviation, S.&lt;/td&gt;&#xA;          &lt;td&gt;The sample standard deviation S is an estimator of the standard deviation of a population based on a random sample from the population. The sample standard deviation is a statistic that measures how “spread out” the sample is around the sample mean. It is quite similar to the standard deviation of the sample, but instead of averaging the squared deviations (to get the rms of the deviations of the data from the sample mean) it divides the sum of the squared deviations by (number of data − 1) before taking the square-root. Suppose there are n data, {x1, x2, … , xn}, with mean M = (x1 + x2 + … + xn)/n. Then s = ( ((x1 − M)2 + (x2 − M)2 + … + (xn − M)2)/(n−1) )½ The square of the sample standard deviation, S2 (the sample variance) is an unbiased estimator of the square of the SD of the population (the variance of the population).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;236&lt;/td&gt;&#xA;          &lt;td&gt;Sample Sum.&lt;/td&gt;&#xA;          &lt;td&gt;The sum of a random sample from a population. The expected value of the sample sum is the sample size times the population mean. For sampling with replacement, the SE of the sample sum is the population standard deviation, times the square-root of the sample size. For sampling without replacement, the SE of the sample sum is the finite-population correction ((N−n)/(N−1))½ times the SE of the sample sum for sampling with replacement, with N the size of the population and n the size of the sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;237&lt;/td&gt;&#xA;          &lt;td&gt;Sample Survey.&lt;/td&gt;&#xA;          &lt;td&gt;A survey based on the responses of a sample of individuals, rather than the entire population.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;238&lt;/td&gt;&#xA;          &lt;td&gt;Sample Variance&lt;/td&gt;&#xA;          &lt;td&gt;The sample variance is the square of the sample standard deviation S. It is an unbiased estimator of the square of the population standard deviation, which is also called the variance of the population.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;239&lt;/td&gt;&#xA;          &lt;td&gt;Sampling distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The sampling distribution of an estimator is the probability distribution of the estimator when it is applied to random samples. The tool on this page allows you to explore empirically the sampling distribution of the sample mean and the sample percentage of random draws with or without replacement draws from a box of numbered tickets.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;240&lt;/td&gt;&#xA;          &lt;td&gt;Sampling error.&lt;/td&gt;&#xA;          &lt;td&gt;In estimating from a random sample, the difference between the estimator and the parameter can be written as the sum of two components: bias and sampling error. The bias is the average error of the estimator over all possible samples. The bias is not random. Sampling error is the component of error that varies from sample to sample. The sampling error is random: it comes from “the luck of the draw” in which units happen to be in the sample. It is the chance variation of the estimator. The average of the sampling error over all possible samples (the expected value of the sampling error) is zero. The standard error of the estimator is a measure of the typical size of the sampling error.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;241&lt;/td&gt;&#xA;          &lt;td&gt;Sampling unit.&lt;/td&gt;&#xA;          &lt;td&gt;A sample from a population can be drawn one unit at a time, or more than one unit at a time (one can sample clusters of units). The fundamental unit of the sample is called the sampling unit. It need not be a unit of the population.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;242&lt;/td&gt;&#xA;          &lt;td&gt;Scatterplot.&lt;/td&gt;&#xA;          &lt;td&gt;A scatterplot is a way to visualize bivariate data. A scatterplot is a plot of pairs of measurements on a collection of “individuals” (which need not be people). For example, suppose we record the heights and weights of a group of 100 people. The scatterplot of those data would be 100 points. Each point represents one person’s height and weight. In a scatterplot of weight against height, the x-coordinate of each point would be height of one person, the y-coordinate of that point would be the weight of the same person. In a scatterplot of height against weight, the x-coordinates would be the weights and the y-coordinates would be the heights.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;243&lt;/td&gt;&#xA;          &lt;td&gt;Scientific Method.&lt;/td&gt;&#xA;          &lt;td&gt;The scientific method….&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;244&lt;/td&gt;&#xA;          &lt;td&gt;SD line.&lt;/td&gt;&#xA;          &lt;td&gt;For a scatterplot, a line that goes through the point of averages, with slope equal to the ratio of the standard deviations of the two plotted variables. If the variable plotted on the horizontal axis is called X and the variable plotted on the vertical axis is called Y, the slope of the SD line is the SD of Y, divided by the SD of X.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;245&lt;/td&gt;&#xA;          &lt;td&gt;Secular Trend.&lt;/td&gt;&#xA;          &lt;td&gt;A linear association (trend) with time.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;246&lt;/td&gt;&#xA;          &lt;td&gt;Selection Bias.&lt;/td&gt;&#xA;          &lt;td&gt;A systematic tendency for a sampling procedure to include and/or exclude units of a certain type. For example, in a quota sample, unconscious prejudices or predilections on the part of the interviewer can result in selection bias. Selection bias is a potential problem whenever a human has latitude in selecting individual units for the sample; it tends to be eliminated by probability sampling schemes in which the interviewer is told exactly whom to contact (with no room for individual choice).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;247&lt;/td&gt;&#xA;          &lt;td&gt;Self-Selection.&lt;/td&gt;&#xA;          &lt;td&gt;Self-selection occurs when individuals decide for themselves whether they are in the control group or the treatment group. Self-selection is quite common in studies of human behavior. For example, studies of the effect of smoking on human health involve self-selection: individuals choose for themselves whether or not to smoke. Self-selection precludes an experiment; it results in an observational study. When there is self-selection, one must be wary of possible confounding from factors that influence individuals’ decisions to belong to the treatment group.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;248&lt;/td&gt;&#xA;          &lt;td&gt;Set.&lt;/td&gt;&#xA;          &lt;td&gt;A set is a collection of things (called elements), without regard to their order. An item is either in a set (it is an element of the set), or it is not. It cannot be in the set more than once. Two sets are equal if they contain electly the same elements. For instance, the set {1, 2, 3, 4} is equal to the set {1, 4, 3, 2}, but not to the set {0, 1, 2, 3}. As another example, the set {1, 2, 2} is equal to the set {1, 2}: they have the same two (distinct) elements, 1 and 2.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;249&lt;/td&gt;&#xA;          &lt;td&gt;Significance, Significance level, Statistical significance.&lt;/td&gt;&#xA;          &lt;td&gt;The significance level of an hypothesis test is the chance that the test erroneously rejects the null hypothesis when the null hypothesis is true.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;250&lt;/td&gt;&#xA;          &lt;td&gt;Simple Random Sample.&lt;/td&gt;&#xA;          &lt;td&gt;A simple random sample of n units from a population is a random sample drawn by a procedure that is equally likely to give every collection of n units from the population; that is, the probability that the sample will consist of any given subset of n of the N units in the population is 1/NCn. Simple random sampling is sampling at random without replacement (without replacing the units between draws). A simple random sample of size n from a population of N ≥ n units can be constructed by assigning a random number between zero and one to each unit in the population, then taking those units that were assigned the n largest random numbers to be the sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;251&lt;/td&gt;&#xA;          &lt;td&gt;Simpson’s Paradox.&lt;/td&gt;&#xA;          &lt;td&gt;What is true for the parts is not necessarily true for the whole. See also confounding.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;252&lt;/td&gt;&#xA;          &lt;td&gt;Skewed Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;A distribution that is not symmetrical.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;253&lt;/td&gt;&#xA;          &lt;td&gt;Spread, Measure of.&lt;/td&gt;&#xA;          &lt;td&gt;See also inter-quartile range, range, and standard deviation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;254&lt;/td&gt;&#xA;          &lt;td&gt;Square-Root Law.&lt;/td&gt;&#xA;          &lt;td&gt;The Square-Root Law says that the standard error (SE) of the sample sum of n random draws with replacement from a box of tickets with numbers on them is SE(sample sum) = n½×SD(box), and the standard error of the sample mean of n random draws with replacement from a box of tickets is SE(sample mean) = n−½×SD(box), where SD(box) is the standard deviation of the list of the numbers on all the tickets in the box (including repeated values).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;255&lt;/td&gt;&#xA;          &lt;td&gt;Standard Deviation (SD).&lt;/td&gt;&#xA;          &lt;td&gt;The standard deviation of a set of numbers is the rms of the set of deviations between each element of the set and the mean of the set. See also sample standard deviation.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;256&lt;/td&gt;&#xA;          &lt;td&gt;Standard Error (SE).&lt;/td&gt;&#xA;          &lt;td&gt;The Standard Error of a random variable is a measure of how far it is likely to be from its expected value; that is, its scatter in repeated experiments. The SE of a random variable X is defined to be SE(X) = [E( (X − E(X))2 )] ½. That is, the standard error is the square-root of the expected squared difference between the random variable and its expected value. The SE of a random variable is analogous to the SD of a list.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;257&lt;/td&gt;&#xA;          &lt;td&gt;Standard Normal Curve.&lt;/td&gt;&#xA;          &lt;td&gt;See normal curve.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;258&lt;/td&gt;&#xA;          &lt;td&gt;Standard Units.&lt;/td&gt;&#xA;          &lt;td&gt;A variable (a set of data) is said to be in standard units if its mean is zero and its standard deviation is one. You transform a set of data into standard units by subtracting the mean from each element of the list, and dividing the results by the standard deviation. A random variable is said to be in standard units if its expected value is zero and its standard error is one. You transform a random variable to standard units by subtracting its expected value then dividing by its standard error.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;259&lt;/td&gt;&#xA;          &lt;td&gt;Standardize.&lt;/td&gt;&#xA;          &lt;td&gt;To transform into standard units.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;260&lt;/td&gt;&#xA;          &lt;td&gt;Statistic.&lt;/td&gt;&#xA;          &lt;td&gt;A number that can be computed from data, involving no unknown parameters. As a function of a random sample, a statistic is a random variable. Statistics are used to estimate parameters, and to test hypotheses.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;261&lt;/td&gt;&#xA;          &lt;td&gt;Stratified Sample.&lt;/td&gt;&#xA;          &lt;td&gt;In a stratified sample, subsets of sampling units are selected separately from different strata, rather than from the frame as a whole.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;262&lt;/td&gt;&#xA;          &lt;td&gt;Stratified sampling&lt;/td&gt;&#xA;          &lt;td&gt;The act of drawing a stratified sample.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;263&lt;/td&gt;&#xA;          &lt;td&gt;Stratum&lt;/td&gt;&#xA;          &lt;td&gt;In random sampling, sometimes the sample is drawn separately from different disjoint subsets of the population. Each such subset is called a stratum. (The plural of stratum is strata.) Samples drawn in such a way are called stratified samples. Estimators based on stratified random samples can have smaller sampling errors than estimators computed from simple random samples of the same size, if the average variability of the variable of interest within strata is smaller than it is across the entire population; that is, if stratum membership is associated with the variable. For example, to determine average home prices in the U.S., it would be advantageous to stratify on geography, because average home prices vary enormously with location. We might divide the country into states, then divide each state into urban, suburban, and rural areas; then draw random samples separately from each such division.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;264&lt;/td&gt;&#xA;          &lt;td&gt;Studentized score&lt;/td&gt;&#xA;          &lt;td&gt;The observed value of a statistic, minus the expected value of the statistic, divided by the estimated standard error of the statistic.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;265&lt;/td&gt;&#xA;          &lt;td&gt;Student’s t curve.&lt;/td&gt;&#xA;          &lt;td&gt;Student’s t curve is a family of curves indexed by a parameter called the degrees of freedom, which can take the values 1, 2, … Student’s t curve is used to approximate some probability histograms. Consider a population of numbers that are nearly normally distributed and have population mean is μ. Consider drawing a random sample of size n with replacement from the population, and computing the sample mean M and the sample standard deviation S. Define the random variable T = (M − μ)/(S/n½). If the sample size n is large, the probability histogram of T can be approximated accurately by the normal curve. However, for small and intermediate values of n, Student’s t curve with n − 1 degrees of freedom gives a better approximation. That is, P(a &amp;lt; T &amp;lt; b) is approximately the area under Student’s T curve with n − 1 degrees of freedom, from a to b. Student’s t curve can be used to test hypotheses about the population mean and construct confidence intervals for the population mean, when the population distribution is known to be nearly normally distributed. This page contains a tool that shows Student’s t curve and lets you find the area under parts of the curve.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;266&lt;/td&gt;&#xA;          &lt;td&gt;Subject, Experimental Subject.&lt;/td&gt;&#xA;          &lt;td&gt;A member of the control group or the treatment group.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;267&lt;/td&gt;&#xA;          &lt;td&gt;Subset.&lt;/td&gt;&#xA;          &lt;td&gt;A subset of a given set is a collection of things that belong to the original set. Every element of the subset must belong to the original set, but not every element of the original set need be in a subset (otherwise, a subset would always be identical to the set it came from).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;268&lt;/td&gt;&#xA;          &lt;td&gt;Survey.&lt;/td&gt;&#xA;          &lt;td&gt;See sample survey.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;269&lt;/td&gt;&#xA;          &lt;td&gt;Symmetric Distribution.&lt;/td&gt;&#xA;          &lt;td&gt;The probability distribution of a random variable X is symmetric if there is a number a such that the chance that X≥a+b is the same as the chance that X≤a−b for every value of b. A list of numbers has a symmetric distribution if there is a number a such that the fraction of numbers in the list that are greater than or equal to a+b is the same as the fraction of numbers in the list that are less than or equal to a−b, for every value of b. In either case, the histogram or the probability histogram will be symmetrical about a vertical line drawn at x=a.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;270&lt;/td&gt;&#xA;          &lt;td&gt;Systematic error.&lt;/td&gt;&#xA;          &lt;td&gt;An error that affects all the measurements similarly. For example, if a ruler is too short, everything measured with it will appear to be longer than it really is (ignoring random error). If your watch runs fast, every time interval you measure with it will appear to be longer than it really is (again, ignoring random error). Systematic errors do not tend to average out.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;271&lt;/td&gt;&#xA;          &lt;td&gt;Systematic sample.&lt;/td&gt;&#xA;          &lt;td&gt;A systematic sample from a frame of units is one drawn by listing the units and selecting every kth element of the list. For example, if there are N units in the frame, and we want a sample of size N/10, we would take every tenth unit: the first unit, the eleventh unit, the 21st unit, etc. Systematic samples are not random samples, but they often behave essentially as if they were random, if the order in which the units appears in the list is haphazard. Systematic samples are a special case of cluster samples.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;272&lt;/td&gt;&#xA;          &lt;td&gt;Systematic random sample.&lt;/td&gt;&#xA;          &lt;td&gt;A systematic sample starting at a random point in the listing of units in the of frame, instead of starting at the first unit. Systematic random sampling is better than systematic sampling, but typically not as good as simple random sampling.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;273&lt;/td&gt;&#xA;          &lt;td&gt;t test.&lt;/td&gt;&#xA;          &lt;td&gt;An hypothesis test based on approximating the probability histogram of the test statistic by Student’s t curve. t tests usually are used to test hypotheses about the mean of a population when the sample size is intermediate and the distribution of the population is known to be nearly normal.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;274&lt;/td&gt;&#xA;          &lt;td&gt;Test Statistic.&lt;/td&gt;&#xA;          &lt;td&gt;A statistic used to test hypotheses. An hypothesis test can be constructed by deciding to reject the null hypothesis when the value of the test statistic is in some range or collection of ranges. To get a test with a specified significance level, the chance when the null hypothesis is true that the test statistic falls in the range where the hypothesis would be rejected must be at most the specified significance level. The Z statistic is a common test statistic.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;275&lt;/td&gt;&#xA;          &lt;td&gt;Transformation.&lt;/td&gt;&#xA;          &lt;td&gt;Transformations turn lists into other lists, or variables into other variables. For example, to transform a list of temperatures in degrees Celsius into the corresponding list of temperatures in degrees Fahrenheit, you multiply each element by 9/5, and add 32 to each product. This is an example of an affine transformation: multiply by something and add something (y = ax + b is the general affine transformation of x; it’s the familiar equation of a straight line). In a linear transformation, you only multiply by something (y = ax). Affine transformations are used to put variables in standard units. In that case, you subtract the mean and divide the results by the SD. This is equivalent to multiplying by the reciprocal of the SD and adding the negative of the mean, divided by the SD, so it is an affine transformation. Affine transformations with positive multiplicative constants have a simple effect on the mean, median, mode, quartiles, and other percentiles: the new value of any of these is the old one, transformed using exactly the same formula. When the multiplicative constant is negative, the mean, median, mode, are still transformed by the same rule, but quartiles and percentiles are reversed: the qth quantile of the transformed distribution is the transformed value of the 1−qth quantile of the original distribution (ignoring the effect of data spacing). The effect of an affine transformation on the SD, range, and IQR, is to make the new value the old value times the absolute value of the number you multiplied the first list by: what you added does not affect them.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;276&lt;/td&gt;&#xA;          &lt;td&gt;Treatment.&lt;/td&gt;&#xA;          &lt;td&gt;The substance or procedure studied in an experiment or observational study. At issue is whether the treatment has an effect on the outcome or variable of interest.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;277&lt;/td&gt;&#xA;          &lt;td&gt;Treatment Effect.&lt;/td&gt;&#xA;          &lt;td&gt;The effect of the treatment on the variable of interest. Establishing whether the treatment has an effect is the point of an experiment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;278&lt;/td&gt;&#xA;          &lt;td&gt;Treatment group.&lt;/td&gt;&#xA;          &lt;td&gt;The individuals who receive the treatment, as opposed to those in the control group, who do not.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;279&lt;/td&gt;&#xA;          &lt;td&gt;Tuple, n-tuple.&lt;/td&gt;&#xA;          &lt;td&gt;A tuple is an ordered collection of things. Two tuples are equal if they contain the same things, in the same order. For instance, the tuple (1, 2, 3) is equal to the tuple (1, 2, 3) but not equal to the tuple (1, 3, 2). Tuples can contain repeated elements. For instance, the tuple (1, 2, 2) is not equal to the tuple (1, 2), nor to the tuple (2, 2, 1). An n-tuple, where n is an integer, is a tuple with n positions. For example, (1, 2) is a 2-tuple (aka ordered pair) and (7, 3, 2, 2, 2, 1) is a 6-tuple.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;280&lt;/td&gt;&#xA;          &lt;td&gt;Two-sided Hypothesis test.&lt;/td&gt;&#xA;          &lt;td&gt;C.f. one-sided test. An hypothesis test of the null hypothesis that the value of a parameter, μ, is equal to a null value, μ0, designed to have power against the alternative hypothesis that either μ &amp;lt; μ0 or μ &amp;gt; μ0 (the alternative hypothesis contains values on both sides of the null value). For example, a significance level 5%, two-sided z test of the null hypothesis that the mean of a population equals zero against the alternative that it is greater than zero would reject the null hypothesis for values of $$ /z/ = \left / \frac{\mbox{sample mean}}{\mbox{SE}} \right / &amp;gt; 1.96.$$&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;281&lt;/td&gt;&#xA;          &lt;td&gt;Type I and Type II errors.&lt;/td&gt;&#xA;          &lt;td&gt;These refer to hypothesis testing. A Type I error occurs when the null hypothesis is rejected erroneously when it is in fact true. A Type II error occurs if the null hypothesis is not rejected when it is in fact false. See also significance level and power.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;282&lt;/td&gt;&#xA;          &lt;td&gt;Unbiased.&lt;/td&gt;&#xA;          &lt;td&gt;Not biased; having zero bias.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;283&lt;/td&gt;&#xA;          &lt;td&gt;Uncontrolled Experiment.&lt;/td&gt;&#xA;          &lt;td&gt;An experiment in which there is no control group; i.e., in which the method of comparison is not used: the experimenter decides who gets the treatment, but the outcome of the treated group is not compared with the outcome of a control group that does not receive treatment.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;284&lt;/td&gt;&#xA;          &lt;td&gt;Uncorrelated.&lt;/td&gt;&#xA;          &lt;td&gt;A set of bivariate data is uncorrelated if its correlation coefficient is zero. Two random variables are uncorrelated if the expected value of their product equals the product of their expected values. If two random variables are independent, they are uncorrelated. (The converse is not true in general.)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;285&lt;/td&gt;&#xA;          &lt;td&gt;Uncountable.&lt;/td&gt;&#xA;          &lt;td&gt;A set is uncountable if it is not countable, that is, if its elements cannot be put in one-to-one correspondence with the positive integers.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;286&lt;/td&gt;&#xA;          &lt;td&gt;Unimodal.&lt;/td&gt;&#xA;          &lt;td&gt;Having exactly one mode.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;287&lt;/td&gt;&#xA;          &lt;td&gt;Union.&lt;/td&gt;&#xA;          &lt;td&gt;The union of two or more sets is the set of objects contained by at least one of the sets. The union of the events A and B is denoted “A+B”, “A or B”, and “A∪B”. C.f. intersection.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;288&lt;/td&gt;&#xA;          &lt;td&gt;Unit.&lt;/td&gt;&#xA;          &lt;td&gt;A member of a population.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;289&lt;/td&gt;&#xA;          &lt;td&gt;Univariate.&lt;/td&gt;&#xA;          &lt;td&gt;Having or having to do with a single variable. Some univariate techniques and statistics include the histogram, IQR, mean, median, percentiles, quantiles, and SD. C.f. bivariate.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;290&lt;/td&gt;&#xA;          &lt;td&gt;Upper Quartile (UQ).&lt;/td&gt;&#xA;          &lt;td&gt;See quartiles.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;291&lt;/td&gt;&#xA;          &lt;td&gt;Valid (logical) argument.&lt;/td&gt;&#xA;          &lt;td&gt;A valid logical argument is one in which the truth of the premises indeed guarantees the truth of the conclusion. For example, the following logical argument is valdraft: false&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;id: If the forecast calls for rain, I will not wear sandals. The forecast calls for rain. Therefore, I will not wear sandals. This argument has two premises which, together, guarantee the truth of the conclusion. An argument can be logically valid even if its premises are false. See also invalid argument and sound argument.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;292&lt;/td&gt;&#xA;          &lt;td&gt;Variable.&lt;/td&gt;&#xA;          &lt;td&gt;A numerical value or a characteristic that can differ from individual to individual. See also categorical variable, qualitative variable, quantitative variable, discrete variable, continuous variable, and random variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;293&lt;/td&gt;&#xA;          &lt;td&gt;Variance, population variance&lt;/td&gt;&#xA;          &lt;td&gt;The variance of a list is the square of the standard deviation of the list, that is, the average of the squares of the deviations of the numbers in the list from their mean. The variance of a random variable X, Var(X), is the expected value of the squared difference between the variable and its expected value: Var(X) = E((X − E(X))2). The variance of a random variable is the square of the standard error (SE) of the variable.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;294&lt;/td&gt;&#xA;          &lt;td&gt;Venn Diagram.&lt;/td&gt;&#xA;          &lt;td&gt;A pictorial way of showing the relations among sets or events. The universal set or outcome space is usually drawn as a rectangle; sets are regions within the rectangle. The overlap of the regions corresponds to the intersection of the sets. If the regions do not overlap, the sets are disjoint. The part of the rectangle included in one or more of the regions corresponds to the union of the sets. This page contains a tool that illustrates Venn diagrams; the tool represents the probability of an event by the area of the event.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;295&lt;/td&gt;&#xA;          &lt;td&gt;XOR, exclusive disjunction.&lt;/td&gt;&#xA;          &lt;td&gt;XOR is an operation on two logical propositions. If p and q are two propositions, (p XOR q) is a proposition that is true if either p is true or if q is true, but not both. (p XOR q) is logically equivalent to ((p&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;296&lt;/td&gt;&#xA;          &lt;td&gt;z-score&lt;/td&gt;&#xA;          &lt;td&gt;The observed value of the Z statistic.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;297&lt;/td&gt;&#xA;          &lt;td&gt;Z statistic&lt;/td&gt;&#xA;          &lt;td&gt;A Z statistic is a test statistic whose distribution under the null hypothesis has expected value zero and can be approximated well by the normal curve. Usually, Z statistics are constructed by standardizing some other statistic. The Z statistic is related to the original statistic by Z = (original − expected value of original)/SE(original).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;298&lt;/td&gt;&#xA;          &lt;td&gt;z-test&lt;/td&gt;&#xA;          &lt;td&gt;An hypothesis test based on approximating thehttps://dasarpai.com/300-important-statistical-terms/ probability histogram of the Z statistic under the null hypothesis by the normal curve.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;&#xA;&lt;p&gt;These definitions are taken from - &lt;a href=&#34;https://www.stat.berkeley.edu/~stark/SticiGui/Text/gloss.htm&#34;&gt;https://www.stat.berkeley.edu/~stark/SticiGui/Text/gloss.htm&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Folder Structure for ML Project</title>
      <link>http://localhost:1313/dsblog/Folder-Structure-for-ML-Project/</link>
      <pubDate>Mon, 20 Sep 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Folder-Structure-for-ML-Project/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6010-Directory-Strucutre-of-ML-Project.jpg&#34; alt=&#34;Configuration Management&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Directory Structure for ML Project&lt;/strong&gt; is critical for any serious data science project. What we learn from a technology college and institution is useful in a real-world business, but the problem is that environment is completely different, and it takes proper guidance to adapt to a real business environment. Many times traveling on this path is full of frustration without any proper guidance. Sometimes guidance is there, but it is like blind is leading blind. One has already navigated a lot with struggle, so she/he is trying to guide a new person. Data-science education is not any different from this. From universities and institutions, we learn many concepts, algorithms, art, and science of developing models, etc. but when our customer or management tells us a problem with a simplistic dataset then we don’t know how to proceed. Although there are many templates and frameworks to approach, yet there is no simple cookie-cutter solution for all kinds of problems. Depending upon project duration, resources (human + machine + software), client, and his/her need, the technology available at hand we can choose different approaches.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Generalized AI Model for Prediction</title>
      <link>http://localhost:1313/dsblog/Generalized-AI-Model-for-Prediction/</link>
      <pubDate>Fri, 17 Sep 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Generalized-AI-Model-for-Prediction/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6009-Generalized-AI-Model-for-Prediction.jpg&#34; alt=&#34;Generalized AI Model for Prediction&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;Can we really Develop AI solutions that can predict human behavior? If you are not a technical person then don’t get overwhelmed by the next paragraph, you can read further, and it will make sense to you.&lt;/p&gt;&#xA;&lt;p&gt;We know the basic equation, y = mx + c. This comes from algebra and trigonometry. Here, y is the predicted value, and x is the input. The x can be a simple scalar value or a vector. Similarly, m is the coefficient in this equation, and it can be a simple scalar value or a vector. If m or x is a vector, then it can hold multiple values. The value of m corresponding to x is also called slope in trigonometry. If a plane is 2 dimensional, then you have one m and one x. But if a plane is complex, and it has, let us say, 10 dimensions then it has 9 m and 9 x. 10th dimensions is predicted by these 9 m and 9 x, using the earlier formula. How that multiplication happens is easy for those who know vector and matrix multiplication, but for others, it is really complicated. So, you can leave it for the time being.&lt;/p&gt;</description>
    </item>
    <item>
      <title>20 Reasons Why AI Project Fails</title>
      <link>http://localhost:1313/dsblog/20-Reasons-Why-AI-Project-Fails/</link>
      <pubDate>Fri, 20 Aug 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/20-Reasons-Why-AI-Project-Fails/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6007-Why-AI-Project-Fails.jpg&#34; alt=&#34;Why AI Project Fails&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;why-does-ai-project-fails&#34;&gt;Why Does AI Project Fails?&lt;/h1&gt;&#xA;&lt;p&gt;I have been in IT project management for 2+ decades. Being in the industry for quite a good time, I have been observing the rise and fall of project success trends of different industries. In the last couple of years, I have observed some trends in AI projects and their failure rate. Based on my understanding I am trying to summarize the reasons for AI project failure. I am sure many of the points will resonate with you. &lt;/p&gt;</description>
    </item>
    <item>
      <title>What Are Transformers in AI</title>
      <link>http://localhost:1313/dsblog/What-Are-Transformers-in-AI/</link>
      <pubDate>Tue, 03 Aug 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-Are-Transformers-in-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6031-What-are-Transformers-in-AI.jpg&#34; alt=&#34;What-are-Transformers-in-AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-are-transformers-in-ai&#34;&gt;What Are Transformers in AI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;transformer-architecture&#34;&gt;Transformer Architecture&lt;/h2&gt;&#xA;&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/transformer/transformer-arch.jpg&#34; alt=&#34;Transformer&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;&#xA;&lt;p&gt;Whether GPT, ChatGPT, DALL-E, Whisper, Satablity AI or whatever significant you see in the AI worlds nowdays it is because of Transformer Architecture. Transformers are a type of neural network architecture that have several properties that make them effective for modeling data with long-range dependencies. They generally feature a combination of multi-headed attention mechanisms, residual connections, layer normalization, feedforward connections, and positional embeddings.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Github Repos for Data Science</title>
      <link>http://localhost:1313/dsblog/Github-Repos-for-DataScience/</link>
      <pubDate>Thu, 22 Jul 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Github-Repos-for-DataScience/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr122-Github-Repos-to-Learn-DataScience.jpg&#34; alt=&#34;Github Repos for Data Science&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;github-repos-for-datascience&#34;&gt;Github-Repos-for-DataScience&lt;/h1&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno.&lt;/th&gt;&#xA;          &lt;th&gt;Repo Name&lt;/th&gt;&#xA;          &lt;th&gt;Repo Description&lt;/th&gt;&#xA;          &lt;th&gt;Language&lt;/th&gt;&#xA;          &lt;th&gt;Starred&lt;/th&gt;&#xA;          &lt;th&gt;Fork&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/abacaj/awesome-transformers&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A curated list of awesome transformer models.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;504&lt;/td&gt;&#xA;          &lt;td&gt;35&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/academic/awesome-datascience&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;:memo: An awesome Data Science repository to learn and apply for real world problems.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;21350&lt;/td&gt;&#xA;          &lt;td&gt;5461&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Detailed and tailored guide for undergraduate students or anybody want to dig deep into the field of AI with solid foundation.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;6440&lt;/td&gt;&#xA;          &lt;td&gt;900&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/AI4Bharat/indicnlp_catalog&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A collaborative catalog of NLP resources for Indic languages&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;432&lt;/td&gt;&#xA;          &lt;td&gt;64&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/alexeygrigorev/mlbookcamp-code&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The code from the Machine Learning Bookcamp book and a free course based on the book&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;6042&lt;/td&gt;&#xA;          &lt;td&gt;1562&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/alexlenail/NN-SVG&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Publication-ready NN-architecture schematics.&lt;/td&gt;&#xA;          &lt;td&gt;JavaScript&lt;/td&gt;&#xA;          &lt;td&gt;3770&lt;/td&gt;&#xA;          &lt;td&gt;478&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/altryne/chatGPT-telegram-bot&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is a very early attempt at having chatGPT work within a telegram bot&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1639&lt;/td&gt;&#xA;          &lt;td&gt;247&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/andrewgbruce/statistics-for-data-scientists&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Code and data associated with the book &amp;ldquo;Statistics for Data Scientists: 50 Essential Concepts&amp;rdquo;&lt;/td&gt;&#xA;          &lt;td&gt;R&lt;/td&gt;&#xA;          &lt;td&gt;1018&lt;/td&gt;&#xA;          &lt;td&gt;633&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Apress/text-analytics-w-python-2e&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Source Code for &amp;lsquo;Text Analytics with Python,&amp;rsquo; 2nd Edition by Dipanjan Sarkar&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;72&lt;/td&gt;&#xA;          &lt;td&gt;70&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ashishpatel26/365-Days-Computer-Vision-Learning-Linkedin-Post&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;365 Days Computer Vision Learning Linkedin Post&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;395&lt;/td&gt;&#xA;          &lt;td&gt;129&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;500 AI Machine learning Deep learning Computer vision NLP Projects with code&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;12607&lt;/td&gt;&#xA;          &lt;td&gt;3747&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ashishpatel26/Computer-Vision-Papers-of-the-week&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Computer Vision Papers of the week&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/aupasana/ashtadhyayi&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Various vrittis associated with the ashtadhyayi&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/avinsit123/HindiNLP&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python library to aid with your Hindi NLP tasks&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/aws-samples/ml-inference-using-aws-lambda-and-amazon-efs&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;38&lt;/td&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/aws/sagemaker-python-sdk&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A library for training and deploying machine learning models on Amazon SageMaker&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1856&lt;/td&gt;&#xA;          &lt;td&gt;985&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;17&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/b7leung/MLE-Flashcards&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;200+ detailed flashcards useful for reviewing topics in machine learning, computer vision, and computer science.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;1631&lt;/td&gt;&#xA;          &lt;td&gt;135&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;18&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/benedekrozemberczki/awesome-community-detection&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A curated list of community detection research papers with implementations.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2145&lt;/td&gt;&#xA;          &lt;td&gt;356&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/benfred/implicit&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Fast Python Collaborative Filtering for Implicit Feedback Datasets&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;3177&lt;/td&gt;&#xA;          &lt;td&gt;599&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/bfelbo/DeepMoji&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;State-of-the-art deep learning model for analyzing sentiment, emotion, sarcasm etc.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1449&lt;/td&gt;&#xA;          &lt;td&gt;317&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/bigscience-workshop/petals&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🌸 Run 100B+ language models at home, BitTorrent-style. Fine-tuning and inference up to 10x faster than offloading&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;4807&lt;/td&gt;&#xA;          &lt;td&gt;175&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/BNN-UPC/ignnition&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Framework for fast prototyping of Graph Neural Networks&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/booknlp/booknlp&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;BookNLP, a natural language processing pipeline for books&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;700&lt;/td&gt;&#xA;          &lt;td&gt;74&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;24&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/carpentries/carpentries.org&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The Carpentries website&lt;/td&gt;&#xA;          &lt;td&gt;HTML&lt;/td&gt;&#xA;          &lt;td&gt;62&lt;/td&gt;&#xA;          &lt;td&gt;122&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;25&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/carpentries/instructor-training&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Instructor Training&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;161&lt;/td&gt;&#xA;          &lt;td&gt;271&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;26&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ChristosChristofidis/awesome-deep-learning&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A curated list of awesome Deep Learning tutorials, projects and communities.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;21030&lt;/td&gt;&#xA;          &lt;td&gt;5852&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/cleanlab/cleanlab&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The standard data-centric AI package for data quality and machine learning with messy, real-world data and labels.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;6057&lt;/td&gt;&#xA;          &lt;td&gt;500&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/cmunch1/nba-prediction&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A project to deploy an online app that predicts the win probability for each NBA game every day. Demonstrates end-to-end Machine Learning deployment.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;104&lt;/td&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;29&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/codebasics/deep-learning-keras-tf-tutorial&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Learn deep learning with tensorflow2.0, keras and python through this comprehensive deep learning tutorial series. Learn deep learning from scratch. Deep learning series for beginners. Tensorflow tutorials, tensorflow 2.0 tutorial. deep learning tutorial python.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;643&lt;/td&gt;&#xA;          &lt;td&gt;1685&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;30&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/comet-ml/kangas&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🦘 Explore multimedia datasets at scale&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;920&lt;/td&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;31&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/connorferster/handcalcs&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python library for converting Python calculations into rendered latex.&lt;/td&gt;&#xA;          &lt;td&gt;CSS&lt;/td&gt;&#xA;          &lt;td&gt;5211&lt;/td&gt;&#xA;          &lt;td&gt;398&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;32&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/continuum-llms/chatgpt-memory&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Allows to scale the ChatGPT API to multiple simultaneous sessions with infinite contextual and adaptive memory powered by GPT and Redis datastore.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;363&lt;/td&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;33&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/CoreyMSchafer/code_snippets&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;9796&lt;/td&gt;&#xA;          &lt;td&gt;17732&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dair-ai/d2l-study-group&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🧠 Material for the Deep Learning Study Group&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;385&lt;/td&gt;&#xA;          &lt;td&gt;52&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;35&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dair-ai/ML-Papers-Explained&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Explanation to key concepts in ML&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;4297&lt;/td&gt;&#xA;          &lt;td&gt;355&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;36&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dair-ai/nlp_paper_summaries&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;✍️ A carefully curated list of NLP paper summaries&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;1453&lt;/td&gt;&#xA;          &lt;td&gt;249&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/darklord0303/Hindi-OCR&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;38&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dasarpai/Fish-Weight_Prediction_dep&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Fish Weight Prediction Deployment&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dasarpai/House-Price-Prediction_dep&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;40&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dasarpai/Malaria-Detection_dep&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Malaria Detection Deployed&lt;/td&gt;&#xA;          &lt;td&gt;PureBasic&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dasarpai/NLP&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;42&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dataflowr/notebooks&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;code for deep learning courses&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;877&lt;/td&gt;&#xA;          &lt;td&gt;282&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/DataForScience/Epidemiology101&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Epidemic Modeling for Everyone&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;261&lt;/td&gt;&#xA;          &lt;td&gt;72&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;44&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/datameet/india-election-data&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;To map publicly available datasets related to General Assembly (Lok Sabha) elections in India.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;137&lt;/td&gt;&#xA;          &lt;td&gt;114&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/DataTalksClub/mlops-zoomcamp&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Free MLOps course from DataTalks.Club&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;7175&lt;/td&gt;&#xA;          &lt;td&gt;1416&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;46&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Deci-AI/super-gradients&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Easily train or fine-tune SOTA computer vision models with one open source training library. The home of Yolo-NAS.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2721&lt;/td&gt;&#xA;          &lt;td&gt;235&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepchem/deepchem&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Democratizing Deep-Learning for Drug Discovery, Quantum Chemistry, Materials Science and Biology&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;4367&lt;/td&gt;&#xA;          &lt;td&gt;1499&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;48&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Developer-Y/cs-video-courses&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;List of Computer Science courses with video lectures.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;56725&lt;/td&gt;&#xA;          &lt;td&gt;8028&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;49&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dipanjanS/nlp_crash_course_plugin20&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Contains relevant notebooks for the hands-on NLP workshop for the Analytics India Magazine Plugin Conference -2020 Edition&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;70&lt;/td&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dipanjanS/nlp_workshop_odsc_europe20&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Extensive tutorials for the Advanced NLP Workshop in Open Data Science Conference Europe 2020. We will leverage machine learning, deep learning and deep transfer learning to learn and solve popular tasks using NLP including NER, Classification, Recommendation \ Information Retrieval, Summarization, Classification, Language Translation, Q&amp;amp;A and Topic Models.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;130&lt;/td&gt;&#xA;          &lt;td&gt;65&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;51&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/donnemartin/data-science-ipython-notebooks&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Data science Python notebooks: Deep learning (TensorFlow, Theano, Caffe, Keras), scikit-learn, Kaggle, big data (Spark, Hadoop MapReduce, HDFS), matplotlib, pandas, NumPy, SciPy, Python essentials, AWS, and various command lines.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;25169&lt;/td&gt;&#xA;          &lt;td&gt;7588&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;52&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dosisod/refurb&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A tool for refurbishing and modernizing Python codebases&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2250&lt;/td&gt;&#xA;          &lt;td&gt;44&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;53&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ebatty/MathToolsforNeuroscience&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Materials for Mathematical Tools for Neuroscience course  at Harvard (Neurobio 212)&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;410&lt;/td&gt;&#xA;          &lt;td&gt;55&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;54&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/equester/mlops-plugin_2020&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;MlOps End 2 End&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;55&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/eugeneyan/applied-ml&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;📚 Papers &amp;amp; tech blogs by companies sharing their work on data science &amp;amp; machine learning in production.&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;24281&lt;/td&gt;&#xA;          &lt;td&gt;3381&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;56&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/explosion/projects&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🪐 End-to-end NLP workflows from prototype to production&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1106&lt;/td&gt;&#xA;          &lt;td&gt;444&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;57&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/explosion/spaCy&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;💫 Industrial-strength Natural Language Processing (NLP) in Python&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;26318&lt;/td&gt;&#xA;          &lt;td&gt;4134&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;58&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/dropout&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Code release for &amp;ldquo;Dropout Reduces Underfitting&amp;rdquo;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;290&lt;/td&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;59&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/fairseq&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Facebook AI Research Sequence-to-Sequence Toolkit written in Python.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;26266&lt;/td&gt;&#xA;          &lt;td&gt;5833&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;60&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/fastText&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Library for fast text representation and classification.&lt;/td&gt;&#xA;          &lt;td&gt;HTML&lt;/td&gt;&#xA;          &lt;td&gt;24685&lt;/td&gt;&#xA;          &lt;td&gt;4608&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;61&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/hiplot&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;HiPlot makes understanding high dimensional data easy&lt;/td&gt;&#xA;          &lt;td&gt;TypeScript&lt;/td&gt;&#xA;          &lt;td&gt;2485&lt;/td&gt;&#xA;          &lt;td&gt;125&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;62&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/llama&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Inference code for LLaMA models&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;23064&lt;/td&gt;&#xA;          &lt;td&gt;3680&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;63&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/fastai/fastbook&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The fastai book, published as Jupyter Notebooks&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;18575&lt;/td&gt;&#xA;          &lt;td&gt;7081&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;64&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/fastai/numerical-linear-algebra&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Free online textbook of Jupyter notebooks for fast.ai Computational Linear Algebra course&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;9442&lt;/td&gt;&#xA;          &lt;td&gt;2413&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;65&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/FavioVazquez/ds-cheatsheets&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;List of Data Science Cheatsheets to rule the world&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;12211&lt;/td&gt;&#xA;          &lt;td&gt;3437&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;66&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/flairNLP/flair&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A very simple framework for state-of-the-art Natural Language Processing (NLP)&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;12852&lt;/td&gt;&#xA;          &lt;td&gt;2027&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;67&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/freeCodeCamp/freeCodeCamp&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;freeCodeCamp.org&amp;rsquo;s open-source codebase and curriculum. Learn to code for free.&lt;/td&gt;&#xA;          &lt;td&gt;TypeScript&lt;/td&gt;&#xA;          &lt;td&gt;368430&lt;/td&gt;&#xA;          &lt;td&gt;32357&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;68&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/GokuMohandas/Made-With-ML&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Learn how to responsibly develop, deploy and maintain production machine learning applications.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;33342&lt;/td&gt;&#xA;          &lt;td&gt;5462&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;69&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/goodrahstar/draw-neural-network&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Quick tool to draw fully connected neural network architectures&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;42&lt;/td&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;70&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/google-research/google-research&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Google Research&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;29664&lt;/td&gt;&#xA;          &lt;td&gt;7307&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;71&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/goru001/nlp-for-sanskrit&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;State of the Art Language models and Classifier for Sanskrit language (ancient indian language)&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;63&lt;/td&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;72&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/hannarud/ExData_Plotting1&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Plotting Assignment 1 for Exploratory Data Analysis&lt;/td&gt;&#xA;          &lt;td&gt;R&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;73&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Hironsan/awesome-embedding-models&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A curated list of awesome embedding models tutorials, projects and communities.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;1629&lt;/td&gt;&#xA;          &lt;td&gt;243&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;74&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/HKUNLP/icl-ceil&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;[ICML 2023] Code for our paper “Compositional Exemplars for In-context Learning”.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;75&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/diffusers&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🤗 Diffusers: State-of-the-art diffusion models for image and audio generation in PyTorch&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;15407&lt;/td&gt;&#xA;          &lt;td&gt;3082&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;76&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/neuralcoref&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;✨Fast Coreference Resolution in spaCy with Neural Networks&lt;/td&gt;&#xA;          &lt;td&gt;C&lt;/td&gt;&#xA;          &lt;td&gt;2698&lt;/td&gt;&#xA;          &lt;td&gt;470&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;77&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🤗 Transformers: State-of-the-art Machine Learning for Pytorch, TensorFlow, and JAX.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;103371&lt;/td&gt;&#xA;          &lt;td&gt;20879&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;78&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/hundredblocks/concrete_NLP_tutorial&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An NLP workshop about concrete solutions to real problems&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;1078&lt;/td&gt;&#xA;          &lt;td&gt;453&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;79&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/hwchase17/langchain&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;⚡ Building applications with LLMs through composability ⚡&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;46250&lt;/td&gt;&#xA;          &lt;td&gt;5424&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;80&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Ileriayo/markdown-badges&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Badges for your personal developer branding, profile, and projects.&lt;/td&gt;&#xA;          &lt;td&gt;SCSS&lt;/td&gt;&#xA;          &lt;td&gt;8133&lt;/td&gt;&#xA;          &lt;td&gt;1193&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;81&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Instruction-Tuning-with-GPT-4/GPT-4-LLM&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Instruction Tuning with GPT-4&lt;/td&gt;&#xA;          &lt;td&gt;HTML&lt;/td&gt;&#xA;          &lt;td&gt;2805&lt;/td&gt;&#xA;          &lt;td&gt;198&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;82&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/iryna-kondr/scikit-llm&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1789&lt;/td&gt;&#xA;          &lt;td&gt;139&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;83&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/isl-org/Open3D&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Open3D: A Modern Library for 3D Data Processing&lt;/td&gt;&#xA;          &lt;td&gt;C++&lt;/td&gt;&#xA;          &lt;td&gt;8999&lt;/td&gt;&#xA;          &lt;td&gt;1987&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;84&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/javascriptdata/dnotebook&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Dnotebook is a Jupyter-like library for javaScript environment. It allows you to create and share pages that contain live code, text and visualizations.&lt;/td&gt;&#xA;          &lt;td&gt;TypeScript&lt;/td&gt;&#xA;          &lt;td&gt;139&lt;/td&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;85&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/jaymody/picoGPT&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An unnecessarily tiny implementation of GPT-2 in NumPy.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2392&lt;/td&gt;&#xA;          &lt;td&gt;301&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;86&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/jivoi/awesome-ml-for-cybersecurity&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;:octocat: Machine Learning for Cyber Security&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;5964&lt;/td&gt;&#xA;          &lt;td&gt;1626&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;87&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/jonathan-laurent/AlphaZero.jl&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A generic, simple and fast implementation of Deepmind&amp;rsquo;s AlphaZero algorithm.&lt;/td&gt;&#xA;          &lt;td&gt;Julia&lt;/td&gt;&#xA;          &lt;td&gt;1132&lt;/td&gt;&#xA;          &lt;td&gt;119&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;88&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/josephmisiti/awesome-machine-learning&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A curated list of awesome Machine Learning frameworks, libraries and software.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;59061&lt;/td&gt;&#xA;          &lt;td&gt;14052&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;89&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/JuliaAI/MLJBase.jl&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Core functionality for the MLJ machine learning framework&lt;/td&gt;&#xA;          &lt;td&gt;Julia&lt;/td&gt;&#xA;          &lt;td&gt;140&lt;/td&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;90&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/justmarkham/DAT5&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;General Assembly&amp;rsquo;s Data Science course in Washington, DC&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;187&lt;/td&gt;&#xA;          &lt;td&gt;212&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;91&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/kadirnar/segment-anything-video&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;MetaSeg: Packaged version of the Segment Anything repository&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;649&lt;/td&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;92&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/kailashahirwar/cheatsheets-ai&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Essential Cheat Sheets for deep learning and machine learning researchers &lt;a href=&#34;https://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5&#34;&gt;https://medium.com/@kailashahirwar/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;14619&lt;/td&gt;&#xA;          &lt;td&gt;3457&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;93&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/karpathy/arxiv-sanity-preserver&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Web interface for browsing, search and filtering recent arxiv submissions&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;4846&lt;/td&gt;&#xA;          &lt;td&gt;1319&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;94&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/kedro-org/kedro&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A Python framework for creating maintainable and modular data science code.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;8421&lt;/td&gt;&#xA;          &lt;td&gt;796&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;95&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/kmario23/deep-learning-drizzle&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Drench yourself in Deep Learning, Reinforcement Learning, Machine Learning, Computer Vision, and NLP by learning from these exciting lectures!!&lt;/td&gt;&#xA;          &lt;td&gt;HTML&lt;/td&gt;&#xA;          &lt;td&gt;11207&lt;/td&gt;&#xA;          &lt;td&gt;2832&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;96&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/krishnaik06/Transfer-Learning&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;67&lt;/td&gt;&#xA;          &lt;td&gt;100&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;97&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/kyrolabs/awesome-langchain&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;😎 Awesome list of tools and projects with the awesome LangChain framework&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;2834&lt;/td&gt;&#xA;          &lt;td&gt;145&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;98&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/labmlai/annotated_deep_learning_paper_implementations&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🧑‍🏫 59 Implementations/tutorials of deep learning papers with side-by-side notes 📝; including transformers (original, xl, switch, feedback, vit, &amp;hellip;), optimizers (adam, adabelief, &amp;hellip;), gans(cyclegan, stylegan2, &amp;hellip;), 🎮 reinforcement learning (ppo, dqn), capsnet, distillation, &amp;hellip; 🧠&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;24047&lt;/td&gt;&#xA;          &lt;td&gt;2580&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;99&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/lllyasviel/ControlNet&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Let us control diffusion models!&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;20472&lt;/td&gt;&#xA;          &lt;td&gt;1899&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;100&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/lucidrains/DALLE2-pytorch&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Implementation of DALL-E 2, OpenAI&amp;rsquo;s updated text-to-image synthesis neural network,  in Pytorch&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;9799&lt;/td&gt;&#xA;          &lt;td&gt;934&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;101&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/maikherbig/AIDeveloper&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;GUI-based software for training, evaluating and applying deep neural nets for image classification&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;82&lt;/td&gt;&#xA;          &lt;td&gt;18&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;102&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/manoss96/pregex&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PRegEx - Programmable Regular Expressions&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;718&lt;/td&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;103&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/matplotlib/ipympl&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Matplotlib Jupyter Integration&lt;/td&gt;&#xA;          &lt;td&gt;TypeScript&lt;/td&gt;&#xA;          &lt;td&gt;1434&lt;/td&gt;&#xA;          &lt;td&gt;216&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;104&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/MaxDu17/BehaviorRetrieval&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Code for the Behavior Retrieval Paper&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;105&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/mdipietro09/DataScience_ArtificialIntelligence_Utils&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Examples of Data Science projects and Artificial Intelligence use-cases&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;344&lt;/td&gt;&#xA;          &lt;td&gt;267&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;106&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/Data-Science-For-Beginners&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;10 Weeks, 20 Lessons, Data Science for All!&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;19639&lt;/td&gt;&#xA;          &lt;td&gt;3872&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;107&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/ML-For-Beginners&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;12 weeks, 26 lessons, 52 quizzes, classic Machine Learning for all&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;49227&lt;/td&gt;&#xA;          &lt;td&gt;10169&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;108&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/microsoft/torchscale&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Transformers at any scale&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1667&lt;/td&gt;&#xA;          &lt;td&gt;92&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;109&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/MicrosoftLearning/AI-102-AIEngineer&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Lab files for AI-102 - AI Engineer&lt;/td&gt;&#xA;          &lt;td&gt;C#&lt;/td&gt;&#xA;          &lt;td&gt;342&lt;/td&gt;&#xA;          &lt;td&gt;452&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;110&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/MicrosoftLearning/MCT-User-Guide&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;GitHub User Guide for MCTs&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;38&lt;/td&gt;&#xA;          &lt;td&gt;25&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;111&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/mikblack/instructor-training&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Software and Data Carpentry instructor training course material&lt;/td&gt;&#xA;          &lt;td&gt;HTML&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;112&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/mindsdb/lightwood&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Lightwood is Legos for Machine Learning.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;369&lt;/td&gt;&#xA;          &lt;td&gt;82&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;113&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/mljar/mercury&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Build Web Apps in Jupyter Notebook with Python only&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;3117&lt;/td&gt;&#xA;          &lt;td&gt;188&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;114&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/muthuishere/rxpython-sessions&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;115&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/nomic-ai/gpt4all&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;gpt4all: an ecosystem of open-source chatbots trained on a massive collections of clean assistant data including code, stories and dialogue&lt;/td&gt;&#xA;          &lt;td&gt;C++&lt;/td&gt;&#xA;          &lt;td&gt;45786&lt;/td&gt;&#xA;          &lt;td&gt;4869&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;116&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/nshiab/simple-data-analysis.js&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Easy-to-use JavaScript library for most common data analysis tasks.&lt;/td&gt;&#xA;          &lt;td&gt;TypeScript&lt;/td&gt;&#xA;          &lt;td&gt;121&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;117&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/NVlabs/GroupViT&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Official PyTorch implementation of GroupViT: Semantic Segmentation Emerges from Text Supervision, CVPR 2022.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;595&lt;/td&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;118&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Nyandwi/machine_learning_complete&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A comprehensive machine learning repository containing 30+ notebooks on different concepts, algorithms and techniques.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;4139&lt;/td&gt;&#xA;          &lt;td&gt;654&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;119&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/omarsar/nlp_overview&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Overview of Modern Deep Learning Techniques Applied to Natural Language Processing&lt;/td&gt;&#xA;          &lt;td&gt;CSS&lt;/td&gt;&#xA;          &lt;td&gt;1294&lt;/td&gt;&#xA;          &lt;td&gt;198&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;120&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/online-ml/river&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🌊 Online machine learning in Python&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;4262&lt;/td&gt;&#xA;          &lt;td&gt;474&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;121&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/openai-cookbook&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Examples and guides for using the OpenAI API&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;38518&lt;/td&gt;&#xA;          &lt;td&gt;5764&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;122&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openvenues/libpostal&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A C library for parsing/normalizing street addresses around the world. Powered by statistical NLP and open geo data.&lt;/td&gt;&#xA;          &lt;td&gt;C&lt;/td&gt;&#xA;          &lt;td&gt;3718&lt;/td&gt;&#xA;          &lt;td&gt;392&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;123&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openvenues/pypostal&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python bindings to libpostal for fast international address parsing/normalization&lt;/td&gt;&#xA;          &lt;td&gt;C&lt;/td&gt;&#xA;          &lt;td&gt;678&lt;/td&gt;&#xA;          &lt;td&gt;80&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;124&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ourownstory/neural_prophet&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;NeuralProphet: A simple forecasting package&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2977&lt;/td&gt;&#xA;          &lt;td&gt;419&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;125&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/PacktPublishing/Data-Science-for-Marketing-Analytics-Second-Edition&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;79&lt;/td&gt;&#xA;          &lt;td&gt;89&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;126&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/paperswithcode/paperswithcode-data&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The full dataset behind paperswithcode.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;267&lt;/td&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;127&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/pemagrg1/Hindi-POS-Tagging-and-Keyword-Extraction&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Hindi POS Tags and keywords using TNT model. Created Date: 28 Sept 2018&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;128&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/piyushpathak03/cracking-the-data-science-interview-in-7-days&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;125&lt;/td&gt;&#xA;          &lt;td&gt;49&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;129&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ploomber/ploomber&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The fastest ⚡️ way to build data pipelines. Develop iteratively, deploy anywhere. ☁️&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;3088&lt;/td&gt;&#xA;          &lt;td&gt;210&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;130&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/PrashanthVangipurapu/Sarcasm-Detection-in-Hindi-Text&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This is used for identifying whether a given text has sarcasm in it or not.&lt;/td&gt;&#xA;          &lt;td&gt;Java&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;131&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/probml/pml-book&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&amp;ldquo;Probabilistic Machine Learning&amp;rdquo; - a book series by Kevin Murphy&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;3935&lt;/td&gt;&#xA;          &lt;td&gt;484&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;132&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Public-course/TensorboardX&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Using tensorboardX (tensorboard for pytorch) e.g. ploting more than one graph in the same chat etc.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;133&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/pycaret/pycaret&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An open-source, low-code machine learning library in Python&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;7373&lt;/td&gt;&#xA;          &lt;td&gt;1604&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;134&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/pytorch/pytorch&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensors and Dynamic neural networks in Python with strong GPU acceleration&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;67669&lt;/td&gt;&#xA;          &lt;td&gt;18541&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;135&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/rafiqhasan/auto-tensorflow&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Build Low Code Automated Tensorflow explainable models in just 3 lines of code. Library created by: Hasan Rafiq - &lt;a href=&#34;https://www.linkedin.com/in/sam04/&#34;&gt;https://www.linkedin.com/in/sam04/&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;177&lt;/td&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;136&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/RamiKrispin/30DayChartChallenge&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Code for 30DayChartChallenge&lt;/td&gt;&#xA;          &lt;td&gt;R&lt;/td&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;137&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/RaoUmer/dwx&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Deep Web Extractor (DWX): Deep Web Extractor system is using statistical machine learning models for crawling and data discovery from the Deep Web (i.e., massive and quality portion of World Wide Web) to build knowledge based databases.&lt;/td&gt;&#xA;          &lt;td&gt;HTML&lt;/td&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;138&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/RasaHQ/rasa&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;💬   Open source machine learning framework to automate text- and voice-based conversations: NLU, dialogue management, connect to Slack, Facebook, and more - Create chatbots and voice assistants&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;16510&lt;/td&gt;&#xA;          &lt;td&gt;4359&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;139&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/RasaHQ/rasa-nlu-trainer&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;DEPRECATED: We recommend using Rasa X &lt;a href=&#34;https://rasa.com/docs/rasa-x/&#34;&gt;https://rasa.com/docs/rasa-x/&lt;/a&gt; for managing NLU data&lt;/td&gt;&#xA;          &lt;td&gt;JavaScript&lt;/td&gt;&#xA;          &lt;td&gt;467&lt;/td&gt;&#xA;          &lt;td&gt;183&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;140&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/replicate/cog&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Containers for machine learning&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;4838&lt;/td&gt;&#xA;          &lt;td&gt;286&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;141&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/roboflow/notebooks&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Examples and tutorials on using SOTA computer vision models and techniques. Learn everything from old-school ResNet, through YOLO and object-detection transformers like DETR, to the latest models like Grounding DINO and SAM.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;2403&lt;/td&gt;&#xA;          &lt;td&gt;338&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;142&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/rohitsaluja22/OpenOCRCorrect&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An end to end Interactive Interface for correcting mistakes in OCR output.&lt;/td&gt;&#xA;          &lt;td&gt;C++&lt;/td&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;46&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;143&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ryankiros/skip-thoughts&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Sent2Vec encoder and training code from the paper &amp;ldquo;Skip-Thought Vectors&amp;rdquo;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2050&lt;/td&gt;&#xA;          &lt;td&gt;555&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;144&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/salesforce/DeepTime&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch code for Learning Deep Time-index Models for Time Series Forecasting (ICML 2023)&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;257&lt;/td&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;145&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/salesforce/Merlion&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Merlion: A Machine Learning Framework for Time Series Intelligence&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2991&lt;/td&gt;&#xA;          &lt;td&gt;258&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;146&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/sassoftware/python-swat&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The SAS Scripting Wrapper for Analytics Transfer (SWAT) package is the Python client to SAS Cloud Analytic Services (CAS).  It allows users to execute CAS actions and process the results all from Python.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;134&lt;/td&gt;&#xA;          &lt;td&gt;54&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;147&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/satellite-image-deep-learning/datasets&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Datasets for deep learning with satellite &amp;amp; aerial imagery&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;246&lt;/td&gt;&#xA;          &lt;td&gt;33&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;148&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/SeldonIO/alibi-detect&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Algorithms for outlier, adversarial and drift detection&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1838&lt;/td&gt;&#xA;          &lt;td&gt;180&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;149&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/SeldonIO/seldon-core&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An MLOps framework to package, deploy, monitor and manage thousands of production machine learning models&lt;/td&gt;&#xA;          &lt;td&gt;HTML&lt;/td&gt;&#xA;          &lt;td&gt;3754&lt;/td&gt;&#xA;          &lt;td&gt;758&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;150&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/shellysheynin/Deep-Learning-Book&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Deep Learning book the covers the principles of deep learning, motivation, explanations, state of the art papers for the various tasks and architectures: CNNs, object detection, semantic segmentation, generative models, denoising, super resolution, style transfer and style manipulation, inpaintig, self supervised learning, vision transformers, OCR, and multi modal. Hope that it will be useful to some of you 🙂&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;91&lt;/td&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;151&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Shivampanwar/Bert-text-classification&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This shows how to fine-tune Bert language model and use PyTorch-transformers  for text classififcation&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;63&lt;/td&gt;&#xA;          &lt;td&gt;35&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;152&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/shivanikohlii/SanTran&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A Machine Learning project to translate Sanskrit text to English&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;153&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/shuyanzhou/docprompting&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Data and code for &amp;ldquo;DocPrompting: Generating Code by Retrieving the Docs&amp;rdquo; @ICLR 2023&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;165&lt;/td&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;154&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/sid573/Hindi_Sentiment_Analysis&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Model to predict the sentiment of Hindi sentences developed this model during my 2nd-year Internship @ algo8.ai&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;155&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/SigmaQuan/Better-Python-59-Ways&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Code Sample of Book &amp;ldquo;Effective Python: 59 Specific Ways to Write Better Pyton&amp;rdquo; by Brett Slatkin&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;1362&lt;/td&gt;&#xA;          &lt;td&gt;213&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;156&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/SkalskiP/courses&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;This repository is a curated collection of links to various courses and resources about Artificial Intelligence (AI)&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2855&lt;/td&gt;&#xA;          &lt;td&gt;224&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;157&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/smadha/SarcasmDetector&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;CSCI-544 Final Project&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;158&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Stability-AI/StableLM&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;StableLM: Stability AI Language Models&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;14581&lt;/td&gt;&#xA;          &lt;td&gt;878&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;159&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorchord/Awesome-LLMOps&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An awesome &amp;amp; curated list of best LLMOps tools for developers&lt;/td&gt;&#xA;          &lt;td&gt;Shell&lt;/td&gt;&#xA;          &lt;td&gt;905&lt;/td&gt;&#xA;          &lt;td&gt;83&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;160&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/gnn&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;TensorFlow GNN is a library to build Graph Neural Networks on the TensorFlow platform.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;986&lt;/td&gt;&#xA;          &lt;td&gt;136&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;161&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Textualize/rich&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Rich is a Python library for rich text and beautiful formatting in the terminal.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;43554&lt;/td&gt;&#xA;          &lt;td&gt;1569&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;162&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/thakarprathamesh/Time-Series-Analysis&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;163&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/theerfan/Q&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;My attempt at researching Quantum Mechanics &amp;amp; Quantum Computing when I was a junior.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;116&lt;/td&gt;&#xA;          &lt;td&gt;55&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;164&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/thuml/Autoformer&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;About Code release for &amp;ldquo;Autoformer: Decomposition Transformers with Auto-Correlation for Long-Term Series Forecasting&amp;rdquo; (NeurIPS 2021), &lt;a href=&#34;https://arxiv.org/abs/2106.13008&#34;&gt;https://arxiv.org/abs/2106.13008&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;1132&lt;/td&gt;&#xA;          &lt;td&gt;286&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;165&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/trekhleb/homemade-machine-learning&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;🤖 Python examples of popular machine learning algorithms with interactive Jupyter demos and math being explained&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;21377&lt;/td&gt;&#xA;          &lt;td&gt;3912&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;166&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/TrigonaMinima/HinglishNLP&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;40&lt;/td&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;167&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Trusted-AI/AIF360&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A comprehensive set of fairness metrics for datasets and machine learning models, explanations for these metrics, and algorithms to mitigate bias in datasets and models.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;2046&lt;/td&gt;&#xA;          &lt;td&gt;687&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;168&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/udacity/CarND-Object-Detection-Lab&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;102&lt;/td&gt;&#xA;          &lt;td&gt;340&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;169&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/unit8co/darts&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A python library for user-friendly forecasting and anomaly detection on time series.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;5968&lt;/td&gt;&#xA;          &lt;td&gt;673&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;170&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/varunshenoy/GraphGPT&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Extrapolating knowledge graphs from unstructured text using GPT-3 🕵️‍♂️&lt;/td&gt;&#xA;          &lt;td&gt;JavaScript&lt;/td&gt;&#xA;          &lt;td&gt;3502&lt;/td&gt;&#xA;          &lt;td&gt;289&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;171&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/xingyaoww/LeTI&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Official repo for paper &amp;ldquo;LeTI: Learning to Generate from Textual Interactions.&amp;rdquo;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;172&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Yimeng-Zhang/feature-engineering-and-feature-selection&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A Guide for Feature Engineering and Feature Selection, with implementations and examples in Python.&lt;/td&gt;&#xA;          &lt;td&gt;Jupyter Notebook&lt;/td&gt;&#xA;          &lt;td&gt;1118&lt;/td&gt;&#xA;          &lt;td&gt;371&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;173&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/yoheinakajima/babyagi&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;15233&lt;/td&gt;&#xA;          &lt;td&gt;2094&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;174&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/youssefHosni/Data-Science-Interview-Preperation-Resources&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Resoruce to help you to prepare for your comming data science interviews&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;409&lt;/td&gt;&#xA;          &lt;td&gt;65&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;175&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/zacharski/pg2dm-python&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;867&lt;/td&gt;&#xA;          &lt;td&gt;479&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;176&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/zhouhaoyi/Informer2020&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The GitHub repository for the paper &amp;ldquo;Informer&amp;rdquo; accepted by AAAI 2021.&lt;/td&gt;&#xA;          &lt;td&gt;Python&lt;/td&gt;&#xA;          &lt;td&gt;3764&lt;/td&gt;&#xA;          &lt;td&gt;851&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;177&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/zinggAI/zingg&#34;&gt;Link&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Scalable identity resolution, entity resolution, data mastering and deduplication using ML&lt;/td&gt;&#xA;          &lt;td&gt;Java&lt;/td&gt;&#xA;          &lt;td&gt;741&lt;/td&gt;&#xA;          &lt;td&gt;85&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>AI ML Resources from My Diary</title>
      <link>http://localhost:1313/dsblog/AI-ML-Resources-from-My-Diary/</link>
      <pubDate>Wed, 21 Jul 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-ML-Resources-from-My-Diary/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr121-AI-ML-Resources-from-My-Diary.jpg&#34; alt=&#34;AI ML Resources from My Diary&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-ml-resources-from-my-diary&#34;&gt;AI ML Resources from My Diary&lt;/h1&gt;&#xA;&lt;p&gt;This is my personal diary which contains resources, which I know, learned or people have told me&#xA;to experiment with. I started writing this diary in Mar’ 2019. This diary is related to my work/learning&#xA;in data science, AI, ML, NLP, DL, GNN, GAN, Statistics, etc. A few links related to Software&#xA;Development, People Management, Project Management are also kept in this diary. The resources&#xA;here are python/R library link, blog articles, YouTube video links, article links, AI products links,&#xA;architecture, images etc. The Table of Content and Content of this diary is not any specific order.&#xA;Whatever I was/am getting I keep adding into this, mostly towards the end but not always.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Basic Statistics for Data Science</title>
      <link>http://localhost:1313/dsblog/basic-statistics-for-data-science/</link>
      <pubDate>Sun, 18 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/basic-statistics-for-data-science/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr118-Basic-Statistics-for-Data-Science.jpg&#34; alt=&#34;Basic Statistics for Data Science&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;basic-statistics-for-data-science&#34;&gt;Basic Statistics for Data Science&lt;/h1&gt;&#xA;&lt;h2 id=&#34;important-webpages-on-statistics&#34;&gt;Important Webpages on Statistics&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.sciencedirect.com/topics/neuroscience/statistical-inference&#34;&gt;Statistical Inference – an overview - ScienceDirect Topics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datajournalismhandbook.org/1.0/en/index.html&#34;&gt;Welcome – The Data Journalism Handbook&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://math.tutorvista.com/calculus.html&#34;&gt;Calculus – Get Help from Online Calculus Tutor - Math@TutorVista.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mathsisfun.com/data/probability.html&#34;&gt;Probability&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mathopolis.com/questions/q.php?id=700&amp;amp;site=1&amp;amp;ref=/data/probability.html&amp;amp;qs=700_701_702_1475_1476_1477_2175_2176_2177_2178&#34;&gt;Mathopolis Question Database&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mathgoodies.com/lessons/vol6/addition_rules&#34;&gt;Addition Rules for Probability - Math Goodies&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.calculatorsoup.com/calculators/discretemathematics/combinations.php&#34;&gt;Combinations Calculator (nCr)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/large-enough-sample-condition/&#34;&gt;Large Enough Sample Condition – Statistics How To&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ztable.net/&#34;&gt;Z Table - Z Table&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dataquest.io/blog/basic-statistics-in-python-probability/&#34;&gt;Probability in Python – Dataquest&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.evolytics.com/resources/calculators/zscore-calculator/&#34;&gt;Z Score to Confidence Level Calculator – Evolytics - Data Analytics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.statisticshowto.datasciencecentral.com/probability-and-statistics/confidence-interval/&#34;&gt;How to Find a Confidence Interval: The Easy Way! – Statistics How To&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://newonlinecourses.science.psu.edu/stat414/node/93/&#34;&gt;Lesson 17: Distributions of Two Discrete Random Variables&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.optimizely.com/optimization-glossary/&#34;&gt;Optipedia: Glossary of CRO Terms &amp;amp; Acronyms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.khanacademy.org/math/ap-statistics/chi-square-tests/chi-square-goodness-fit/v/goodness-of-fit-example&#34;&gt;Chi-square statistic for hypothesis testing (video) - Khan Academy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dummies.com/education/math/statistics/statistics-workbook-for-dummies-cheat-sheet/&#34;&gt;Statistics Workbook For Dummies Cheat Sheet&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://byjus.com/maths/polynomial/?utm_source=google&amp;amp;utm_medium=cpc&amp;amp;utm_campaign=K12-Search-Traffic-Desktop-Class9-Maths-May29&amp;amp;utm_term=%2Bpolynomials&amp;amp;gclid=CjwKCAjwsIbpBRBNEiwAZF8-z2rFLubD9w8tdE3t2urJiDzVmXZRbq1RSKCSnTGtFaf3gF5pslnRcxoCXhYQAvD_BwE&#34;&gt;Polynomials – Definition, Types, Degree and Solved Examples&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mathplanet.com/education/algebra-1&#34;&gt;Algebra 1 – Mathplanet&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mathplanet.com/&#34;&gt;Mathplanet&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;websites-to-learn-basic-statistics&#34;&gt;Websites to Learn Basic Statistics&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://byjus.com&#34;&gt;https://byjus.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://calculatorsoup.com&#34;&gt;https://calculatorsoup.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datajournalismhandbook.org&#34;&gt;https://datajournalismhandbook.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dataquest.io&#34;&gt;https://dataquest.io&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://dummies.com&#34;&gt;https://dummies.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://evolytics.com&#34;&gt;https://evolytics.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://khanacademy.org&#34;&gt;https://khanacademy.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://math.tutorvista.com&#34;&gt;https://math.tutorvista.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mathgoodies.com&#34;&gt;https://mathgoodies.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mathopolis.com&#34;&gt;https://mathopolis.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mathplanet.com&#34;&gt;https://mathplanet.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mathsisfun.com&#34;&gt;https://mathsisfun.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://newonlinecourses.science.psu.edu&#34;&gt;https://newonlinecourses.science.psu.edu&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://optimizely.com&#34;&gt;https://optimizely.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sciencedirect.com&#34;&gt;https://sciencedirect.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://statisticshowto.datasciencecentral.com&#34;&gt;https://statisticshowto.datasciencecentral.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ztable.net&#34;&gt;https://ztable.net&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Data Scientists and AI, ML Researchers</title>
      <link>http://localhost:1313/dsblog/ds-ai-ml-researchers/</link>
      <pubDate>Sat, 17 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ds-ai-ml-researchers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr117-Data-Scientists-and-AI-ML-Researchers.jpg&#34; alt=&#34;Data Scientists and AI, ML Researchers&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;data-scientists-and-ai-ml-researchers&#34;&gt;Data Scientists and AI, ML Researchers&lt;/h1&gt;&#xA;&lt;p&gt;For the initial list, I have taken content from &lt;a href=&#34;https://github.com/datasciencescoop/awesome-deep-learning&#34;&gt;github&lt;/a&gt;. I have expanded this and will keep updating this in the future. If you know any, please feel free to put the name in the comment box.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aaroncourville.wordpress.com/&#34;&gt;Aaron Courville&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~asamir/&#34;&gt;Abdel-rahman Mohamed&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs.stanford.edu/~acoates/&#34;&gt;Adam Coates&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.microsoft.com/en-us/people/alexac/&#34;&gt;Alex Acero&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.utoronto.ca/~kriz/index.html&#34;&gt;Alex Krizhevsky&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://users.ics.aalto.fi/alexilin/&#34;&gt;Alexander Ilin&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://homepages.inf.ed.ac.uk/amos/&#34;&gt;Amos Storkey&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs.stanford.edu/~karpathy/&#34;&gt;Andrej Karpathy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://andrewnc.github.io&#34;&gt;Andrew Carr&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.stanford.edu/~asaxe/&#34;&gt;Andrew M. Saxe&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.stanford.edu/people/ang/&#34;&gt;Andrew Ng&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.google.com/pubs/author37792.html&#34;&gt;Andrew W. Senior&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.gatsby.ucl.ac.uk/~amnih/&#34;&gt;Andriy Mnih&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.nyu.edu/~naz/&#34;&gt;Ayse Naz Erkan&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://reslab.elis.ugent.be/benjamin&#34;&gt;Benjamin Schrauwen&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cisuc.uc.pt/people/show/2020&#34;&gt;Bernardete Ribeiro&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vision.caltech.edu/~bchen3/Site/Bo_David_Chen.html&#34;&gt;Bo David Chen&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs.nyu.edu/~ylan/&#34;&gt;Boureau Y-Lan&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://researcher.watson.ibm.com/researcher/view.php?person=us-bedk&#34;&gt;Brian Kingsbury&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://chrisalbon.com&#34;&gt;Chris Albon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nlp.stanford.edu/~manning/&#34;&gt;Christopher Manning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datasciencemasters.org&#34;&gt;Clare Corthell&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.clement.farabet.net/&#34;&gt;Clement Farabet&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://colah.github.io&#34;&gt;Colah’s Blog&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.idsia.ch/~ciresan/&#34;&gt;Dan Claudiu Cireșan&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://serre-lab.clps.brown.edu/person/david-reichert/&#34;&gt;David Reichert&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mil.engr.utk.edu/nmil/member/5.html&#34;&gt;Derek Rose&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.microsoft.com/en-us/people/dongyu/default.aspx&#34;&gt;Dong Yu&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.seas.upenn.edu/~wulsin/&#34;&gt;Drausin Wulsin&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://drewconway.com&#34;&gt;Drew Conway&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://music.ece.drexel.edu/people/eschmidt&#34;&gt;Erik M. Schmidt&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://engineering.purdue.edu/BME/People/viewPersonById?resource_id=71333&#34;&gt;Eugenio Culurciello&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vision.stanford.edu/feifeili&#34;&gt;Fei-Fei Li&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.microsoft.com/en-us/people/fseide/&#34;&gt;Frank Seide&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://homes.cs.washington.edu/~galen/&#34;&gt;Galen Andrew&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~hinton/&#34;&gt;Geoffrey Hinton&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~gdahl/&#34;&gt;George Dahl&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.uoguelph.ca/~gwtaylor/&#34;&gt;Graham Taylor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://gregoire.montavon.name/&#34;&gt;Grégoire Montavon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://personal-homepages.mis.mpg.de/montufar/&#34;&gt;Guido Francisco Montúfar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://brainlogging.wordpress.com/&#34;&gt;Guillaume Desjardins&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ais.uni-bonn.de/~schulz/&#34;&gt;Hannes Schulz&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.lri.fr/~hpaugam/&#34;&gt;Hélène Paugam-Moisy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hilarymason.com&#34;&gt;Hilary Mason&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hilaryparker.com&#34;&gt;Hilary Parker&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://web.eecs.umich.edu/~honglak/&#34;&gt;Honglak Lee&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.dmi.usherb.ca/~larocheh/index_en.html&#34;&gt;Hugo Larochelle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.google.com/pubs/105214.html&#34;&gt;Ian Goodfellow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~ilya/&#34;&gt;Ilya Sutskever&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mil.engr.utk.edu/nmil/member/2.html&#34;&gt;Itamar Arel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~jmartens/&#34;&gt;James Martens&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.jasonmorton.com/&#34;&gt;Jason Morton&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.thespermwhale.com/jaseweston/&#34;&gt;Jason Weston&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.google.com/pubs/jeff.html&#34;&gt;Jeff Dean&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs.stanford.edu/~jngiam/&#34;&gt;Jiquan Mgiam&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www-etud.iro.umontreal.ca/~turian/&#34;&gt;Joseph Turian&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aclab.ca/users/josh/index.html&#34;&gt;Joshua Matthew Susskind&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.idsia.ch/~juergen/&#34;&gt;Jürgen Schmidhuber&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/blancousna/&#34;&gt;Justin A. Blanco&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://kldavenport.com&#34;&gt;Kevin Davenport&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://koray.kavukcuoglu.org/&#34;&gt;Koray Kavukcuoglu&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://users.ics.aalto.fi/kcho/&#34;&gt;KyungHyun Cho&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.microsoft.com/en-us/people/deng/&#34;&gt;Li Deng&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kyb.tuebingen.mpg.de/nc/employee/details/lucas.html&#34;&gt;Lucas Theis&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ludovicarnold.altervista.org/home/&#34;&gt;Ludovic Arnold&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.nyu.edu/~ranzato/&#34;&gt;Marc’Aurelio Ranzato&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://aass.oru.se/~mlt/&#34;&gt;Martin Längkvist&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hairysun.com&#34;&gt;Matt Harrison&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://miningthesocialweb.com&#34;&gt;Matthew Russell&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mdenil.com/&#34;&gt;Misha Denil&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~norouzi/&#34;&gt;Mohammad Norouzi&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.ubc.ca/~nando/&#34;&gt;Nando de Freitas&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.utoronto.ca/~ndjaitly/&#34;&gt;Navdeep Jaitly&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nicolas.le-roux.name/&#34;&gt;Nicolas Le Roux&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~nitish/&#34;&gt;Nitish Srivastava&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://complexdiagrams.com&#34;&gt;Noah Iliinsky&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cisuc.uc.pt/people/show/2028&#34;&gt;Noel Lopes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.berkeley.edu/~vinyals/&#34;&gt;Oriol Vinyals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.iro.umontreal.ca/~vincentp&#34;&gt;Pascal Vincent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/drpngx/&#34;&gt;Patrick Nguyen&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cloudofdata.com&#34;&gt;Paul Miller&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://homes.cs.washington.edu/~pedrod/&#34;&gt;Pedro Domingos&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://homepages.inf.ed.ac.uk/pseries/&#34;&gt;Peggy Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs.nyu.edu/~sermanet&#34;&gt;Pierre Sermanet&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.nyu.edu/~mirowski/&#34;&gt;Piotr Mirowski&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ai.stanford.edu/~quocle/&#34;&gt;Quoc V. Le&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bci.tugraz.at/scherer/&#34;&gt;Reinhold Scherer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.socher.org/&#34;&gt;Richard Socher&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs.nyu.edu/~fergus/pmwiki/pmwiki.php&#34;&gt;Rob Fergus&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mil.engr.utk.edu/nmil/member/19.html&#34;&gt;Robert Coop&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://homes.cs.washington.edu/~rcg/&#34;&gt;Robert Gens&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.site.uottawa.ca/~laganier/&#34;&gt;Robert Laganière&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://people.csail.mit.edu/rgrosse/&#34;&gt;Roger Grosse&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ronan.collobert.com/&#34;&gt;Ronan Collobert&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.utstat.toronto.edu/~rsalakhu/&#34;&gt;Ruslan Salakhutdinov&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://seanjtaylor.com&#34;&gt;Sean J. Taylor&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kyb.tuebingen.mpg.de/nc/employee/details/sgerwinn.html&#34;&gt;Sebastian Gerwinn&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sebastianruder.com&#34;&gt;Sebastian’s&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openresearch.wordpress.com&#34;&gt;Siah&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cmap.polytechnique.fr/~mallat/&#34;&gt;Stéphane Mallat&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ais.uni-bonn.de/behnke/&#34;&gt;Sven Behnke&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://users.ics.aalto.fi/praiko/&#34;&gt;Tapani Raiko&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sites.google.com/site/tsainath/&#34;&gt;Tara Sainath&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://magnus-notitia.blogspot.com.tr&#34;&gt;Tevfik Kosar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~tijmen/&#34;&gt;Tijmen Tieleman&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mil.engr.utk.edu/nmil/member/36.html&#34;&gt;Tom Karnowski&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://research.facebook.com/tomas-mikolov&#34;&gt;Tomáš Mikolov&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.idsia.ch/~meier/&#34;&gt;Ueli Meier&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vincent.vanhoucke.com/&#34;&gt;Vincent Vanhoucke&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~vmnih/&#34;&gt;Volodymyr Mnih&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wesmckinney.com&#34;&gt;Wes McKinney&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://yann.lecun.com/&#34;&gt;Yann LeCun&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.toronto.edu/~tang/&#34;&gt;Yichuan Tang&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.iro.umontreal.ca/~bengioy/yoshua_en/index.html&#34;&gt;Yoshua Bengio&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://yota.ro/&#34;&gt;Yotaro Kubo&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ai.stanford.edu/~wzou&#34;&gt;Youzhi (Will) Zou&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Navigating the Data Landscape: Exploring Data Sources, Databases, and ETL Tools for Machine Learning Projects</title>
      <link>http://localhost:1313/dsblog/navigating-the-data=landscape/</link>
      <pubDate>Fri, 16 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/navigating-the-data=landscape/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr116-Data-Sources-Databases-ETL-Tools.jpg&#34; alt=&#34;Data Sources, Databases, ETL Tools&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;navigating-the-data-landscape&#34;&gt;Navigating the Data Landscape:&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Exploring Data Sources, Databases, and ETL Tools for Machine Learning Projects&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Data sources: Data sources refer to the origins or locations from which data is collected or generated. They can include various platforms, systems, devices, or applications that generate or store data, such as databases, APIs, files, sensors, social media platforms, or web services.&lt;/p&gt;&#xA;&lt;p&gt;Databases: Databases are organized collections of structured data that are stored, managed, and accessed using database management systems (DBMS). They provide a structured way to store and retrieve data efficiently, enabling data storage, retrieval, manipulation, and querying operations for various applications.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Thousands of Machine Learning Datasets  </title>
      <link>http://localhost:1313/dsblog/datasets/</link>
      <pubDate>Thu, 15 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/datasets/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr115-Datasets.jpg&#34; alt=&#34;Datasets&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;thousands-of-machine-learning-datasets&#34;&gt;Thousands of Machine Learning Datasets&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction:&lt;/h2&gt;&#xA;&lt;p&gt;Without Data there is no Machine Learning, no AI, no Deep Learning. Because of heavy automation, IOT devices all around, there is no dirth of data. The first issue is, due to privacy and security related issues, data is not available for everyone. The second issue is cleaning this data. He third issues is getting complete data which can solve a given business problem. To get the complete data you need to get the data from multiple sources, identify the key to connect different records/sample of different sources. It is an expensive and time-consuming step of data science project. If you want to learn data science or want to solve any existing problem using new methods. Then you need some benchmarking framework in place which can display the model metrics (recall/precision/accuracy etc.) of each new approach (algorithm) against a given dataset. So datasets play a critical role in benchmarking algorithm performance.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning Tasks and Model Evaluation</title>
      <link>http://localhost:1313/dsblog/ml-tasks-and-model-evaluation/</link>
      <pubDate>Wed, 14 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ml-tasks-and-model-evaluation/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr114-ml-tasks-and-model-evaluation.jpg&#34; alt=&#34;Deep Learning Tasks and Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;machine-learning-tasks-and-model-evaluation&#34;&gt;Machine Learning Tasks and Model Evaluation&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Machine learning is a subject where we study how to create &amp;amp; evaluate machine learning models. To create these models, we need different types of data. We build models which can help us do various kinds of tasks. There are hundreds of model building techniques and researchers keep adding new techniques, and architectures as when need arises. But, the question is how do you evaluate these models which are output of the model trainings? To evaluate the performance of a model on structured data, or classification/regression/clustering models, we require one kind of metrics. But this becomes complicated when we are dealing with voice, text and audio data. How do you evaluate ten models which are responsible for translation, or locating an object in the image, transcribing voice into text, captioning an image? To solve this problem, standard databases are created and everyone needs to demonstrate the performance of their model, architecture, or approach against that dataset. But, even if you have a baseline dataset, how will you evaluate various NLP or deep learning tasks? For that GLUE, SuperGLUE benchmarks are created.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Machine Learning Framework, Library, Tools</title>
      <link>http://localhost:1313/dsblog/ml-frameworks-libraries-tools/</link>
      <pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ml-frameworks-libraries-tools/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr113-Machine-Learning-Framework-Library-Tools.jpg&#34; alt=&#34;Machine Learning Framework, Library, Tools&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;machine-learning-framework-library-tools&#34;&gt;Machine Learning Framework, Library, Tools&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;As of 2022, Data Science, AI, and Machine Learning are very fast-evolving domains. In the last 5 years, it has picked up momentum. Every day a new library, framework, and tools pops out before our eyes. Many of these are very interesting and some are just duplicates with little value addition. I am listing below some tools that I came across during my work. The purpose of this listing is not to describe every tool but to provide a link and just put them in sorted order. There are so many jargons, and we use to forget these. Sometimes, it becomes difficult to recall them. It was useful for me and I hope some of you will find this useful.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI, ML, DL Blogs Sites</title>
      <link>http://localhost:1313/dsblog/ai-ml-blogs/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ai-ml-blogs/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr109-AI-ML-DL-Blogs-Sites.jpg&#34; alt=&#34;AI, ML, DL Blogs Sites&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-ml-dl-blogs-sites&#34;&gt;AI, ML, DL Blogs Sites&lt;/h1&gt;&#xA;&lt;p&gt;370+ blogs/website, who publishes articles, research, opinions, observations related to AI, ML, DL, Signal Processing, Computer Vision, Text Processing, Audio Processing, Image/video/Audio/Text Generation on regular basis.&lt;/p&gt;&#xA;&lt;p&gt;1 &lt;a href=&#34;http://101.datascience.community&#34;&gt;101.datasciencemunity&lt;/a&gt; &lt;br&gt;&#xA;2 &lt;a href=&#34;https://2020.emnlp.org&#34;&gt;2020.emnlp.org&lt;/a&gt; &lt;br&gt;&#xA;3 &lt;a href=&#34;https://24x7coach.com&#34;&gt;24x7coach&lt;/a&gt; &lt;br&gt;&#xA;4 &lt;a href=&#34;https://www.aaai.org&#34;&gt;aaai.org&lt;/a&gt; &lt;br&gt;&#xA;5 &lt;a href=&#34;https://academic.microsoft.com&#34;&gt;academic.microsoft&lt;/a&gt; &lt;br&gt;&#xA;6 &lt;a href=&#34;https://aclweb.org&#34;&gt;aclweb.org&lt;/a&gt; &lt;br&gt;&#xA;7 &lt;a href=&#34;https://ai.facebook.com&#34;&gt;ai.facebook&lt;/a&gt; &lt;br&gt;&#xA;8 &lt;a href=&#34;http://www.ai.sri.com&#34;&gt;ai.sri&lt;/a&gt; &lt;br&gt;&#xA;9 &lt;a href=&#34;https://ai4bharat.org&#34;&gt;ai4bharat.org&lt;/a&gt; &lt;br&gt;&#xA;10 &lt;a href=&#34;http://www.aiai.ed.ac.uk&#34;&gt;aiai.ed.ac.uk&lt;/a&gt; &lt;br&gt;&#xA;11 &lt;a href=&#34;http://www.ai-junkie.com&#34;&gt;ai-junkie&lt;/a&gt; &lt;br&gt;&#xA;12 &lt;a href=&#34;http://aiweekly.co&#34;&gt;aiweekly.co&lt;/a&gt; &lt;br&gt;&#xA;13 &lt;a href=&#34;http://algorithmica-technologies.com&#34;&gt;algorithmica-technologies&lt;/a&gt; &lt;br&gt;&#xA;14 &lt;a href=&#34;https://allenai.org&#34;&gt;allenai.org&lt;/a&gt; &lt;br&gt;&#xA;15 &lt;a href=&#34;https://allthingsds.wordpress.com&#34;&gt;allthingsds.wordpress&lt;/a&gt; &lt;br&gt;&#xA;16 &lt;a href=&#34;https://amitness.com&#34;&gt;amitness&lt;/a&gt; &lt;br&gt;&#xA;17 &lt;a href=&#34;https://analytics.google.com&#34;&gt;analytics.google&lt;/a&gt; &lt;br&gt;&#xA;18 &lt;a href=&#34;https://analyticsindiamag.com&#34;&gt;analyticsindiamag&lt;/a&gt; &lt;br&gt;&#xA;19 &lt;a href=&#34;https://analyticstraining.com&#34;&gt;analyticstraining&lt;/a&gt; &lt;br&gt;&#xA;20 &lt;a href=&#34;https://analyticsvidhya.com&#34;&gt;analyticsvidhya&lt;/a&gt; &lt;br&gt;&#xA;21 &lt;a href=&#34;https://apache.org&#34;&gt;apache.org&lt;/a&gt; &lt;br&gt;&#xA;22 &lt;a href=&#34;https://archive.ics.uci.edu&#34;&gt;archive.ics.uci.edu&lt;/a&gt; &lt;br&gt;&#xA;23 &lt;a href=&#34;https://arxiv.org&#34;&gt;arxiv.org&lt;/a&gt; &lt;br&gt;&#xA;24 &lt;a href=&#34;http://arxiv-sanity.com&#34;&gt;arxiv-sanity&lt;/a&gt; &lt;br&gt;&#xA;25 &lt;a href=&#34;https://atom.io&#34;&gt;atom.io&lt;/a&gt; &lt;br&gt;&#xA;26 &lt;a href=&#34;http://becomingadatascientist.com&#34;&gt;becomingadatascientist&lt;/a&gt; &lt;br&gt;&#xA;27 &lt;a href=&#34;https://blockchain.com&#34;&gt;blockchain&lt;/a&gt; &lt;br&gt;&#xA;28 &lt;a href=&#34;https://blog.cloudera.com&#34;&gt;blog.cloudera&lt;/a&gt; &lt;br&gt;&#xA;29 &lt;a href=&#34;http://blog.datadive.net&#34;&gt;blog.datadive.net&lt;/a&gt; &lt;br&gt;&#xA;30 &lt;a href=&#34;http://blog.data-miners.com&#34;&gt;blog.data-miners&lt;/a&gt; &lt;br&gt;&#xA;31 &lt;a href=&#34;https://blog.dominodatalab.com&#34;&gt;blog.dominodatalab&lt;/a&gt; &lt;br&gt;&#xA;32 &lt;a href=&#34;https://blog.gramener.com&#34;&gt;blog.gramener&lt;/a&gt; &lt;br&gt;&#xA;33 &lt;a href=&#34;http://blog.kaggle.com&#34;&gt;blog.kaggle&lt;/a&gt; &lt;br&gt;&#xA;34 &lt;a href=&#34;https://blog.mendeley.com&#34;&gt;blog.mendeley&lt;/a&gt; &lt;br&gt;&#xA;35 &lt;a href=&#34;http://blog.pythonlibrary.org&#34;&gt;blog.pythonlibrary.org&lt;/a&gt; &lt;br&gt;&#xA;36 &lt;a href=&#34;http://blog.revolutionanalytics.com&#34;&gt;blog.revolutionanalytics&lt;/a&gt; &lt;br&gt;&#xA;37 &lt;a href=&#34;http://blog.smola.org&#34;&gt;blog.smola.org&lt;/a&gt; &lt;br&gt;&#xA;38 &lt;a href=&#34;http://blogs.sun.com&#34;&gt;blogs.sun&lt;/a&gt; &lt;br&gt;&#xA;39 &lt;a href=&#34;https://bokeh.pydata.org&#34;&gt;bokeh.pydata.org&lt;/a&gt; &lt;br&gt;&#xA;40 &lt;a href=&#34;https://brilliant.org&#34;&gt;brilliant.org&lt;/a&gt; &lt;br&gt;&#xA;41 &lt;a href=&#34;https://bsc.hcverma.in&#34;&gt;bsc.hcverma.in&lt;/a&gt; &lt;br&gt;&#xA;42 &lt;a href=&#34;https://byjus.com&#34;&gt;byjus&lt;/a&gt; &lt;br&gt;&#xA;43 &lt;a href=&#34;http://calculatedriskblog.com&#34;&gt;calculatedriskblog&lt;/a&gt; &lt;br&gt;&#xA;44 &lt;a href=&#34;https://campus.datacamp.com&#34;&gt;campus.datacamp&lt;/a&gt; &lt;br&gt;&#xA;45 &lt;a href=&#34;https://catalog.data.gov&#34;&gt;catalog.data.gov&lt;/a&gt; &lt;br&gt;&#xA;46 &lt;a href=&#34;http://censusindia.gov.in&#34;&gt;censusindia.gov.in&lt;/a&gt; &lt;br&gt;&#xA;47 &lt;a href=&#34;http://chioka.in&#34;&gt;chioka.in&lt;/a&gt; &lt;br&gt;&#xA;48 &lt;a href=&#34;https://ci.pytorch.org&#34;&gt;ci.pytorch.org&lt;/a&gt; &lt;br&gt;&#xA;49 &lt;a href=&#34;https://classroom.udacity.com&#34;&gt;classroom.udacity&lt;/a&gt; &lt;br&gt;&#xA;50 &lt;a href=&#34;https://cloud.google.com/public-datasets&#34;&gt;cloud.google&lt;/a&gt; &lt;br&gt;&#xA;51 &lt;a href=&#34;https://codecogs.com&#34;&gt;codecogs&lt;/a&gt; &lt;br&gt;&#xA;52 &lt;a href=&#34;https://community.powerbi.com&#34;&gt;community.powerbi&lt;/a&gt; &lt;br&gt;&#xA;53 &lt;a href=&#34;https://community.tableau.com&#34;&gt;community.tableau&lt;/a&gt; &lt;br&gt;&#xA;54 &lt;a href=&#34;http://corenlp.run&#34;&gt;corenlp.run&lt;/a&gt; &lt;br&gt;&#xA;55 &lt;a href=&#34;https://coursera.org&#34;&gt;coursera.org&lt;/a&gt; &lt;br&gt;&#xA;56 &lt;a href=&#34;https://cran.r-project.org&#34;&gt;cran.r-project.org&lt;/a&gt; &lt;br&gt;&#xA;57 &lt;a href=&#34;http://cs.brown.edu&#34;&gt;cs.brown.edu&lt;/a&gt; &lt;br&gt;&#xA;58 &lt;a href=&#34;http://www.cs.rochester.edu&#34;&gt;cs.rochester.edu&lt;/a&gt; &lt;br&gt;&#xA;59 &lt;a href=&#34;http://www.cs.utexas.edu&#34;&gt;cs.utexas.edu&lt;/a&gt; &lt;br&gt;&#xA;60 &lt;a href=&#34;http://www.cs.washington.edu&#34;&gt;cs.washington.edu&lt;/a&gt; &lt;br&gt;&#xA;61 &lt;a href=&#34;http://www.csail.mit.edu&#34;&gt;csail.mit.edu&lt;/a&gt; &lt;br&gt;&#xA;62 &lt;a href=&#34;https://cse.unr.edu&#34;&gt;cse.unr.edu&lt;/a&gt; &lt;br&gt;&#xA;63 &lt;a href=&#34;https://dair.ai&#34;&gt;dair.ai&lt;/a&gt; &lt;br&gt;&#xA;64 &lt;a href=&#34;http://danielforsyth.me&#34;&gt;danielforsyth.me&lt;/a&gt; &lt;br&gt;&#xA;65 &lt;a href=&#34;https://dartpad.dartlang.org&#34;&gt;dartpad.dartlang.org&lt;/a&gt; &lt;br&gt;&#xA;66 &lt;a href=&#34;https://data.gov.in&#34;&gt;data.gov.in&lt;/a&gt; &lt;br&gt;&#xA;67 &lt;a href=&#34;https://data.gov.uk&#34;&gt;data.gov.uk&lt;/a&gt; &lt;br&gt;&#xA;68 &lt;a href=&#34;https://data.mendeley.com&#34;&gt;data.mendeley&lt;/a&gt; &lt;br&gt;&#xA;69 &lt;a href=&#34;https://data.world&#34;&gt;data.world&lt;/a&gt; &lt;br&gt;&#xA;70 &lt;a href=&#34;https://databricks.com&#34;&gt;databricks&lt;/a&gt; &lt;br&gt;&#xA;71 &lt;a href=&#34;https://datacamp.com&#34;&gt;datacamp&lt;/a&gt; &lt;br&gt;&#xA;72 &lt;a href=&#34;http://dataconomy.com&#34;&gt;dataconomy&lt;/a&gt; &lt;br&gt;&#xA;73 &lt;a href=&#34;https://data-flair.training&#34;&gt;data-flair.training&lt;/a&gt; &lt;br&gt;&#xA;74 &lt;a href=&#34;https://datahack.analyticsvidhya.com&#34;&gt;datahack.analyticsvidhya&lt;/a&gt; &lt;br&gt;&#xA;75 &lt;a href=&#34;http://dataists.com&#34;&gt;dataists&lt;/a&gt; &lt;br&gt;&#xA;76 &lt;a href=&#34;https://datajournalismhandbook.org&#34;&gt;datajournalismhandbook.org&lt;/a&gt; &lt;br&gt;&#xA;77 &lt;a href=&#34;https://datalabsagency.com&#34;&gt;datalabsagency&lt;/a&gt; &lt;br&gt;&#xA;78 &lt;a href=&#34;http://data-magnum.com&#34;&gt;data-magnum&lt;/a&gt; &lt;br&gt;&#xA;79 &lt;a href=&#34;http://data-mania.com&#34;&gt;data-mania&lt;/a&gt; &lt;br&gt;&#xA;80 &lt;a href=&#34;https://datamation.com&#34;&gt;datamation&lt;/a&gt; &lt;br&gt;&#xA;81 &lt;a href=&#34;http://datanews.tumblr.com&#34;&gt;datanews.tumblr&lt;/a&gt; &lt;br&gt;&#xA;82 &lt;a href=&#34;https://dataplatform.cloud.ibm.com&#34;&gt;dataplatform.cloud.ibm&lt;/a&gt; &lt;br&gt;&#xA;83 &lt;a href=&#34;https://dataquest.io&#34;&gt;dataquest.io&lt;/a&gt; &lt;br&gt;&#xA;84 &lt;a href=&#34;https://dataschool.io&#34;&gt;dataschool.io&lt;/a&gt; &lt;br&gt;&#xA;85 &lt;a href=&#34;https://datascience.com&#34;&gt;datascience&lt;/a&gt; &lt;br&gt;&#xA;86 &lt;a href=&#34;https://datasciencecentral.com&#34;&gt;datasciencecentral&lt;/a&gt; &lt;br&gt;&#xA;87 &lt;a href=&#34;https://datasciencedegreeprograms.net&#34;&gt;datasciencedegreeprograms.net&lt;/a&gt; &lt;br&gt;&#xA;88 &lt;a href=&#34;https://datasciencelab.wordpress.com&#34;&gt;datasciencelab.wordpress&lt;/a&gt; &lt;br&gt;&#xA;89 &lt;a href=&#34;http://datasciencelondon.org&#34;&gt;datasciencelondon.org&lt;/a&gt; &lt;br&gt;&#xA;90 &lt;a href=&#34;http://datasciencemadesimple.com&#34;&gt;datasciencemadesimple&lt;/a&gt; &lt;br&gt;&#xA;91 &lt;a href=&#34;https://datascienceplus.com&#34;&gt;datascienceplus&lt;/a&gt; &lt;br&gt;&#xA;92 &lt;a href=&#34;http://datasciencereport.com&#34;&gt;datasciencereport&lt;/a&gt; &lt;br&gt;&#xA;93 &lt;a href=&#34;https://datasciencevademecum.wordpress.com&#34;&gt;datasciencevademecum.wordpress&lt;/a&gt; &lt;br&gt;&#xA;94 &lt;a href=&#34;https://datascienceweekly.org&#34;&gt;datascienceweekly.org&lt;/a&gt; &lt;br&gt;&#xA;95 &lt;a href=&#34;https://datascientistjourney.wordpress.com&#34;&gt;datascientistjourney.wordpress&lt;/a&gt; &lt;br&gt;&#xA;96 &lt;a href=&#34;http://datascientists.net&#34;&gt;datascientists.net&lt;/a&gt; &lt;br&gt;&#xA;97 &lt;a href=&#34;https://datascopeanalytics.com&#34;&gt;datascopeanalytics&lt;/a&gt; &lt;br&gt;&#xA;98 &lt;a href=&#34;https://datasets.quantumstat.com&#34;&gt;datasets.quantumstat&lt;/a&gt; &lt;br&gt;&#xA;99 &lt;a href=&#34;https://datasetsearch.research.google.com&#34;&gt;datasetsearch.research.google&lt;/a&gt; &lt;br&gt;&#xA;100 &lt;a href=&#34;http://datastori.es&#34;&gt;datastori.es&lt;/a&gt; &lt;br&gt;&#xA;101 &lt;a href=&#34;https://datastudio.google.com&#34;&gt;datastudio.google&lt;/a&gt; &lt;br&gt;&#xA;102 &lt;a href=&#34;https://datatofish.com&#34;&gt;datatofish&lt;/a&gt; &lt;br&gt;&#xA;103 &lt;a href=&#34;https://dataversity.net&#34;&gt;dataversity.net&lt;/a&gt; &lt;br&gt;&#xA;104 &lt;a href=&#34;http://datawrangling.com&#34;&gt;datawrangling&lt;/a&gt; &lt;br&gt;&#xA;105 &lt;a href=&#34;https://deeplearning.ai&#34;&gt;deeplearning.ai&lt;/a&gt; &lt;br&gt;&#xA;106 &lt;a href=&#34;http://deeplearning.cs.toronto.edu&#34;&gt;deeplearning.cs.toronto.edu&lt;/a&gt; &lt;br&gt;&#xA;107 &lt;a href=&#34;http://deeplearning.net&#34;&gt;deeplearning.net&lt;/a&gt; &lt;br&gt;&#xA;108 &lt;a href=&#34;http://deeplearning.stanford.edu&#34;&gt;deeplearning.stanford.edu&lt;/a&gt; &lt;br&gt;&#xA;109 &lt;a href=&#34;http://deeplearningbook.org&#34;&gt;deeplearningbook.org&lt;/a&gt; &lt;br&gt;&#xA;110 &lt;a href=&#34;https://degruyter.com&#34;&gt;degruyter&lt;/a&gt; &lt;br&gt;&#xA;111 &lt;a href=&#34;https://desmos.com&#34;&gt;desmos&lt;/a&gt; &lt;br&gt;&#xA;112 &lt;a href=&#34;https://developer.ibm.com&#34;&gt;developer.ibm&lt;/a&gt; &lt;br&gt;&#xA;113 &lt;a href=&#34;https://developers.google.com&#34;&gt;developers.google&lt;/a&gt; &lt;br&gt;&#xA;114 &lt;a href=&#34;https://devops.com&#34;&gt;devops&lt;/a&gt; &lt;br&gt;&#xA;115 &lt;a href=&#34;https://dezyre.com&#34;&gt;dezyre&lt;/a&gt; &lt;br&gt;&#xA;116 &lt;a href=&#34;https://digitalvidya.com&#34;&gt;digitalvidya&lt;/a&gt; &lt;br&gt;&#xA;117 &lt;a href=&#34;http://distill.pub&#34;&gt;distill.pub&lt;/a&gt; &lt;br&gt;&#xA;118 &lt;a href=&#34;https://dl.acm.org&#34;&gt;dl.acm.org&lt;/a&gt; &lt;br&gt;&#xA;119 &lt;a href=&#34;https://docs.bokeh.org&#34;&gt;docs.bokeh.org&lt;/a&gt; &lt;br&gt;&#xA;120 &lt;a href=&#34;https://docs.cltk.org&#34;&gt;docs.cltk.org&lt;/a&gt; &lt;br&gt;&#xA;121 &lt;a href=&#34;https://docs.docker.com&#34;&gt;docs.docker&lt;/a&gt; &lt;br&gt;&#xA;122 &lt;a href=&#34;https://docs.fast.ai&#34;&gt;docs.fast.ai&lt;/a&gt; &lt;br&gt;&#xA;123 &lt;a href=&#34;https://docs.flutter.io&#34;&gt;docs.flutter.io&lt;/a&gt; &lt;br&gt;&#xA;124 &lt;a href=&#34;https://docs.microsoft.com/en-gb/&#34;&gt;docs.microsoft&lt;/a&gt; &lt;br&gt;&#xA;125 &lt;a href=&#34;https://docs.opencv.org&#34;&gt;docs.opencv.org&lt;/a&gt; &lt;br&gt;&#xA;126 &lt;a href=&#34;https://docs.oracle.com&#34;&gt;docs.oracle&lt;/a&gt; &lt;br&gt;&#xA;127 &lt;a href=&#34;https://docs.python-guide.org&#34;&gt;docs.python-guide.org&lt;/a&gt; &lt;br&gt;&#xA;128 &lt;a href=&#34;https://docs.scipy.org&#34;&gt;docs.scipy.org&lt;/a&gt; &lt;br&gt;&#xA;129 &lt;a href=&#34;https://docs.sympy.org&#34;&gt;docs.sympy.org&lt;/a&gt; &lt;br&gt;&#xA;130 &lt;a href=&#34;https://doi.org&#34;&gt;doi.org&lt;/a&gt; &lt;br&gt;&#xA;131 &lt;a href=&#34;https://drivendata.org&#34;&gt;drivendata.org&lt;/a&gt; &lt;br&gt;&#xA;132 &lt;a href=&#34;http://www.eecs.umich.edu&#34;&gt;eecs.umich.edu&lt;/a&gt; &lt;br&gt;&#xA;133 &lt;a href=&#34;http://emilio.ferrara.name&#34;&gt;emilio.ferrara.name&lt;/a&gt; &lt;br&gt;&#xA;134 &lt;a href=&#34;https://explosion.ai&#34;&gt;explosion.ai&lt;/a&gt; &lt;br&gt;&#xA;135 &lt;a href=&#34;http://fastml.com&#34;&gt;fastml&lt;/a&gt; &lt;br&gt;&#xA;136 &lt;a href=&#34;http://flowingdata.com&#34;&gt;flowingdata&lt;/a&gt; &lt;br&gt;&#xA;137 &lt;a href=&#34;https://freecodecamp.org&#34;&gt;freecodecamp.org&lt;/a&gt; &lt;br&gt;&#xA;138 &lt;a href=&#34;https://gapminder.org&#34;&gt;gapminder.org&lt;/a&gt; &lt;br&gt;&#xA;139 &lt;a href=&#34;http://gartner.com&#34;&gt;gartner&lt;/a&gt; &lt;br&gt;&#xA;140 &lt;a href=&#34;https://geeksforgeeks.org&#34;&gt;geeksforgeeks.org&lt;/a&gt; &lt;br&gt;&#xA;141 &lt;a href=&#34;https://gluebenchmark.com&#34;&gt;gluebenchmark&lt;/a&gt; &lt;br&gt;&#xA;142 &lt;a href=&#34;https://gramener.com&#34;&gt;gramener&lt;/a&gt; &lt;br&gt;&#xA;143 &lt;a href=&#34;http://gregreda.com&#34;&gt;gregreda&lt;/a&gt; &lt;br&gt;&#xA;144 &lt;a href=&#34;http://guide2research.com&#34;&gt;guide2research&lt;/a&gt; &lt;br&gt;&#xA;145 &lt;a href=&#34;https://guru99.com&#34;&gt;guru99&lt;/a&gt; &lt;br&gt;&#xA;146 &lt;a href=&#34;https://hackernoon.com&#34;&gt;hackernoon&lt;/a&gt; &lt;br&gt;&#xA;147 &lt;a href=&#34;https://hackr.io&#34;&gt;hackr.io&lt;/a&gt; &lt;br&gt;&#xA;148 &lt;a href=&#34;http://harvarddatascience.com&#34;&gt;harvarddatascience&lt;/a&gt; &lt;br&gt;&#xA;149 &lt;a href=&#34;https://hbr.org&#34;&gt;hbr.org&lt;/a&gt; &lt;br&gt;&#xA;150 &lt;a href=&#34;https://heroku.com&#34;&gt;heroku&lt;/a&gt; &lt;br&gt;&#xA;151 &lt;a href=&#34;http://herokuapp.com/&#34;&gt;herokuapp&lt;/a&gt; &lt;br&gt;&#xA;152 &lt;a href=&#34;http://hips.seas.harvard.edu&#34;&gt;hips.seas.harvard.edu&lt;/a&gt; &lt;br&gt;&#xA;153 &lt;a href=&#34;http://howstat.com&#34;&gt;howstat&lt;/a&gt; &lt;br&gt;&#xA;154 &lt;a href=&#34;https://huggingface.co&#34;&gt;huggingface.co&lt;/a&gt; &lt;br&gt;&#xA;155 &lt;a href=&#34;http://i2ocr.com&#34;&gt;i2ocr&lt;/a&gt; &lt;br&gt;&#xA;156 &lt;a href=&#34;https://icsalabs.com&#34;&gt;icsalabs&lt;/a&gt; &lt;br&gt;&#xA;157 &lt;a href=&#34;https://ieee-dataport.org&#34;&gt;ieee-dataport.org&lt;/a&gt; &lt;br&gt;&#xA;158 &lt;a href=&#34;https://ieeexplore.ieee.org&#34;&gt;ieeexplore.ieee.org&lt;/a&gt; &lt;br&gt;&#xA;159 &lt;a href=&#34;https://www.iisc.ac.in/&#34;&gt;iisc.ac.in&lt;/a&gt; &lt;br&gt;&#xA;160 &lt;a href=&#34;https://www.iitm.ac.in/donlab/tts/database.php&#34;&gt;iitm.ac.in&lt;/a&gt; &lt;br&gt;&#xA;161 &lt;a href=&#34;http://incompleteideas.net&#34;&gt;incompleteideas.net&lt;/a&gt; &lt;br&gt;&#xA;162 &lt;a href=&#34;https://inltk.readthedocs.io&#34;&gt;inltk.readthedocs.io&lt;/a&gt; &lt;br&gt;&#xA;163 &lt;a href=&#34;http://inventwithpython.com&#34;&gt;inventwithpython&lt;/a&gt; &lt;br&gt;&#xA;164 &lt;a href=&#34;https://investopedia.com&#34;&gt;investopedia&lt;/a&gt; &lt;br&gt;&#xA;165 &lt;a href=&#34;https://iot-analytics.com&#34;&gt;iot-analytics&lt;/a&gt; &lt;br&gt;&#xA;166 &lt;a href=&#34;http://isca-students.org&#34;&gt;isca-students.org&lt;/a&gt; &lt;br&gt;&#xA;167 &lt;a href=&#34;http://www.isi.edu&#34;&gt;isi.edu&lt;/a&gt; &lt;br&gt;&#xA;168 &lt;a href=&#34;http://itbusinessedge.com&#34;&gt;itbusinessedge&lt;/a&gt; &lt;br&gt;&#xA;169 &lt;a href=&#34;http://jeffdonahue.com&#34;&gt;jeffdonahue&lt;/a&gt; &lt;br&gt;&#xA;170 &lt;a href=&#34;http://jmlr.org&#34;&gt;jmlr.org&lt;/a&gt; &lt;br&gt;&#xA;171 &lt;a href=&#34;http://johnmyleswhite.com&#34;&gt;johnmyleswhite&lt;/a&gt; &lt;br&gt;&#xA;172 &lt;a href=&#34;https://journaldev.com&#34;&gt;journaldev&lt;/a&gt; &lt;br&gt;&#xA;173 &lt;a href=&#34;https://journals.elsevier.com&#34;&gt;journals.elsevier&lt;/a&gt; &lt;br&gt;&#xA;174 &lt;a href=&#34;https://kaushik.net&#34;&gt;kaushik.net&lt;/a&gt; &lt;br&gt;&#xA;175 &lt;a href=&#34;https://kdnuggets.com&#34;&gt;kdnuggets&lt;/a&gt; &lt;br&gt;&#xA;176 &lt;a href=&#34;http://kennybastani.com&#34;&gt;kennybastani&lt;/a&gt; &lt;br&gt;&#xA;177 &lt;a href=&#34;https://khanacademy.org&#34;&gt;khanacademy.org&lt;/a&gt; &lt;br&gt;&#xA;178 &lt;a href=&#34;https://kore.ai&#34;&gt;kore.ai&lt;/a&gt; &lt;br&gt;&#xA;179 &lt;a href=&#34;https://kubicle.com/library&#34;&gt;kubicle&lt;/a&gt; &lt;br&gt;&#xA;180 &lt;a href=&#34;https://latex4technics.com&#34;&gt;latex4technics&lt;/a&gt; &lt;br&gt;&#xA;181 &lt;a href=&#34;http://learninglover.com&#34;&gt;learninglover&lt;/a&gt; &lt;br&gt;&#xA;182 &lt;a href=&#34;https://learnopencv.com&#34;&gt;learnopencv&lt;/a&gt; &lt;br&gt;&#xA;183 &lt;a href=&#34;https://learnpythonthehardway.org&#34;&gt;learnpythonthehardway.org&lt;/a&gt; &lt;br&gt;&#xA;184 &lt;a href=&#34;https://lexalytics.com&#34;&gt;lexalytics&lt;/a&gt; &lt;br&gt;&#xA;185 &lt;a href=&#34;https://www.lexilogos.com/&#34;&gt;lexilogos&lt;/a&gt; &lt;br&gt;&#xA;186 &lt;a href=&#34;https://link.springer.com&#34;&gt;link.springer&lt;/a&gt; &lt;br&gt;&#xA;187 &lt;a href=&#34;https://listendata.com&#34;&gt;listendata&lt;/a&gt; &lt;br&gt;&#xA;188 &lt;a href=&#34;http://louisdorard.com&#34;&gt;louisdorard&lt;/a&gt; &lt;br&gt;&#xA;189 &lt;a href=&#34;https://lukasbiewald.com&#34;&gt;lukasbiewald&lt;/a&gt; &lt;br&gt;&#xA;190 &lt;a href=&#34;https://machinelearningmastery.com&#34;&gt;machinelearningmastery&lt;/a&gt; &lt;br&gt;&#xA;191 &lt;a href=&#34;https://mapr.com&#34;&gt;mapr&lt;/a&gt; &lt;br&gt;&#xA;192 &lt;a href=&#34;https://mastersindatascience.org&#34;&gt;mastersindatascience.org&lt;/a&gt; &lt;br&gt;&#xA;193 &lt;a href=&#34;https://mathgoodies.com&#34;&gt;mathgoodies&lt;/a&gt; &lt;br&gt;&#xA;194 &lt;a href=&#34;https://mathopenref.com&#34;&gt;mathopenref&lt;/a&gt; &lt;br&gt;&#xA;195 &lt;a href=&#34;https://mathopolis.com&#34;&gt;mathopolis&lt;/a&gt; &lt;br&gt;&#xA;196 &lt;a href=&#34;https://mathplanet.com&#34;&gt;mathplanet&lt;/a&gt; &lt;br&gt;&#xA;197 &lt;a href=&#34;https://mathsisfun.com&#34;&gt;mathsisfun&lt;/a&gt; &lt;br&gt;&#xA;198 &lt;a href=&#34;https://matplotlib.org&#34;&gt;matplotlib.org&lt;/a&gt; &lt;br&gt;&#xA;199 &lt;a href=&#34;http://mdmgeek.com&#34;&gt;mdmgeek&lt;/a&gt; &lt;br&gt;&#xA;200 &lt;a href=&#34;https://medium.com&#34;&gt;medium&lt;/a&gt; &lt;br&gt;&#xA;201 &lt;a href=&#34;http://metabrown.com&#34;&gt;metabrown&lt;/a&gt; &lt;br&gt;&#xA;202 &lt;a href=&#34;http://micfarris.com&#34;&gt;micfarris&lt;/a&gt; &lt;br&gt;&#xA;203 &lt;a href=&#34;http://mickaellegal.com&#34;&gt;mickaellegal&lt;/a&gt; &lt;br&gt;&#xA;204 &lt;a href=&#34;https://mindsmapped.com&#34;&gt;mindsmapped&lt;/a&gt; &lt;br&gt;&#xA;205 &lt;a href=&#34;https://www.mitpressjournals.org&#34;&gt;mitpressjournals.org&lt;/a&gt; &lt;br&gt;&#xA;206 &lt;a href=&#34;https://ml-compiled.readthedocs.io&#34;&gt;ml-compiled.readthedocs.io&lt;/a&gt; &lt;br&gt;&#xA;207 &lt;a href=&#34;https://www.mpi-inf.mpg.de&#34;&gt;mpi-inf.mpg.de&lt;/a&gt; &lt;br&gt;&#xA;208 &lt;a href=&#34;https://mybinder.org&#34;&gt;mybinder.org&lt;/a&gt; &lt;br&gt;&#xA;209 &lt;a href=&#34;https://mybinder.readthedocs.io&#34;&gt;mybinder.readthedocs.io&lt;/a&gt; &lt;br&gt;&#xA;210 &lt;a href=&#34;https://naftaliharris.com&#34;&gt;naftaliharris&lt;/a&gt; &lt;br&gt;&#xA;211 &lt;a href=&#34;https://www.namami.gov.in/&#34;&gt;namami.gov.in&lt;/a&gt; &lt;br&gt;&#xA;212 &lt;a href=&#34;https://nbviewer.jupyter.org&#34;&gt;nbviewer.jupyter.org&lt;/a&gt; &lt;br&gt;&#xA;213 &lt;a href=&#34;http://newdatascientist.blogspot.com&#34;&gt;newdatascientist.blogspot&lt;/a&gt; &lt;br&gt;&#xA;214 &lt;a href=&#34;http://news.startup.ml&#34;&gt;news.startup.ml&lt;/a&gt; &lt;br&gt;&#xA;215 &lt;a href=&#34;https://nips.cc&#34;&gt;nips.cc&lt;/a&gt; &lt;br&gt;&#xA;216 &lt;a href=&#34;https://nlp.stanford.edu&#34;&gt;nlp.stanford.edu&lt;/a&gt; &lt;br&gt;&#xA;217 &lt;a href=&#34;https://nltk.org&#34;&gt;nltk.org&lt;/a&gt; &lt;br&gt;&#xA;218 &lt;a href=&#34;http://www.nltk.org/nltk_data/&#34;&gt;nltk.org&lt;/a&gt; &lt;br&gt;&#xA;219 &lt;a href=&#34;https://nplt.in&#34;&gt;nplt.in&lt;/a&gt; &lt;br&gt;&#xA;220 &lt;a href=&#34;http://www.nrl.navy.mil&#34;&gt;nrl.navy.mil&lt;/a&gt; &lt;br&gt;&#xA;221 &lt;a href=&#34;http://numpy.org&#34;&gt;numpy.org&lt;/a&gt; &lt;br&gt;&#xA;222 &lt;a href=&#34;https://oigetit.com&#34;&gt;oigetit&lt;/a&gt; &lt;br&gt;&#xA;223 &lt;a href=&#34;https://online.tableau.com&#34;&gt;online.tableau&lt;/a&gt; &lt;br&gt;&#xA;224 &lt;a href=&#34;https://online.umich.edu&#34;&gt;online.umich.edu&lt;/a&gt; &lt;br&gt;&#xA;225 &lt;a href=&#34;https://onlinecourses.nptel.ac.in&#34;&gt;onlinecourses.nptel.ac.in&lt;/a&gt; &lt;br&gt;&#xA;226 &lt;a href=&#34;https://onlinemathlearning.com&#34;&gt;onlinemathlearning&lt;/a&gt; &lt;br&gt;&#xA;227 &lt;a href=&#34;https://open.wolframcloud.com&#34;&gt;open.wolframcloud&lt;/a&gt; &lt;br&gt;&#xA;228 &lt;a href=&#34;https://openaccess.thecvf.com&#34;&gt;openaccess.thecvf&lt;/a&gt; &lt;br&gt;&#xA;229 &lt;a href=&#34;https://openai.com&#34;&gt;openai&lt;/a&gt; &lt;br&gt;&#xA;230 &lt;a href=&#34;https://opencv.org&#34;&gt;opencv.org&lt;/a&gt; &lt;br&gt;&#xA;231 &lt;a href=&#34;https://opencv-python-tutroals.readthedocs.io&#34;&gt;opencv-python-tutroals.readthedocs.io&lt;/a&gt; &lt;br&gt;&#xA;232 &lt;a href=&#34;http://opengroup.org&#34;&gt;opengroup.org&lt;/a&gt; &lt;br&gt;&#xA;233 &lt;a href=&#34;https://opensciencedatacloud.org&#34;&gt;opensciencedatacloud.org&lt;/a&gt; &lt;br&gt;&#xA;234 &lt;a href=&#34;https://oreilly.com&#34;&gt;oreilly&lt;/a&gt; &lt;br&gt;&#xA;235 &lt;a href=&#34;https://pandas.pydata.org&#34;&gt;pandas.pydata.org&lt;/a&gt; &lt;br&gt;&#xA;236 &lt;a href=&#34;https://pantechsolutions.net&#34;&gt;pantechsolutions.net&lt;/a&gt; &lt;br&gt;&#xA;237 &lt;a href=&#34;https://www.pantechsolutions.net/&#34;&gt;pantechsolutions.net&lt;/a&gt; &lt;br&gt;&#xA;238 &lt;a href=&#34;https://paperswithcode.com&#34;&gt;paperswithcode&lt;/a&gt; &lt;br&gt;&#xA;239 &lt;a href=&#34;https://paralleldots.com&#34;&gt;paralleldots&lt;/a&gt; &lt;br&gt;&#xA;240 &lt;a href=&#34;https://pathmind.com&#34;&gt;pathmind&lt;/a&gt; &lt;br&gt;&#xA;241 &lt;a href=&#34;https://pbpython.com&#34;&gt;pbpython&lt;/a&gt; &lt;br&gt;&#xA;242 &lt;a href=&#34;http://periscopic.com&#34;&gt;periscopic&lt;/a&gt; &lt;br&gt;&#xA;243 &lt;a href=&#34;https://www.pewresearch.org/download-datasets/&#34;&gt;pewresearch.org&lt;/a&gt; &lt;br&gt;&#xA;244 &lt;a href=&#34;https://portal.azure.com&#34;&gt;portal.azure&lt;/a&gt; &lt;br&gt;&#xA;245 &lt;a href=&#34;https://portal.office.com&#34;&gt;portal.office&lt;/a&gt; &lt;br&gt;&#xA;246 &lt;a href=&#34;https://powerbi.microsoft.com&#34;&gt;powerbi.microsoft&lt;/a&gt; &lt;br&gt;&#xA;247 &lt;a href=&#34;https://practicalquant.blogspot.com&#34;&gt;practicalquant.blogspot&lt;/a&gt; &lt;br&gt;&#xA;248 &lt;a href=&#34;https://projects.apache.org&#34;&gt;projects.apache.org&lt;/a&gt; &lt;br&gt;&#xA;249 &lt;a href=&#34;http://p-value.info&#34;&gt;p-value.info&lt;/a&gt; &lt;br&gt;&#xA;250 &lt;a href=&#34;https://pyimagesearch.com&#34;&gt;pyimagesearch&lt;/a&gt; &lt;br&gt;&#xA;251 &lt;a href=&#34;https://pymbook.readthedocs.io&#34;&gt;pymbook.readthedocs.io&lt;/a&gt; &lt;br&gt;&#xA;252 &lt;a href=&#34;https://python.org&#34;&gt;python.org&lt;/a&gt; &lt;br&gt;&#xA;253 &lt;a href=&#34;https://python-graph-gallery.com&#34;&gt;python-graph-gallery&lt;/a&gt; &lt;br&gt;&#xA;254 &lt;a href=&#34;https://pythonlinks.info&#34;&gt;pythonlinks.info&lt;/a&gt; &lt;br&gt;&#xA;255 &lt;a href=&#34;https://pythonprogramming.net&#34;&gt;pythonprogramming.net&lt;/a&gt; &lt;br&gt;&#xA;256 &lt;a href=&#34;https://quickdraw.withgoogle.com&#34;&gt;quickdraw.withgoogle&lt;/a&gt; &lt;br&gt;&#xA;257 &lt;a href=&#34;https://rapidapi.com&#34;&gt;rapidapi&lt;/a&gt; &lt;br&gt;&#xA;258 &lt;a href=&#34;https://rasa.com&#34;&gt;rasa&lt;/a&gt; &lt;br&gt;&#xA;259 &lt;a href=&#34;https://r-bloggers.com&#34;&gt;r-bloggers&lt;/a&gt; &lt;br&gt;&#xA;260 &lt;a href=&#34;https://realpython.com&#34;&gt;realpython&lt;/a&gt; &lt;br&gt;&#xA;261 &lt;a href=&#34;https://reddit.com&#34;&gt;reddit&lt;/a&gt; &lt;br&gt;&#xA;262 &lt;a href=&#34;https://regex101.com&#34;&gt;regex101&lt;/a&gt; &lt;br&gt;&#xA;263 &lt;a href=&#34;https://regexone.com&#34;&gt;regexone&lt;/a&gt; &lt;br&gt;&#xA;264 &lt;a href=&#34;https://researchgate.net&#34;&gt;researchgate.net&lt;/a&gt; &lt;br&gt;&#xA;265 &lt;a href=&#34;https://scholar.google.co.in&#34;&gt;scholar.google.co.in&lt;/a&gt; &lt;br&gt;&#xA;266 &lt;a href=&#34;https://scholar.google.com&#34;&gt;scholar.google&lt;/a&gt; &lt;br&gt;&#xA;267 &lt;a href=&#34;https://sciencedirect.com&#34;&gt;sciencedirect&lt;/a&gt; &lt;br&gt;&#xA;268 &lt;a href=&#34;https://sci-hub.tw&#34;&gt;sci-hub.tw&lt;/a&gt; &lt;br&gt;&#xA;269 &lt;a href=&#34;https://scikit-image.org&#34;&gt;scikit-image.org&lt;/a&gt; &lt;br&gt;&#xA;270 &lt;a href=&#34;https://scikit-learn.org&#34;&gt;scikit-learn.org&lt;/a&gt; &lt;br&gt;&#xA;271 &lt;a href=&#34;http://scl.samsaadhanii.in/&#34;&gt;scl.samsaadhanii.in&lt;/a&gt; &lt;br&gt;&#xA;272 &lt;a href=&#34;http://scribd.com&#34;&gt;scribd&lt;/a&gt; &lt;br&gt;&#xA;273 &lt;a href=&#34;https://seaborn.pydata.org&#34;&gt;seaborn.pydata.org&lt;/a&gt; &lt;br&gt;&#xA;274 &lt;a href=&#34;https://searchtechnologies.com&#34;&gt;searchtechnologies&lt;/a&gt; &lt;br&gt;&#xA;275 &lt;a href=&#34;https://sebastianraschka.com&#34;&gt;sebastianraschka&lt;/a&gt; &lt;br&gt;&#xA;276 &lt;a href=&#34;https://semanticscholar.org&#34;&gt;semanticscholar.org&lt;/a&gt; &lt;br&gt;&#xA;277 &lt;a href=&#34;https://setosa.io&#34;&gt;setosa.io&lt;/a&gt; &lt;br&gt;&#xA;278 &lt;a href=&#34;https://sid.iisc.ac.in&#34;&gt;sid.iisc.ac.in&lt;/a&gt; &lt;br&gt;&#xA;279 &lt;a href=&#34;https://sigdat.org&#34;&gt;sigdat.org&lt;/a&gt; &lt;br&gt;&#xA;280 &lt;a href=&#34;http://sigir.org&#34;&gt;sigir.org&lt;/a&gt; &lt;br&gt;&#xA;281 &lt;a href=&#34;http://signll.org&#34;&gt;signll.org&lt;/a&gt; &lt;br&gt;&#xA;282 &lt;a href=&#34;https://www.sjri.res.in/&#34;&gt;sjri.res.in&lt;/a&gt; &lt;br&gt;&#xA;283 &lt;a href=&#34;https://smartcities.data.gov.in/&#34;&gt;smartcities.data.gov.in&lt;/a&gt; &lt;br&gt;&#xA;284 &lt;a href=&#34;https://sotabench.com&#34;&gt;sotabench&lt;/a&gt; &lt;br&gt;&#xA;285 &lt;a href=&#34;https://sourceforge.net&#34;&gt;sourceforge.net&lt;/a&gt; &lt;br&gt;&#xA;286 &lt;a href=&#34;http://spenczar.com&#34;&gt;spenczar&lt;/a&gt; &lt;br&gt;&#xA;287 &lt;a href=&#34;https://springboard.com&#34;&gt;springboard&lt;/a&gt; &lt;br&gt;&#xA;288 &lt;a href=&#34;https://springer.com&#34;&gt;springer&lt;/a&gt; &lt;br&gt;&#xA;289 &lt;a href=&#34;https://sqlbi.com&#34;&gt;sqlbi&lt;/a&gt; &lt;br&gt;&#xA;290 &lt;a href=&#34;http://www.stat.ucla.edu&#34;&gt;stat.ucla.edu&lt;/a&gt; &lt;br&gt;&#xA;291 &lt;a href=&#34;https://statisticshowto.datasciencecentral.com&#34;&gt;statisticshowto.datasciencecentral&lt;/a&gt; &lt;br&gt;&#xA;292 &lt;a href=&#34;https://statlect.com&#34;&gt;statlect&lt;/a&gt; &lt;br&gt;&#xA;293 &lt;a href=&#34;https://stats.stackexchange.com&#34;&gt;stats.stackexchange&lt;/a&gt; &lt;br&gt;&#xA;294 &lt;a href=&#34;https://stattrek.com&#34;&gt;stattrek&lt;/a&gt; &lt;br&gt;&#xA;295 &lt;a href=&#34;https://studio.azureml.net&#34;&gt;studio.azureml.net&lt;/a&gt; &lt;br&gt;&#xA;296 &lt;a href=&#34;https://sundog-education.com&#34;&gt;sundog-education&lt;/a&gt; &lt;br&gt;&#xA;297 &lt;a href=&#34;https://superdatascience.com&#34;&gt;superdatascience&lt;/a&gt; &lt;br&gt;&#xA;298 &lt;a href=&#34;https://susiddha.org/sanskrit-language/&#34;&gt;susiddha.org&lt;/a&gt; &lt;br&gt;&#xA;299 &lt;a href=&#34;https://tableau.com&#34;&gt;tableau&lt;/a&gt; &lt;br&gt;&#xA;300 &lt;a href=&#34;http://tarrysingh.com&#34;&gt;tarrysingh&lt;/a&gt; &lt;br&gt;&#xA;301 &lt;a href=&#34;https://tcdata360.worldbank.org&#34;&gt;tcdata360.worldbank.org&lt;/a&gt; &lt;br&gt;&#xA;302 &lt;a href=&#34;https://techcrunch.com&#34;&gt;techcrunch&lt;/a&gt; &lt;br&gt;&#xA;303 &lt;a href=&#34;https://techgig.com/&#34;&gt;techgig&lt;/a&gt; &lt;br&gt;&#xA;304 &lt;a href=&#34;https://technologyreview.com&#34;&gt;technologyreview&lt;/a&gt; &lt;br&gt;&#xA;305 &lt;a href=&#34;https://techrepublic.com&#34;&gt;techrepublic&lt;/a&gt; &lt;br&gt;&#xA;306 &lt;a href=&#34;https://tensorflow.org&#34;&gt;tensorflow.org&lt;/a&gt; &lt;br&gt;&#xA;307 &lt;a href=&#34;https://theaisummer.com&#34;&gt;theaisummer&lt;/a&gt; &lt;br&gt;&#xA;308 &lt;a href=&#34;https://theblog.okcupid.com&#34;&gt;theblog.okcupid&lt;/a&gt; &lt;br&gt;&#xA;309 &lt;a href=&#34;https://theinsaneapp.com&#34;&gt;theinsaneapp&lt;/a&gt; &lt;br&gt;&#xA;310 &lt;a href=&#34;https://the-scientist.com&#34;&gt;the-scientist&lt;/a&gt; &lt;br&gt;&#xA;311 &lt;a href=&#34;https://thisismetis.com&#34;&gt;thisismetis&lt;/a&gt; &lt;br&gt;&#xA;312 &lt;a href=&#34;https://tn.data.gov.in&#34;&gt;tn.data.gov.in&lt;/a&gt; &lt;br&gt;&#xA;313 &lt;a href=&#34;https://towardsdatascience.com&#34;&gt;towardsdatascience&lt;/a&gt; &lt;br&gt;&#xA;314 &lt;a href=&#34;https://translate.google.com&#34;&gt;translate.google&lt;/a&gt; &lt;br&gt;&#xA;315 &lt;a href=&#34;https://trends.google.com&#34;&gt;trends.google&lt;/a&gt; &lt;br&gt;&#xA;316 &lt;a href=&#34;https://tutorialandexample.com&#34;&gt;tutorialandexample&lt;/a&gt; &lt;br&gt;&#xA;317 &lt;a href=&#34;https://tutorialspoint.com&#34;&gt;tutorialspoint&lt;/a&gt; &lt;br&gt;&#xA;318 &lt;a href=&#34;https://varsitytutors.com&#34;&gt;varsitytutors&lt;/a&gt; &lt;br&gt;&#xA;319 &lt;a href=&#34;https://www.vistawide.com&#34;&gt;vistawide&lt;/a&gt; &lt;br&gt;&#xA;320 &lt;a href=&#34;http://www.visualqa.org&#34;&gt;visualqa.org&lt;/a&gt; &lt;br&gt;&#xA;321 &lt;a href=&#34;https://visualstudio.com&#34;&gt;visualstudio&lt;/a&gt; &lt;br&gt;&#xA;322 &lt;a href=&#34;https://w3schools.com&#34;&gt;w3schools&lt;/a&gt; &lt;br&gt;&#xA;323 &lt;a href=&#34;https://www.wandb.com&#34;&gt;wandb&lt;/a&gt; &lt;br&gt;&#xA;324 &lt;a href=&#34;https://whatsthebigdata.com&#34;&gt;whatsthebigdata&lt;/a&gt; &lt;br&gt;&#xA;325 &lt;a href=&#34;https://wiki.python.org&#34;&gt;wiki.python.org&lt;/a&gt; &lt;br&gt;&#xA;326 &lt;a href=&#34;http://www.wikicfp.com&#34;&gt;wikicfp&lt;/a&gt; &lt;br&gt;&#xA;327 &lt;a href=&#34;https://wolframalpha.com&#34;&gt;wolframalpha&lt;/a&gt; &lt;br&gt;&#xA;328 &lt;a href=&#34;https://wordnet.princeton.edu/related-projects&#34;&gt;wordnet.princeton.edu&lt;/a&gt; &lt;br&gt;&#xA;329 &lt;a href=&#34;http://www-aig.jpl.nasa.gov&#34;&gt;www-aig.jpl.nasa.gov&lt;/a&gt; &lt;br&gt;&#xA;330 &lt;a href=&#34;http://yerevann.com&#34;&gt;yerevann&lt;/a&gt; &lt;br&gt;&#xA;331 &lt;a href=&#34;http://yet-another-data-blog.blogspot.com.tr&#34;&gt;yet-another-data-blog.blogspot.tr&lt;/a&gt; &lt;br&gt;&#xA;332 &lt;a href=&#34;https://ztable.net&#34;&gt;ztable.net&lt;/a&gt; &lt;br&gt;&#xA;333 &lt;a href=&#34;https://excel.tips.net&#34;&gt;excel.tips.net&lt;/a&gt; &lt;br&gt;&#xA;334 &lt;a href=&#34;https://excelcampus.com&#34;&gt;excelcampus&lt;/a&gt; &lt;br&gt;&#xA;335 &lt;a href=&#34;https://exceleratorbi.com.au&#34;&gt;exceleratorbi.au&lt;/a&gt; &lt;br&gt;&#xA;336 &lt;a href=&#34;https://intellipaat.com&#34;&gt;intellipaat&lt;/a&gt; &lt;br&gt;&#xA;337 &lt;a href=&#34;https://www.knowledgehut.com/data-science&#34;&gt;knowledgehut&lt;/a&gt; &lt;br&gt;&#xA;338 &lt;a href=&#34;https://leaps.analyttica.com&#34;&gt;leaps.analyttica&lt;/a&gt; &lt;br&gt;&#xA;339 &lt;a href=&#34;https://learn.byjus.com&#34;&gt;learn.byjus&lt;/a&gt; &lt;br&gt;&#xA;340 &lt;a href=&#34;https://learning.edureka.co&#34;&gt;learndigital.withgoogle&lt;/a&gt; &lt;br&gt;&#xA;341 &lt;a href=&#34;https://learning.edureka.co&#34;&gt;learning.edureka.co&lt;/a&gt; &lt;br&gt;&#xA;342 &lt;a href=&#34;https://udacity.com&#34;&gt;udacity&lt;/a&gt; &lt;br&gt;&#xA;343 &lt;a href=&#34;https://udemy.com&#34;&gt;udemy&lt;/a&gt; &lt;br&gt;&#xA;344 &lt;a href=&#34;https://anaconda.com&#34;&gt;anaconda&lt;/a&gt; &lt;br&gt;&#xA;345 &lt;a href=&#34;https://codegrepper.com&#34;&gt;codegrepper&lt;/a&gt; &lt;br&gt;&#xA;346 &lt;a href=&#34;http://codepad.org&#34;&gt;codepad.org&lt;/a&gt; &lt;br&gt;&#xA;347 &lt;a href=&#34;https://codingbat.com&#34;&gt;codingbat&lt;/a&gt; &lt;br&gt;&#xA;348 &lt;a href=&#34;https://colab.research.google.com&#34;&gt;colab.research.google&lt;/a&gt; &lt;br&gt;&#xA;349 &lt;a href=&#34;https://docs.python.org&#34;&gt;docs.python.org&lt;/a&gt; &lt;br&gt;&#xA;350 &lt;a href=&#34;http://interactivepython.org&#34;&gt;interactivepython.org&lt;/a&gt; &lt;br&gt;&#xA;351 &lt;a href=&#34;https://julialang.org&#34;&gt;julialang.org&lt;/a&gt; &lt;br&gt;&#xA;352 &lt;a href=&#34;https://jupyter.org&#34;&gt;jupyter.org&lt;/a&gt; &lt;br&gt;&#xA;353 &lt;a href=&#34;https://kaggle.com&#34;&gt;kaggle&lt;/a&gt; &lt;br&gt;&#xA;354 &lt;a href=&#34;https://learnpython.org&#34;&gt;learnpython.org&lt;/a&gt; &lt;br&gt;&#xA;355 &lt;a href=&#34;https://paperspace.com/&#34;&gt;paperspace&lt;/a&gt; &lt;br&gt;&#xA;356 &lt;a href=&#34;https://pytorch.org&#34;&gt;pytorch.org&lt;/a&gt; &lt;br&gt;&#xA;357 &lt;a href=&#34;https://adeshpande3.github.io&#34;&gt;adeshpande3.github.io&lt;/a&gt; &lt;br&gt;&#xA;358 &lt;a href=&#34;https://harvard-iacs.github.io&#34;&gt;harvard-iacs.github.io&lt;/a&gt; &lt;br&gt;&#xA;359 &lt;a href=&#34;http://iamtrask.github.io&#34;&gt;iamtrask.github.io&lt;/a&gt; &lt;br&gt;&#xA;360 &lt;a href=&#34;https://kiwidamien.github.io&#34;&gt;kiwidamien.github.io&lt;/a&gt; &lt;br&gt;&#xA;361 &lt;a href=&#34;https://ronxin.github.io&#34;&gt;ronxin.github.io&lt;/a&gt; &lt;br&gt;&#xA;362 &lt;a href=&#34;https://spandan-madan.github.io&#34;&gt;spandan-madan.github.io&lt;/a&gt; &lt;br&gt;&#xA;363 &lt;a href=&#34;https://stanfordnlp.github.io&#34;&gt;stanfordnlp.github.io&lt;/a&gt; &lt;br&gt;&#xA;364 &lt;a href=&#34;https://trigonaminima.github.io&#34;&gt;trigonaminima.github.io&lt;/a&gt; &lt;br&gt;&#xA;365 &lt;a href=&#34;https://www.interviewquery.com/&#34;&gt;Interview Query&lt;/a&gt; &lt;br&gt;&#xA;366 &lt;a href=&#34;https://www.hackerrank.com/&#34;&gt;Hackerrank&lt;/a&gt; &lt;br&gt;&#xA;367 &lt;a href=&#34;https://www.crackingthecodinginterview.com/&#34;&gt;CrackingTheCodingInterview&lt;/a&gt; &lt;br&gt;&#xA;368 &lt;a href=&#34;https://research.google/&#34;&gt;Google Research&lt;/a&gt; &lt;br&gt;&#xA;369 &lt;a href=&#34;https://ai.googleblog.com/&#34;&gt;Google AI Blog&lt;/a&gt; &lt;br&gt;&#xA;370 &lt;a href=&#34;https://medium.com/paperswithcode/ml-code-completeness-checklist-e9127b168501&#34;&gt;ML Code Completeness Checklist,&lt;/a&gt; &lt;br&gt;&#xA;371 &lt;a href=&#34;https://www.cs.mcgill.ca/~jpineau/ReproducibilityChecklist.pdf&#34;&gt;ML Reproducibility Checklist&lt;/a&gt; &lt;br&gt;&#xA;372 &lt;a href=&#34;https://github.com/huggingface/transformers&#34;&gt;Huggingface Transformer&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>My Daily Tools</title>
      <link>http://localhost:1313/dsblog/my-daily-tools/</link>
      <pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/my-daily-tools/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr112-My-Daily-Tools.jpg&#34; alt=&#34;My Daily Tools&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;my-daily-tools&#34;&gt;My Daily Tools&lt;/h1&gt;&#xA;&lt;p&gt;[My Daily Tools]&lt;/p&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno&lt;/th&gt;&#xA;          &lt;th&gt;Category&lt;/th&gt;&#xA;          &lt;th&gt;Subcategory&lt;/th&gt;&#xA;          &lt;th&gt;URL&lt;/th&gt;&#xA;          &lt;th&gt;Purpose/Remarks&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Blogging&lt;/td&gt;&#xA;          &lt;td&gt;Wordpress&lt;/td&gt;&#xA;          &lt;td&gt;Create a free website or build a blog with ease on WordPress.com. Dozens of free, customizable, mobile-ready designs and themes.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Bookmarking&lt;/td&gt;&#xA;          &lt;td&gt;Scrible&lt;/td&gt;&#xA;          &lt;td&gt;Modern research and writing platform for school &amp;amp; work&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Bookmarking&lt;/td&gt;&#xA;          &lt;td&gt;Diigo&lt;/td&gt;&#xA;          &lt;td&gt;Diigo is a powerful research tool and a knowledge-sharing community.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;fiverr.com&lt;/td&gt;&#xA;          &lt;td&gt;Find the perfect freelance services for your business&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;freelancer.com&lt;/td&gt;&#xA;          &lt;td&gt;Diigo is a powerful research tool and a knowledge-sharing community.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;jobscan.co&lt;/td&gt;&#xA;          &lt;td&gt;Optimize your resume to get more interviews&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;upwork.com&lt;/td&gt;&#xA;          &lt;td&gt;Upwork connects businesses with independent professionals and agencies around the globe.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;Crunchbase&lt;/td&gt;&#xA;          &lt;td&gt;Crunchbase Has Access to Millions of Contacts at Growing Companies for You to Search From.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;Careers Linkedin&lt;/td&gt;&#xA;          &lt;td&gt;LinkedIn is the world’s largest professional network on a mission to connect the world&amp;rsquo;s professionals to make them more productive and successful.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;AngelList&lt;/td&gt;&#xA;          &lt;td&gt;Apply privately to 130000+ remote jobs and startup jobs near you with one application&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;Behance&lt;/td&gt;&#xA;          &lt;td&gt;Behance is the world&amp;rsquo;s largest creative network for showcasing and discovering creative work.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;Hacker Earth&lt;/td&gt;&#xA;          &lt;td&gt;Helping 3M+ developers be better through coding contests, data science competitions, and hackathons.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;HackerRank&lt;/td&gt;&#xA;          &lt;td&gt;HackerRank is the market-leading technical assessment and remote interview solution for hiring developers.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Work/Job/Business&lt;/td&gt;&#xA;          &lt;td&gt;Indeed&lt;/td&gt;&#xA;          &lt;td&gt;With Indeed, you can search millions of jobs online to find the next step in your career.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Absolutely Free Clipart&lt;/td&gt;&#xA;          &lt;td&gt;Home to thousands of free clip art images.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Flickr&lt;/td&gt;&#xA;          &lt;td&gt;Flickr is a place where you can store your photos, tag them and share them with others.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;17&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;FreeFoto&lt;/td&gt;&#xA;          &lt;td&gt;FreeFoto.com is the largest collection of free photographs on the Internet (link back and attribution required).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;18&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;FreeImages&lt;/td&gt;&#xA;          &lt;td&gt;More than 16,000 images in the collection.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Icon Finder&lt;/td&gt;&#xA;          &lt;td&gt;Search through over 650,000 icons or browse over 12,000 icon sets.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Icons8 Background Remover&lt;/td&gt;&#xA;          &lt;td&gt;Free background remover tool&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;iStock&lt;/td&gt;&#xA;          &lt;td&gt;Explore millions of royalty-free images, illustrations, videos, and music clips.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;PhotoPeach&lt;/td&gt;&#xA;          &lt;td&gt;Photopeach lets you quickly upload photos and make slideshows, share your shows via email IM or Facebook, embed in your blog or website.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Pics4Learning&lt;/td&gt;&#xA;          &lt;td&gt;Pics4Learning is a safe, free image library for education.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;24&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;PictureTrail&lt;/td&gt;&#xA;          &lt;td&gt;Biggest slideshow selection on the web.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;25&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Pixabay&lt;/td&gt;&#xA;          &lt;td&gt;Over 500,000 free photos, vectors and art illustrations.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;26&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Shutterstock&lt;/td&gt;&#xA;          &lt;td&gt;Over 80 Million stock photos, vectors, videos, and music tracks&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;SmugMug&lt;/td&gt;&#xA;          &lt;td&gt;Stunning photo websites for you, your family or your business.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Unsplash&lt;/td&gt;&#xA;          &lt;td&gt;10 free high-resolution photos every day&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;29&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Clip Art, Image &amp;amp; Photo&lt;/td&gt;&#xA;          &lt;td&gt;Web Photo Resizer&lt;/td&gt;&#xA;          &lt;td&gt;Helps you optimize images for web and email.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;30&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Creative Thinking&lt;/td&gt;&#xA;          &lt;td&gt;mindtools.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;31&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Creative Thinking&lt;/td&gt;&#xA;          &lt;td&gt;Brain Metrix&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;32&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Creative Thinking&lt;/td&gt;&#xA;          &lt;td&gt;Lumosity&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;33&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Creative Thinking&lt;/td&gt;&#xA;          &lt;td&gt;Sharpbrains&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Creative Thinking&lt;/td&gt;&#xA;          &lt;td&gt;Mindgames&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;35&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Creative Thinking&lt;/td&gt;&#xA;          &lt;td&gt;Vedic Maths&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;36&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Data in Cloud&lt;/td&gt;&#xA;          &lt;td&gt;gdrive&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Data in Cloud&lt;/td&gt;&#xA;          &lt;td&gt;Dropbox&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;38&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Data in Cloud&lt;/td&gt;&#xA;          &lt;td&gt;Onedrive&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Development&lt;/td&gt;&#xA;          &lt;td&gt;unicode.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;40&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Dharma&lt;/td&gt;&#xA;          &lt;td&gt;gitasupersite.iitk.ac.in&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;File Converter&lt;/td&gt;&#xA;          &lt;td&gt;onlinevideoconverter.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;42&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;File Converter&lt;/td&gt;&#xA;          &lt;td&gt;pdf2go.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;File Converter&lt;/td&gt;&#xA;          &lt;td&gt;pdftables.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;44&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;File Converter&lt;/td&gt;&#xA;          &lt;td&gt;pdftotext.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;File Converter&lt;/td&gt;&#xA;          &lt;td&gt;products.aspose.app&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;46&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;File Converter&lt;/td&gt;&#xA;          &lt;td&gt;HTML to Markdown&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;PDF Drive&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;48&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;Free-Ebooks dot net&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;49&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;Internet Archive Books&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;Bookboon&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;51&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;Obooko&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;52&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;Manybooks&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;53&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;PDF Search Engine&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;54&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;PDFBooksWorld&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;55&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;ScienceDirect&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;56&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;Engineering Books&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;57&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Free ebook&lt;/td&gt;&#xA;          &lt;td&gt;BC Open Collection&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;58&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Omni calculator&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;59&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Language Chinese&lt;/td&gt;&#xA;          &lt;td&gt;omniglot.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;60&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Language English&lt;/td&gt;&#xA;          &lt;td&gt;howtopronounce.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;61&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Language English&lt;/td&gt;&#xA;          &lt;td&gt;languagetool.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;62&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Language Indic&lt;/td&gt;&#xA;          &lt;td&gt;quillpad.in&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;63&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Learn Drawing&lt;/td&gt;&#xA;          &lt;td&gt;Proko How to Draw&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;64&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Learn Drawing&lt;/td&gt;&#xA;          &lt;td&gt;Proko Model Poses Drawing&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;65&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Mass Mailing&lt;/td&gt;&#xA;          &lt;td&gt;mailchimp&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;66&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Misc-Tools&lt;/td&gt;&#xA;          &lt;td&gt;palmetto.demos.dice-research.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;67&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Misc-Tools&lt;/td&gt;&#xA;          &lt;td&gt;tableizer.journalistopia.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;68&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Notes&lt;/td&gt;&#xA;          &lt;td&gt;Evernote&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;69&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Notes&lt;/td&gt;&#xA;          &lt;td&gt;MarkText&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;70&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Audio&lt;/td&gt;&#xA;          &lt;td&gt;Sound Cloud&lt;/td&gt;&#xA;          &lt;td&gt;MarkText - Markdown Editor using Chocolatey&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;71&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;classpoint.app&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;72&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;Share Screenshots&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;73&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;e.ggtimer.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;74&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;kahoot.it&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;75&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;mentimeter.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;76&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;miro.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;77&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;noises.online&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;78&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;polls.io&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;79&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;quizizz.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;80&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;rawshorts.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;81&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;snag.gy&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;82&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;timeanddate.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;83&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;Online Voting&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;84&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Research&lt;/td&gt;&#xA;          &lt;td&gt;academic.microsoft.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;85&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Research&lt;/td&gt;&#xA;          &lt;td&gt;researchgate.net&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;86&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Research&lt;/td&gt;&#xA;          &lt;td&gt;semanticscholar.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;87&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Research&lt;/td&gt;&#xA;          &lt;td&gt;subjectguides.esc.edu&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;88&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ACA Capture Pro&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;89&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Articulate Replay&lt;/td&gt;&#xA;          &lt;td&gt;It captures screen images, web pages, Flash, icons, etc, it creates videos of your computer screen.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;90&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;BB Flashback&lt;/td&gt;&#xA;          &lt;td&gt;Create screencasts with Articulate Replay.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;91&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;BSR Screen recorder&lt;/td&gt;&#xA;          &lt;td&gt;Record, enhance, share. Create compelling demos and tutorials with BB FlashBack screen recorder.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;92&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;CamStudio&lt;/td&gt;&#xA;          &lt;td&gt;Captures video, sound and pictures of anything you see on your screen.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;93&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Camtasia&lt;/td&gt;&#xA;          &lt;td&gt;CamStudio is able to record all screen and audio activity on your computer and create industry-standard AVI video files.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;94&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Capture Assistant&lt;/td&gt;&#xA;          &lt;td&gt;Techsmith’s Camtasia is a tool to record, edit and enhance on-screen activity in the form of screencasts.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;95&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Capture WizPro&lt;/td&gt;&#xA;          &lt;td&gt;Capture Assistant is a convenient and easy-to-use text and graphics capture tool.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;96&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Clarify&lt;/td&gt;&#xA;          &lt;td&gt;Capture or record anything on your PC fast.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;97&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;clip2net&lt;/td&gt;&#xA;          &lt;td&gt;Use multiple screenshots to tell your story. Mark them up, add some text and export them as a document to PDF, Word or Dropbox.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;98&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Demo Builder&lt;/td&gt;&#xA;          &lt;td&gt;Share screenshots and files the easiest way.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;99&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Faststone Capture&lt;/td&gt;&#xA;          &lt;td&gt;Demo Builder provides an easy way to create tutorials, presentations or demonstrations that show how software and systems work.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;100&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Gadwin PrintScreen&lt;/td&gt;&#xA;          &lt;td&gt;A powerful, lightweight, yet full-featured screen capture tool that allows you to easily capture and annotate anything on the screen.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;101&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Greenshot&lt;/td&gt;&#xA;          &lt;td&gt;Want to create a screenshot suitable for saving or printing? Then just hit a key on your keyboard. Oh yeah, you’ll have to download this program first.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;102&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Instant Demo&lt;/td&gt;&#xA;          &lt;td&gt;A free screenshot tool optimized for productivity.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;103&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;iShowU&lt;/td&gt;&#xA;          &lt;td&gt;Screen Recorder Software for Presentations, Training and Support&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;104&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Jing&lt;/td&gt;&#xA;          &lt;td&gt;iShowU is a “realtime” video screen recorder for Macs.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;105&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;KingKong Capture&lt;/td&gt;&#xA;          &lt;td&gt;Techsmith’s Jing is a free screencasting program that lets you capture anything you see on your computer screen, as an image or short video, and share it instantly.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;106&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;LICEcap&lt;/td&gt;&#xA;          &lt;td&gt;Capture onscreen images fast and easy.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;107&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Loom&lt;/td&gt;&#xA;          &lt;td&gt;Simple animated screen capture. LICEcap can capture an area of your desktop and save it directly to .GIF&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;108&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Monosnap&lt;/td&gt;&#xA;          &lt;td&gt;Screen recorder for Mac, Windows, and Chromebooks. Record your camera and screen with audio directly from your Chrome browser&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;109&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;MWSnap&lt;/td&gt;&#xA;          &lt;td&gt;Monosnap is a tool that allows you to take, share and manage your screenshots.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;110&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;PrtScr&lt;/td&gt;&#xA;          &lt;td&gt;MWSnap is a small yet powerful Windows program for snapping (capturing) images from selected parts of the screen.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;111&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Replay Video Capture for Mac&lt;/td&gt;&#xA;          &lt;td&gt;Captures full screen, rectangle selection, freehand selection, or active window.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;112&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Rikisoft EasySnap&lt;/td&gt;&#xA;          &lt;td&gt;Use it to record online video, and anything else playing on your screen.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;113&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Screenbird&lt;/td&gt;&#xA;          &lt;td&gt;Get any part of your screen captured and saved automatically with speed and quality.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;114&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Screencastify&lt;/td&gt;&#xA;          &lt;td&gt;Screenbird is a full cross platform video screen capture tool and host.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;115&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ScreenCastle&lt;/td&gt;&#xA;          &lt;td&gt;Screencastify is a free screen recorder for Chrome. No download required. Record, edit and share videos in seconds. Videos autsave to your Google Drive.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;116&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Screencast-O-matic&lt;/td&gt;&#xA;          &lt;td&gt;Online screen recorder&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;117&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ScreenDash&lt;/td&gt;&#xA;          &lt;td&gt;Screencast-O-Matic makes screencasting free and easy, with one-click screen capture, online or you can download and install the application on Mac OSX.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;118&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ScreenFlow&lt;/td&gt;&#xA;          &lt;td&gt;Capture screenshots from your computer, webcam &amp;amp; iPhone.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;119&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Screenhunter&lt;/td&gt;&#xA;          &lt;td&gt;Screencasting and video editing software for Mac.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;120&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Screenpresso&lt;/td&gt;&#xA;          &lt;td&gt;An award-winning screen capture software solution to capture any part of screen image, print, edit screenshot with annotations.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;121&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ScreenRecord&lt;/td&gt;&#xA;          &lt;td&gt;Screenpresso captures your desktop (screenshots and HD videos) for your training documents, collaborative design work, IT bug reports, and more.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;122&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Screenshot Captor&lt;/td&gt;&#xA;          &lt;td&gt;ScreenRecord is a screen recording tool that allows the user to capture the screen as a Quicktime movie.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;123&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ScreenSnapr&lt;/td&gt;&#xA;          &lt;td&gt;A best-in-class tool for grabbing, manipulating, annotating, and sharing screenshots.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;124&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Screeny&lt;/td&gt;&#xA;          &lt;td&gt;Effortlessly share images: show the world what you see with ScreenSnapr.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;125&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;SnagIt&lt;/td&gt;&#xA;          &lt;td&gt;Screeny makes screen capturing easy and gives you the freedom to capture your videos or images at any size.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;126&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;SnapIt&lt;/td&gt;&#xA;          &lt;td&gt;Techsmith’s Snagit is a screen capture tool that lets you grab an image or video of what you see on your computer screen and then add enhancing text and other effects.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;127&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;TinyGrab&lt;/td&gt;&#xA;          &lt;td&gt;Easy to use screen capture software which allows you to easily capture anything on the screen including windows, menus, full screen, rectangular regions, web pages and take shots of moving images.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;128&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;TurboDemo&lt;/td&gt;&#xA;          &lt;td&gt;Take a screenshot and share it with your clients or friends in less time than it took you to read this sentence!&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;129&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ViewletBuilder&lt;/td&gt;&#xA;          &lt;td&gt;Capture screenshots and explain software, PC applications, websites and products with animated demos and tutorials.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;130&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;ViewletCam&lt;/td&gt;&#xA;          &lt;td&gt;Create Flash tutorials or simulations that exactly mirror the way your product or web site works.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;131&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Voila&lt;/td&gt;&#xA;          &lt;td&gt;ViewletCam is the fastest, easiest way to record PC applications, PowerPoint presentations, animations, and video directly from your PC screen.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;132&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Webinaria&lt;/td&gt;&#xA;          &lt;td&gt;The ultimate screen capture app for Mac.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;133&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;websnapr&lt;/td&gt;&#xA;          &lt;td&gt;Tools to create software demos.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;134&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Screencapture &amp;amp; Screencasting Tools&lt;/td&gt;&#xA;          &lt;td&gt;Wink&lt;/td&gt;&#xA;          &lt;td&gt;websnapr lets you capture screenshots of (almost) any web page.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;135&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Sharing&lt;/td&gt;&#xA;          &lt;td&gt;cloudup.com&lt;/td&gt;&#xA;          &lt;td&gt;Wink is a Tutorial and Presentation creation software, primarily aimed at creating tutorials on how to use software (like a tutor for MS-Word/Excel etc).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;136&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Sharing&lt;/td&gt;&#xA;          &lt;td&gt;credential.net&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;137&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Skill Testing&lt;/td&gt;&#xA;          &lt;td&gt;interviewbit.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;138&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Video and Image Creation&lt;/td&gt;&#xA;          &lt;td&gt;TechSmitch&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;139&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Video Download&lt;/td&gt;&#xA;          &lt;td&gt;YTD Downloader&lt;/td&gt;&#xA;          &lt;td&gt;Create and share images and videos for better training, tutorials, lessons, and everyday communication.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;140&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Voice Recording&lt;/td&gt;&#xA;          &lt;td&gt;Audacity&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;141&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Web Scrapping&lt;/td&gt;&#xA;          &lt;td&gt;wordhtml.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;142&lt;/td&gt;&#xA;          &lt;td&gt;General&lt;/td&gt;&#xA;          &lt;td&gt;Website Content&lt;/td&gt;&#xA;          &lt;td&gt;Joomla&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;143&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;          &lt;td&gt;regex101.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;144&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;          &lt;td&gt;TTS&lt;/td&gt;&#xA;          &lt;td&gt;Natural Reader&lt;/td&gt;&#xA;          &lt;td&gt;Desktop&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;145&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;          &lt;td&gt;TTS&lt;/td&gt;&#xA;          &lt;td&gt;TTS Reader&lt;/td&gt;&#xA;          &lt;td&gt;Listening Your Text&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;146&lt;/td&gt;&#xA;          &lt;td&gt;NLP&lt;/td&gt;&#xA;          &lt;td&gt;TTS&lt;/td&gt;&#xA;          &lt;td&gt;Listening Your Text&lt;/td&gt;&#xA;          &lt;td&gt;Listening Your Text&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;147&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;sanskrit.jnu.ac.in&lt;/td&gt;&#xA;          &lt;td&gt;Listening Your Text&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;148&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;sanskrit.uohyd.ac.in&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;149&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;ashtadhyayi.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;150&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;kosha.sanskrit.today&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;151&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;openpathshala.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;152&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;sanskrit.inria.fr&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;153&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;sanskritdocuments.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;154&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;sanskritfromhome.in&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;155&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;sanskritslokas.info&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;156&lt;/td&gt;&#xA;          &lt;td&gt;Sanskrit Text&lt;/td&gt;&#xA;          &lt;td&gt;Language Sanskrit&lt;/td&gt;&#xA;          &lt;td&gt;spokensanskrit.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;157&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;app.logobly.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;158&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;shields.io&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;159&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;beautifytools.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;160&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;camstudio.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;161&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;rawshorts.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;162&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;thestocks.im&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;163&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;animoto.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;164&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;burst.shopify.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;165&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;canva.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;166&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;color.adobe.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;167&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;colorhunt.co&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;168&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;doodly.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;169&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;dribbble.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;170&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;excalidraw.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;171&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;flickr.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;172&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;fontconverter.in&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;173&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;fonts.google.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;174&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;freepik.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;175&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;getgreenshot.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;176&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;giphy.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;177&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;htmlcolorcodes.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;178&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;imgur.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;179&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;mycolor.space&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;180&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;pexels.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;181&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;pixabay.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;182&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;quickdraw.withgoogle.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;183&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;remove.bg&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;184&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;shutterstock.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;185&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;sketch2code.azurewebsites.net&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;186&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;stocksnap.io&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;187&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;unsplash.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;188&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Design-FE&lt;/td&gt;&#xA;          &lt;td&gt;wordclouds.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;189&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Designer UI&lt;/td&gt;&#xA;          &lt;td&gt;Pencil&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;190&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Designer UI&lt;/td&gt;&#xA;          &lt;td&gt;GIMP&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;191&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;videoask.com&lt;/td&gt;&#xA;          &lt;td&gt;Desktop&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;192&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;webtoolkitonline.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;193&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;Google Ads&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;194&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;ahrefs.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;195&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;analytics.google.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;196&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;app.neilpatel.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;197&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;creatoracademy.youtube.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;198&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;developers.facebook.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;199&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;Thumbnail for Social Media&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;200&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;domaintyper.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;201&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;follow.it&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;202&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;gtmetrix.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;203&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;h-supertools.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;204&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;keyword.io&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;205&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;lookup.icann.org&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;206&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;marketingaiinstitute.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;207&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;marketingplatform.google.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;208&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;mashable.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;209&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;moz.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;210&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;namelix.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;211&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;namemesh.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;212&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;privacypolicygenerator.info&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;213&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;seoptimer.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;214&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;tagmanager.google.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;215&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;SEO/SEM&lt;/td&gt;&#xA;          &lt;td&gt;wordtracker.com&lt;/td&gt;&#xA;          &lt;td&gt;&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;216&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;Krisp&lt;/td&gt;&#xA;          &lt;td&gt;Noise Cancellation Tool During Zoom/Meet Call&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;217&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;beatoven.ai&lt;/td&gt;&#xA;          &lt;td&gt;Create customisable royalty free music that elevates your story&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;218&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;Cleanvoice.ai&lt;/td&gt;&#xA;          &lt;td&gt;Stop wasting hours editing your podcast&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;219&lt;/td&gt;&#xA;          &lt;td&gt;Website&lt;/td&gt;&#xA;          &lt;td&gt;Online Training&lt;/td&gt;&#xA;          &lt;td&gt;podcastle.ai&lt;/td&gt;&#xA;          &lt;td&gt;The One-Stop Shop for Broadcast Storytelling&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>My Favorite Chrome Extensions</title>
      <link>http://localhost:1313/dsblog/myfab-chrome-extensions/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/myfab-chrome-extensions/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr111-My-Favorite-Chrome-Extensions.jpg&#34; alt=&#34;My Favorite Chrome Extensions&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;my-favorite-chrome-extensions&#34;&gt;My Favorite Chrome Extensions&lt;/h1&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Application Launcher For Drive (by Google) : Open Drive files directly from your browser in compatible applications installed on your computer.&lt;/li&gt;&#xA;&lt;li&gt;Bardeen - automate manual work : Automate manual work with one click! Connect 30+ apps, scrape the web, and boost your productivity.&lt;/li&gt;&#xA;&lt;li&gt;Bell of Mindfulness : A bell that reminds us to breathe and be mindful of our body and mind.&lt;/li&gt;&#xA;&lt;li&gt;ChatGPT for Google : Show ChatGPT response alongside search engine results&lt;/li&gt;&#xA;&lt;li&gt;Cisco Webex Extension : Join Webex meetings using Google Chrome ™&lt;/li&gt;&#xA;&lt;li&gt;ColorZilla : Advanced Eyedropper, Color Picker, Gradient Generator and other colorful goodies&lt;/li&gt;&#xA;&lt;li&gt;Dark Mode - Dark Reader for Сhrome : Dark Mode a classic dark theme for every website. Switch website to dark reader and for night and daily browsing.&lt;/li&gt;&#xA;&lt;li&gt;DeepSeek AI : Chat with DeepSeek AI – Boost your creativity and productivity using DeepSeek R1, the ultimate AI-powered browser tool.&lt;/li&gt;&#xA;&lt;li&gt;Editor for Docs, Sheets &amp;amp; Slides : View, edit and select the layout of Google Docs, Sheets, and Slides with an easy access via extension menu&lt;/li&gt;&#xA;&lt;li&gt;Eightify: Youtube Summary with ChatGPT : Youtube video summaries with ChatGPT. Extract key ideas from Youtube videos with GPT.&lt;/li&gt;&#xA;&lt;li&gt;Glasp Web Highlighter: PDF &amp;amp; Web Highlight : AI-powered Web Highlighter for Websites, PDF, and YouTube videos. YouTube Summary with ChatGPT, Claude, and Gemini.&lt;/li&gt;&#xA;&lt;li&gt;Glasp: Social Web Highlight &amp;amp; YouTube Summary : Take notes and add highlights on web pages. Discover and save articles from friends. A tool for writers, avid readers, and thinkers.&lt;/li&gt;&#xA;&lt;li&gt;GoFullPage - Full Page Screen Capture : Capture a screenshot of your current page in entirety and reliably—without requesting any extra permissions!&lt;/li&gt;&#xA;&lt;li&gt;Google Dictionary (by Google) : View definitions easily as you browse the web.&lt;/li&gt;&#xA;&lt;li&gt;Google Docs Offline : Edit, create, and view your documents, spreadsheets, and presentations — all without internet access.&lt;/li&gt;&#xA;&lt;li&gt;Google Input Tools : Input Tools lets you type in the language of your choice.&lt;/li&gt;&#xA;&lt;li&gt;Google Keep Chrome Extension : Save to Google Keep in a single click!&lt;/li&gt;&#xA;&lt;li&gt;Google Scholar Button : Lookup scholarly articles as you browse the web.&lt;/li&gt;&#xA;&lt;li&gt;Google Translate : View translations easily as you browse the web. By the Google Translate team.&lt;/li&gt;&#xA;&lt;li&gt;Grammar &amp;amp; Spell Checker — LanguageTool : Check your texts for spelling and grammar problems everywhere on the web&lt;/li&gt;&#xA;&lt;li&gt;Grammar Checker &amp;amp; Paraphraser – LanguageTool : Instantly Enhance Your Texts with LanguageTool’s Grammar Checker and Paraphrasing Tool&lt;/li&gt;&#xA;&lt;li&gt;Grammarly: AI Writing and Grammar Checker App : Improve your writing with all-in-one assistance—including generative AI, grammar check, and more.&lt;/li&gt;&#xA;&lt;li&gt;Headline Studio by CoSchedule : The headline analyzer from CoSchedule enables you to create headlines that drives maximum traffic, clicks, &amp;amp; SEO&lt;/li&gt;&#xA;&lt;li&gt;Highlighter : Highlight text on websites with a simple right-click or keyboard shortcut. Saves highlights on your device.&lt;/li&gt;&#xA;&lt;li&gt;IPEVO Whiteboard : IPEVO Whiteboard for Chromebook is specifically designed to create an interactive whiteboard with IPEVO IW2 on your Chromebook.&lt;/li&gt;&#xA;&lt;li&gt;Keepa - Amazon Price Tracker : Adds price history charts and the option to be alerted on price drops to all supported Amazon sites.&lt;/li&gt;&#xA;&lt;li&gt;Keyword Tool Dominator : Keyword Tool Dominator Extension&lt;/li&gt;&#xA;&lt;li&gt;Keywords Everywhere - Keyword Tool : Keyword search volume, cpc and competition for 15+ websites like Google™ Search Console, YouTube™, Amazon™ &amp;amp; more&lt;/li&gt;&#xA;&lt;li&gt;Marinara: Pomodoro® Assistant : Pomodoro® time management assistant.&lt;/li&gt;&#xA;&lt;li&gt;Markdown Viewer : Dark Mode • Themes • Autoreload • Mermaid Diagrams • MathJax • ToC • Syntax Highlighting&lt;/li&gt;&#xA;&lt;li&gt;Mendeley Web Importer : Fast, convenient import of references and PDFs to your Mendeley Reference Manager library.&lt;/li&gt;&#xA;&lt;li&gt;Microsoft Bing Search for Chrome : Set Microsoft Bing as your default search provider&lt;/li&gt;&#xA;&lt;li&gt;MindStudio : MindStudio Chrome Extension&lt;/li&gt;&#xA;&lt;li&gt;MozBar : MozBar from Moz&lt;/li&gt;&#xA;&lt;li&gt;Neeva AI Search : AI powered, instant answers with citations&lt;/li&gt;&#xA;&lt;li&gt;Office Editing for Docs, Sheets &amp;amp; Slides : View and edit Microsoft Word, Excel, and PowerPoint files with Google Docs, Sheets, and Slides&lt;/li&gt;&#xA;&lt;li&gt;OneTab : Save up to 95% memory and reduce tab clutter&lt;/li&gt;&#xA;&lt;li&gt;Open in Colab : Open a Github-hosted notebook in Google Colab&lt;/li&gt;&#xA;&lt;li&gt;ParagraphAI - Write Better, Faster : ParagraphAI is an AI-powered writing tool that crafts perfectly curated content for all your writing needs.&lt;/li&gt;&#xA;&lt;li&gt;Pomodoro® Assistant : Pomodoro® time management assistan&lt;/li&gt;&#xA;&lt;li&gt;Power Thesaurus : Use the power of synonyms by button in toolbar, right-click or by word selection on any page.&lt;/li&gt;&#xA;&lt;li&gt;Pronounce: Speech and Pronunciation Checker : Speak confidently with instant feedback on any conversation from an AI speech coach.&lt;/li&gt;&#xA;&lt;li&gt;Read Aloud: A Text to Speech Voice Reader : Read aloud the current web-page article with one click, using text to speech (TTS). Supports 40+ languages.&lt;/li&gt;&#xA;&lt;li&gt;RoboForm Password Manager : RoboForm Password Manager makes your life easier by remembering passwords and logging you into websites automatically&lt;/li&gt;&#xA;&lt;li&gt;Sci-Hub : Science Paper Research&lt;/li&gt;&#xA;&lt;li&gt;Selenium IDE : Selenium Record and Playback tool for ease of getting acquainted with Selenium WebDriver.&lt;/li&gt;&#xA;&lt;li&gt;Sider: Chat with all AI models (DeepSeek, Gemini, Claude, etc.) : AI sidebar support chat with all AI models (DeepSeek, Gemini, Claude, etc.) for advanced AI search, read, and write.&lt;/li&gt;&#xA;&lt;li&gt;Signer.Digital Digital Signature, PKI : Digital Signature of eReturns, PDF &amp;amp; Web User Auth, RSA Encryption/Decryption, Certificate Enrollment/Download on Smartcard.&lt;/li&gt;&#xA;&lt;li&gt;Simplescraper — a fast and free web scraper : A web scraper that&amp;rsquo;s fast, free and simple to use. Scrape website data and table data in seconds&lt;/li&gt;&#xA;&lt;li&gt;Slido : Engage your audience with live polling and Q&amp;amp;A without ever leaving Google Slides&lt;/li&gt;&#xA;&lt;li&gt;Star History : A chrome extension showing star history graph of current GitHub repository&lt;/li&gt;&#xA;&lt;li&gt;Tabbed Postman - REST Client :&lt;/li&gt;&#xA;&lt;li&gt;Table Capture : Copies HTML tables to the clipboard or exports them to Microsoft Excel, CSV, Google Sheets, Office 365, etc.&lt;/li&gt;&#xA;&lt;li&gt;Tag Assistant Legacy (by Google) : Tag Assistant helps to troubleshoot installation of various Google tags including Google Analytics, Google Tag Manager and more.&lt;/li&gt;&#xA;&lt;li&gt;Talk-to-ChatGPT : Talk to ChatGPT through your microphone and hear its responses with a voice. Uses speech recognition and text-to-speech technologies&lt;/li&gt;&#xA;&lt;li&gt;Transliterate South Asian Scripts : Transliterate South Asian Scripts&lt;/li&gt;&#xA;&lt;li&gt;Ubersuggest - SEO and Keyword Discovery : Keyword search volume, CPC and insights for all keywords you search. Works with Google, YouTube and Amazon. SEO tool by Neil Patel.&lt;/li&gt;&#xA;&lt;li&gt;Web Scraper - GetData.IO : Turn any webpage into an API in 3 click&lt;/li&gt;&#xA;&lt;li&gt;WhatFont : The easiest way to identify fonts on web pages.&lt;/li&gt;&#xA;&lt;li&gt;Wikiwand - Wikipedia, and beyond : AI-driven wiki aggregator created to enhance user experience on Wikipedia by streamlining knowledge consumption&lt;/li&gt;&#xA;&lt;li&gt;Wordtune: AI Paraphrasing and Grammar Tool : Unlock your potential with Wordtune&amp;rsquo;s free AI writer – paraphrase, rewrite, translate, fix grammar, and more.&lt;/li&gt;&#xA;&lt;li&gt;You.com : Search, chat, and create with AI : Experience the future of search with generative AI&lt;/li&gt;&#xA;&lt;li&gt;YouTube Summary with ChatGPT &amp;amp; Claude : Summarize YouTube videos, web articles, and PDFs to save time, powered by ChatGPT, Claude, Mistral AI, and Gemini.&lt;/li&gt;&#xA;&lt;li&gt;Zotero Connector : Save references to Zotero from your web browser&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Best Resources to Learn Python</title>
      <link>http://localhost:1313/dsblog/best-resources-to-learn-python/</link>
      <pubDate>Sat, 10 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/best-resources-to-learn-python/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr110-Best-Resources-to-Learn-Python.jpg&#34; alt=&#34;Best Resources to Learn Python&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;best-resources-to-learn-python&#34;&gt;Best Resources to Learn Python&lt;/h1&gt;&#xA;&lt;h2 id=&#34;best-python-resources&#34;&gt;Best Python Resources&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learnpythonthehardway.org/book/&#34;&gt;Learn Python the Hard Way&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://anandology.com/python-practice-book/index.html&#34;&gt;Python Practice Book — Python Practice Book&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://inventwithpython.com/pygame/chapters/&#34;&gt;Making Games with Python &amp;amp; Pygame&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pythonprogramming.net/&#34;&gt;Python Programming Tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/jmportilla/&#34;&gt;Jupyter Notebook Viewer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/&#34;&gt;nbviewer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/github/jmportilla/Complete-Python-Bootcamp/blob/master/Final%20Capstone%20Projects/Final%20Capstone%20Project%20Ideas.ipynb&#34;&gt;Jupyter Notebook Viewer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/jmportilla/Complete-Python-Bootcamp/blob/master/Final%20Capstone%20Projects/Projects-Solutions/Solution%20Links.md&#34;&gt;Complete-Python-Bootcamp/Solution Links.md at master&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.python-guide.org/intro/learning/&#34;&gt;Learning Python – The Hitchhiker’s Guide to Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.python.org/3/library/index.html&#34;&gt;The Python Standard Library – Python 3.7.2 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/complete-python-bootcamp/learn/v4/t/lecture/9523126?start=0&#34;&gt;Complete Python Bootcamp: Go from zero to hero in Python 3 - Udemy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pymbook.readthedocs.io/en/latest/&#34;&gt;Welcome to Python for you and me&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://interactivepython.org/runestone/static/pythonds/index.html&#34;&gt;Problem Solving with Algorithms and Data Structures using Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://codingbat.com/python&#34;&gt;CodingBat Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wiki.python.org/moin/GuiProgramming&#34;&gt;GuiProgramming – Python Wiki&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.freecodecamp.org/news/the-10-most-popular-coding-challenge-websites-of-2016-fb8a5672d22f/&#34;&gt;The 10 most popular coding challenge websites for 2017&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.learnpython.org/&#34;&gt;Learn Python – Free Interactive Python Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.python.org/&#34;&gt;Welcome to Python.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.python.org/3/library/functions.html#dir&#34;&gt;Built-in Functions — Python 3.7.3 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.learnpython.org/en/Hello,_World!&#34;&gt;Hello, World! – Learn Python – Free Interactive Python Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.python.org/3/tutorial/&#34;&gt;The Python Tutorial — Python 3.7.3 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2015/11/quick-introduction-boosting-algorithms-machine-learning/&#34;&gt;Quick Guide to Boosting Algorithms in Machine Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/&#34;&gt;Analytics Community - Analytics Discussions - Big Data Discussion&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://data-flair.training/blogs/python-tutorials-home/&#34;&gt;Learn Python – Python Tutorials – DataFlair&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;best-numpy-resources&#34;&gt;Best Numpy Resources&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/993984/what-are-the-advantages-of-numpy-over-regular-python-lists&#34;&gt;arrays – What are the advantages of NumPy over regular Python lists? – Stack Overflow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/8385602/why-are-numpy-arrays-so-fast&#34;&gt;python – Why are NumPy arrays so fast? – Stack Overflow&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/&#34;&gt;Numpy and Scipy Documentation – Numpy and Scipy documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.numpy.org/&#34;&gt;NumPy – NumPy&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/doc/numpy/&#34;&gt;Overview – NumPy v1.16 Manual&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;best-pandas-resources&#34;&gt;Best Pandas Resources&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;pandas&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/reference/frame.html&#34;&gt;DataFrame – pandas 0.24.2 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html&#34;&gt;Merge, join, and concatenate — pandas 0.24.2 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/reference/series.html#plotting&#34;&gt;Series – pandas 0.24.2 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stattrek.com/online-calculator/binomial.aspx&#34;&gt;Binomial Probability Calculator&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/pandas-docs/stable/reference/series.html#indexing-iteration&#34;&gt;Series – pandas 0.24.2 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blogs.baruch.cuny.edu/cis3100/?p=56&#34;&gt;Reshaping in Pandas – Pivot, Pivot-Table, Stack and Unstack explained with Pictures – Python / C++&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://etav.github.io/python/count_basic_freq_plot.html&#34;&gt;Counting and Basic Frequency Plots – Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;python-visualization-resources&#34;&gt;Python Visualization Resources&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://seaborn.pydata.org/api.html&#34;&gt;Seaborn&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/rougier/matplotlib-tutorial&#34;&gt;rougier/matplotlib-tutorial: Matplotlib tutorial for beginner&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/a-step-by-step-guide-for-creating-advanced-python-data-visualizations-with-seaborn-matplotlib-1579d6a1a7d0&#34;&gt;A step-by-step guide for creating advanced Python data visualizations with Seaborn / Matplotlib&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://matplotlib.org/users/pyplot_tutorial.html&#34;&gt;Pyplot tutorial — Matplotlib 2.0.2 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.analyticsvidhya.com/blog/2017/02/top-28-cheat-sheets-for-machine-learning-data-science-probability-sql-big-data/&#34;&gt;Top 28 Cheat Sheets for Machine Learning, Data Science, Probability, SQL &amp;amp; Big Data&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;other-resources&#34;&gt;Other Resources&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datahack.analyticsvidhya.com/contest/all/&#34;&gt;Contests - Analytics Vidhya&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html#loading-the-20-newsgroups-dataset&#34;&gt;Working With Text Data — scikit-learn 0.20.3 documentation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.w3schools.com/python/python_regex.asp&#34;&gt;Python RegEx&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.guru99.com/python-regular-expressions-complete-tutorial.html&#34;&gt;Python Regex: re.match(), re.search(), re.findall() with Example&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/FakeNewsDetection/FakeBuster&#34;&gt;FakeNewsDetection/FakeBuster: Fake News Detection with Machine Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;websites-to-learn-python&#34;&gt;Websites to learn Python&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://interactivepython.org/&#34;&gt;https://interactivepython.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://inventwithpython.com/&#34;&gt;https://inventwithpython.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://numpy.org/&#34;&gt;https://numpy.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;https://pandas.pydata.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://analyticsvidhya.com/&#34;&gt;https://analyticsvidhya.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://anandology.com/&#34;&gt;https://anandology.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blogs.baruch.cuny.edu/&#34;&gt;https://blogs.baruch.cuny.edu&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://codingbat.com/&#34;&gt;https://codingbat.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://data-flair.training/&#34;&gt;https://data-flair.training&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://datahack.analyticsvidhya.com/&#34;&gt;https://datahack.analyticsvidhya.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.python.org/&#34;&gt;https://docs.python.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.python-guide.org/&#34;&gt;https://docs.python-guide.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.scipy.org/&#34;&gt;https://docs.scipy.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://etav.github.io/&#34;&gt;https://etav.github.io&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://freecodecamp.org/&#34;&gt;https://freecodecamp.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/&#34;&gt;https://github.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://guru99.com/&#34;&gt;https://guru99.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learnpython.org/&#34;&gt;https://learnpython.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learnpythonthehardway.org/&#34;&gt;https://learnpythonthehardway.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://matplotlib.org/&#34;&gt;https://matplotlib.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nbviewer.jupyter.org/&#34;&gt;https://nbviewer.jupyter.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pandas.pydata.org/&#34;&gt;https://pandas.pydata.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pymbook.readthedocs.io/&#34;&gt;https://pymbook.readthedocs.io&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://python.org/&#34;&gt;https://python.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://pythonprogramming.net/&#34;&gt;https://pythonprogramming.net&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://scikit-learn.org/&#34;&gt;https://scikit-learn.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://seaborn.pydata.org/&#34;&gt;https://seaborn.pydata.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/&#34;&gt;https://stackoverflow.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://stattrek.com/&#34;&gt;https://stattrek.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://towardsdatascience.com/&#34;&gt;https://towardsdatascience.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://udemy.com/&#34;&gt;https://udemy.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://w3schools.com/&#34;&gt;https://w3schools.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://wiki.python.org/&#34;&gt;https://wiki.python.org&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>AI, ML, Deep Learning, NLP Conferences &amp; Journals</title>
      <link>http://localhost:1313/dsblog/ai-ml-dl-nlp-conferences/</link>
      <pubDate>Thu, 08 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ai-ml-dl-nlp-conferences/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr108-AI-ML-Deep-Learning-NLP-Conferences-Journals.jpg&#34; alt=&#34;AI, ML, Deep Learning, NLP Conferences &amp;amp; Journals&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-ml-deep-learning-nlp-conferences--journals&#34;&gt;AI, ML, Deep Learning, NLP Conferences &amp;amp; Journals&lt;/h1&gt;&#xA;&lt;p&gt;&lt;strong&gt;Content on this page keeps changing. These links are taken from my chrome browser favorites.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;A list of 30+ AI conferences and journals related to AI, NLP, Deep Learning. Almost all major happening in the world of AI/ML is presented in these conferences and published in these magazines.&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.aaai.org/&#34;&gt;AAAI – Association for the Advancement of Artificial Intelligence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://celweb.vuse.vanderbilt.edu/aamas18/&#34;&gt;AAMAS – International Joint Conference on Autonomous Agents and Multiagent Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.aclweb.org/portal/&#34;&gt;ACL Member Portal – The Association for Computational Linguistics Member Portal&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sigdat.org/&#34;&gt;ACL SIGDAT – SIGDAT&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://arxiv.org/list/cs.LG/recent&#34;&gt;ArXiv: Machine Learning - Authors and titles for recent submissions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.aaai.org/&#34;&gt;Association for the Advancement of Artificial Intelligence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;CIKM (ACM Conference on Information and Knowledge Management)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikiwand.com/en/Conference_on_Neural_Information_Processing_Systems&#34;&gt;Conference on Neural Information Processing Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.signll.org/conll/&#34;&gt;CoNLL – SIGNLL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cvpr2018.thecvf.com/&#34;&gt;CVPR – IEEE Conference on Computer Vision and Pattern Recognition&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;CVPR (IEEE Conference on Computer Vision and Pattern Recognition)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://eacl.org/&#34;&gt;EACL: European Chapter of the Association for Computational Linguistics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ECCV (European Conference on Computer Vision)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ecmlpkdd2018.org/&#34;&gt;ECML – European Conference on Machine Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://2020.emnlp.org/&#34;&gt;EMNLP 2020&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://iccv2017.thecvf.com/&#34;&gt;ICCV – International Conference on Computer Vision&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.waset.org/conference/2018/07/istanbul/ICDM&#34;&gt;ICDM – International Conference on Data Mining&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;ICLR (International Conference on Learning Representations)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikiwand.com/en/International_Conference_on_Machine_Learning&#34;&gt;ICML – International Conference on Machine Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ijcai-18.org/&#34;&gt;IJCAI – International Joint Conference on Artificial Intelligence&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ijcse.com/aim-and-scope.html&#34;&gt;Indian journal of Computer Science and Engineering&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.degruyter.com/view/journals/stuf/18/1-6/article-p589.xml&#34;&gt;International Conference on Computational Linguistics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikicfp.com/cfp/servlet/event.showcfp?eventid=98130&amp;amp;copyownerid=52097&#34;&gt;International Conference on Data Mining&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikiwand.com/en/Journal_of_Machine_Learning_Research&#34;&gt;JMLR (Journal of Machine Learning Research)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kdd.org/kdd2018/&#34;&gt;KDD – Knowledge Discovery and Data Mining&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.mitpressjournals.org/loi/coli&#34;&gt;List of Issues – Computational Linguistics – MIT Press Journals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lrec-conf.org/&#34;&gt;LREC Conferences&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikiwand.com/en/Machine_Learning_%28journal%29&#34;&gt;Machine Learning Journal&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://montrealaisymposium.wordpress.com/&#34;&gt;MAIS – Montreal AI Symposium&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;MOBICOM (International Conference on Mobile Computing and Networking)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://naacl.org/&#34;&gt;NAACL: North American Chapter of the ACL (Association for Computational Linguistics)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nips.cc/&#34;&gt;Neural IPS&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nips.cc/Conferences/2018&#34;&gt;NIPS – Neural Information Processing Systems&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://conferences.oreilly.com/artificial-intelligence/ai-ny&#34;&gt;O’Reilly AI Conference – O’Reilly Artificial Intelligence Conference&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;SIGCOMM (ACM Special Interest Group on Data Communications)&lt;/li&gt;&#xA;&lt;li&gt;SIGGRAPH (ACM Special Interest Group on Computer Graphics and Interactive Techniques)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://sigir.org/&#34;&gt;SIGIR – Special Interest Group on Information Retrieval&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;SIGMOD (ACM Special Interest Group on Management of Data)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://link.springer.com/journal/11760/volumes-and-issues&#34;&gt;Signal, Image and Video Processing: Springer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://transacl.org/index.php/tacl/issue/view/17&#34;&gt;Transactions of the Association for Computational Linguistics&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.wikicfp.com/cfp/&#34;&gt;WikiCFP : Call For Papers of Conferences, Workshops and Journals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Best YouTube Channels to Learn Data Science</title>
      <link>http://localhost:1313/dsblog/best-youtube-channels-for-ds/</link>
      <pubDate>Wed, 07 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/best-youtube-channels-for-ds/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr107-Best-YouTube-Channels-to-Learn-Data-Science.jpg&#34; alt=&#34;Best YouTube Channels to Learn Data Science&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;best-youtube-channels-to-learn-data-science&#34;&gt;Best YouTube Channels to Learn Data Science&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;The way we are learning new technologies has hugely changed in the last 5 years. Many educators, researchers, voices for quality education for all have come to create their educational videos and share those with community members, peers, and learners from industries. Many subjects and topics like Data Science, Artificial Intelligence, Machine Learning, Deep Learning, Reinforcement Learning have gained has huge popularity in the market because they have brought disruption in the existing businesses and knowledge is openly available in the market. If you have time and money, then it makes sense to join some full-time or part-time course from some good university and learn these subjects systematically in depth and detail. But, if time or/and money is the issue, and you know what you want to learn, then there are many YouTube channels. From there you can learn everything you need to become a good ML Engineer, Data Scientist, Data Engineer, DL Engineer, NLP Engineer, etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>High School Maths for Data Science</title>
      <link>http://localhost:1313/dsblog/high-school-maths-for-ds/</link>
      <pubDate>Tue, 06 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/high-school-maths-for-ds/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr106-High-School-Maths-for-Data-Science.jpg&#34; alt=&#34;High School Maths for Data Science&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;high-school-maths-for-data-science&#34;&gt;High School Maths for Data Science&lt;/h1&gt;&#xA;&lt;h2 id=&#34;algebra-i&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/algebra-i&#34;&gt;Algebra I&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-graph-an-ordered-pair&#34;&gt;How to graph an ordered pair&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-equation-of-a-circle&#34;&gt;How to find the equation of a circle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-equation-of-a-curve&#34;&gt;How to find the equation of a curve&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-x-or-y-intercept&#34;&gt;How to find x or y intercept&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-endpoints-of-a-line-segment&#34;&gt;How to find the endpoints of a line segment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-a-line-with-distance-formula&#34;&gt;How to find the length of a line with distance formula&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-midpoint-of-a-line-segment&#34;&gt;How to find the midpoint of a line segment&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-out-if-lines-are-parallel&#34;&gt;How to find out if lines are parallel&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-equation-of-a-parallel-line&#34;&gt;How to find the equation of a parallel line&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-slope-of-parallel-lines&#34;&gt;How to find the slope of parallel lines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-out-if-lines-are-perpendicular&#34;&gt;How to find out if lines are perpendicular&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-equation-of-a-perpendicular-line&#34;&gt;How to find the equation of a perpendicular line&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-slope-of-a-perpendicular-line&#34;&gt;How to find the slope of a perpendicular line&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;algebra-ii&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/algebra-ii&#34;&gt;Algebra II&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/setting-up-equations&#34;&gt;Setting up Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Simplifying Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Setting up Expressions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Simplifying Expressions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Inequalities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Direct Proportionality&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Indirect Proportionality&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Mean, Median, and Mode&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Range&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Normal Distributions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Z-Scores&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Identifying Variables and Relationships&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using Box and Whisker Plots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using Scatter Plots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Quartiles and Percentiles&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Standard Deviation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Variance&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Domain and Range&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Functional Notations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Inverse Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Transformation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Graphing Linear Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Transformations of Linear Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Vertical and Horizontal Lines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Transformations of Polynomial Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Polynomial Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Finding the Center and Radius&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Graphing Circle Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Circle Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Parabolic Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Factoring Polynomials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Simplifying Polynomials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Non-Quadratic Polynomials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Polynomials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Completing the Square&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Finding Roots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Quadratic Inequalities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using the Quadratic Formula&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Simplifying and Expanding Quadratic Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Quadratic Roots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding the Discriminant&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using FOIL&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Simplifying Rational Expressions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Rational Equations and Inequalities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Rational Expressions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Graphing Absolute Value&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Absolute Value Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Absolute Value&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Addition and Subtraction&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Multiplication and Division&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Distributing Exponents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Multiplying and Dividing Exponents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Graphing Exponential Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Exponential Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Asymptotes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Fractional Exponents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Negative Exponents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Multiplying and Dividing Factorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Factorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Imaginary and Complex Numbers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using Expressions with Complex Numbers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Multiplying and dividing Logarithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using Logarithms with Exponents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Logarithmic Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using Natural Log and Log-Base-10&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Factoring Radicals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Using Radicals with Elementary Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Solving Radical Equations and Inequalities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Expressing Radicals as Exponents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Square Roots&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Arithmetic Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Geometric Sequences&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Sequences&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Number Lines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Number Sets&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/simplifying-equations&#34;&gt;Understanding Real Numbers&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;calculus-i--derivatives&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/calculus-i-derivatives&#34;&gt;Calculus I — Derivatives&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-concavity-and-convexity&#34;&gt;Finding Regions of Concavity and Convexity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Finding Regions of Increasing and Decreasing Value&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Finding Derivative at a Point&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Finding Derivative of a Function&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Finding Second Derivative of a Function&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Using the Chain Rule&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Understanding Derivatives of Exponents&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Understanding Derivatives of Sums, Quotients, and Products&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Understanding Derivatives of Trigonometric Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Using Implicit Differentiation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Conceptualizing Derivatives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Understanding Integrals of Sums, Quotients, and Products&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Calculating Limits&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Identifying Absolute and Local Extrema&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-regions-of-increasing-and-decreasing-value&#34;&gt;Identifying Slope at a Point&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;calculus-ii--integrals&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/calculus-ii-integrals&#34;&gt;Calculus II — Integrals&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/finding-first-and-second-derivatives&#34;&gt;Finding First and Second Derivatives&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Understanding L’Hospital’s Rule&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Finding Definite Integrals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Finding Indefinite Integrals&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Finding Integrals by Substitution&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Using Limits with Continuity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Understanding Polar Coordinates&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Understanding Vector Calculations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Understanding Vector Coordinates&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Applying Taylor Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Understanding Maclaurin Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-l-hospital-s-rule&#34;&gt;Understanding Taylor Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;geometry&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/geometry&#34;&gt;Geometry&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-angle-of-clock-hands&#34;&gt;How to find the angle of clock hands&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the diameter&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the ratio of diameter and circumference&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find circumference&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a circle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of a radius&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the angle for a percentage of a circle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the angle of a sector&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a sector&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of an arc&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the percentage of a sector from an angle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in a hexagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a hexagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the diagonal of a hexagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a hexagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle of a line&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in a polygon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a polygon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of a side of a polygon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a polygon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in a pentagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a pentagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the diagonal of a pentagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of a pentagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a pentagon&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a kite&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of kite&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find if quadrilaterals are similar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in a parallelogram&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a parallelogram&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a parallelogram&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find if rectangles are similar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a rectangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the diagonal of a rectangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of a rectangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a rectangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find if rhombuses are similar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a rhombus&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a rhombus&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a square&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the diagonal of a square&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of a square&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a square&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in a trapezoid&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a trapezoid&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of a trapezoid&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a trapezoid&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in an acute / obtuse triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find if two acute / obtuse triangles are similar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of an acute / obtuse triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the height of an acute / obtuse triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the hypotenuse of an acute / obtuse triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of an acute / obtuse triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of an acute / obtuse triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of an equilateral triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the height of an equilateral triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of an equilateral triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of an equilateral triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a 45/45/90 right isosceles triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the hypotenuse of a 45/45/90 right isosceles triangle : Pythagorean Theorem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of a 45/45/90 right isosceles triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a 45/45/90 right isosceles triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in an acute / obtuse isosceles triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the height of of an acute / obtuse isosceles triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of of an acute / obtuse isosceles triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of an acute / obtuse isosceles triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find an angle in a right triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find if right triangles are similar&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the area of a right triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the hypotenuse of a right triangle : Pythagorean Theorem&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the length of the side of a right triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-length-of-the-diameter&#34;&gt;How to find the perimeter of a right triangle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;solid-geometry&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/geometry/solid-geometry&#34;&gt;Solid Geometry&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-surface-area-of-a-cone&#34;&gt;How to find the surface area of a cone&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the volume of a cone&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the diagonal of a cube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the length of an edge of a cube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the surface area of a cube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the volume of a cube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the surface area of a cylinder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the volume of a cylinder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the length of an edge of a prism&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the surface area of a prism&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the volume of a prism&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the surface area of a polyhedron&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the volume of a polyhedron&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the surface area of a pyramid&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the volume of a pyramid&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the diameter of a sphere&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the radius of a sphere&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the surface area of a sphere&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-find-the-volume-of-a-cone&#34;&gt;How to find the volume of a sphere&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;pre-algebra&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/pre-algebra&#34;&gt;Pre-Algebra&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-decimals-in-pre-algebra&#34;&gt;How to solve one-step equations with decimals in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to solve one-step equations with fractions in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to solve one-step equations with integers in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to solve two-step equations with decimals in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to solve two-step equations with fractions in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to solve two-step equations with integers in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to write an algebraic equation in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to do word problems where one quantity is unknown&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to do word problems where two quantities are unknown&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the area of a circle in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the area of a parallelogram in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the area of a rectangle in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the area of a square in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the area of a triangle in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the circumference of a circle in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the perimeter of a rectangle in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the perimeter of a square in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the perimeter of a triangle in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the volume of a cone in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the volume of a cylinder in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the volume of a pyramid in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the volume of a rectangular solid in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to find the volume of a sphere in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to graph a line in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to graph a point in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to identify a point in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to add and subtract integers in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to combine like terms with negative numbers in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to compare integers in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to define integers in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to do absolute value in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to multiply and divide integers in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to add and subtract polynomials in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to divide polynomials in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to use the power rule for exponents in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to use the product rule for exponents in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to multiply polynomials in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to solve a polynomial in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to combine like terms in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to do exponents in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to use the distributive property in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/how-to-solve-one-step-equations-with-fractions-in-pre-algebra&#34;&gt;How to use the order of operations in pre-algebra&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;pre-calculus&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/pre-calculus&#34;&gt;Pre-Calculus&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/solving-circle-functions&#34;&gt;Solving Circle Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Graphing Ellipses&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Graphing Hyperbolas&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Solving Hyperbola Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Graphing Parabolic Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Solving Parabola Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Simplifying Exponential Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Simplifying Logarithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Solving Logarithms&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Asymptotes&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Domain and Range&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Maxima and Minima&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Symmetries&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Zeros of a Polynomial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Simplifying Polynomial Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Understanding Zeros of a Polynomial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Limits&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Limits as X Approaches Infinity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding One-Sided Limits&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Understanding the Definition of Limits&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Partial Sums in a Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Sums of Infinite Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Finding Terms in a Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Understanding Arithmetic and Geometric Series&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/graphing-ellipses&#34;&gt;Using Sigma Notation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;trigonometry&#34;&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/trigonometry&#34;&gt;Trigonometry&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles&#34;&gt;Understanding Angles&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Angles in Different Quadrants&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Complementary and Suplmentary Angles&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Coterminal Angles&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Angles in the Unit Circle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Radians and Conversions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Using the Unit Circle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Applying the Law of Cosines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Applying the Law of Sines&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Applying Trigonometric Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding 30-60-90 Triangles&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Finding Sides&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Solving Trigonometric Equations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Simplifying Trigonometric Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Trigonometric Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Period and Amplitude&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Using Basic and Definitional Identities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Using Identities of Inverse Operations&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Using Identities of Squared Functions&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Using Pythagorean Identities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Using Sum and Product Identities&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Arcsine, Arccosine, and Arctangent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Secant, Cosecant, and Cotangent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.varsitytutors.com/high_school_math-help/understanding-angles-in-different-quadrants&#34;&gt;Understanding Sine, Cosine, and Tangent&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Important AI Research Papers</title>
      <link>http://localhost:1313/dsblog/important-ai-research-papers/</link>
      <pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/important-ai-research-papers/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr105-Important-AI-Research-Papers.jpg&#34; alt=&#34;Important AI Research Papers&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;important-ai-research-papers&#34;&gt;Important AI Research Papers&lt;/h1&gt;&#xA;&lt;p&gt;Content from this page is migrated to &lt;a href=&#34;https://dasarpai.com/dsblog/select-ai-papers&#34;&gt;Link&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Mathematics for Data Scientist</title>
      <link>http://localhost:1313/dsblog/maths-for-ds/</link>
      <pubDate>Sun, 04 Jul 2021 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/maths-for-ds/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr104-Mathematics-for-Data-Scientist.jpg&#34; alt=&#34;Mathematics for Data Scientist&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;mathematics-for-data-scientist&#34;&gt;Mathematics for Data Scientist&lt;/h1&gt;&#xA;&lt;p&gt;To excel in the field of data science, especially as a data scientist, I would recommend you have good command over the topics mentioned below. These are the topics from mathematics and statistics. There are many YouTube channels that you can use for this purpose. Because this is 10+2 level mathematics, and it is just a matter of revision. So I am not offering any course unless there is a specific need for some group, organization.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How Naive Bayes Classifier Works</title>
      <link>http://localhost:1313/dsblog/How-Naive-Bayes-Classifier-Works/</link>
      <pubDate>Wed, 31 Mar 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/How-Naive-Bayes-Classifier-Works/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6005-How-Naive-Bayes-Work-for-Recommendation.jpg&#34; alt=&#34;Naive Bayes&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;how-naive-bayes-classifier-works&#34;&gt;How Naive Bayes Classifier Works?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;naive-bayes-classifier-example&#34;&gt;Naive Bayes classifier example&lt;/h2&gt;&#xA;&lt;p&gt;In this presentation, I am not going into the depth of the Naive Bayes algorithm. I am assuming you have heard this term many times but are not able to visualize it mentally or struggling to comprehend this. If that is the case, then you are on the right page.&lt;/p&gt;&#xA;&lt;p&gt;How does Naive Bayes Classifier work in Machine Learning? There are many good explanations, many ways to explain the conditional probability formula but many times even after many reading, and memorizing the formula it does not help. In this presentation, I am trying to explain How the Naive Bayes Classifier works with a simple example and calculations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Top 10 Technologies of Future</title>
      <link>http://localhost:1313/dsblog/Top-10-Technologies-of-Future/</link>
      <pubDate>Thu, 04 Mar 2021 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Top-10-Technologies-of-Future/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6004-Top-10-Future-Technologies.jpg&#34; alt=&#34;Future Technologies&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;top-10-technologies-of-future&#34;&gt;Top 10 Technologies of Future&lt;/h1&gt;&#xA;&lt;h2 id=&#34;augmented-reality-&#34;&gt;Augmented Reality :&lt;/h2&gt;&#xA;&lt;p&gt;Helps surgeons see inside their patients&lt;br&gt;&#xA;Help workers operating in dangerous conditions&lt;/p&gt;&#xA;&lt;h2 id=&#34;lab-grown-meat-to-save-the-environment&#34;&gt;Lab-Grown Meat: To save the environment&lt;/h2&gt;&#xA;&lt;p&gt;Address the ethical issues raised by industrial farming&lt;/p&gt;&#xA;&lt;h2 id=&#34;quantum-computers&#34;&gt;Quantum Computers:&lt;/h2&gt;&#xA;&lt;p&gt;Using quantum mechanics to make calculations. These computers are many thousand times faster than our today’s computers.&lt;/p&gt;&#xA;&lt;h2 id=&#34;plasmonic-materials-light-controlled-nanomaterial&#34;&gt;Plasmonic Materials: Light controlled nanomaterial&lt;/h2&gt;&#xA;&lt;p&gt;Cure invisible cloak, nano-particles to kill cancer.&lt;/p&gt;&#xA;&lt;h2 id=&#34;super-advance-personal-assitant&#34;&gt;Super Advance Personal Assitant.&lt;/h2&gt;&#xA;&lt;p&gt;Experts are feeling that you can do ethical debates with digital helpers.&lt;/p&gt;</description>
    </item>
    <item>
      <title>EDA &amp; Feature Engineering 101</title>
      <link>http://localhost:1313/dsblog/EDA-Feature-Engineering-101/</link>
      <pubDate>Mon, 24 Aug 2020 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/EDA-Feature-Engineering-101/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6008-EDA101.jpg&#34; alt=&#34;EDA &amp;amp; Feature Engineering&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-is-eda&#34;&gt;What is EDA?&lt;/h2&gt;&#xA;&lt;p&gt;EDA means Exploratory Data Analysis. The purpose of data analysis is to explore. Exploration means try to understand what kind of data I have in my hand. Using EDA we try to get the answer to the following questions.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What kind of data is this? (file format, volume of data, number of columns, metadata data of image/video/audio or some feedback in English or other languages, or tabular data, etc)&lt;/li&gt;&#xA;&lt;li&gt;How complex is this data? (How many files are there? primary key? how these files are connected to each other? is nested data in some files? is some field having nested data, etc.)&lt;/li&gt;&#xA;&lt;li&gt;Is this data sufficient for meeting our ultimate goal, i.e. Model building?&lt;/li&gt;&#xA;&lt;li&gt;Is there any missing data? Data needed but not given by the business or not available at all or costly to get that data etc.&lt;/li&gt;&#xA;&lt;li&gt;Are there any missing values? In the given dataset do we have complete information or some values are missing for some records or some columns?&lt;/li&gt;&#xA;&lt;li&gt;What are different independent and dependent fields?&lt;/li&gt;&#xA;&lt;li&gt;Is there any relationship between different independent variables of the dataset? If yes then how strong is that relationship?&lt;/li&gt;&#xA;&lt;li&gt;Are observations independent or tightly coupled like we see in time-series data?&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;In the data scient project lifecycle, EDA is not a sequential, one-time, isolated process. Till the time data is not ready for modeling we keep doing EDA and cleaning the data. So, EDA is followed by a list of decisions taken to clean the dataset, and finally, data cleaning steps are implemented. If the dataset is not in the good shape after the first iteration of EDA we continue EDA in the next cycle. In this article, I am not referring to EDA as just visualizing and understanding the dataset but all the steps required till the dataset is not ready for modeling.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Science Interview Question Answers</title>
      <link>http://localhost:1313/dsblog/ds-ai-ml-interview-resources/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ds-ai-ml-interview-resources/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr102-Data-Science-Interview-Question-Answers.jpg&#34; alt=&#34;Data Science Interview Question Answers&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;data-science-interview-question-answers&#34;&gt;Data Science Interview Question Answers&lt;/h1&gt;&#xA;&lt;p&gt;Thousands of interview questions on various topic related to Machine Learning, Deep Learning, Computer Vision, NLP, AWS, GCP, MLOPS, Data Analytics, SQL, Python &amp;amp; Statistics. These questions are related to technology, architectures and solving business problem. &lt;a href=&#34;https://drive.google.com/drive/folders/1O9DcVhE5r0lBPpZd8bFjaA0FqPv94Vbm?usp=sharing&#34;&gt;This gdrive link&lt;/a&gt; has 51 pdf files which contains the questions and answers.&lt;/p&gt;&#xA;&lt;h2 id=&#34;interview-question-answers&#34;&gt;Interview Question Answers&lt;/h2&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno&lt;/th&gt;&#xA;          &lt;th&gt;Book&lt;/th&gt;&#xA;          &lt;th&gt;Pages&lt;/th&gt;&#xA;          &lt;th&gt;Size(MB)&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;10 Interview Puzzle-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;0.295&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;100+NLP_QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;0.237&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;1001+Data Engineering-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;0.202&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;100_data_engineering_questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;58&lt;/td&gt;&#xA;          &lt;td&gt;9.001&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;120+Data Science Interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;0.374&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;150+Data_Science_Interview_QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;54&lt;/td&gt;&#xA;          &lt;td&gt;1.76&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;164-Data_Science_Interview_QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;111&lt;/td&gt;&#xA;          &lt;td&gt;17.595&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;20 Coding Patterns to master Tech in-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;          &lt;td&gt;4.053&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;200+Questions-Requirement-Gathering-Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;0.409&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;          &lt;td&gt;200+Tableau_Interview_QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;69&lt;/td&gt;&#xA;          &lt;td&gt;1.541&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;21+Data Science Questions that you must know-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;2.285&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;240-Cord-Java-Interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;0.49&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;25 Golden Rules for System Design-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;0.291&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;250+AWS-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;0.373&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;250+Big Data Engineering-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;189&lt;/td&gt;&#xA;          &lt;td&gt;1.496&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;27-Common-Job-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;0.586&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;17&lt;/td&gt;&#xA;          &lt;td&gt;301+Smart-answers-to-tough-interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;249&lt;/td&gt;&#xA;          &lt;td&gt;1.428&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;18&lt;/td&gt;&#xA;          &lt;td&gt;350+ML_DL_QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;0.127&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;40+Data Engineering QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;30&lt;/td&gt;&#xA;          &lt;td&gt;10.073&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;          &lt;td&gt;40+Python_QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;0.099&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;400+ JavaScript InterviewQA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;176&lt;/td&gt;&#xA;          &lt;td&gt;5.417&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;44-Deep Learning-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;0.633&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;450-DSA-Cracker-QA.pdf&lt;/td&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;0.527&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;24&lt;/td&gt;&#xA;          &lt;td&gt;50 MySQL Interview Questions-In2023-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;0.881&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;25&lt;/td&gt;&#xA;          &lt;td&gt;50+Data Structure-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;0.032&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;26&lt;/td&gt;&#xA;          &lt;td&gt;50+Machine Learning-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;0.255&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;          &lt;td&gt;50+ML Interview QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;0.096&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;50+OOPS Interview Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;0.293&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;29&lt;/td&gt;&#xA;          &lt;td&gt;60 Most Toughest Python InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;0.76&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;30&lt;/td&gt;&#xA;          &lt;td&gt;60+ SQL interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;0.479&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;31&lt;/td&gt;&#xA;          &lt;td&gt;64-Toghest-Interview-Question-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;0.396&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;32&lt;/td&gt;&#xA;          &lt;td&gt;800 Data Science Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;258&lt;/td&gt;&#xA;          &lt;td&gt;16.639&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;33&lt;/td&gt;&#xA;          &lt;td&gt;800+ SQL-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;92&lt;/td&gt;&#xA;          &lt;td&gt;1.024&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;A Beginner_s Guide to Getting your first Data Science Job-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;63&lt;/td&gt;&#xA;          &lt;td&gt;2.382&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;35&lt;/td&gt;&#xA;          &lt;td&gt;Advanced Data Analytics QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;26&lt;/td&gt;&#xA;          &lt;td&gt;1.282&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;36&lt;/td&gt;&#xA;          &lt;td&gt;Agile Interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;          &lt;td&gt;0.389&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;Apache Sparks Interview-QA-Guide-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;31&lt;/td&gt;&#xA;          &lt;td&gt;3.015&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;38&lt;/td&gt;&#xA;          &lt;td&gt;API Testing-QA.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;1.307&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;AWS Solution Architect Associate Exam Dumps.pdf&lt;/td&gt;&#xA;          &lt;td&gt;263&lt;/td&gt;&#xA;          &lt;td&gt;1.511&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;40&lt;/td&gt;&#xA;          &lt;td&gt;AWS Solution Architect Associate Practice Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;171&lt;/td&gt;&#xA;          &lt;td&gt;0.423&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;AWS SYSOPS Associate QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;187&lt;/td&gt;&#xA;          &lt;td&gt;0.526&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;42&lt;/td&gt;&#xA;          &lt;td&gt;AWS-Certified-Solutions-Architect-Associate.pdf&lt;/td&gt;&#xA;          &lt;td&gt;119&lt;/td&gt;&#xA;          &lt;td&gt;3.468&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;          &lt;td&gt;AWS-Solutions-Architect-Professional Exam Dumps.pdf&lt;/td&gt;&#xA;          &lt;td&gt;75&lt;/td&gt;&#xA;          &lt;td&gt;0.646&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;44&lt;/td&gt;&#xA;          &lt;td&gt;Azure Data Factory Interview Questions.pdf&lt;/td&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;Azure interview questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;0.966&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;46&lt;/td&gt;&#xA;          &lt;td&gt;BA Interview-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;17&lt;/td&gt;&#xA;          &lt;td&gt;0.078&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;Basics_Probability-MCQ-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;0.119&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;48&lt;/td&gt;&#xA;          &lt;td&gt;Behavioral Interview Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;29&lt;/td&gt;&#xA;          &lt;td&gt;3.373&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;49&lt;/td&gt;&#xA;          &lt;td&gt;BFSI BA Interview Questions and Answers-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;18&lt;/td&gt;&#xA;          &lt;td&gt;0.398&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;Coding Interview Preparation&amp;ndash;InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;100&lt;/td&gt;&#xA;          &lt;td&gt;0.892&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;51&lt;/td&gt;&#xA;          &lt;td&gt;Common-Job-Interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;0.586&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;52&lt;/td&gt;&#xA;          &lt;td&gt;Complete Interview-GUIDE.pdf&lt;/td&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;0.788&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;53&lt;/td&gt;&#xA;          &lt;td&gt;Comprehensive Guide  To Interviews For  Data Science-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;61&lt;/td&gt;&#xA;          &lt;td&gt;2.946&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;54&lt;/td&gt;&#xA;          &lt;td&gt;Computer Science-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;60&lt;/td&gt;&#xA;          &lt;td&gt;2.349&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;55&lt;/td&gt;&#xA;          &lt;td&gt;Continuous_Probability_Distributions-MCQ-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;0.135&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;56&lt;/td&gt;&#xA;          &lt;td&gt;Data Analytics Handbook for Big Data-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;30&lt;/td&gt;&#xA;          &lt;td&gt;0.862&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;57&lt;/td&gt;&#xA;          &lt;td&gt;Data Analytics Handbook for CEO_Managers-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;          &lt;td&gt;0.73&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;58&lt;/td&gt;&#xA;          &lt;td&gt;Data Analytics Handbook for DA_DS-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;32&lt;/td&gt;&#xA;          &lt;td&gt;0.709&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;59&lt;/td&gt;&#xA;          &lt;td&gt;Data Analytics Handbook for Researchers_Academics-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;36&lt;/td&gt;&#xA;          &lt;td&gt;0.731&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;60&lt;/td&gt;&#xA;          &lt;td&gt;Data Engineering-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;126&lt;/td&gt;&#xA;          &lt;td&gt;0.933&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;61&lt;/td&gt;&#xA;          &lt;td&gt;Data Science Guide-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;75&lt;/td&gt;&#xA;          &lt;td&gt;4.429&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;62&lt;/td&gt;&#xA;          &lt;td&gt;Data science interview inuron-DAY02-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;1.575&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;63&lt;/td&gt;&#xA;          &lt;td&gt;Data science interview Questions-by-Akash-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;1.059&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;64&lt;/td&gt;&#xA;          &lt;td&gt;Data Science Interview Questions-by-Steve-Nouri-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;257&lt;/td&gt;&#xA;          &lt;td&gt;13.805&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;65&lt;/td&gt;&#xA;          &lt;td&gt;Data Science Interview Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;257&lt;/td&gt;&#xA;          &lt;td&gt;13.805&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;66&lt;/td&gt;&#xA;          &lt;td&gt;Data Science Interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;0.227&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;67&lt;/td&gt;&#xA;          &lt;td&gt;Data Science-QA-for-Interview-practice-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;0.636&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;68&lt;/td&gt;&#xA;          &lt;td&gt;Data_Science_Interview_Ques_company_wise-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;0.199&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;69&lt;/td&gt;&#xA;          &lt;td&gt;Deep Learning Interview Preparation .pdf&lt;/td&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;1.481&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;70&lt;/td&gt;&#xA;          &lt;td&gt;Deep Learning Interview Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;401&lt;/td&gt;&#xA;          &lt;td&gt;15.083&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;71&lt;/td&gt;&#xA;          &lt;td&gt;Deep Learning-Interview Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;0.64&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;72&lt;/td&gt;&#xA;          &lt;td&gt;Deep-Learning-Interviews-Problem-Solutions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;202&lt;/td&gt;&#xA;          &lt;td&gt;13.472&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;73&lt;/td&gt;&#xA;          &lt;td&gt;DevOps Interview -1.pdf&lt;/td&gt;&#xA;          &lt;td&gt;67&lt;/td&gt;&#xA;          &lt;td&gt;0.369&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;74&lt;/td&gt;&#xA;          &lt;td&gt;DevOps Interview Guide-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;5.102&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;75&lt;/td&gt;&#xA;          &lt;td&gt;DevOps-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;67&lt;/td&gt;&#xA;          &lt;td&gt;0.369&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;76&lt;/td&gt;&#xA;          &lt;td&gt;Devops-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;44&lt;/td&gt;&#xA;          &lt;td&gt;1.554&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;77&lt;/td&gt;&#xA;          &lt;td&gt;Devops-QA-SimpliLearn-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;4.634&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;78&lt;/td&gt;&#xA;          &lt;td&gt;Discrete_Probability_Distributions_QA-MCQ-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;0.13&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;79&lt;/td&gt;&#xA;          &lt;td&gt;Docker Interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;1.081&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;80&lt;/td&gt;&#xA;          &lt;td&gt;Docker Questions _ Answers-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;2.701&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;81&lt;/td&gt;&#xA;          &lt;td&gt;DS-Interview_presentation-InterviewQ.pptx&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;          &lt;td&gt;1.107&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;82&lt;/td&gt;&#xA;          &lt;td&gt;DSA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;6.277&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;83&lt;/td&gt;&#xA;          &lt;td&gt;Everything About Devops Questions-Answers format-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;222&lt;/td&gt;&#xA;          &lt;td&gt;1.908&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;84&lt;/td&gt;&#xA;          &lt;td&gt;Everything About Devops-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;222&lt;/td&gt;&#xA;          &lt;td&gt;1.908&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;85&lt;/td&gt;&#xA;          &lt;td&gt;Four Selected Topics in CV+DL-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;78&lt;/td&gt;&#xA;          &lt;td&gt;8.087&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;86&lt;/td&gt;&#xA;          &lt;td&gt;Google SDE P-2-Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;101&lt;/td&gt;&#xA;          &lt;td&gt;8.158&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;87&lt;/td&gt;&#xA;          &lt;td&gt;Hottest Data Analyst Interview Questions .pdf&lt;/td&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;1.944&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;88&lt;/td&gt;&#xA;          &lt;td&gt;How to Ace Faang-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;24&lt;/td&gt;&#xA;          &lt;td&gt;1.659&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;89&lt;/td&gt;&#xA;          &lt;td&gt;How to Answer the 64 Toughest Interview Question-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;0.396&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;90&lt;/td&gt;&#xA;          &lt;td&gt;HR_Behavioral_Interview_Questions-InterviewBit-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;2.791&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;91&lt;/td&gt;&#xA;          &lt;td&gt;Import Python interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;56&lt;/td&gt;&#xA;          &lt;td&gt;0.254&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;92&lt;/td&gt;&#xA;          &lt;td&gt;Interview questions on PySpark-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;126&lt;/td&gt;&#xA;          &lt;td&gt;1.283&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;93&lt;/td&gt;&#xA;          &lt;td&gt;Interview Questions.pdf&lt;/td&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;0.374&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;94&lt;/td&gt;&#xA;          &lt;td&gt;Interviews_with_15_data_scientists-REPORT.pdf&lt;/td&gt;&#xA;          &lt;td&gt;146&lt;/td&gt;&#xA;          &lt;td&gt;2.932&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;95&lt;/td&gt;&#xA;          &lt;td&gt;Intuitive explanations to Data Science Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;0.192&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;96&lt;/td&gt;&#xA;          &lt;td&gt;Java Top 100 Interview questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;0.61&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;97&lt;/td&gt;&#xA;          &lt;td&gt;Java-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;0.82&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;98&lt;/td&gt;&#xA;          &lt;td&gt;Kubernetes_Backup_Recovery_FD-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;53&lt;/td&gt;&#xA;          &lt;td&gt;2.082&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;99&lt;/td&gt;&#xA;          &lt;td&gt;LASSO _ Ridge-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;0.235&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;100&lt;/td&gt;&#xA;          &lt;td&gt;LeetCode 50 Common Interview QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;100&lt;/td&gt;&#xA;          &lt;td&gt;1.607&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;101&lt;/td&gt;&#xA;          &lt;td&gt;Machine-Learning-A-Z-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;52&lt;/td&gt;&#xA;          &lt;td&gt;2.258&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;102&lt;/td&gt;&#xA;          &lt;td&gt;Management Consulting-Case Interview Workbook-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;177&lt;/td&gt;&#xA;          &lt;td&gt;0.892&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;103&lt;/td&gt;&#xA;          &lt;td&gt;Mastering the Data Science Interview Loop-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;0.49&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;104&lt;/td&gt;&#xA;          &lt;td&gt;Medium-Hard Data Analyst SQL-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;17&lt;/td&gt;&#xA;          &lt;td&gt;0.146&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;105&lt;/td&gt;&#xA;          &lt;td&gt;ML Interview Questions_8Ques-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;          &lt;td&gt;0.457&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;106&lt;/td&gt;&#xA;          &lt;td&gt;Most_common_interview_questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;0.074&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;107&lt;/td&gt;&#xA;          &lt;td&gt;Practitioners_guide_to_mlops_whitepaper-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;7.983&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;108&lt;/td&gt;&#xA;          &lt;td&gt;Python from InterviewBit-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;60&lt;/td&gt;&#xA;          &lt;td&gt;1.772&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;109&lt;/td&gt;&#xA;          &lt;td&gt;Remote-Jobs-Interview.pdf&lt;/td&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;1.939&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;110&lt;/td&gt;&#xA;          &lt;td&gt;Resumes and Cover Letters.pdf&lt;/td&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;1.44&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;111&lt;/td&gt;&#xA;          &lt;td&gt;Salesforce BA Interview Questions and Answers-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;0.406&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;112&lt;/td&gt;&#xA;          &lt;td&gt;Sampling_and_Sampling_Distributions-MCQ-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;          &lt;td&gt;0.236&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;113&lt;/td&gt;&#xA;          &lt;td&gt;Software-Engineering-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;1.582&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;114&lt;/td&gt;&#xA;          &lt;td&gt;SQL Interview Questions-Answers-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;51&lt;/td&gt;&#xA;          &lt;td&gt;1.285&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;115&lt;/td&gt;&#xA;          &lt;td&gt;SQL Interview Questions-InterviewQ (2).pdf&lt;/td&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;0.499&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;116&lt;/td&gt;&#xA;          &lt;td&gt;SQL Interview Questions-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;0.499&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;117&lt;/td&gt;&#xA;          &lt;td&gt;SQL-Most-asked-Questions.md&lt;/td&gt;&#xA;          &lt;td&gt;0&lt;/td&gt;&#xA;          &lt;td&gt;0.003&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;118&lt;/td&gt;&#xA;          &lt;td&gt;Stats+DS+ML+DL-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;169&lt;/td&gt;&#xA;          &lt;td&gt;10.1&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;119&lt;/td&gt;&#xA;          &lt;td&gt;TensorFlow_Examples_Notebookx_DrAngShu-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;0.212&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;120&lt;/td&gt;&#xA;          &lt;td&gt;The complete guide to the System Design Interview in 2022-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;4.964&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;121&lt;/td&gt;&#xA;          &lt;td&gt;The Ultimate Guide To SQL Interview Prep-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;          &lt;td&gt;1.712&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;122&lt;/td&gt;&#xA;          &lt;td&gt;The_Data_Science_Handbook-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;285&lt;/td&gt;&#xA;          &lt;td&gt;2.745&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;123&lt;/td&gt;&#xA;          &lt;td&gt;Three Fundamentals for CV+DL-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;56&lt;/td&gt;&#xA;          &lt;td&gt;6.171&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;124&lt;/td&gt;&#xA;          &lt;td&gt;Top 10 puzzles asked in interview-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;0.295&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;125&lt;/td&gt;&#xA;          &lt;td&gt;Top 100 interview questions on AI.pdf&lt;/td&gt;&#xA;          &lt;td&gt;186&lt;/td&gt;&#xA;          &lt;td&gt;2.651&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;126&lt;/td&gt;&#xA;          &lt;td&gt;Top 100 Interview Questions on Deep Learning.pdf&lt;/td&gt;&#xA;          &lt;td&gt;157&lt;/td&gt;&#xA;          &lt;td&gt;2.101&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;127&lt;/td&gt;&#xA;          &lt;td&gt;Top 100 SQL Interview QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;29&lt;/td&gt;&#xA;          &lt;td&gt;1.55&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;128&lt;/td&gt;&#xA;          &lt;td&gt;Top 40 Python Interview QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;0.093&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;129&lt;/td&gt;&#xA;          &lt;td&gt;Top Google Question-Part1-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;121&lt;/td&gt;&#xA;          &lt;td&gt;10.22&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;130&lt;/td&gt;&#xA;          &lt;td&gt;Top+50-Machine Learning Interview-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;0.107&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;131&lt;/td&gt;&#xA;          &lt;td&gt;Top-40-Python-QA-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;0.246&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;132&lt;/td&gt;&#xA;          &lt;td&gt;Top-80-Application and Information Security-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;33&lt;/td&gt;&#xA;          &lt;td&gt;11.011&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;133&lt;/td&gt;&#xA;          &lt;td&gt;Ultimate Guide to Data Science-InterviewQ.pdf&lt;/td&gt;&#xA;          &lt;td&gt;87&lt;/td&gt;&#xA;          &lt;td&gt;3.24&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>DS, AI, ML Online Course, Tutorial, Videos</title>
      <link>http://localhost:1313/dsblog/data-science-tutorial-video-resources/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/data-science-tutorial-video-resources/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr119-DS-AI-ML-Online-Course-Tutorial-Videos.jpg&#34; alt=&#34;DS, AI, ML Online Course, Tutorial, Videos&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ds-ai-ml-online-course-tutorial-videos&#34;&gt;DS, AI, ML Online Course, Tutorial, Videos&lt;/h1&gt;&#xA;&lt;h2 id=&#34;courses&#34;&gt;Courses&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://class.coursera.org/ml-005&#34;&gt;Machine Learning – Stanford&lt;/a&gt; by Andrew Ng in Coursera (2010-2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://work.caltech.edu/lectures.html&#34;&gt;Machine Learning – Caltech&lt;/a&gt; by Yaser Abu-Mostafa (2012-2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml&#34;&gt;Machine Learning – Carnegie Mellon&lt;/a&gt; by Tom Mitchell (Spring 2011)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://class.coursera.org/neuralnets-2012-001&#34;&gt;Neural Networks for Machine Learning&lt;/a&gt; by Geoffrey Hinton in Coursera (2012)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&#34;&gt;Neural networks class&lt;/a&gt; by Hugo Larochelle from Université de Sherbrooke (2013)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start&#34;&gt;Deep Learning Course&lt;/a&gt; by CILVR lab @ NYU (2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/courseware/&#34;&gt;A.I – Berkeley&lt;/a&gt; by Dan Klein and Pieter Abbeel (2013)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/&#34;&gt;A.I – MIT&lt;/a&gt; by Patrick Henry Winston (2010)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://web.mit.edu/course/other/i2course/www/vision_and_learning_fall_2013.html&#34;&gt;Vision and learning – computers and brains&lt;/a&gt; by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vision.stanford.edu/teaching/cs231n/syllabus.html&#34;&gt;Convolutional Neural Networks for Visual Recognition – Stanford&lt;/a&gt; by Fei-Fei Li, Andrej Karpathy (2017)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs224d.stanford.edu/&#34;&gt;Deep Learning for Natural Language Processing – Stanford&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://info.usherbrooke.ca/hlarochelle/neural_networks/content.html&#34;&gt;Neural Networks – usherbrooke&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/&#34;&gt;Machine Learning – Oxford&lt;/a&gt; (2014-2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/deep-learning-courses&#34;&gt;Deep Learning – Nvidia&lt;/a&gt; (2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA&#34;&gt;Graduate Summer School: Deep Learning, Feature Learning&lt;/a&gt; by Geoffrey Hinton, Yoshua Bengio, Yann LeCun, Andrew Ng, Nando de Freitas and several others @ IPAM, UCLA (2012)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/deep-learning--ud730&#34;&gt;Deep Learning – Udacity/Google&lt;/a&gt; by Vincent Vanhoucke and Arpan Chakraborty (2016)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE&#34;&gt;Deep Learning – UWaterloo&lt;/a&gt; by Prof. Ali Ghodsi at University of Waterloo (2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=azaLcvuql_g&amp;amp;list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r&#34;&gt;Statistical Machine Learning – CMU&lt;/a&gt; by Prof. Larry Wasserman&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm&#34;&gt;Deep Learning Course&lt;/a&gt; by Yann LeCun (2016)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLkFD6_40KJIxopmdJF_CLNqG3QuDFHQUm&#34;&gt;Designing, Visualizing and Understanding Deep Neural Networks-UC Berkeley&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://uvadlc.github.io/&#34;&gt;UVA Deep Learning Course&lt;/a&gt; MSc in Artificial Intelligence for the University of Amsterdam.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://selfdrivingcars.mit.edu/&#34;&gt;MIT 6.S094: Deep Learning for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://introtodeeplearning.com/&#34;&gt;MIT 6.S191: Introduction to Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rll.berkeley.edu/deeprlcourse/&#34;&gt;Berkeley CS 294: Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/keras-in-motion&#34;&gt;Keras in Motion video course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://course.fast.ai/&#34;&gt;Practical Deep Learning For Coders&lt;/a&gt; by Jeremy Howard – Fast.ai&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://deeplearning.cs.cmu.edu/&#34;&gt;Introduction to Deep Learning&lt;/a&gt; by Prof. Bhiksha Raj (2017)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.deeplearning.ai/ai-for-everyone/&#34;&gt;AI for Everyone&lt;/a&gt; by Andrew Ng (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://introtodeeplearning.com/&#34;&gt;MIT Intro to Deep Learning 7 day bootcamp&lt;/a&gt; – A seven day bootcamp designed in MIT to introduce deep learning methods and applications (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mithi.github.io/deep-blueberry&#34;&gt;Deep Blueberry: Deep Learning&lt;/a&gt; – A free five-weekend plan to self-learners to learn the basics of deep-learning architectures like CNNs, LSTMs, RNNs, VAEs, GANs, DQN, A3C and more (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://spinningup.openai.com/&#34;&gt;Spinning Up in Deep Reinforcement Learning&lt;/a&gt; – A free deep reinforcement learning course by OpenAI (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization – Coursera&lt;/a&gt; – Breaking into AI with the best course from Andrew NG.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW&#34;&gt;Deep Learning – UC Berkeley STAT-157&lt;/a&gt; by Alex Smola and Mu Li (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/machine-learning-for-mere-mortals&#34;&gt;Machine Learning for Mere Mortals video course&lt;/a&gt; by Nick Chase&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developers.google.com/machine-learning/crash-course/&#34;&gt;Machine Learning Crash Course with TensorFlow APIs&lt;/a&gt; -Google AI&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://course.fast.ai/part2&#34;&gt;Deep Learning from the Foundations&lt;/a&gt; Jeremy Howard – Fast.ai&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893&#34;&gt;Deep Reinforcement Learning (nanodegree) – Udacity&lt;/a&gt; a 3-6 month Udacity nanodegree, spanning multiple courses (2018)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/grokking-deep-learning-in-motion&#34;&gt;Grokking Deep Learning in Motion&lt;/a&gt; by Beau Carnes (2018)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/share/1000gAA0QdcV9aQng=/&#34;&gt;Face Detection with Computer Vision and Deep Learning&lt;/a&gt; by Hakan Cebeci&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/slides?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;siteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34;&gt;Presentation skills: Designing Presentation Slides - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;siteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34;&gt;Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/machine-learning/home/welcome&#34;&gt;Machine Learning – Home Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;siteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34;&gt;Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/browse/data-science&#34;&gt;Data Science Certificates - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learning.edureka.co/mycourses&#34;&gt;Edureka&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bdlabs.edureka.co:50001/cmf/services/18/status&#34;&gt;Edureka-Cloudera Manager&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/&#34;&gt;Udemy Courses&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://onlinereikicourse.com/&#34;&gt;Courses – Online Reiki Course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datacamp.com/courses&#34;&gt;DataCamp Courses&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learn.byjus.com/video/chapter-videos/44724&#34;&gt;Byju&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229&#34;&gt;udacity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://intellipaat.com/blog/what-is-apache-spark/&#34;&gt;What is Spark – A Comparison Between Spark vs. Hadoop&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://studio.azureml.net/Home/ViewWorkspaceCached/086ca408664942138b618398589b02ff#Workspace/Settings/Name&#34;&gt;Microsoft Azure Machine Learning Studio (classic)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.apache.org/&#34;&gt;Welcome to The Apache Software Foundation!&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://makingindiaemployable.com/&#34;&gt;Making India Employable - Vivid Vision 10  10  10&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ideone.com/&#34;&gt;GpI8H5 – Online Python3 Interpreter &amp;amp; Debugging Tool – Ideone.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLOU2XLYxmsILVTiOlMJdo7RQS55jYhsMi&#34;&gt;Google I/O 2019 – All Sessions – YouTube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLQY2H8rRoyvy2_vtWvCpQWM9GJXNTa5rV&#34;&gt;TensorFlow at Google I/O 2019 – YouTube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bsc.hcverma.in/course/quantum&#34;&gt;Quantum Mechanics - BSc Lectures by Prof. H C Verma and Team&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openpathshala.com/&#34;&gt;Open Pathshala - Your Best Source to Learn Sanskrit&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.classcentral.com/&#34;&gt;Class Central #1 Search Engine for Free Online Courses &amp;amp; MOOCs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.class-central.com/course/coursera-mathematics-for-machine-learning-multivariate-calculus-10452&#34;&gt;Free Online Course: Mathematics for Machine Learning: Multivariate Calculus from Coursera - Class Central&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://byjus.com/&#34;&gt;e Learning for Basic Science and Maths&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.skillshare.com/&#34;&gt;Online Classes by Skillshare - Start for Free Today&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learndigital.withgoogle.com/digitalgarage&#34;&gt;Learn online marketing with free courses – Google Digital Garage&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://moz.com/blog&#34;&gt;Moz Blog – SEO and Inbound Marketing Blog – Moz&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://onlinecourses.nptel.ac.in/m#/lesson/noc19_hs53/8/15&#34;&gt;NPTEL Online Courses Mobile&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/learn/overview&#34;&gt;Learn Python, Data Viz, Pandas &amp;amp; More - Tutorials - Kaggle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.superdatascience.com/training/&#34;&gt;Data Science Training&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;tutorials&#34;&gt;Tutorials&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial&#34;&gt;UFLDL Tutorial 1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ufldl.stanford.edu/tutorial/supervised/LinearRegression/&#34;&gt;UFLDL Tutorial 2&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial&#34;&gt;Deep Learning for NLP (without Magic)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks&#34;&gt;A Deep Learning Tutorial: From Perceptrons to Deep Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.metacademy.org/roadmaps/rgrosse/deep_learning&#34;&gt;Deep Learning from the Bottom up&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://deeplearning.net/tutorial/deeplearning.pdf&#34;&gt;Theano Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://uk.mathworks.com/help/pdf_doc/nnet/nnet_ug.pdf&#34;&gt;Neural Networks for Matlab&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/&#34;&gt;Using convolutional neural nets to detect facial keypoints tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/clementfarabet/ipam-tutorials/tree/master/th_tutorials&#34;&gt;Torch7 Tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/josephmisiti/machine-learning-module&#34;&gt;The Best Machine Learning Tutorials On The Web&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html&#34;&gt;VGG Convolutional Neural Networks Practical&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/nlintz/TensorFlow-Tutorials&#34;&gt;TensorFlow tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/pkmital/tensorflow_tutorials&#34;&gt;More TensorFlow tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/aymericdamien/TensorFlow-Examples&#34;&gt;TensorFlow Python Notebooks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/Vict0rSch/deep_learning&#34;&gt;Keras and Lasagne Deep Learning Tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition&#34;&gt;Classification on raw time series in TensorFlow with a LSTM RNN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/&#34;&gt;Using convolutional neural nets to detect facial keypoints tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/astorfi/TensorFlow-World&#34;&gt;TensorFlow-World&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-with-python&#34;&gt;Deep Learning with Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/grokking-deep-learning&#34;&gt;Grokking Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-for-search&#34;&gt;Deep Learning for Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.sicara.com/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511&#34;&gt;Keras Tutorial: Content Based Image Retrieval Using a Convolutional Denoising Autoencoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/yunjey/pytorch-tutorial&#34;&gt;Pytorch Tutorial by Yunjey Choi&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html&#34;&gt;Understanding deep Convolutional Neural Networks with a practical use-case in Tensorflow and Keras&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ahmedbesbes.com/overview-and-benchmark-of-traditional-and-deep-learning-models-in-text-classification.html&#34;&gt;Overview and benchmark of traditional and deep learning models in text classification&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/MelAbgrall/HardwareforAI&#34;&gt;Hardware for AI: Understanding computer hardware &amp;amp; build your own computer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hackr.io/tutorials/learn-artificial-intelligence-ai&#34;&gt;Programming Community Curated Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://amitness.com/2020/02/illustrated-self-supervised-learning/&#34;&gt;The Illustrated Self-Supervised Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://amitness.com/2020/02/albert-visual-summary/&#34;&gt;Visual Paper Summary: ALBERT (A Lite BERT)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;videos-and-lectures&#34;&gt;Videos and Lectures&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=RIkxVci-R4k&#34;&gt;How To Create A Mind&lt;/a&gt; By Ray Kurzweil&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=n1ViNeWhC24&#34;&gt;Deep Learning, Self-Taught Learning and Unsupervised Feature Learning&lt;/a&gt; By Andrew Ng&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=vShMxxqtDDs&amp;amp;index=3&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT&#34;&gt;Recent Developments in Deep Learning&lt;/a&gt; By Geoff Hinton&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sc-KbuZqGkI&#34;&gt;The Unreasonable Effectiveness of Deep Learning&lt;/a&gt; by Yann LeCun&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4xsVFLnHC_0&#34;&gt;Deep Learning of Representations&lt;/a&gt; by Yoshua bengio&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6ufPpZDmPKA&#34;&gt;Principles of Hierarchical Temporal Memory&lt;/a&gt; by Jeff Hawkins&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2QJi0ArLq7s&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT&#34;&gt;Machine Learning Discussion Group – Deep Learning w/ Stanford AI Lab&lt;/a&gt; by Adam Coates&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vimeo.com/80821560&#34;&gt;Making Sense of the World with Deep Learning&lt;/a&gt; By Adam Coates&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wZfVBwOO0-k&#34;&gt;Demystifying Unsupervised Feature Learning&lt;/a&gt; By Adam Coates&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3boKlkPBckA&#34;&gt;Visual Perception with Deep Learning&lt;/a&gt; By Yann LeCun&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=AyzOUbkUf3M&#34;&gt;The Next Generation of Neural Networks&lt;/a&gt; By Geoffrey Hinton at GoogleTechTalks&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn&#34;&gt;The wonderful and terrifying implications of computers that can learn&lt;/a&gt; By Jeremy Howard at TEDxBrussels&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/class/cs294a/handouts.html&#34;&gt;Unsupervised Deep Learning – Stanford&lt;/a&gt; by Andrew Ng in Stanford (2011)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/class/cs224n/handouts/&#34;&gt;Natural Language Processing&lt;/a&gt; By Chris Manning in Stanford&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://googleresearch.blogspot.com/2015/09/a-beginners-guide-to-deep-neural.html&#34;&gt;A beginners Guide to Deep Neural Networks&lt;/a&gt; By Natalie Hammel and Lorraine Yurshansky&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=czLI3oLDe8M&#34;&gt;Deep Learning: Intelligence from Big Data&lt;/a&gt; by Steve Jurvetson (and panel) at VLAB in Stanford.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=FoO8qDB8gUU&#34;&gt;Introduction to Artificial Neural Networks and Deep Learning&lt;/a&gt; by Leo Isikdogan at Motorola Mobility HQ&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule&#34;&gt;NIPS 2016 lecture and workshop videos&lt;/a&gt; – NIPS 2016&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oS5fz_mHVz0&amp;amp;list=PLWKotBjTDoLj3rXBL-nEIPRN9V3a9Cx07&#34;&gt;Deep Learning Crash Course&lt;/a&gt;: a series of mini-lectures by Leo Isikdogan on YouTube (2018)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/deep-learning-crash-course&#34;&gt;Deep Learning Crash Course&lt;/a&gt; By Oliver Zeigermann&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/deep-learning-with-r-in-motion&#34;&gt;Deep Learning with R in Motion&lt;/a&gt;: a live video course that teaches how to apply deep learning to text and images using the powerful Keras library and its R language interface.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f5vUg6i&#34;&gt;8 Essential Tips for People starting a Career in Data Science&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fMEhi4D&#34;&gt;Cheatsheet: How to become a data scientist&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fruY2AC&#34;&gt;The Art of Learning Data Science&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fxReDab&#34;&gt;The Periodic Table of Data Science&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fXSE-us&#34;&gt;Aspiring Data Scientists! Start to learn Statistics with these 6 books&lt;/a&gt;!&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f8S3Ygd&#34;&gt;8 Skills You Need to Be a Data Scientist&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fKugicE&#34;&gt;Top 10 Essential Books for the Data Enthusiast&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fTGDkju&#34;&gt;Aspiring data scientist? Master these fundamentals&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f_Zhpzf&#34;&gt;How to Become a Data Scientist – On your own.&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;gretl--great-statistical-software-for-beginners&#34;&gt;GRETL – Great Statistical software for Beginners&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Simple Linear Regression &lt;a href=&#34;https://lnkd.in/ecfsV9c&#34;&gt;https://lnkd.in/ecfsV9c&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Coding Dummy Variables &lt;a href=&#34;https://lnkd.in/ef7Yd7f&#34;&gt;https://lnkd.in/ef7Yd7f&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Forecasting New Observations &lt;a href=&#34;https://lnkd.in/eNKbxbU&#34;&gt;https://lnkd.in/eNKbxbU&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Forecasting a Large Number of Observations &lt;a href=&#34;https://lnkd.in/eHmibGs&#34;&gt;https://lnkd.in/eHmibGs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Logistic Regression &lt;a href=&#34;https://lnkd.in/eRfhQ87&#34;&gt;https://lnkd.in/eRfhQ87&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Forecasting and Confusion Matrix &lt;a href=&#34;https://lnkd.in/eaqrFJr&#34;&gt;https://lnkd.in/eaqrFJr&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Modeling and Forecasting Time Series Data &lt;a href=&#34;https://lnkd.in/e6fqKpF&#34;&gt;https://lnkd.in/e6fqKpF&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Comparing Time Series Trend Models &lt;a href=&#34;https://lnkd.in/eKjEUAE&#34;&gt;https://lnkd.in/eKjEUAE&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Khan Academy is the best online free resource to learn Math for Data Science. ( &lt;a href=&#34;https://www.khanacademy.org/math/&#34;&gt;https://www.khanacademy.org/math/&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Krista King has also done a great job in creating an exceptionally good introductory course. She is too good at designing the course. ( &lt;a href=&#34;https://www.udemy.com/user/kristaking/&#34;&gt;https://www.udemy.com/user/kristaking/&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;3Blue1Brown ( &lt;a href=&#34;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists&#34;&gt;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Every Intro to Data Science Course on the Internet, Ranked. (&lt;a href=&#34;https://lnkd.in/fQDMiNX&#34;&gt;https://lnkd.in/fQDMiNX&lt;/a&gt; )&lt;/li&gt;&#xA;&lt;li&gt;What would be useful for aspiring data scientists to know? (&lt;a href=&#34;https://lnkd.in/fmcFyN7&#34;&gt;https://lnkd.in/fmcFyN7&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
    <item>
      <title>Reinforcement Learning Git Repositories</title>
      <link>http://localhost:1313/dsblog/rl-git-repo/</link>
      <pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/rl-git-repo/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr101-Reinforcement-Learning-Git-Repositories.jpg&#34; alt=&#34;Reinforcement Learning Git Repositories&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;reinforcement-learning-git-repositories&#34;&gt;Reinforcement Learning Git Repositories&lt;/h1&gt;&#xA;&lt;table&gt;&#xA;  &lt;thead&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;th&gt;Sno.&lt;/th&gt;&#xA;          &lt;th&gt;URL&lt;/th&gt;&#xA;          &lt;th&gt;Description&lt;/th&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/thead&gt;&#xA;  &lt;tbody&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;1&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/baselines&#34;&gt;https://github.com/openai/baselines&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;OpenAI Baselines: high-quality implementations of reinforcement learning algorithms&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;2&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A fork of OpenAI Baselines, implementations of reinforcement learning algorithms&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;3&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/spinningup&#34;&gt;https://github.com/openai/spinningup&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An educational resource to help anyone learn deep reinforcement learning.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;4&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/google/dopamine&#34;&gt;https://github.com/google/dopamine&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Dopamine is a research framework for fast prototyping of reinforcement learning algorithms.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;5&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/agents&#34;&gt;https://github.com/tensorflow/agents&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;TF-Agents is a library for Reinforcement Learning in TensorFlow&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;6&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/trfl&#34;&gt;https://github.com/deepmind/trfl&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;TensorFlow Reinforcement Learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;7&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/Horizon&#34;&gt;https://github.com/facebookresearch/Horizon&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A platform for Applied Reinforcement Learning (Applied RL)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;8&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/ELF&#34;&gt;https://github.com/facebookresearch/ELF&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;An End-To-End, Lightweight and Flexible Platform for Game Research&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;9&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/NervanaSystems/coach&#34;&gt;https://github.com/NervanaSystems/coach&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Reinforcement Learning Coach by Intel AI Lab enables easy experimentation with state of the art Reinforcement Learning algorithms&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;10&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ray-project/ray/tree/master/python/ray/rllib&#34;&gt;https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A fast and simple framework for building and running distributed applications.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;11&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/keras-rl/keras-rl&#34;&gt;https://github.com/keras-rl/keras-rl&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Deep Reinforcement Learning for Keras.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;12&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&#34;&gt;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch implementation of Advantage Actor Critic (A2C), Proximal Policy Optimization (PPO), Scalable trust-region method for deep reinforcement learning using Kronecker-factored approximation (ACKTR) and Generative Adversarial Imitation Learning (GAIL).&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;13&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Kaixhin/Rainbow&#34;&gt;https://github.com/Kaixhin/Rainbow&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Rainbow: Combining Improvements in Deep Reinforcement Learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;14&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/MillionIntegrals/vel&#34;&gt;https://github.com/MillionIntegrals/vel&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Velocity in deep-learning research&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;15&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorforce/tensorforce&#34;&gt;https://github.com/tensorforce/tensorforce&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorforce: A TensorFlow library for applied reinforcement learning&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;16&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/kengz/SLM-Lab&#34;&gt;https://github.com/kengz/SLM-Lab&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Modular Deep Reinforcement Learning framework in PyTorch.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;17&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/rlworkgroup/garage&#34;&gt;https://github.com/rlworkgroup/garage&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A framework for reproducible reinforcement learning research&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;18&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/catalyst-team/catalyst&#34;&gt;https://github.com/catalyst-team/catalyst&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Reproducible and fast DL &amp;amp; RL.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;19&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/higgsfield/RL-Adventure&#34;&gt;https://github.com/higgsfield/RL-Adventure&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Pytorch Implementation of DQN / DDQN / Prioritized replay/ noisy networks/ distributional values/ Rainbow/ hierarchical RL&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;20&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/qfettes/DeepRL-Tutorials&#34;&gt;https://github.com/qfettes/DeepRL-Tutorials&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Contains high quality implementations of Deep Reinforcement Learning algorithms written in PyTorch&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;21&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/gym&#34;&gt;https://github.com/openai/gym&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A toolkit for developing and comparing reinforcement learning algorithms.&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;22&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/lab&#34;&gt;https://github.com/deepmind/lab&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;A customisable 3D platform for agent-based AI research&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;23&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Microsoft/malmo&#34;&gt;https://github.com/Microsoft/malmo&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Project Malmo is a platform for Artificial Intelligence experimentation and research built on top of Minecraft. We aim to inspire a new generation of research into challenging new problems presented by this unique environment. — For installation instruct&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;24&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/retro&#34;&gt;https://github.com/openai/retro&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Retro Games in Gym&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;25&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/dm_control&#34;&gt;https://github.com/deepmind/dm_control&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;The DeepMind Control Suite and Package&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;26&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/neural-mmo&#34;&gt;https://github.com/openai/neural-mmo&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Neural MMO – A Massively Multiagent Game Environment&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;27&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/gym&#34;&gt;https://github.com/openai/gym&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Gym @ OpenAI&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;28&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/lab&#34;&gt;https://github.com/deepmind/lab&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Lab @ DeepMind&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;29&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Microsoft/malmo&#34;&gt;https://github.com/Microsoft/malmo&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Project Malmo @ Microsoft&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;30&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/retro&#34;&gt;https://github.com/openai/retro&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Retro @ OpenAI&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;31&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/dm_control&#34;&gt;https://github.com/deepmind/dm_control&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Control Suite @ DeepMind&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;32&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/neural-mmo&#34;&gt;https://github.com/openai/neural-mmo&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Neural MMO @ OpenAI&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;33&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/baselines&#34;&gt;https://github.com/openai/baselines&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by OpenAI&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;34&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/hill-a/stable-baselines&#34;&gt;https://github.com/hill-a/stable-baselines&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by Antonin Raffin, Ashley Hill&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;35&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/catalyst-team/catalyst&#34;&gt;https://github.com/catalyst-team/catalyst&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch Maintained by Sergey Kolesnikov&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;36&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ray-project/ray/tree/master/python/ray/rllib&#34;&gt;https://github.com/ray-project/ray/tree/master/python/ray/rllib&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by Ray Team&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;37&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorflow/agents&#34;&gt;https://github.com/tensorflow/agents&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by Google&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;38&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/Horizon&#34;&gt;https://github.com/facebookresearch/Horizon&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch Maintained by Facebook&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;39&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/NervanaSystems/coach&#34;&gt;https://github.com/NervanaSystems/coach&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by Intel&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;40&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/rlworkgroup/garage&#34;&gt;https://github.com/rlworkgroup/garage&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by community&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;41&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/kengz/SLM-Lab&#34;&gt;https://github.com/kengz/SLM-Lab&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch Maintained by Wah Loon Keng, Laura Graesser&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;42&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/google/dopamine&#34;&gt;https://github.com/google/dopamine&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by Google&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;43&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/openai/spinningup&#34;&gt;https://github.com/openai/spinningup&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by OpenAI&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;44&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/trfl&#34;&gt;https://github.com/deepmind/trfl&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by DeepMind&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;45&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/deepmind/scalable_agent&#34;&gt;https://github.com/deepmind/scalable_agent&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by DeepMind&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;46&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/facebookresearch/ELF&#34;&gt;https://github.com/facebookresearch/ELF&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch Maintained by Facebook&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;47&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/keras-rl/keras-rl&#34;&gt;https://github.com/keras-rl/keras-rl&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow Maintained by Matthias Plappert&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;48&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&#34;&gt;https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch Maintained by Ilya Kostrikov&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;49&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Kaixhin/Rainbow&#34;&gt;https://github.com/Kaixhin/Rainbow&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch Maintained by Kai Arulkumaran&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;50&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/MillionIntegrals/vel&#34;&gt;https://github.com/MillionIntegrals/vel&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch Maintained by Jerry (?)&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;51&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Khrylx/PyTorch-RL&#34;&gt;https://github.com/Khrylx/PyTorch-RL&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;52&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/tensorforce/tensorforce&#34;&gt;https://github.com/tensorforce/tensorforce&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;53&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/higgsfield/RL-Adventure&#34;&gt;https://github.com/higgsfield/RL-Adventure&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;54&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/qfettes/DeepRL-Tutorials&#34;&gt;https://github.com/qfettes/DeepRL-Tutorials&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;55&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/SurrealAI/surreal&#34;&gt;https://github.com/SurrealAI/surreal&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;TorchX&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;56&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/zuoxingdong/lagom&#34;&gt;https://github.com/zuoxingdong/lagom&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;57&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/dennybritz/reinforcement-learning&#34;&gt;https://github.com/dennybritz/reinforcement-learning&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;58&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/unixpickle/anyrl-py&#34;&gt;https://github.com/unixpickle/anyrl-py&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;59&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/Scitator/rl-course-experiments&#34;&gt;https://github.com/Scitator/rl-course-experiments&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;Tensorflow&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;      &lt;tr&gt;&#xA;          &lt;td&gt;60&lt;/td&gt;&#xA;          &lt;td&gt;&lt;a href=&#34;https://github.com/oxwhirl/pymarl&#34;&gt;https://github.com/oxwhirl/pymarl&lt;/a&gt;&lt;/td&gt;&#xA;          &lt;td&gt;PyTorch&lt;/td&gt;&#xA;      &lt;/tr&gt;&#xA;  &lt;/tbody&gt;&#xA;&lt;/table&gt;</description>
    </item>
    <item>
      <title>What is XAI?</title>
      <link>http://localhost:1313/dsblog/What-is-XAI/</link>
      <pubDate>Fri, 15 May 2020 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/What-is-XAI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6003-XAI.jpg&#34; alt=&#34;XAI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-xai&#34;&gt;What is XAI?&lt;/h1&gt;&#xA;&lt;h2 id=&#34;xai-in-simple-language&#34;&gt;XAI in Simple Language!&lt;/h2&gt;&#xA;&lt;p&gt;The discipline of Data Science and AI has introduced many terms into discussions that might seem complicated at first. In reality, many of these terms are intuitive and straightforward when considered from a natural intelligence perspective. However, from a technological standpoint, they can be complex. To understand XAI, let’s explore a few examples.&lt;/p&gt;&#xA;&lt;p&gt;All AI or ML-based systems rely on data for training. Once trained, the system works by providing answers or predictions based on input data. The quality of these answers depends on factors such as the algorithm used, the quantity and quality of the data, and hyperparameters, among others.&lt;/p&gt;</description>
    </item>
    <item>
      <title>100&#43; High Level AI Usecases and Future Prediction for AI as on 2020</title>
      <link>http://localhost:1313/dsblog/100&#43;High-Level-AI-Usecases/</link>
      <pubDate>Sat, 02 May 2020 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/100&#43;High-Level-AI-Usecases/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6002-High-Level-UsesCases-AI.jpg&#34; alt=&#34;HighLevel-UsesCases-AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;150-high-level-ai-usecases---2020&#34;&gt;150 High Level AI Usecases - 2020&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Nowadays, we frequently hear and read about AI and its role in shaping both our present and future. However, many people, even those who are tech-savvy, struggle to understand and answer some fundamental questions, such as:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is AI (Artificial Intelligence)? Is it just another buzzword in technology?&lt;/li&gt;&#xA;&lt;li&gt;What exactly can I do with AI?&lt;/li&gt;&#xA;&lt;li&gt;How will AI affect my job and life?&lt;/li&gt;&#xA;&lt;li&gt;In today’s volatile job market and business environment, what should I learn to secure my future?&lt;/li&gt;&#xA;&lt;li&gt;I’m not a technology expert—will AI render me redundant?&lt;/li&gt;&#xA;&lt;li&gt;Where is AI? I only see electronic gadgets around me.&lt;/li&gt;&#xA;&lt;li&gt;What is the relationship between AI, ML (Machine Learning), Automation, Robotics, IoT, and similar technologies?&lt;/li&gt;&#xA;&lt;li&gt;And many other questions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;On the other hand, there are professionals with degrees in Data Science, AI, and ML who want to pursue their passion for building and researching meaningful, practical projects within limited timeframes and resources. Yet, many of them struggle to identify viable opportunities.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Dealing with Sensitive Data</title>
      <link>http://localhost:1313/dsblog/2020-03-10-6001-dealing-with-sensitive-data/</link>
      <pubDate>Tue, 10 Mar 2020 15:50:00 +0530</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/2020-03-10-6001-dealing-with-sensitive-data/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6001-Dealing-with-Sensitive-Data.jpg&#34; alt=&#34;XAI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;dealing-with-sensitive-data&#34;&gt;Dealing with Sensitive Data&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;One of the biggest problems for a Data Science project team is to protect the data. We know, data is the basic raw material for building any supervised or unsupervised models. We cannot make a without data. Let’s assume you are working for an eCommerce retail company like Amazon; or in the health domain with some big hospital chain or government hospital; or in the banking industry with some big bank like Bank of America, Standard Charted, SBI, or ICICI Bank. They have huge data. That data can be used to develop ML models. These models can help them to serve their customers or other stakeholders in a better and efficient way. To develop these models, data should be given to the Data Science team. When the data is moving out from the production environment to the project environment, there is no guarantee that data will not fall in the wrong hands and will not be misused during the project or post the project completion. When the data is moving within the same company, there are lesser chances of this disaster. But when the company is giving data to third parties or vendors, then there are high chances.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
