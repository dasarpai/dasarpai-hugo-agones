<!doctype html>
<html itemscope itemtype="http://schema.org/WebPage" lang="en" class="no-js">
  <head><script src="/site/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=site/livereload" data-no-instant defer></script>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="generator" content="Hugo 0.147.0">

<META NAME="ROBOTS" CONTENT="NOINDEX, NOFOLLOW">



<link rel="shortcut icon" href="/site/favicons/favicon.ico?v=1" >
<link rel="apple-touch-icon" href="/site/favicons/apple-touch-icon-180x180.png?v=1" sizes="180x180">
<link rel="icon" type="image/png" href="/site/favicons/favicon-16x16.png?v=1" sizes="16x16">
<link rel="icon" type="image/png" href="/site/favicons/favicon-32x32.png?v=1" sizes="32x32">
<link rel="apple-touch-icon" href="/site/favicons/apple-touch-icon-180x180.png?v=1" sizes="180x180">
<title>Distances in Machine Learning | Agones</title><meta property="og:url" content="http://localhost:1313/site/dsblog/dsblog/2023-08-27-6093-distances-in-machine-learning/">
  <meta property="og:site_name" content="Agones">
  <meta property="og:title" content="Distances in Machine Learning">
  <meta property="og:description" content="Distances in Machine Learning Every sample, record, word, sentence, object, image etc in the Machine learning language is called vector. If we want to measure the similarity or dissimilarity between two data points then we need distance function.
Distance metrics play a crucial role in various machine learning algorithms, including clustering, classification, and anomaly detection. Different distance measures capture different types of relationships between data points.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="dsblog">
    <meta property="article:published_time" content="2023-08-27T00:00:00+00:00">
    <meta property="article:modified_time" content="2023-08-27T00:00:00+00:00">
    <meta property="article:tag" content="Machine Learning">
    <meta property="article:tag" content="Maths in AI">
    <meta property="article:tag" content="Distance Metrics">
    <meta property="article:tag" content="Mathematical Concepts">
    <meta property="article:tag" content="Data Analysis">
    <meta property="article:tag" content="Similarity Measures">

  <meta itemprop="name" content="Distances in Machine Learning">
  <meta itemprop="description" content="Distances in Machine Learning Every sample, record, word, sentence, object, image etc in the Machine learning language is called vector. If we want to measure the similarity or dissimilarity between two data points then we need distance function.
Distance metrics play a crucial role in various machine learning algorithms, including clustering, classification, and anomaly detection. Different distance measures capture different types of relationships between data points.">
  <meta itemprop="datePublished" content="2023-08-27T00:00:00+00:00">
  <meta itemprop="dateModified" content="2023-08-27T00:00:00+00:00">
  <meta itemprop="wordCount" content="1017">
  <meta itemprop="keywords" content="Distance Metrics,Machine Learning Distance,Similarity Measures,Mathematical Distance,ML Algorithms,Data Analysis Methods,Statistical Distance,Vector Space Metrics">
  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="Distances in Machine Learning">
  <meta name="twitter:description" content="Distances in Machine Learning Every sample, record, word, sentence, object, image etc in the Machine learning language is called vector. If we want to measure the similarity or dissimilarity between two data points then we need distance function.
Distance metrics play a crucial role in various machine learning algorithms, including clustering, classification, and anomaly detection. Different distance measures capture different types of relationships between data points.">



<link rel="stylesheet" href="/site/css/prism.css"/>

<link href="/site/scss/main.css" rel="stylesheet">

<link rel="stylesheet" type="text/css" href=http://localhost:1313/site/css/asciinema-player.css />
<script
  src="https://code.jquery.com/jquery-3.3.1.min.js"
  integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8="
  crossorigin="anonymous"></script>

  </head>
  <body class="td-page">
    <header>
      
<nav class="js-navbar-scroll navbar navbar-expand navbar-light  nav-shadow flex-column flex-md-row td-navbar">

	<a id="agones-top"  class="navbar-brand" href="/site/">
		<svg xmlns="http://www.w3.org/2000/svg" xmlns:cc="http://creativecommons.org/ns#" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#" xmlns:svg="http://www.w3.org/2000/svg" viewBox="0 0 276 276" height="30" width="30" id="svg2"><defs id="defs6"><clipPath id="clipPath18" clipPathUnits="userSpaceOnUse"><path id="path16" d="M0 8e2H8e2V0H0z"/></clipPath></defs><g transform="matrix(1.3333333,0,0,-1.3333333,-398.3522,928.28029)" id="g10"><g transform="translate(2.5702576,82.614887)" id="g12"><circle transform="scale(1,-1)" r="102.69205" cy="-510.09534" cx="399.71484" id="path930" style="opacity:1;vector-effect:none;fill:#fff;fill-opacity:1;stroke:none;stroke-width:.65861601;stroke-linecap:butt;stroke-linejoin:miter;stroke-miterlimit:4;stroke-dasharray:none;stroke-dashoffset:0;stroke-opacity:1"/><g id="g40" transform="translate(239.9974,355.2515)"/><g transform="translate(4.931459e-6,39.355242)" id="g917"><g transform="translate(386.7049,451.9248)" id="g44"><path id="path46" style="fill:#2d70de;fill-opacity:1;fill-rule:nonzero;stroke:none" d="m0 0c.087-2.62-1.634-4.953-4.163-5.646-7.609-2.083-14.615-5.497-21.089-10.181-5.102-3.691-10.224-7.371-15.52-10.769-3.718-2.385-7.711-4.257-12.438-3.601-6.255.868-10.629 4.828-12.313 11.575-.619 2.478-1.169 4.997-1.457 7.53-.47 4.135-.699 8.297-1.031 12.448.32 18.264 5.042 35.123 15.47 50.223 6.695 9.693 16.067 14.894 27.708 16.085 4.103.419 8.134.365 12.108-.059 3.313-.353 5.413-3.475 5.034-6.785-.039-.337-.059-.682-.059-1.033.0-.2.008-.396.021-.593-.03-1.164-.051-1.823-.487-3.253-.356-1.17-1.37-3.116-4.045-3.504h-10.267c-3.264.0-5.91-3.291-5.91-7.35.0-4.059 2.646-7.35 5.91-7.35H4.303C6.98 37.35 7.996 35.403 8.352 34.232 8.81 32.726 8.809 32.076 8.843 30.787 8.837 30.655 8.834 30.521 8.834 30.387c0-4.059 2.646-7.349 5.911-7.349h3.7c3.264.0 5.911-3.292 5.911-7.35.0-4.06-2.647-7.351-5.911-7.351H5.878c-3.264.0-5.911-3.291-5.911-7.35z"/></g><g transform="translate(467.9637,499.8276)" id="g48"><path id="path50" style="fill:#17252e;fill-opacity:1;fill-rule:nonzero;stroke:none" d="m0 0c-8.346 13.973-20.665 20.377-36.728 20.045-1.862-.038-3.708-.16-5.539-.356-1.637-.175-2.591-2.02-1.739-3.428.736-1.219 1.173-2.732 1.173-4.377.0-4.059-2.646-7.35-5.912-7.35h-17.733c-3.264.0-5.911-3.291-5.911-7.35.0-4.059 2.647-7.35 5.911-7.35h13.628c3.142.0 5.71-3.048 5.899-6.895l.013.015c.082-1.94-.032-2.51.52-4.321.354-1.165 1.359-3.095 4.001-3.498h14.69c3.265.0 5.911-3.292 5.911-7.35.0-4.06-2.646-7.351-5.911-7.351h-23.349c-2.838-.311-3.897-2.33-4.263-3.532-.434-1.426-.456-2.085-.485-3.246.011-.189.019-.379.019-.572.0-.341-.019-.677-.055-1.006-.281-2.535 1.584-4.771 4.057-5.396 8.245-2.084 15.933-5.839 23.112-11.209 5.216-3.901 10.678-7.497 16.219-10.922 2.152-1.331 4.782-2.351 7.279-2.578 8.033-.731 13.657 3.531 15.686 11.437 1.442 5.615 2.093 11.343 2.244 17.134C13.198-31.758 9.121-15.269.0.0"/></g></g></g></g></svg> <span class="text-uppercase fw-bold">Agones</span>
	</a>

	<div class="td-navbar-nav-scroll ms-md-auto" id="main_navbar">
		<ul class="navbar-nav mt-2 mt-lg-0">
			
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				<a class="nav-link" href="/site/docs/"><span>Documentation</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				<a class="nav-link" href="/site/blog/"><span>Blog</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				
				
				
				
				<a class="nav-link" href="/site/community/"><span>Community</span></a>
			</li>
			
			<li class="nav-item mr-4 mb-2 mb-lg-0">
				<a class="nav-link" href="https://github.com/googleforgames/agones">GitHub</a>
			</li>
			<li class="nav-item dropdown d-none d-lg-block">
				<a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-bs-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
					Release
				</a>
				<div class="dropdown-menu" aria-labelledby="navbarDropdownMenuLink">
					<a class="dropdown-item" href="https://development.agones.dev">Development</a>
					<a class="dropdown-item" href="https://agones.dev">1.48.0</a>
					<a class="dropdown-item" href="https://1-47-0.agones.dev">1.47.0</a>
					<a class="dropdown-item" href="https://1-46-0.agones.dev">1.46.0</a>
					<a class="dropdown-item" href="https://1-45-0.agones.dev">1.45.0</a>
					<a class="dropdown-item" href="https://1-44-0.agones.dev">1.44.0</a>
					<a class="dropdown-item" href="https://1-43-0.agones.dev">1.43.0</a>
					<a class="dropdown-item" href="https://1-42-0.agones.dev">1.42.0</a>
					<a class="dropdown-item" href="https://1-41-0.agones.dev">1.41.0</a>
					<a class="dropdown-item" href="https://1-40-0.agones.dev">1.40.0</a>
					<a class="dropdown-item" href="https://1-39-0.agones.dev">1.39.0</a>
					<a class="dropdown-item" href="https://1-38-0.agones.dev">1.38.0</a>
					<a class="dropdown-item" href="https://1-37-0.agones.dev">1.37.0</a>
					<a class="dropdown-item" href="https://1-36-0.agones.dev">1.36.0</a>
					<a class="dropdown-item" href="https://1-35-0.agones.dev">1.35.0</a>
					<a class="dropdown-item" href="https://1-34-0.agones.dev">1.34.0</a>
					<a class="dropdown-item" href="https://1-33-0.agones.dev">1.33.0</a>
					<a class="dropdown-item" href="https://1-32-0.agones.dev">1.32.0</a>
					<a class="dropdown-item" href="https://1-31-0.agones.dev">1.31.0</a>
				</div>
			</li>
			
		</ul>
	</div>
	<div class="navbar-nav mx-lg-2 d-none d-lg-block"><div class="td-search">
  <div class="td-search__icon"></div>
  <input id="agones-search" type="search" class="td-search__input form-control td-search-input" placeholder="Search this site…" aria-label="Search this site…" autocomplete="off">
</div></div>
</nav>

    </header>
    <div class="container-fluid td-default td-outer">
      <main role="main" class="td-main">
        <p><img src="/assets/images/dspost/dsp6093-Distances-in-Machine-Learning.jpg" alt="Distances in Machine Learning"></p>
<h1 id="distances-in-machine-learning">Distances in Machine Learning</h1>
<p>Every sample, record, word, sentence, object, image etc in the Machine learning language is called vector. If we want to measure the similarity or dissimilarity between two data points then we need distance function.</p>
<p>Distance metrics play a crucial role in various machine learning algorithms, including clustering, classification, and anomaly detection. Different distance measures capture different types of relationships between data points.</p>
<p>The choice of distance function depends on the specific task at hand and the properties of the data. For example,</p>
<ul>
<li>the Euclidean distance is often used for tasks such as classification and regression,</li>
<li>the Jaccard distance is often used for tasks such as text classification,</li>
<li>the Mahalanobis distance is often used for tasks such as fraud detection.</li>
<li>the Manhattan distance is often used for tasks such as clustering.</li>
</ul>
<h2 id="1-manhattan-distance-l1-norm">1. Manhattan Distance (L1 Norm):</h2>
<p>This is the sum of the absolute values of the vector components. It&rsquo;s called the Manhattan distance because it represents the distance between two points in a grid-based path (like navigating streets in a city laid out in a grid).</p>
<p>$$
| \mathbf{x} |_1 = |x_1| + |x_2| + \ldots + |x_n|
$$</p>
<h2 id="euclidean-distancel2-norm">Euclidean Distance(L2 Norm):</h2>
<p>This is the square root of the sum of the squares of the vector components. It corresponds to the straight-line distance (or Euclidean distance) between two points in Euclidean space.</p>
<p>$$
| \mathbf{x} |_2 = \sqrt{x_1^2 + x_2^2 + \ldots + x_n^2}
$$</p>
<h2 id="2-minkowski-distance">2. Minkowski distance:</h2>
<p>This is a generalization of the Euclidean and Manhattan distances. It is defined by a parameter p, and the value of p determines the type of distance metric. For example, p=1 is the Manhattan distance, p=2 is the Euclidean distance, and p=infinity is the Chebyshev distance.</p>
<p>$$
| \mathbf{x} |_3 = \left(|x_1|^3 + |x_2|^3 + \ldots + |x_n|^3\right)^{\frac{1}{3}}
$$</p>
<p>In general, the Lp norm is defined as:</p>
<p>$$
| \mathbf{x} |_p = \left(|x_1|^p + |x_2|^p + \ldots + |x_n|^p\right)^{\frac{1}{p}}
$$</p>
<p>where $$p$$ is a positive integer. Each norm measures &ldquo;distance&rdquo; in different ways, with larger values of $$ p$$ putting more emphasis on larger components of the vector.</p>
<h2 id="distance-metrics-in-machine-learning">Distance Metrics in Machine Learning</h2>
<p>:</p>
<h3 id="3-hamming-distance">3. Hamming Distance</h3>
<p>Hamming distance measures the number of positions at which two binary vectors differ. It is particularly useful for categorical data.</p>
<p><strong>Formula:</strong>
$$
d_{\text{Hamming}}(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^{n} \mathbf{1}(x_i \neq y_i)
$$</p>
<p>where $$\mathbf{x}$$ and $$\mathbf{y}$$ are binary vectors, and $$\mathbf{1}(x_i \neq y_i)$$ is an indicator function that equals 1 if $$x_i \neq y_i$$ and 0 otherwise.</p>
<h3 id="4-cosine-similarity">4. Cosine Similarity</h3>
<p>Cosine similarity measures the cosine of the angle between two non-zero vectors in a multi-dimensional space. It is used to measure how similar two vectors are, regardless of their magnitude.</p>
<p><strong>Formula:</strong>
$$
\text{Cosine Similarity}(\mathbf{x}, \mathbf{y}) = \frac{\mathbf{x} \cdot \mathbf{y}}{|\mathbf{x}| |\mathbf{y}|}
$$</p>
<p>where $$ \mathbf{x} \cdot \mathbf{y} $$ is the dot product of the vectors, and $$ |\mathbf{x}| $$ and $$ |\mathbf{y}| $$ are their Euclidean norms.</p>
<h3 id="5-jaccard-distance">5. Jaccard Distance</h3>
<p>Jaccard distance measures the dissimilarity between two sets. It is defined as 1 minus the Jaccard similarity, which is the ratio of the intersection over the union of the two sets.</p>
<p><strong>Formula:</strong>
$$
d_{\text{Jaccard}}(A, B) = 1 - \frac{|A \cap B|}{|A \cup B|}
$$</p>
<p>where $$ A $$ and $$ B $$ are two sets.</p>
<h3 id="6-overlap-coefficient">6. Overlap Coefficient</h3>
<p>The overlap coefficient is a similarity measure that is the size of the intersection of two sets divided by the size of the smaller set. It is useful for comparing two sets where one is a subset of the other.</p>
<p><strong>Formula:</strong>
$$
\text{Overlap Coefficient}(A, B) = \frac{|A \cap B|}{\min(|A|, |B|)}
$$</p>
<h3 id="7-sokal-michener-distance">7. Sokal-Michener Distance</h3>
<p>Sokal-Michener distance is used to measure similarity between two categorical sequences. It is defined as the proportion of matches over the total number of attributes.</p>
<p><strong>Formula:</strong>
$$
d_{\text{Sokal-Michener}}(\mathbf{x}, \mathbf{y}) = \frac{\text{Number of matches}}{\text{Total number of attributes}}
$$</p>
<h3 id="8-mahalanobis-distance">8. Mahalanobis Distance</h3>
<p>Mahalanobis distance is a measure that accounts for the correlations of the data set and is scale-invariant. It calculates the distance between a point and a distribution.</p>
<p><strong>Formula:</strong>
$$
d_{\text{Mahalanobis}}(\mathbf{x}, \mathbf{y}) = \sqrt{(\mathbf{x} - \mathbf{y})^T \mathbf{S}^{-1} (\mathbf{x} - \mathbf{y})}
$$</p>
<p>where $$ \mathbf{S} $$ is the covariance matrix of the data.</p>
<h3 id="9-wasserstein-distance-earth-movers-distance">9. Wasserstein Distance (Earth Mover&rsquo;s Distance)</h3>
<p>Wasserstein distance measures the minimum &ldquo;cost&rdquo; of transforming one probability distribution into another. It is used in tasks such as optimal transport.</p>
<p><strong>Formula:</strong>
For 1D distributions $$ P $$ and $$ Q $$:</p>
<p>$$
W(P, Q) = \int_{-\infty}^{\infty} |F_P(x) - F_Q(x)| , dx
$$</p>
<p>where $$ F_P $$ and $$ F_Q $$ are the cumulative distribution functions of $$ P $$ and $$ Q $$.</p>
<h3 id="10-chebyshev-distance">10. Chebyshev Distance</h3>
<p>Chebyshev distance measures the greatest of the absolute differences along any coordinate dimension. It is used in chess as the minimum number of moves a king requires to travel from one square to another.</p>
<p><strong>Formula:</strong>
$$
d_{\text{Chebyshev}}(\mathbf{x}, \mathbf{y}) = \max_i |x_i - y_i|
$$</p>
<h3 id="11-canberra-distance">11. Canberra Distance</h3>
<p>Canberra distance is sensitive to small changes near zero and is defined as the sum of the ratios of the absolute differences and the sums of the coordinates.</p>
<p><strong>Formula:</strong>
$$
d_{\text{Canberra}}(\mathbf{x}, \mathbf{y}) = \sum_{i=1}^{n} \frac{|x_i - y_i|}{|x_i| + |y_i|}
$$</p>
<h3 id="12-kendall-tau-distance">12. Kendall Tau Distance</h3>
<p>Kendall tau distance measures the ordinal association between two ranked lists. It counts the number of inversions between the lists.</p>
<p><strong>Formula:</strong>
$$
d_{\text{Kendall Tau}}(\mathbf{x}, \mathbf{y}) = \text{Number of inversions between } \mathbf{x} \text{ and } \mathbf{y}
$$</p>
<h3 id="13-spearmans-rank-correlation-coefficient">13. Spearman&rsquo;s Rank Correlation Coefficient</h3>
<p>Spearman&rsquo;s rank correlation coefficient measures the strength and direction of association between two ranked variables. It is the Pearson correlation coefficient between the ranked variables.</p>
<p><strong>Formula:</strong>
$$
\rho = 1 - \frac{6 \sum d_i^2}{n(n^2 - 1)}
$$</p>
<p>where $$ d_i $$ is the difference between the ranks of corresponding values of $$ \mathbf{x} $$ and $$ \mathbf{y} $$, and $$ n $$ is the number of observations.</p>
<h3 id="14-jensen-shannon-divergence">14. Jensen-Shannon Divergence</h3>
<p>Jensen-Shannon divergence is a symmetric measure of the difference between two probability distributions. It is based on the Kullback-Leibler divergence.</p>
<p><strong>Formula:</strong>
$$
D_{\text{JS}}(P | Q) = \frac{1}{2} D_{\text{KL}}(P | M) + \frac{1}{2} D_{\text{KL}}(Q | M)
$$</p>
<p>where $$ M = \frac{1}{2}(P + Q) $$ and $$ D_{\text{KL}} $$ is the Kullback-Leibler divergence.</p>

      </main>
      <footer class="td-footer row d-print-none">
  <div class="container-fluid">
    <div class="row mx-md-2">
      <div class="td-footer__left col-6 col-sm-4 order-sm-1">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Slack" aria-label="Slack">
    <a target="_blank" rel="noopener" href="https://join.slack.com/t/agones/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="User mailing list" aria-label="User mailing list">
    <a target="_blank" rel="noopener" href="https://groups.google.com/forum/#!forum/agones-discuss" aria-label="User mailing list">
      <i class="fa fa-envelope"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Twitter" aria-label="Twitter">
    <a target="_blank" rel="noopener" href="https://twitter.com/agonesdev" aria-label="Twitter">
      <i class="fab fa-twitter"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Community Meetings" aria-label="Community Meetings">
    <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" aria-label="Community Meetings">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

      </div><div class="td-footer__right col-6 col-sm-4 order-sm-3">
        <ul class="td-footer__links-list">
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="GitHub" aria-label="GitHub">
    <a target="_blank" rel="noopener" href="https://github.com/googleforgames/agones" aria-label="GitHub">
      <i class="fab fa-github"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Slack" aria-label="Slack">
    <a target="_blank" rel="noopener" href="https://join.slack.com/t/agones/shared_invite/zt-2mg1j7ddw-0QYA9IAvFFRKw51ZBK6mkQ" aria-label="Slack">
      <i class="fab fa-slack"></i>
    </a>
  </li>
  
  <li class="td-footer__links-item" data-bs-toggle="tooltip" title="Community Meetings" aria-label="Community Meetings">
    <a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLhkWKwFGACw2dFpdmwxOyUCzlGP2-n7uF" aria-label="Community Meetings">
      <i class="fab fa-youtube"></i>
    </a>
  </li>
  
</ul>

      </div><div class="td-footer__center col-12 col-sm-4 py-2 order-sm-2">
        <span class="td-footer__copyright">&copy;
    2025
    <span class="td-footer__authors">Copyright Google LLC All Rights Reserved.</span></span><span class="td-footer__all_rights_reserved">All Rights Reserved</span><span class="ms-2"><a href="https://policies.google.com/privacy" target="_blank" rel="noopener">Privacy Policy</a></span>
      </div>
    </div>
  </div>
</footer>

    </div>
    <script src="/site/js/main.js"></script>
<script src='/site/js/prism.js'></script>
<script src='/site/js/tabpane-persist.js'></script>
<script src=http://localhost:1313/site/js/asciinema-player.js></script>


<script > 
    (function() {
      var a = document.querySelector("#td-section-nav");
      addEventListener("beforeunload", function(b) {
          localStorage.setItem("menu.scrollTop", a.scrollTop)
      }), a.scrollTop = localStorage.getItem("menu.scrollTop")
    })()
  </script>
  

  </body>
</html>