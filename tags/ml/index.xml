<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>ML on Agones</title>
    <link>http://localhost:1313/tags/ml/</link>
    <description>Recent content in ML on Agones</description>
    <generator>Hugo</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Hari Thapliyaal)</webMaster>
    <lastBuildDate>Thu, 08 May 2025 15:25:42 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ml/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Exploring Graphics Processing Units (GPUs)</title>
      <link>http://localhost:1313/dsblog/Exploring-GPUs/</link>
      <pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-GPUs/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6188-Exploring-GPUs.jpg&#34; alt=&#34;Exploring Graphics Processing Units (GPUs)&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-graphics-processing-units-gpus&#34;&gt;Exploring Graphics Processing Units (GPUs)&lt;/h1&gt;&#xA;&lt;h2 id=&#34;overall-computational-power-of-gpus&#34;&gt;&lt;strong&gt;Overall Computational Power of GPUs&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;⚡ &lt;strong&gt;Incredible Calculation Speed:&lt;/strong&gt; Modern GPUs can perform tens of trillions of calculations per second (e.g., 36 trillion for Cyberpunk 2077).&lt;/li&gt;&#xA;&lt;li&gt;🌍 &lt;strong&gt;Human Comparison:&lt;/strong&gt; Achieving this manually would require the equivalent of over 4,400 Earths full of people, each doing one calculation every second.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;gpu-vs-cpu&#34;&gt;&lt;strong&gt;GPU vs. CPU&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🚢 &lt;strong&gt;Cargo Ship vs. Airplane Analogy:&lt;/strong&gt; GPUs are like cargo ships (massive capacity, slower), and CPUs are like jets (fast, versatile, fewer tasks at once).&lt;/li&gt;&#xA;&lt;li&gt;⚖️ &lt;strong&gt;Different Strengths:&lt;/strong&gt; CPUs handle operating systems, flexible tasks, and fewer but more complex instructions. GPUs excel at huge amounts of simple, repetitive calculations.&lt;/li&gt;&#xA;&lt;li&gt;🔀 &lt;strong&gt;Parallel vs. General Purpose:&lt;/strong&gt; GPUs are less flexible but highly parallel, CPUs are more general-purpose and can run a wide variety of programs and instructions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;gpu-architecture--components-ga102-example&#34;&gt;&lt;strong&gt;GPU Architecture &amp;amp; Components (GA102 Example)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💽 &lt;strong&gt;Central GPU Die (GA102):&lt;/strong&gt; A large chip with 28.3 billion transistors organized into Graphics Processing Clusters (GPCs), Streaming Multiprocessors (SMs), and cores.&lt;/li&gt;&#xA;&lt;li&gt;🏗️ &lt;strong&gt;Hierarchical Structure:&lt;/strong&gt; GA102 has 7 GPCs → 12 SMs per GPC → 4 Warps per SM → 32 CUDA Per Wrap and 4 Tensor Per Warmp and 1 Ray Tracing Per GPC.&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Types of Cores:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;⚙️ CUDA Cores: Handle basic arithmetic (addition, multiplication) most commonly used in gaming.&lt;/li&gt;&#xA;&lt;li&gt;🧩 Tensor Cores: Perform massive matrix calculations for AI and neural networks.&lt;/li&gt;&#xA;&lt;li&gt;💎 Ray Tracing Cores: Specialized for lighting and reflection calculations in real-time graphics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;manufacturing--binning&#34;&gt;&lt;strong&gt;Manufacturing &amp;amp; Binning&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔧 &lt;strong&gt;Shared Chip Design:&lt;/strong&gt; Different GPU models (e.g., 3080, 3090, 3090 Ti) share the same GA102 design.&lt;/li&gt;&#xA;&lt;li&gt;🕳️ &lt;strong&gt;Defects &amp;amp; Binning:&lt;/strong&gt; Manufacturing imperfections result in some cores being disabled. This leads to different “tiers” of the same GPU architecture.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;cuda-core-internals&#34;&gt;&lt;strong&gt;CUDA Core Internals&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;➕ &lt;strong&gt;Simple Calculator Design:&lt;/strong&gt; Each CUDA core is basically a tiny calculator that does fused multiply-add (FMA) and a few other operations.&lt;/li&gt;&#xA;&lt;li&gt;💻 &lt;strong&gt;Common Operations:&lt;/strong&gt; Primarily handles 32-bit floating-point and integer arithmetic. More complex math (division, trignometry) is done by fewer, special function units.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;memory-systems-gddr6x--gddr7&#34;&gt;&lt;strong&gt;Memory Systems: GDDR6X &amp;amp; GDDR7&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💾 &lt;strong&gt;Graphics Memory:&lt;/strong&gt; GDDR6X chips (by Micron) feed terabytes of data per second into the GPU’s thousands of cores.&lt;/li&gt;&#xA;&lt;li&gt;🚀 &lt;strong&gt;High Bandwidth:&lt;/strong&gt; GPU memory operates at huge bandwidths (over 1 terabyte/s) compared to typical CPU memory (~64 GB/s).&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Beyond Binary:&lt;/strong&gt; GDDR6X and GDDR7 use multiple voltage levels (PAM-4 and PAM-3) to encode more data per signal, increasing transfer rates.&lt;/li&gt;&#xA;&lt;li&gt;🏗️ &lt;strong&gt;Future Memory Tech:&lt;/strong&gt; Micron also develops HBM (High Bandwidth Memory) for AI accelerators, stacking memory chips in 3D, greatly boosting capacity and speed while reducing power.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;parallel-computing-concepts-simd--simt&#34;&gt;&lt;strong&gt;Parallel Computing Concepts (SIMD &amp;amp; SIMT)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;♻️ &lt;strong&gt;Embarrassingly Parallel:&lt;/strong&gt; Tasks like graphics rendering, Bitcoin mining, or AI training are easily split into millions of independent calculations.&lt;/li&gt;&#xA;&lt;li&gt;📜 &lt;strong&gt;Single Instruction Multiple Data (SIMD):&lt;/strong&gt; Apply the same instruction to many data points at once—perfect for transforming millions of vertices in a 3D scene.&lt;/li&gt;&#xA;&lt;li&gt;🔓 &lt;strong&gt;From SIMD to SIMT:&lt;/strong&gt; Newer GPUs use Single Instruction Multiple Threads (SIMT), allowing threads to progress independently and handle complex branching more efficiently.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;thread--warp-organization&#34;&gt;&lt;strong&gt;Thread &amp;amp; Warp Organization&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📦 &lt;strong&gt;Thread Hierarchy:&lt;/strong&gt; Threads → Warps (groups of 32 threads) → Thread Blocks → Grids.&lt;/li&gt;&#xA;&lt;li&gt;🎛️ &lt;strong&gt;Gigathread Engine:&lt;/strong&gt; Manages the allocation of thread blocks to streaming multiprocessors, optimizing parallel processing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;practical-applications&#34;&gt;&lt;strong&gt;Practical Applications&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🎮 &lt;strong&gt;Video Games:&lt;/strong&gt; GPUs transform coordinates, apply textures, shading, and handle complex rendering pipelines. Millions of identical operations on different vertices and pixels are done in parallel.&lt;/li&gt;&#xA;&lt;li&gt;₿ &lt;strong&gt;Bitcoin Mining:&lt;/strong&gt; GPUs can run the SHA-256 hashing algorithm in parallel many millions of times per second. Though now replaced by ASIC miners, GPUs were initially very efficient at this.&lt;/li&gt;&#xA;&lt;li&gt;🤖 &lt;strong&gt;AI &amp;amp; Neural Networks:&lt;/strong&gt; Tensor cores accelerate matrix multiplications critical for training neural nets and powering generative AI.&lt;/li&gt;&#xA;&lt;li&gt;💡 &lt;strong&gt;Ray Tracing:&lt;/strong&gt; Specialized cores handle ray tracing calculations for realistic lighting and reflections in real-time graphics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;microns-role--advancements&#34;&gt;&lt;strong&gt;Micron’s Role &amp;amp; Advancements&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🏭 &lt;strong&gt;Micron Memory Chips:&lt;/strong&gt; GDDR6X and future GDDR7 designed by Micron power high-speed data transfers on GPUs.&lt;/li&gt;&#xA;&lt;li&gt;🔮 &lt;strong&gt;Innovations in Memory:&lt;/strong&gt; High Bandwidth Memory (HBM) for AI chips stacks DRAM vertically, creating high-capacity, high-throughput solutions at lower energy costs.&lt;/li&gt;&#xA;&lt;li&gt;📚 &lt;strong&gt;Technological Marvel:&lt;/strong&gt; Modern graphics cards are a blend of advanced materials, clever architectures, and innovative manufacturing. They enable astonishing levels of visual realism, parallel computation, and AI capabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=h9Z4oGN89MU&#34;&gt;How do Graphics Cards Work? Exploring GPU Architecture&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Models and Creators</title>
      <link>http://localhost:1313/dsblog/AI-Models-and-Creators/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Models-and-Creators/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6187-ai-models-and-creators.jpg&#34; alt=&#34;AI Models and Creators&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-models-and-creators&#34;&gt;AI Models and Creators&lt;/h1&gt;&#xA;&lt;h2 id=&#34;popular-models-and-their-creator&#34;&gt;Popular Models and Their Creator&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Nova - Amazon&lt;/li&gt;&#xA;&lt;li&gt;Gemini, Gemma - Google&lt;/li&gt;&#xA;&lt;li&gt;Granite - Oracle&lt;/li&gt;&#xA;&lt;li&gt;GPT - OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Phi - Microsoft Azure&lt;/li&gt;&#xA;&lt;li&gt;Einstein - Salesforce&lt;/li&gt;&#xA;&lt;li&gt;Joule - SAP&lt;/li&gt;&#xA;&lt;li&gt;Grok - X (formerly Twitter)&lt;/li&gt;&#xA;&lt;li&gt;Llama - Meta&lt;/li&gt;&#xA;&lt;li&gt;Qwen - Alibaba&lt;/li&gt;&#xA;&lt;li&gt;Claude - Anthropic&lt;/li&gt;&#xA;&lt;li&gt;Bard - Google&lt;/li&gt;&#xA;&lt;li&gt;PaLM - Google&lt;/li&gt;&#xA;&lt;li&gt;Mistral - Mistral AI&lt;/li&gt;&#xA;&lt;li&gt;Falcon - Technology Innovation Institute (TII), UAE&lt;/li&gt;&#xA;&lt;li&gt;Gato - DeepMind&lt;/li&gt;&#xA;&lt;li&gt;Jasper - Jasper AI&lt;/li&gt;&#xA;&lt;li&gt;Bloom - BigScience (collaborative project)&lt;/li&gt;&#xA;&lt;li&gt;Ernie - Baidu&lt;/li&gt;&#xA;&lt;li&gt;Alpaca - Stanford University (fine-tuned LLaMA model)&lt;/li&gt;&#xA;&lt;li&gt;Stable Diffusion - Stability AI&lt;/li&gt;&#xA;&lt;li&gt;HuggingChat - Hugging Face&lt;/li&gt;&#xA;&lt;li&gt;Cohere of Command&lt;/li&gt;&#xA;&lt;li&gt;Alpha fold of deepmind&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;models-developed-by-microsoft&#34;&gt;Models Developed by Microsoft&lt;/h2&gt;&#xA;&lt;p&gt;Microsoft has developed or collaborated on several AI models and frameworks, especially as part of its Azure AI ecosystem and its partnership with OpenAI. Below is a list of models and AI systems associated with Microsoft:&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI/ML with Oracle Cloud</title>
      <link>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6166-AI-ML-With-Oracle-Cloud.jpg&#34; alt=&#34;AI/ML with Oracle Cloud&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;aiml-with-oracle-cloud&#34;&gt;AI/ML with Oracle Cloud&lt;/h1&gt;&#xA;&lt;h2 id=&#34;oracle-infrastructure-services&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/services.htm&#34;&gt;Oracle Infrastructure Services&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Register for &lt;a href=&#34;https://www.oracle.com/cloud/free/?source=:ow:o:h:po:OHPPanel1nav0625&amp;amp;intcmp=:ow:o:h:po:OHPPanel1nav0625&#34;&gt;Oracle Cloud Free Tier&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;oracle-ai-main-services&#34;&gt;Oracle AI Main services&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cloud.oracle.com/digital-assistant/oda-instances?region=ap-mumbai-1&#34;&gt;Digital Assistant&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/document-understanding/using/home.htm&#34;&gt;Document Understanding&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/language/using/pretrain-models.htm#lang-detect&#34;&gt;Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/vision/using/pretrained-model-using-image.htm&#34;&gt;Vision&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/speech/home.htm&#34;&gt;Speech&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/Streaming/home.htm&#34;&gt;Stream&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/process-automation/oci-process-automation/overview-oci-process-automation.html&#34;&gt;Cloud Infra Automation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;generative-ai&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm&#34;&gt;Generative AI&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Generative AI is a fully managed Oracle Cloud Infrastructure service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, including chat, text generation, summarization, and creating text embeddings.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
