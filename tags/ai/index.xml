<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on Agones</title>
    <link>http://localhost:1313/tags/ai/</link>
    <description>Recent content in AI on Agones</description>
    <generator>Hugo</generator>
    <language>en</language>
    <managingEditor>hari@dasarpai.com (Hari Thapliyaal)</managingEditor>
    <webMaster>hari@dasarpai.com (Hari Thapliyaal)</webMaster>
    <lastBuildDate>Thu, 08 May 2025 15:25:42 +0530</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What is a Digital Twin?</title>
      <link>http://localhost:1313/dsblog/what-is-a-digital-twin/</link>
      <pubDate>Sun, 27 Apr 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/what-is-a-digital-twin/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6268-what-is-a-digital-twin.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;what-is-a-digital-twin&#34;&gt;What is a digital twin?&lt;/h1&gt;&#xA;&lt;p&gt;A digital twin is a &lt;strong&gt;virtual representation&lt;/strong&gt; of a real-world entity or process, created to simulate its behavior and performance. It consists of three main components: representation of the physical entity itself, the digital model that represents it, and the data that links the two (original and twin). Keep in mind the data is generated by model based on the representation of the physical entity. This technology allows users to monitor, analyze, and optimize the performance of physical objects or systems in real-time by providing insights based on data collected from sensors and IoT devices [1][2][3].&lt;/p&gt;</description>
    </item>
    <item>
      <title>Understanding the Working of CNN</title>
      <link>http://localhost:1313/dsblog/understanding-working-of-cnn/</link>
      <pubDate>Wed, 29 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/understanding-working-of-cnn/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6213-Understanding-Working-of-CNN.jpg&#34; alt=&#34;Understanding the Working of CNN&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-the-working-of-cnn&#34;&gt;Understanding the Working of CNN&lt;/h1&gt;&#xA;&lt;p&gt;In this article, we aim to delve deeper into the working of CNNs. This article is intended for readers who have a basic understanding of CNNs and have computation-related questions. If you have any other questions about CNNs, feel free to ask in the comments.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;Questions we are looking into.&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;What is the meaning of convolution in neural network?&lt;/li&gt;&#xA;&lt;li&gt;If there is some convolution layer with 64 kernel (filter) and filter size is 3x3 then does the filter get updated during training process?&lt;/li&gt;&#xA;&lt;li&gt;I heard filters has only 0 and 1 value. Depending upon what we want to extract we use the pattern of 0 and 1 on the filter, like for edge detection, contras detection etc.&lt;/li&gt;&#xA;&lt;li&gt;If a layer with 64 filter has 3x3 filter then how many weights are there?&lt;/li&gt;&#xA;&lt;li&gt;There is very famous 1x1 filter. How many weights are there if it layer has 64 neuron? Why it is more effective?&lt;/li&gt;&#xA;&lt;li&gt;Normally we think channel means number of layer in input image (RGB color). How come we can have 256 channels in neural network?&lt;/li&gt;&#xA;&lt;li&gt;How to calculate output size of convolutional layer?&lt;/li&gt;&#xA;&lt;li&gt;When 3x3x3 filter is applied to 224x224x3 image then how it become 224x224?&lt;/li&gt;&#xA;&lt;li&gt;Earlier we discussed weight of each layer R, G, B is different? When and how these weights are decided?&lt;/li&gt;&#xA;&lt;li&gt;Where do we learn features? At the level of differet layers or different channels (filter)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;what-is-the-meaning-of-convolution-in-neural-network&#34;&gt;What is the meaning of convolution in neural network?&lt;/h2&gt;&#xA;&lt;p&gt;In the context of neural networks, specifically Convolutional Neural Networks (CNNs), &lt;em&gt;convolution&lt;/em&gt; refers to a mathematical operation that combines two functions (or datasets) to produce a third function, typically used to extract features from input data. In simple terms, it’s a way of applying a filter or kernel to an input (like an image) to create a feature map, which highlights important patterns or features such as edges, textures, or shapes.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Computer Vision Research Work</title>
      <link>http://localhost:1313/dsblog/computer-vision-research-work/</link>
      <pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/computer-vision-research-work/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6211-Computer-Vision-Research-Work.jpg&#34; alt=&#34;Computer Vision Research Work&amp;#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;computer-vision-research-work&#34;&gt;Computer Vision Research Work&lt;/h1&gt;&#xA;&lt;p&gt;When we talk about &amp;ldquo;vision&amp;rdquo; capabilities, most people don&amp;rsquo;t understand how complex the brain is in processing the visual spectrum (light signals). What kind of processing happens inside our brain that allows us to understand color, depth, motion, speed, segments, objects, scenes, different kinds of art, drawings, culture, etc.? Until recently, when &amp;ldquo;computer vision&amp;rdquo; became a serious field in AI, only neurology researchers, surgeons, and brain specialists had some insights into these processes. But since 2012 (AlexNet Paper), with new papers being published almost every month, we are constantly learning how far we&amp;rsquo;ve come in computer vision. This article is not only about the chronology of computer vision but also about software engineers, computer scientists, AI engineers, and everyone who wants to understand how their phone performs certain computer visions tasks and becomes intelligent.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring AI Benchmarks &amp; Leaderboards</title>
      <link>http://localhost:1313/dsblog/exploring-ai-benchmarks-and-leaderboards/</link>
      <pubDate>Sun, 26 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-ai-benchmarks-and-leaderboards/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6210-Exploring-AI-Benchmarks-and-Leaderboards.jpg&#34; alt=&#34;Exploring AI Benchmarks &amp;amp; Leaderboards&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-ai-benchmarks--leaderboards&#34;&gt;Exploring AI Benchmarks &amp;amp; Leaderboards&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A &lt;strong&gt;benchmark&lt;/strong&gt; is a standardized test or set of metrics used to measure and compare the performance, capabilities, or quality of systems, models, or algorithms. In the context of &lt;strong&gt;AI and machine learning&lt;/strong&gt;, benchmarks provide a way to evaluate how well models perform on specific tasks or datasets, often with respect to predefined metrics like accuracy, speed, robustness, or resource efficiency.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Types of Models</title>
      <link>http://localhost:1313/dsblog/exploring-types-of-models/</link>
      <pubDate>Sat, 25 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-types-of-models/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6209-Exploring-Types-of-Models.jpg&#34; alt=&#34;Exploring Types of Models&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-different-types-of-models&#34;&gt;Understanding Different Types of Models&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;A model is a simplified representation or abstraction of a system, concept, or phenomenon around us. It is used to analyze, understand, predict, or simulate real-world behavior. Models can take many forms, depending on the context in which they are used. For example you also say that I have created a Data Model, Functional Model, UI Model, Simulation Model etc.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring AI Agents</title>
      <link>http://localhost:1313/dsblog/exploring-ai-agents/</link>
      <pubDate>Thu, 23 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-ai-agents/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6207-Exploring-AI-Agents.jpg&#34; alt=&#34;Exploring AI Agents&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-ai-agents&#34;&gt;Exploring AI Agents&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;As of the start of 2025, we are hearing a lot of buzz around Agents, Workflow, System, AI Employee etc. In this article, we are trying to understand some important concepts around these terms in question answer format. These answers are derived from general AI knowledge, principles, and concepts based on publicly available information about AI agents, workflows, and systems. Specific sources include academic literature, industry whitepapers, and commonly understood practices in AI development and usage.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Product Ideas 2025</title>
      <link>http://localhost:1313/dsblog/AI-Product-Ideas-2025/</link>
      <pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Product-Ideas-2025/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6206-AI-Product-Ideas.jpg&#34; alt=&#34;AI Product Ideas 2025&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-product-ideas&#34;&gt;AI Product Ideas&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;There is a flood of AI products in the market, yet some people are still searching for ideas to get started. The following list of ideas can serve as a good starting point for beginners, and even if you are already established, you may find some of these ideas inspiring.&lt;/p&gt;&#xA;&lt;p&gt;Many of these ideas are available either as features of larger products or as standalone solutions. For example, they may exist as features in generic products like Google Drive, OneDrive, Outlook, or Office 365, or as part of domain-specific products such as Pharma Research tools, Banking CRMs, Loan Processing systems, or Project Requirement Management platforms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI ML Project Ideas</title>
      <link>http://localhost:1313/dsblog/AI-Project-Ideas/</link>
      <pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Project-Ideas/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6205-AI-Project-Ideas.jpg&#34; alt=&#34;AI Project Ideas&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-project-ideas&#34;&gt;AI Project Ideas&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;In your journey of learning and practicing AI project you may find these articles and repositories useful. I found it over many places and compiled them here. Some of the link may break. These are beginner level ideas for AI project. If you are starting your journey then you will find value in exploring these. If you have been seriously for more than 5+ years in AI/ML then your can ignore this article.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Adapting AI Models to the Latest Information: Methods and Approaches</title>
      <link>http://localhost:1313/dsblog/adapting-ai-models-to-the-latest-information/</link>
      <pubDate>Fri, 17 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/adapting-ai-models-to-the-latest-information/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6202-Adapting-AI-Models-to-the-Latest-Information.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;adapting-ai-models-to-the-latest-information-methods-and-approaches&#34;&gt;Adapting AI Models to the Latest Information: Methods and Approaches&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Artificial Intelligence offers numerous advantages over traditional search engines like Google or Bing, but it also has a notable limitation: its knowledge is often frozen in the past. Unless a model is retrained or updated with newly available data, it cannot respond effectively to current business, political, social, or scientific developments.&lt;/p&gt;&#xA;&lt;p&gt;To address this limitation, one popular approach is &lt;strong&gt;Retrieval-Augmented Generation (RAG)&lt;/strong&gt;, a method that combines AI models with up-to-date external data sources. You may have come across RAG frequently in recent discussions about AI advancements.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Navigating Open-Source Licensing in the Age of AI: Challenges and Considerations</title>
      <link>http://localhost:1313/dsblog/navigating-open-source-licensing-in-the-age-of-ai/</link>
      <pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/navigating-open-source-licensing-in-the-age-of-ai/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6201-Navigating-Open-Source-Licensing-in-the-Age-of-AI.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;navigating-open-source-licensing-in-the-age-of-ai-challenges-and-considerations&#34;&gt;Navigating Open-Source Licensing in the Age of AI: Challenges and Considerations&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Software products, at their core, are solutions designed to address specific problems. Just as there are many ways to solve a problem in life, there are numerous ways to design software to tackle the same issue. In software development, you don’t always have to reinvent the wheel—open-source code and third-party APIs provide a wealth of solutions that can be integrated into your project. These resources, developed by various organizations, teams, and individuals over time, can range from generic solutions to highly specialized ones. However, integrating them into your product requires careful thought and consideration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Rethinking AI Infrastructure: Advantages of On-Prem Over Cloud Solutions</title>
      <link>http://localhost:1313/dsblog/cloud-vs-on-premse-ai-solutions-and-infrastructures/</link>
      <pubDate>Wed, 08 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/cloud-vs-on-premse-ai-solutions-and-infrastructures/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6199-Rethinking-AI-Infrastructure-Advantages-of-On-Prem-Over-Cloud-Solutions.jpg&#34; alt=&#34;Cloud vs On-Premse AI Solutions and Infrastructures&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;rethinking-ai-infrastructure-advantages-of-on-prem-over-cloud-solutions&#34;&gt;Rethinking AI Infrastructure: Advantages of On-Prem Over Cloud Solutions&lt;/h1&gt;&#xA;&lt;h2 id=&#34;why-not-to-use-cloud-ai-solutions&#34;&gt;Why Not to Use Cloud AI Solutions?&lt;/h2&gt;&#xA;&lt;p&gt;There are valid reasons for considering alternatives to cloud-based infrastructure when developing AI products or working with sensitive organizational data. Here are some key factors:&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1-data-privacy-and-security&#34;&gt;&lt;strong&gt;1. Data Privacy and Security&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Risk of Data Breach:&lt;/strong&gt; Sensitive organizational data stored in the cloud is at risk of breaches or unauthorized access, either by malicious actors or the cloud provider.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Compliance Concerns:&lt;/strong&gt; Many industries (e.g., healthcare, finance) are subject to strict regulations like GDPR, HIPAA, or CCPA that dictate how and where data can be stored or processed. Cloud providers may not guarantee compliance.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Shared Responsibility:&lt;/strong&gt; Even with cloud services, security is often a shared responsibility between the provider and the user, leaving gaps for vulnerabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2-dependency-on-third-party-providers&#34;&gt;&lt;strong&gt;2. Dependency on Third-Party Providers&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Vendor Lock-In:&lt;/strong&gt; Relying on a specific cloud provider can make it difficult to migrate your infrastructure to another platform, potentially limiting flexibility and increasing costs over time.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Unpredictable Costs:&lt;/strong&gt; Cloud costs can escalate unpredictably, especially for AI workloads that require significant compute resources.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Service Outages:&lt;/strong&gt; Downtime or service interruptions by the cloud provider can directly impact your operations.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;3-latency-and-performance-issues&#34;&gt;&lt;strong&gt;3. Latency and Performance Issues&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Network Latency:&lt;/strong&gt; AI applications that require real-time processing (e.g., autonomous systems or predictive maintenance) may face delays due to data transmission to and from the cloud.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Resource Bottlenecks:&lt;/strong&gt; Shared cloud resources might not always guarantee the performance needed for compute-intensive AI workloads.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;4-cost-concerns&#34;&gt;&lt;strong&gt;4. Cost Concerns&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Recurring Costs:&lt;/strong&gt; Cloud-based infrastructure involves ongoing costs for compute, storage, and data transfer, which can become expensive for large-scale AI projects.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Scaling Costs:&lt;/strong&gt; Scaling up AI models and datasets often incurs higher expenses in the cloud compared to owning on-premises infrastructure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;5-intellectual-property-risks&#34;&gt;&lt;strong&gt;5. Intellectual Property Risks&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Risk of Data Misuse:&lt;/strong&gt; Using third-party AI services could expose your organization’s proprietary data, which might be used to improve the provider’s own AI models without explicit consent.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Loss of Competitive Advantage:&lt;/strong&gt; Storing strategic data externally may give competitors indirect access if they also use the same cloud provider.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;6-ethical-and-operational-independence&#34;&gt;&lt;strong&gt;6. Ethical and Operational Independence&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Regulatory Restrictions:&lt;/strong&gt; Some countries restrict the use of foreign cloud providers for sensitive data, especially in government and defense sectors.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Control Over AI Models:&lt;/strong&gt; Running AI models on your own infrastructure allows greater control over training, inference, and updates, ensuring alignment with organizational goals.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;alternatives&#34;&gt;&lt;strong&gt;Alternatives&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;On-Premises Infrastructure:&lt;/strong&gt; Use on-prem servers with GPU/TPU clusters for sensitive or high-performance workloads.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Hybrid Approach:&lt;/strong&gt; Combine on-premises and cloud infrastructure to balance cost, performance, and data security.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Edge Computing:&lt;/strong&gt; Process data locally on devices to minimize latency and keep sensitive information secure.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;how-to-create-on-premises-infrastructure-for-building-ai-products&#34;&gt;How to create On Premises Infrastructure for Building AI Products&lt;/h2&gt;&#xA;&lt;p&gt;Local or on-premises solutions for developing AI products and using AI with your data provide more control, privacy, and customization options. Here&amp;rsquo;s a breakdown of the key categories and tools/solutions for such setups:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Shaping Tomorrow with AI: Nvidia’s Innovations in Graphics, Robotics, and Intelligence</title>
      <link>http://localhost:1313/dsblog/shaping-tomorrow-with-ai-nvidia/</link>
      <pubDate>Tue, 07 Jan 2025 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/shaping-tomorrow-with-ai-nvidia/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6198-shaping-tomorrow-with-ai-nvidia.jpg&#34; alt=&#34;Shaping Tomorrow with AI: Nvidia’s Innovations in Graphics, Robotics, and Intelligence&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;shaping-tomorrow-with-ai-nvidias-innovations-in-graphics-robotics-and-intelligence&#34;&gt;Shaping Tomorrow with AI: Nvidia’s Innovations in Graphics, Robotics, and Intelligence&lt;/h1&gt;&#xA;&lt;p&gt;This article is based on various online resources, including articles and YouTube videos, but is heavily influenced by the NVIDIA CES 2025 Keynote Speech by Jensen Huang.&lt;/p&gt;&#xA;&lt;h2 id=&#34;what-are-tokens-in-ai-and-how-do-they-serve-as-building-blocks-of-intelligence&#34;&gt;&lt;strong&gt;What are tokens in AI, and how do they serve as building blocks of intelligence?&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;In AI, tokens are fundamental units like words or characters that models process to understand and generate human language, serving as the building blocks of intelligence.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How AlphaFold is Revolutionizing Protein Science</title>
      <link>http://localhost:1313/dsblog/How-AlphaFold-is-Revolutionizing-Protein-Science/</link>
      <pubDate>Sat, 28 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/How-AlphaFold-is-Revolutionizing-Protein-Science/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6194-How-AlphaFold-is-Revolutionizing-Protein-Science.jpg&#34; alt=&#34; Answering Big Questions with AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;how-alphafold-is-revolutionizing-protein-science-answering-big-questions-with-ai&#34;&gt;How AlphaFold is Revolutionizing Protein Science: Answering Big Questions with AI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;h3 id=&#34;what-are-proteins-and-why-are-they-important-for-life-&#34;&gt;What are proteins, and why are they important for life? 🧬&lt;/h3&gt;&#xA;&lt;p&gt;Proteins are the workhorses of life. Found in every cell, they perform vital roles such as providing structural support, enabling biochemical reactions, and defending the body against pathogens. Without proteins, life as we know it would not exist.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;how-do-amino-acids-form-proteins-&#34;&gt;How do amino acids form proteins? 🧩&lt;/h3&gt;&#xA;&lt;p&gt;Proteins are composed of amino acids, the building blocks of life. These 20 amino acids combine in specific sequences to create unique proteins. The sequence determines a protein&amp;rsquo;s structure and function, much like letters in words.&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI 12 Days 2024 Announcements</title>
      <link>http://localhost:1313/dsblog/OpenAI-12-Days-2024-Announcements/</link>
      <pubDate>Sun, 22 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/OpenAI-12-Days-2024-Announcements/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6193-OpenAI-12-Days-2024-Announcements.jpg&#34; alt=&#34;OpenAI 12 Days 2024 Announcements&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;openai-12-days-2024-announcements&#34;&gt;OpenAI 12 Days 2024 Announcements&lt;/h1&gt;&#xA;&lt;h2 id=&#34;day-1--announcements&#34;&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=iBfQTnA2n2s&#34;&gt;Day 1- Announcements&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Launch of o1 Full Version&lt;/strong&gt;: This is an upgraded model designed to be faster, smarter, and multimodal, responding better to instructions. It shows significant improvement over its predecessor, especially in coding and problem-solving tasks.&lt;/p&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Introduction of ChatGPT Pro&lt;/strong&gt;: A new subscription tier priced at $200/month offering unlimited access to OpenAI&amp;rsquo;s models, including advanced features like voice mode and o1 PR mode. The PR mode is intended for the most challenging problems, providing even higher performance capabilities.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Framework for using LLM</title>
      <link>http://localhost:1313/dsblog/Framework-for-using-LLM/</link>
      <pubDate>Tue, 17 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Framework-for-using-LLM/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6192-Framework-for-using-LLM.jpg&#34; alt=&#34;Framework for using LLM&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;maximizing-your-llm-project-a-comprehensive-guide-to-effective-prompt-types&#34;&gt;Maximizing Your LLM Project: A Comprehensive Guide to Effective Prompt Types&lt;/h1&gt;&#xA;&lt;p&gt;When working on a project that leverages Large Language Models (LLMs), selecting the right model and prompt type can be daunting. With thousands of models, hundreds of tasks, and numerous output formats available, it&amp;rsquo;s easy to feel overwhelmed. This article aims to simplify your decision-making process by outlining the major types of prompts you can utilize to enhance your project’s effectiveness.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Imperialism: Western Dominance and the Future of Global Technology </title>
      <link>http://localhost:1313/dsblog/AI-Imperialism/</link>
      <pubDate>Mon, 16 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Imperialism/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6191-AI-Imperialism.jpg&#34; alt=&#34;AI Imperialism&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-imperialism-western-dominance-and-the-future-of-global-technology&#34;&gt;AI Imperialism: Western Dominance and the Future of Global Technology&lt;/h1&gt;&#xA;&lt;p&gt;In the rapidly evolving landscape of artificial intelligence (AI), the emergence of transformer models has marked a significant milestone. Among these, OpenAI&amp;rsquo;s GPT-3 stands out as a groundbreaking achievement, yet its dominance raises critical questions about the concentration of power, legal ambiguities, and global technological equity. This article delves into the phenomenon of AI imperialism, exploring how Western dominance shapes the future of global technology and the implications for developing nations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Visualizing Transformers and Attention</title>
      <link>http://localhost:1313/dsblog/Visualizing-transformers-and-attention/</link>
      <pubDate>Fri, 13 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Visualizing-transformers-and-attention/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6189-Visualizing-transformers-and-attention.jpg&#34; alt=&#34;Visualizing transformers and attention&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;visualizing-transformers-and-attention&#34;&gt;Visualizing Transformers and Attention&lt;/h1&gt;&#xA;&lt;p&gt;This is the summary note from Grant Sanderson&amp;rsquo;s talk at TNG Big Tech 2024. My earlir article on transformers can be found &lt;a href=&#34;http://localhost:1313/dsblog/transformers-demystified-a-step-by-step-guide&#34;&gt;here&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;transformers-and-their-flexibility&#34;&gt;&lt;strong&gt;Transformers and Their Flexibility&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📜 &lt;strong&gt;Origin:&lt;/strong&gt; Introduced in 2017 in the &amp;ldquo;Attention is All You Need&amp;rdquo; paper, originally for machine translation.&lt;/li&gt;&#xA;&lt;li&gt;🌍 &lt;strong&gt;Applications Beyond Translation:&lt;/strong&gt; Used in transcription (e.g., Whisper), text-to-speech, and even image classification.&lt;/li&gt;&#xA;&lt;li&gt;🤖 &lt;strong&gt;Chatbot Models:&lt;/strong&gt; Focused on models trained to predict the next token in a sequence, generating text iteratively one token at a time.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;next-token-prediction-and-creativity&#34;&gt;&lt;strong&gt;Next Token Prediction and Creativity&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔮 &lt;strong&gt;Prediction Process:&lt;/strong&gt; Predicts probabilities for possible next tokens, selects one, and repeats the process.&lt;/li&gt;&#xA;&lt;li&gt;🌡️ &lt;strong&gt;Temperature Control:&lt;/strong&gt; Adjusting randomness in token selection affects creativity vs. predictability in outputs.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;tokens-and-tokenization&#34;&gt;&lt;strong&gt;Tokens and Tokenization&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🧩 &lt;strong&gt;What are Tokens?&lt;/strong&gt; Subdivisions of input data (words, subwords, punctuation, or image patches).&lt;/li&gt;&#xA;&lt;li&gt;🔡 &lt;strong&gt;Why Not Characters?&lt;/strong&gt; Using characters increases context size and computational complexity; tokens balance meaning and computational efficiency.&lt;/li&gt;&#xA;&lt;li&gt;📖 &lt;strong&gt;Byte Pair Encoding (BPE):&lt;/strong&gt; A common method for tokenization.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;embedding-tokens-into-vectors&#34;&gt;&lt;strong&gt;Embedding Tokens into Vectors&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📏 &lt;strong&gt;Embedding:&lt;/strong&gt; Tokens are mapped to high-dimensional vectors representing their meaning.&lt;/li&gt;&#xA;&lt;li&gt;🗺️ &lt;strong&gt;Contextual Meaning:&lt;/strong&gt; Vectors evolve through the network to capture context, disambiguate meaning, and encode relationships.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;the-attention-mechanism&#34;&gt;&lt;strong&gt;The Attention Mechanism&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔍 &lt;strong&gt;Purpose:&lt;/strong&gt; Enables tokens to &amp;ldquo;attend&amp;rdquo; to others, updating their vectors based on relevance.&lt;/li&gt;&#xA;&lt;li&gt;🔑 &lt;strong&gt;Key Components:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Query Matrix: Encodes what a token is &amp;ldquo;looking for.&amp;rdquo;&lt;/li&gt;&#xA;&lt;li&gt;Key Matrix: Encodes how a token responds to queries.&lt;/li&gt;&#xA;&lt;li&gt;Value Matrix: Encodes information passed between tokens.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;🧮 &lt;strong&gt;Calculations:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Dot Product: Measures alignment between keys and queries.&lt;/li&gt;&#xA;&lt;li&gt;Softmax: Converts dot products into normalized weights for updates.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;⛓️ &lt;strong&gt;Masked Attention:&lt;/strong&gt; Ensures causality by blocking future tokens from influencing past ones.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;multi-headed-attention&#34;&gt;&lt;strong&gt;Multi-Headed Attention&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💡 &lt;strong&gt;Parallel Heads:&lt;/strong&gt; Multiple attention heads allow different types of relationships (e.g., grammar, semantic context) to be processed simultaneously.&lt;/li&gt;&#xA;&lt;li&gt;🚀 &lt;strong&gt;Efficiency on GPUs:&lt;/strong&gt; Designed to maximize parallelization for faster computation.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;multi-layer-perceptrons-mlps&#34;&gt;&lt;strong&gt;Multi-Layer Perceptrons (MLPs)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🤔 &lt;strong&gt;Role in Transformers:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Add capacity for general knowledge and non-contextual reasoning.&lt;/li&gt;&#xA;&lt;li&gt;Store facts learned during training, e.g., associations like &amp;ldquo;Michael Jordan plays basketball.&amp;rdquo;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Parameters:&lt;/strong&gt; MLPs hold the majority of the model’s parameters.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;training-transformers&#34;&gt;&lt;strong&gt;Training Transformers&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📚 &lt;strong&gt;Learning Framework:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Models are trained on vast datasets using next-token prediction, requiring no manual labels.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Cost Function:&lt;/strong&gt; Measures prediction accuracy using negative log probabilities, guiding parameter updates.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;🏔️ &lt;strong&gt;Optimization:&lt;/strong&gt; Gradient descent navigates a high-dimensional cost surface to minimize error.&lt;/li&gt;&#xA;&lt;li&gt;🌐 &lt;strong&gt;Pretraining:&lt;/strong&gt; Allows large-scale unsupervised learning before fine-tuning with human feedback.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;embedding-space-and-high-dimensions&#34;&gt;&lt;strong&gt;Embedding Space and High Dimensions&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔄 &lt;strong&gt;Semantic Clusters:&lt;/strong&gt; Similar words cluster together; directions in the space encode relationships (e.g., gender: King - Male + Female = Queen).&lt;/li&gt;&#xA;&lt;li&gt;🌌 &lt;strong&gt;High Dimensionality:&lt;/strong&gt; Embedding spaces have thousands of dimensions, enabling distinct representations of complex concepts.&lt;/li&gt;&#xA;&lt;li&gt;📈 &lt;strong&gt;Scaling Efficiency:&lt;/strong&gt; High-dimensional spaces allow exponentially more &amp;ldquo;almost orthogonal&amp;rdquo; directions for encoding meanings.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;practical-applications&#34;&gt;&lt;strong&gt;Practical Applications&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;✍️ &lt;strong&gt;Language Models:&lt;/strong&gt; Effective for chatbots, summarization, and more due to their generality and parallel processing.&lt;/li&gt;&#xA;&lt;li&gt;🖼️ &lt;strong&gt;Multimodal Models:&lt;/strong&gt; Transformers can integrate text, images, and sound by treating all as tokens in a unified framework.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;challenges-and-limitations&#34;&gt;&lt;strong&gt;Challenges and Limitations&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📏 &lt;strong&gt;Context Size Limitations:&lt;/strong&gt; Attention grows quadratically with context size, requiring optimization for large contexts.&lt;/li&gt;&#xA;&lt;li&gt;♻️ &lt;strong&gt;Inference Redundancy:&lt;/strong&gt; Token-by-token generation can involve redundant computations; caching mitigates this at inference time.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;engineering-and-design&#34;&gt;&lt;strong&gt;Engineering and Design&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🛠️ &lt;strong&gt;Hardware Optimization:&lt;/strong&gt; Transformers are designed to exploit GPUs&amp;rsquo; parallelism for efficient matrix multiplication.&lt;/li&gt;&#xA;&lt;li&gt;🔗 &lt;strong&gt;Residual Connections:&lt;/strong&gt; Baked into the architecture to enhance stability and ease of training.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;the-power-of-scale&#34;&gt;&lt;strong&gt;The Power of Scale&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📈 &lt;strong&gt;Scaling Laws:&lt;/strong&gt; Larger models and more data improve performance, often qualitatively.&lt;/li&gt;&#xA;&lt;li&gt;🔄 &lt;strong&gt;Self-Supervised Pretraining:&lt;/strong&gt; Enables training on vast unlabeled datasets before fine-tuning.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;bpe-byte-pair-encoding&#34;&gt;&lt;strong&gt;BPE (Byte Pair Encoding)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;BPE is a widely used tokenization method in natural language processing (NLP) and machine learning. It is designed to balance between breaking text into characters and full words by representing text as a sequence of subword units. This approach helps models handle rare and unseen words effectively while keeping the vocabulary size manageable.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring Graphics Processing Units (GPUs)</title>
      <link>http://localhost:1313/dsblog/Exploring-GPUs/</link>
      <pubDate>Thu, 12 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Exploring-GPUs/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6188-Exploring-GPUs.jpg&#34; alt=&#34;Exploring Graphics Processing Units (GPUs)&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-graphics-processing-units-gpus&#34;&gt;Exploring Graphics Processing Units (GPUs)&lt;/h1&gt;&#xA;&lt;h2 id=&#34;overall-computational-power-of-gpus&#34;&gt;&lt;strong&gt;Overall Computational Power of GPUs&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;⚡ &lt;strong&gt;Incredible Calculation Speed:&lt;/strong&gt; Modern GPUs can perform tens of trillions of calculations per second (e.g., 36 trillion for Cyberpunk 2077).&lt;/li&gt;&#xA;&lt;li&gt;🌍 &lt;strong&gt;Human Comparison:&lt;/strong&gt; Achieving this manually would require the equivalent of over 4,400 Earths full of people, each doing one calculation every second.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;gpu-vs-cpu&#34;&gt;&lt;strong&gt;GPU vs. CPU&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🚢 &lt;strong&gt;Cargo Ship vs. Airplane Analogy:&lt;/strong&gt; GPUs are like cargo ships (massive capacity, slower), and CPUs are like jets (fast, versatile, fewer tasks at once).&lt;/li&gt;&#xA;&lt;li&gt;⚖️ &lt;strong&gt;Different Strengths:&lt;/strong&gt; CPUs handle operating systems, flexible tasks, and fewer but more complex instructions. GPUs excel at huge amounts of simple, repetitive calculations.&lt;/li&gt;&#xA;&lt;li&gt;🔀 &lt;strong&gt;Parallel vs. General Purpose:&lt;/strong&gt; GPUs are less flexible but highly parallel, CPUs are more general-purpose and can run a wide variety of programs and instructions.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;gpu-architecture--components-ga102-example&#34;&gt;&lt;strong&gt;GPU Architecture &amp;amp; Components (GA102 Example)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💽 &lt;strong&gt;Central GPU Die (GA102):&lt;/strong&gt; A large chip with 28.3 billion transistors organized into Graphics Processing Clusters (GPCs), Streaming Multiprocessors (SMs), and cores.&lt;/li&gt;&#xA;&lt;li&gt;🏗️ &lt;strong&gt;Hierarchical Structure:&lt;/strong&gt; GA102 has 7 GPCs → 12 SMs per GPC → 4 Warps per SM → 32 CUDA Per Wrap and 4 Tensor Per Warmp and 1 Ray Tracing Per GPC.&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Types of Cores:&lt;/strong&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;⚙️ CUDA Cores: Handle basic arithmetic (addition, multiplication) most commonly used in gaming.&lt;/li&gt;&#xA;&lt;li&gt;🧩 Tensor Cores: Perform massive matrix calculations for AI and neural networks.&lt;/li&gt;&#xA;&lt;li&gt;💎 Ray Tracing Cores: Specialized for lighting and reflection calculations in real-time graphics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;manufacturing--binning&#34;&gt;&lt;strong&gt;Manufacturing &amp;amp; Binning&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🔧 &lt;strong&gt;Shared Chip Design:&lt;/strong&gt; Different GPU models (e.g., 3080, 3090, 3090 Ti) share the same GA102 design.&lt;/li&gt;&#xA;&lt;li&gt;🕳️ &lt;strong&gt;Defects &amp;amp; Binning:&lt;/strong&gt; Manufacturing imperfections result in some cores being disabled. This leads to different “tiers” of the same GPU architecture.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;cuda-core-internals&#34;&gt;&lt;strong&gt;CUDA Core Internals&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;➕ &lt;strong&gt;Simple Calculator Design:&lt;/strong&gt; Each CUDA core is basically a tiny calculator that does fused multiply-add (FMA) and a few other operations.&lt;/li&gt;&#xA;&lt;li&gt;💻 &lt;strong&gt;Common Operations:&lt;/strong&gt; Primarily handles 32-bit floating-point and integer arithmetic. More complex math (division, trignometry) is done by fewer, special function units.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;memory-systems-gddr6x--gddr7&#34;&gt;&lt;strong&gt;Memory Systems: GDDR6X &amp;amp; GDDR7&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;💾 &lt;strong&gt;Graphics Memory:&lt;/strong&gt; GDDR6X chips (by Micron) feed terabytes of data per second into the GPU’s thousands of cores.&lt;/li&gt;&#xA;&lt;li&gt;🚀 &lt;strong&gt;High Bandwidth:&lt;/strong&gt; GPU memory operates at huge bandwidths (over 1 terabyte/s) compared to typical CPU memory (~64 GB/s).&lt;/li&gt;&#xA;&lt;li&gt;🔢 &lt;strong&gt;Beyond Binary:&lt;/strong&gt; GDDR6X and GDDR7 use multiple voltage levels (PAM-4 and PAM-3) to encode more data per signal, increasing transfer rates.&lt;/li&gt;&#xA;&lt;li&gt;🏗️ &lt;strong&gt;Future Memory Tech:&lt;/strong&gt; Micron also develops HBM (High Bandwidth Memory) for AI accelerators, stacking memory chips in 3D, greatly boosting capacity and speed while reducing power.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;parallel-computing-concepts-simd--simt&#34;&gt;&lt;strong&gt;Parallel Computing Concepts (SIMD &amp;amp; SIMT)&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;♻️ &lt;strong&gt;Embarrassingly Parallel:&lt;/strong&gt; Tasks like graphics rendering, Bitcoin mining, or AI training are easily split into millions of independent calculations.&lt;/li&gt;&#xA;&lt;li&gt;📜 &lt;strong&gt;Single Instruction Multiple Data (SIMD):&lt;/strong&gt; Apply the same instruction to many data points at once—perfect for transforming millions of vertices in a 3D scene.&lt;/li&gt;&#xA;&lt;li&gt;🔓 &lt;strong&gt;From SIMD to SIMT:&lt;/strong&gt; Newer GPUs use Single Instruction Multiple Threads (SIMT), allowing threads to progress independently and handle complex branching more efficiently.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;thread--warp-organization&#34;&gt;&lt;strong&gt;Thread &amp;amp; Warp Organization&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;📦 &lt;strong&gt;Thread Hierarchy:&lt;/strong&gt; Threads → Warps (groups of 32 threads) → Thread Blocks → Grids.&lt;/li&gt;&#xA;&lt;li&gt;🎛️ &lt;strong&gt;Gigathread Engine:&lt;/strong&gt; Manages the allocation of thread blocks to streaming multiprocessors, optimizing parallel processing.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;practical-applications&#34;&gt;&lt;strong&gt;Practical Applications&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🎮 &lt;strong&gt;Video Games:&lt;/strong&gt; GPUs transform coordinates, apply textures, shading, and handle complex rendering pipelines. Millions of identical operations on different vertices and pixels are done in parallel.&lt;/li&gt;&#xA;&lt;li&gt;₿ &lt;strong&gt;Bitcoin Mining:&lt;/strong&gt; GPUs can run the SHA-256 hashing algorithm in parallel many millions of times per second. Though now replaced by ASIC miners, GPUs were initially very efficient at this.&lt;/li&gt;&#xA;&lt;li&gt;🤖 &lt;strong&gt;AI &amp;amp; Neural Networks:&lt;/strong&gt; Tensor cores accelerate matrix multiplications critical for training neural nets and powering generative AI.&lt;/li&gt;&#xA;&lt;li&gt;💡 &lt;strong&gt;Ray Tracing:&lt;/strong&gt; Specialized cores handle ray tracing calculations for realistic lighting and reflections in real-time graphics.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;microns-role--advancements&#34;&gt;&lt;strong&gt;Micron’s Role &amp;amp; Advancements&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;🏭 &lt;strong&gt;Micron Memory Chips:&lt;/strong&gt; GDDR6X and future GDDR7 designed by Micron power high-speed data transfers on GPUs.&lt;/li&gt;&#xA;&lt;li&gt;🔮 &lt;strong&gt;Innovations in Memory:&lt;/strong&gt; High Bandwidth Memory (HBM) for AI chips stacks DRAM vertically, creating high-capacity, high-throughput solutions at lower energy costs.&lt;/li&gt;&#xA;&lt;li&gt;📚 &lt;strong&gt;Technological Marvel:&lt;/strong&gt; Modern graphics cards are a blend of advanced materials, clever architectures, and innovative manufacturing. They enable astonishing levels of visual realism, parallel computation, and AI capabilities.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=h9Z4oGN89MU&#34;&gt;How do Graphics Cards Work? Exploring GPU Architecture&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Models and Creators</title>
      <link>http://localhost:1313/dsblog/AI-Models-and-Creators/</link>
      <pubDate>Tue, 10 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Models-and-Creators/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6187-ai-models-and-creators.jpg&#34; alt=&#34;AI Models and Creators&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-models-and-creators&#34;&gt;AI Models and Creators&lt;/h1&gt;&#xA;&lt;h2 id=&#34;popular-models-and-their-creator&#34;&gt;Popular Models and Their Creator&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Nova - Amazon&lt;/li&gt;&#xA;&lt;li&gt;Gemini, Gemma - Google&lt;/li&gt;&#xA;&lt;li&gt;Granite - Oracle&lt;/li&gt;&#xA;&lt;li&gt;GPT - OpenAI&lt;/li&gt;&#xA;&lt;li&gt;Phi - Microsoft Azure&lt;/li&gt;&#xA;&lt;li&gt;Einstein - Salesforce&lt;/li&gt;&#xA;&lt;li&gt;Joule - SAP&lt;/li&gt;&#xA;&lt;li&gt;Grok - X (formerly Twitter)&lt;/li&gt;&#xA;&lt;li&gt;Llama - Meta&lt;/li&gt;&#xA;&lt;li&gt;Qwen - Alibaba&lt;/li&gt;&#xA;&lt;li&gt;Claude - Anthropic&lt;/li&gt;&#xA;&lt;li&gt;Bard - Google&lt;/li&gt;&#xA;&lt;li&gt;PaLM - Google&lt;/li&gt;&#xA;&lt;li&gt;Mistral - Mistral AI&lt;/li&gt;&#xA;&lt;li&gt;Falcon - Technology Innovation Institute (TII), UAE&lt;/li&gt;&#xA;&lt;li&gt;Gato - DeepMind&lt;/li&gt;&#xA;&lt;li&gt;Jasper - Jasper AI&lt;/li&gt;&#xA;&lt;li&gt;Bloom - BigScience (collaborative project)&lt;/li&gt;&#xA;&lt;li&gt;Ernie - Baidu&lt;/li&gt;&#xA;&lt;li&gt;Alpaca - Stanford University (fine-tuned LLaMA model)&lt;/li&gt;&#xA;&lt;li&gt;Stable Diffusion - Stability AI&lt;/li&gt;&#xA;&lt;li&gt;HuggingChat - Hugging Face&lt;/li&gt;&#xA;&lt;li&gt;Cohere of Command&lt;/li&gt;&#xA;&lt;li&gt;Alpha fold of deepmind&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;models-developed-by-microsoft&#34;&gt;Models Developed by Microsoft&lt;/h2&gt;&#xA;&lt;p&gt;Microsoft has developed or collaborated on several AI models and frameworks, especially as part of its Azure AI ecosystem and its partnership with OpenAI. Below is a list of models and AI systems associated with Microsoft:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Serverless LLM Deployment Platform</title>
      <link>http://localhost:1313/dsblog/serverless-llm-deployment/</link>
      <pubDate>Sun, 08 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/serverless-llm-deployment/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6185-Serverless-LLM-Deployment.jpg&#34; alt=&#34;Serverless-LLM-Deployment&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;serverless-llm-deployment-platform&#34;&gt;Serverless LLM Deployment Platform&lt;/h1&gt;&#xA;&lt;h2 id=&#34;microsoft&#34;&gt;&lt;strong&gt;Microsoft&amp;rsquo;s Serverless LLM Deployment Platform&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;h3 id=&#34;azure-openai-service&#34;&gt;&lt;strong&gt;Azure OpenAI Service&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;p&gt;&lt;strong&gt;Azure OpenAI Service&lt;/strong&gt; is Microsoft&amp;rsquo;s answer to serverless LLM deployment. It provides access to powerful language models, including OpenAI&amp;rsquo;s GPT-4, GPT-3.5, Codex, and DALL-E, within the Azure ecosystem. It simplifies the process of integrating and deploying LLMs in a serverless manner.&lt;/p&gt;&#xA;&lt;h3 id=&#34;key-features&#34;&gt;&lt;strong&gt;Key Features:&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Serverless Deployment&lt;/strong&gt;:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Fully managed platform—no need to manage infrastructure.&lt;/li&gt;&#xA;&lt;li&gt;Automatically scales based on workload and demand.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;Pre-Trained LLMs&lt;/strong&gt;:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Google AI Studio vs Vertex AI</title>
      <link>http://localhost:1313/dsblog/google-ai-studio-vs-vertexai/</link>
      <pubDate>Fri, 06 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/google-ai-studio-vs-vertexai/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6183-Google-AI-Studio-vs-VertexAI.jpg&#34; alt=&#34;Google AI Studio vs Vertex AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;google-ai-studio-vs-vertex-ai&#34;&gt;Google AI Studio vs Vertex AI&lt;/h1&gt;&#xA;&lt;p&gt;The difference between &lt;strong&gt;Vertex AI&lt;/strong&gt; and &lt;strong&gt;Google AI Studio&lt;/strong&gt; lies in their scope, functionality, and target audiences within Google&amp;rsquo;s suite of AI tools.&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h2 id=&#34;1-vertex-ai&#34;&gt;&lt;strong&gt;1. Vertex AI&lt;/strong&gt;&lt;/h2&gt;&#xA;&lt;p&gt;&lt;strong&gt;Vertex AI&lt;/strong&gt; is Google&amp;rsquo;s &lt;strong&gt;end-to-end AI platform&lt;/strong&gt; for machine learning (ML) and AI model development, training, deployment, and management. It is designed for developers and data scientists who want a comprehensive environment to build, deploy, and scale ML models.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to NVIDIA and Products</title>
      <link>http://localhost:1313/dsblog/introduction-nvidia-products/</link>
      <pubDate>Thu, 05 Dec 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/introduction-nvidia-products/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6182-Introduction-NVIDIA-Products.jpg&#34; alt=&#34;Introduction-NVIDIA-Products&#34;&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;nvidia-timeline&#34;&gt;NVIDIA Timeline&lt;/h2&gt;&#xA;&lt;p&gt;NVIDIA Corporation has an illustrious history since its founding in 1993. It started as a graphics processing pioneer and has grown into a global leader in AI, gaming, data center technologies, and more. Here&amp;rsquo;s a timeline of key milestones and activities:&lt;/p&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;1993-1999-founding-and-early-innovations&#34;&gt;&lt;strong&gt;1993-1999: Founding and Early Innovations&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;1993:&lt;/strong&gt; NVIDIA was founded by Jensen Huang, Chris Malachowsky, and Curtis Priem in Santa Clara, California, with a focus on graphics processing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1995:&lt;/strong&gt; Launched the &lt;strong&gt;NV1&lt;/strong&gt;, the company’s first graphics chip, which supported both 2D and 3D graphics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;1999:&lt;/strong&gt; Introduced the &lt;strong&gt;GeForce 256&lt;/strong&gt;, the world&amp;rsquo;s first GPU, which revolutionized graphics processing by offloading 3D rendering tasks from the CPU.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;hr&gt;&#xA;&lt;h3 id=&#34;2000-2009-expanding-into-gaming-and-professional-graphics&#34;&gt;&lt;strong&gt;2000-2009: Expanding into Gaming and Professional Graphics&lt;/strong&gt;&lt;/h3&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;2000:&lt;/strong&gt; NVIDIA acquired 3dfx, a leading graphics company, consolidating its dominance in the GPU market.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2002:&lt;/strong&gt; Released the &lt;strong&gt;GeForce4&lt;/strong&gt; series, establishing itself as a leader in gaming GPUs.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2004:&lt;/strong&gt; Entered the professional graphics market with the &lt;strong&gt;Quadro FX&lt;/strong&gt; series.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2006:&lt;/strong&gt; Launched &lt;strong&gt;CUDA&lt;/strong&gt;, a parallel computing platform enabling developers to use NVIDIA GPUs for general-purpose computing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;2008:&lt;/strong&gt; Introduced the &lt;strong&gt;Tesla series&lt;/strong&gt;, targeting high-performance computing (HPC) and AI research.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h4 id=&#34;fun-fact&#34;&gt;Fun Fact:&lt;/h4&gt;&#xA;&lt;p&gt;Tesla, Inc. (originally Tesla Motors), founded in 2003, is named after Nikola Tesla as well, acknowledging his contributions to electrical systems. Interestingly, NVIDIA and Tesla, Inc. later had a professional relationship. NVIDIA GPUs were used in Tesla&amp;rsquo;s early Autopilot systems, although Tesla later transitioned to building its own custom AI chips.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring GGUF and Other Model Formats</title>
      <link>http://localhost:1313/dsblog/exploring-gguf-and-other-model-formats/</link>
      <pubDate>Tue, 12 Nov 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-gguf-and-other-model-formats/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6180-exploring-gguf.jpg&#34; alt=&#34;Understanding GGUF and Other Model Formats in Machine Learning&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;understanding-gguf-and-other-model-formats-in-machine-learning&#34;&gt;&lt;strong&gt;Understanding GGUF and Other Model Formats in Machine Learning&lt;/strong&gt;&lt;/h1&gt;&#xA;&lt;p&gt;As machine learning models continue to grow in complexity, the need for efficient, flexible, and versatile model formats becomes more pronounced. While formats like ONNX, TensorFlow’s SavedModel, and PyTorch’s native format have been around for some time, newer formats like GGUF are gaining attention for their unique benefits. This article explores these formats, their use cases, and how they support various aspects of machine learning, including deployment, compatibility, and optimization.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Exploring AnythingLLM</title>
      <link>http://localhost:1313/dsblog/exploring-anythingllm/</link>
      <pubDate>Mon, 11 Nov 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/exploring-anythingllm/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6179-exploring-anythingllm.jpg&#34; alt=&#34;Exploring AnythingLLM &#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;exploring-anythingllm&#34;&gt;Exploring AnythingLLM&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-anythingllm&#34;&gt;What is AnythingLLM?&lt;/h2&gt;&#xA;&lt;p&gt;AnythingLLM is an open-source project developed by Mintplex Labs that offers a highly flexible platform for creating personalized language models and knowledge databases. It operates using Retrieval-Augmented Generation (RAG), which combines language models with data from custom document collections. AnythingLLM supports embedding models (e.g., BERT), language models, and vector databases to index and query data, allowing users to fine-tune or deploy various models tailored to their needs, from local deployments to cloud integrations with OpenAI or Azure OpenAI.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI/ML with Oracle Cloud</title>
      <link>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</link>
      <pubDate>Sat, 19 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-ML-With-Oracle-Cloud/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6166-AI-ML-With-Oracle-Cloud.jpg&#34; alt=&#34;AI/ML with Oracle Cloud&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;aiml-with-oracle-cloud&#34;&gt;AI/ML with Oracle Cloud&lt;/h1&gt;&#xA;&lt;h2 id=&#34;oracle-infrastructure-services&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/services.htm&#34;&gt;Oracle Infrastructure Services&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Register for &lt;a href=&#34;https://www.oracle.com/cloud/free/?source=:ow:o:h:po:OHPPanel1nav0625&amp;amp;intcmp=:ow:o:h:po:OHPPanel1nav0625&#34;&gt;Oracle Cloud Free Tier&lt;/a&gt;&lt;/p&gt;&#xA;&lt;h2 id=&#34;oracle-ai-main-services&#34;&gt;Oracle AI Main services&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cloud.oracle.com/digital-assistant/oda-instances?region=ap-mumbai-1&#34;&gt;Digital Assistant&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/document-understanding/using/home.htm&#34;&gt;Document Understanding&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/language/using/pretrain-models.htm#lang-detect&#34;&gt;Language&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/vision/using/pretrained-model-using-image.htm&#34;&gt;Vision&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/speech/home.htm&#34;&gt;Speech&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/Streaming/home.htm&#34;&gt;Stream&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/process-automation/oci-process-automation/overview-oci-process-automation.html&#34;&gt;Cloud Infra Automation&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;generative-ai&#34;&gt;&lt;a href=&#34;https://docs.oracle.com/en-us/iaas/Content/generative-ai/home.htm&#34;&gt;Generative AI&lt;/a&gt;&lt;/h2&gt;&#xA;&lt;p&gt;Generative AI is a fully managed Oracle Cloud Infrastructure service that provides a set of state-of-the-art, customizable large language models (LLMs) that cover a wide range of use cases, including chat, text generation, summarization, and creating text embeddings.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Perplexity AI</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Perplexity-AI/</link>
      <pubDate>Tue, 08 Oct 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Perplexity-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6156-Introduction-to-Perplexity-AI.jpg&#34; alt=&#34;Introduction to Perplexity AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction-to-perplexity-ai&#34;&gt;Introduction to Perplexity AI&lt;/h1&gt;&#xA;&lt;h2 id=&#34;what-is-perplexity-ai&#34;&gt;What is Perplexity AI?&lt;/h2&gt;&#xA;&lt;p&gt;Perplexity AI Founded in 2022 is based in San Francisco, California. Perplexity AI is an AI-powered search engine that uses a large language model to answer questions and provide information. It is a free, open-source search engine that is built on top of the latest advancements in AI and natural language processing. Perplexity AI distinguishes itself as a unique blend of a search engine and an AI chatbot, offering several features that set it apart from traditional search engines like Google and other AI models such as ChatGPT.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AI Usecases in Cybersecurity</title>
      <link>http://localhost:1313/dsblog/AI-Usecases-in-Cybersecurity/</link>
      <pubDate>Wed, 07 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/AI-Usecases-in-Cybersecurity/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6135-AI-Usecases-in-Cybersecurity.jpg&#34; alt=&#34;AI-Usecases-in-Cybersecurity&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ai-usecases-in-cybersecurity&#34;&gt;AI Usecases in Cybersecurity&lt;/h1&gt;&#xA;&lt;h1 id=&#34;ai-in-cyber-security-ethics-related-challenges-and-usecases&#34;&gt;AI in Cyber Security, Ethics Related Challenges and Usecases&lt;/h1&gt;&#xA;&lt;h2 id=&#34;ai-usecases-in-cyber-security&#34;&gt;AI Usecases in Cyber Security&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Threat Detection and Response&#xA;AI can enhance the detection and response to cybersecurity threats by:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;&lt;strong&gt;Anomaly Detection&lt;/strong&gt;: AI models can analyze network traffic and user behavior to identify unusual patterns that may indicate a security breach.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Malware Detection&lt;/strong&gt;: Machine learning algorithms can be trained to recognize malware based on its behavior and characteristics.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Phishing Detection&lt;/strong&gt;: AI can analyze emails and web pages to detect phishing attempts by recognizing patterns and indicators typical of phishing.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Intrusion Detection Systems (IDS):&lt;/strong&gt; AI-powered IDS can detect unauthorized access and potential threats by analyzing network traffic and user behavior in real-time.&lt;/li&gt;&#xA;&lt;li&gt;&lt;strong&gt;Endpoint Protection:&lt;/strong&gt; AI can enhance endpoint protection by continuously monitoring devices for suspicious activity and automatically responding to threats.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;Predictive Analytics&#xA;AI can be used to predict potential security incidents before they occur by:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Open Source vs Closed Source AI</title>
      <link>http://localhost:1313/dsblog/Open-Source-vs-Closed-Source-AI/</link>
      <pubDate>Tue, 06 Aug 2024 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Open-Source-vs-Closed-Source-AI/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6134-Open-Source-vs-Closed-Source-AI.jpg&#34; alt=&#34;Open-Source-vs-Closed-Source-AI&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;open-source-ai-vs-closed-source-ai&#34;&gt;Open Source AI vs Closed Source AI&lt;/h1&gt;&#xA;&lt;p&gt;Major players in the AI industry, such as Google, Microsoft, IBM, Salesforce, etc each have their own proprietary models and infrastructure to host these models. They offer AI services that companies use to develop AI products for either their end customers or internal use. Training or developing AI models requires expensive hardware and highly skilled personnel, making it a costly process. However, the deployment and inference stages are even more expensive, as they involve ongoing costs for hardware and monitoring.&lt;/p&gt;</description>
    </item>
    <item>
      <title>NLP Tasks</title>
      <link>http://localhost:1313/dsblog/nlp-tasks/</link>
      <pubDate>Tue, 15 Aug 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/nlp-tasks/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6085-NLP-Tasks.jpg&#34; alt=&#34;NLP Tasks&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;nlp-tasks&#34;&gt;NLP Tasks&lt;/h1&gt;&#xA;&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;&#xA;&lt;p&gt;Processing words of any language and driving some meaning from these is as old as the human language. Recently, AI momentum is taking on many of these language-processing tasks. Here is the summary of these NLP tasks, this list is continuously growing. Researchers keep creating a dataset for these tasks in different languages. Other researchers keep devising new ways to solve these tasks with better performance. They come up with a new architecture, a new set of hyperparameters, a new pipeline, etc. In summary, as of today, there are around 55 tasks. Hundreds of datasets and research papers exist around these. You can check on &lt;a href=&#34;https://paperswithcode.com/&#34;&gt;PaperWithCode&lt;/a&gt; or &lt;a href=&#34;https://huggingface.co/&#34;&gt;Hggingface&lt;/a&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Introduction to Prompt Engineering</title>
      <link>http://localhost:1313/dsblog/Introduction-to-Prompt-Engineering/</link>
      <pubDate>Mon, 24 Jul 2023 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/Introduction-to-Prompt-Engineering/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dspost/dsp6080-Introduction-to-Prompt-Engineering.jpg&#34; alt=&#34;Introduction to Prompt Engineering&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;introduction-to-prompt-best-engineering&#34;&gt;Introduction to Prompt Best Engineering&lt;/h1&gt;&#xA;&lt;p&gt;Prompts can contain questions, instructions, contextual information, examples, and partial input for the model to complete or continue. After the model receives a prompt, depending on the type of model being used, it can generate text, embeddings, code, images, videos, music, and more. Below are &lt;strong&gt;14 examples of good prompts&lt;/strong&gt;.&lt;/p&gt;&#xA;&lt;h2 id=&#34;example-1-entity-input&#34;&gt;Example 1 (Entity input)&lt;/h2&gt;&#xA;&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;Classify the following items as [large, small].&#xD;&#xA;Elephant&#xD;&#xA;Mouse&#xD;&#xA;Snail&#xA;&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;example-2-completion-input&#34;&gt;Example 2 (completion input)&lt;/h2&gt;&#xA;&lt;p&gt;You can write a prompt like&lt;/p&gt;</description>
    </item>
    <item>
      <title>Data Science, AI, ML, eBooks, PDF Books</title>
      <link>http://localhost:1313/dsblog/ds-ai-ml-books/</link>
      <pubDate>Wed, 20 Jul 2022 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/ds-ai-ml-books/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr120-Data-Science-AI-ML-eBooks-PDF-Books.jpg&#34; alt=&#34;DS, AI, ML, Books Available&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;online-data-science-ai-ml-content&#34;&gt;Online Data Science, AI, ML Content&lt;/h1&gt;&#xA;&lt;p&gt;Data Science, AI, Machine Learning, Books/ Guide/ Reports/ Presentations / Jupyter Notebook Available.&lt;/p&gt;&#xA;&lt;p&gt;All these books are available in pdf format at &lt;a href=&#34;https://drive.google.com/drive/folders/14wS6JWWDsZ2TEXCD9A7jgLVCEVEd1Mpb?usp=sharing&#34; target=&#34;_blank&#34;&gt; this link&lt;/a&gt;. I update this page less frequently but keep adding books in the repo. The list below may not contain the name you are looking for. Therefore, it is suggested to visit the link mentioned earlier. This link contains excellent presentations Book, (PPT), Handbook, Report, Articles (ARTC), Book, Booklet, eBook, Notebook, Notes, PAPER, GUIDE, TOC, Syllabus, LINKS, Handbook, Chapter, Tool, BROC – Broacher on Machine Learning, Deep Learning, NLP, Statistics, Reinforcement Learning, GAN. Approx 800 pdf files which inclues 350+ books.&lt;/p&gt;</description>
    </item>
    <item>
      <title>DS, AI, ML Online Course, Tutorial, Videos</title>
      <link>http://localhost:1313/dsblog/data-science-tutorial-video-resources/</link>
      <pubDate>Thu, 02 Jul 2020 00:00:00 +0000</pubDate><author>hari@dasarpai.com (Hari Thapliyaal)</author>
      <guid>http://localhost:1313/dsblog/data-science-tutorial-video-resources/</guid>
      <description>&lt;p&gt;&lt;img src=&#34;http://localhost:1313/assets/images/dsresources/dsr119-DS-AI-ML-Online-Course-Tutorial-Videos.jpg&#34; alt=&#34;DS, AI, ML Online Course, Tutorial, Videos&#34;&gt;&lt;/p&gt;&#xA;&lt;h1 id=&#34;ds-ai-ml-online-course-tutorial-videos&#34;&gt;DS, AI, ML Online Course, Tutorial, Videos&lt;/h1&gt;&#xA;&lt;h2 id=&#34;courses&#34;&gt;Courses&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://class.coursera.org/ml-005&#34;&gt;Machine Learning – Stanford&lt;/a&gt; by Andrew Ng in Coursera (2010-2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://work.caltech.edu/lectures.html&#34;&gt;Machine Learning – Caltech&lt;/a&gt; by Yaser Abu-Mostafa (2012-2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.cmu.edu/~tom/10701_sp11/lectures.shtml&#34;&gt;Machine Learning – Carnegie Mellon&lt;/a&gt; by Tom Mitchell (Spring 2011)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://class.coursera.org/neuralnets-2012-001&#34;&gt;Neural Networks for Machine Learning&lt;/a&gt; by Geoffrey Hinton in Coursera (2012)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PL6Xpj9I5qXYEcOhn7TqghAJ6NAPrNmUBH&#34;&gt;Neural networks class&lt;/a&gt; by Hugo Larochelle from Université de Sherbrooke (2013)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cilvr.cs.nyu.edu/doku.php?id=deeplearning:slides:start&#34;&gt;Deep Learning Course&lt;/a&gt; by CILVR lab @ NYU (2014)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://courses.edx.org/courses/BerkeleyX/CS188x_1/1T2013/courseware/&#34;&gt;A.I – Berkeley&lt;/a&gt; by Dan Klein and Pieter Abbeel (2013)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-034-artificial-intelligence-fall-2010/lecture-videos/&#34;&gt;A.I – MIT&lt;/a&gt; by Patrick Henry Winston (2010)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://web.mit.edu/course/other/i2course/www/vision_and_learning_fall_2013.html&#34;&gt;Vision and learning – computers and brains&lt;/a&gt; by Shimon Ullman, Tomaso Poggio, Ethan Meyers @ MIT (2013)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vision.stanford.edu/teaching/cs231n/syllabus.html&#34;&gt;Convolutional Neural Networks for Visual Recognition – Stanford&lt;/a&gt; by Fei-Fei Li, Andrej Karpathy (2017)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://cs224d.stanford.edu/&#34;&gt;Deep Learning for Natural Language Processing – Stanford&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://info.usherbrooke.ca/hlarochelle/neural_networks/content.html&#34;&gt;Neural Networks – usherbrooke&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.cs.ox.ac.uk/people/nando.defreitas/machinelearning/&#34;&gt;Machine Learning – Oxford&lt;/a&gt; (2014-2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developer.nvidia.com/deep-learning-courses&#34;&gt;Deep Learning – Nvidia&lt;/a&gt; (2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLHyI3Fbmv0SdzMHAy0aN59oYnLy5vyyTA&#34;&gt;Graduate Summer School: Deep Learning, Feature Learning&lt;/a&gt; by Geoffrey Hinton, Yoshua Bengio, Yann LeCun, Andrew Ng, Nando de Freitas and several others @ IPAM, UCLA (2012)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/deep-learning--ud730&#34;&gt;Deep Learning – Udacity/Google&lt;/a&gt; by Vincent Vanhoucke and Arpan Chakraborty (2016)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLehuLRPyt1Hyi78UOkMPWCGRxGcA9NVOE&#34;&gt;Deep Learning – UWaterloo&lt;/a&gt; by Prof. Ali Ghodsi at University of Waterloo (2015)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=azaLcvuql_g&amp;amp;list=PLjbUi5mgii6BWEUZf7He6nowWvGne_Y8r&#34;&gt;Statistical Machine Learning – CMU&lt;/a&gt; by Prof. Larry Wasserman&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.college-de-france.fr/site/en-yann-lecun/course-2015-2016.htm&#34;&gt;Deep Learning Course&lt;/a&gt; by Yann LeCun (2016)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLkFD6_40KJIxopmdJF_CLNqG3QuDFHQUm&#34;&gt;Designing, Visualizing and Understanding Deep Neural Networks-UC Berkeley&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://uvadlc.github.io/&#34;&gt;UVA Deep Learning Course&lt;/a&gt; MSc in Artificial Intelligence for the University of Amsterdam.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://selfdrivingcars.mit.edu/&#34;&gt;MIT 6.S094: Deep Learning for Self-Driving Cars&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://introtodeeplearning.com/&#34;&gt;MIT 6.S191: Introduction to Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://rll.berkeley.edu/deeprlcourse/&#34;&gt;Berkeley CS 294: Deep Reinforcement Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/keras-in-motion&#34;&gt;Keras in Motion video course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://course.fast.ai/&#34;&gt;Practical Deep Learning For Coders&lt;/a&gt; by Jeremy Howard – Fast.ai&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://deeplearning.cs.cmu.edu/&#34;&gt;Introduction to Deep Learning&lt;/a&gt; by Prof. Bhiksha Raj (2017)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.deeplearning.ai/ai-for-everyone/&#34;&gt;AI for Everyone&lt;/a&gt; by Andrew Ng (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://introtodeeplearning.com/&#34;&gt;MIT Intro to Deep Learning 7 day bootcamp&lt;/a&gt; – A seven day bootcamp designed in MIT to introduce deep learning methods and applications (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://mithi.github.io/deep-blueberry&#34;&gt;Deep Blueberry: Deep Learning&lt;/a&gt; – A free five-weekend plan to self-learners to learn the basics of deep-learning architectures like CNNs, LSTMs, RNNs, VAEs, GANs, DQN, A3C and more (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://spinningup.openai.com/&#34;&gt;Spinning Up in Deep Reinforcement Learning&lt;/a&gt; – A free deep reinforcement learning course by OpenAI (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/specializations/deep-learning&#34;&gt;Deep Learning Specialization – Coursera&lt;/a&gt; – Breaking into AI with the best course from Andrew NG.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLZSO_6-bSqHQHBCoGaObUljoXAyyqhpFW&#34;&gt;Deep Learning – UC Berkeley STAT-157&lt;/a&gt; by Alex Smola and Mu Li (2019)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/machine-learning-for-mere-mortals&#34;&gt;Machine Learning for Mere Mortals video course&lt;/a&gt; by Nick Chase&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://developers.google.com/machine-learning/crash-course/&#34;&gt;Machine Learning Crash Course with TensorFlow APIs&lt;/a&gt; -Google AI&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://course.fast.ai/part2&#34;&gt;Deep Learning from the Foundations&lt;/a&gt; Jeremy Howard – Fast.ai&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893&#34;&gt;Deep Reinforcement Learning (nanodegree) – Udacity&lt;/a&gt; a 3-6 month Udacity nanodegree, spanning multiple courses (2018)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/grokking-deep-learning-in-motion&#34;&gt;Grokking Deep Learning in Motion&lt;/a&gt; by Beau Carnes (2018)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/share/1000gAA0QdcV9aQng=/&#34;&gt;Face Detection with Computer Vision and Deep Learning&lt;/a&gt; by Hakan Cebeci&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/slides?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;siteID=SAyYsTvLiGQ-CmOo_hUqOR9Oj8ApcOw0Kg&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34;&gt;Presentation skills: Designing Presentation Slides - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;siteID=SAyYsTvLiGQ-heqdps0Uveezr1XmtoOPDQ&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34;&gt;Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/machine-learning/home/welcome&#34;&gt;Machine Learning – Home Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/learn/multivariate-calculus-machine-learning?ranMID=40328&amp;amp;ranEAID=SAyYsTvLiGQ&amp;amp;ranSiteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;siteID=SAyYsTvLiGQ-P3iVNag0daUW2nModtd2GA&amp;amp;utm_content=10&amp;amp;utm_medium=partners&amp;amp;utm_source=linkshare&amp;amp;utm_campaign=SAyYsTvLiGQ&#34;&gt;Mathematics for Machine Learning: Multivariate Calculus - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.coursera.org/browse/data-science&#34;&gt;Data Science Certificates - Coursera&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learning.edureka.co/mycourses&#34;&gt;Edureka&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bdlabs.edureka.co:50001/cmf/services/18/status&#34;&gt;Edureka-Cloudera Manager&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udemy.com/&#34;&gt;Udemy Courses&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://onlinereikicourse.com/&#34;&gt;Courses – Online Reiki Course&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.datacamp.com/courses&#34;&gt;DataCamp Courses&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learn.byjus.com/video/chapter-videos/44724&#34;&gt;Byju&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.udacity.com/course/intro-to-machine-learning-nanodegree--nd229&#34;&gt;udacity&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://intellipaat.com/blog/what-is-apache-spark/&#34;&gt;What is Spark – A Comparison Between Spark vs. Hadoop&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://studio.azureml.net/Home/ViewWorkspaceCached/086ca408664942138b618398589b02ff#Workspace/Settings/Name&#34;&gt;Microsoft Azure Machine Learning Studio (classic)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.apache.org/&#34;&gt;Welcome to The Apache Software Foundation!&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://makingindiaemployable.com/&#34;&gt;Making India Employable - Vivid Vision 10  10  10&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ideone.com/&#34;&gt;GpI8H5 – Online Python3 Interpreter &amp;amp; Debugging Tool – Ideone.com&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLOU2XLYxmsILVTiOlMJdo7RQS55jYhsMi&#34;&gt;Google I/O 2019 – All Sessions – YouTube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/playlist?list=PLQY2H8rRoyvy2_vtWvCpQWM9GJXNTa5rV&#34;&gt;TensorFlow at Google I/O 2019 – YouTube&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://bsc.hcverma.in/course/quantum&#34;&gt;Quantum Mechanics - BSc Lectures by Prof. H C Verma and Team&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://openpathshala.com/&#34;&gt;Open Pathshala - Your Best Source to Learn Sanskrit&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.classcentral.com/&#34;&gt;Class Central #1 Search Engine for Free Online Courses &amp;amp; MOOCs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.class-central.com/course/coursera-mathematics-for-machine-learning-multivariate-calculus-10452&#34;&gt;Free Online Course: Mathematics for Machine Learning: Multivariate Calculus from Coursera - Class Central&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://byjus.com/&#34;&gt;e Learning for Basic Science and Maths&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.skillshare.com/&#34;&gt;Online Classes by Skillshare - Start for Free Today&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://learndigital.withgoogle.com/digitalgarage&#34;&gt;Learn online marketing with free courses – Google Digital Garage&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://moz.com/blog&#34;&gt;Moz Blog – SEO and Inbound Marketing Blog – Moz&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://onlinecourses.nptel.ac.in/m#/lesson/noc19_hs53/8/15&#34;&gt;NPTEL Online Courses Mobile&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.kaggle.com/learn/overview&#34;&gt;Learn Python, Data Viz, Pandas &amp;amp; More - Tutorials - Kaggle&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.superdatascience.com/training/&#34;&gt;Data Science Training&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;tutorials&#34;&gt;Tutorials&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://deeplearning.stanford.edu/wiki/index.php/UFLDL_Tutorial&#34;&gt;UFLDL Tutorial 1&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ufldl.stanford.edu/tutorial/supervised/LinearRegression/&#34;&gt;UFLDL Tutorial 2&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.socher.org/index.php/DeepLearningTutorial/DeepLearningTutorial&#34;&gt;Deep Learning for NLP (without Magic)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.toptal.com/machine-learning/an-introduction-to-deep-learning-from-perceptrons-to-deep-networks&#34;&gt;A Deep Learning Tutorial: From Perceptrons to Deep Networks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.metacademy.org/roadmaps/rgrosse/deep_learning&#34;&gt;Deep Learning from the Bottom up&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://deeplearning.net/tutorial/deeplearning.pdf&#34;&gt;Theano Tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://uk.mathworks.com/help/pdf_doc/nnet/nnet_ug.pdf&#34;&gt;Neural Networks for Matlab&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/&#34;&gt;Using convolutional neural nets to detect facial keypoints tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/clementfarabet/ipam-tutorials/tree/master/th_tutorials&#34;&gt;Torch7 Tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/josephmisiti/machine-learning-module&#34;&gt;The Best Machine Learning Tutorials On The Web&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.robots.ox.ac.uk/~vgg/practicals/cnn/index.html&#34;&gt;VGG Convolutional Neural Networks Practical&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/nlintz/TensorFlow-Tutorials&#34;&gt;TensorFlow tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/pkmital/tensorflow_tutorials&#34;&gt;More TensorFlow tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/aymericdamien/TensorFlow-Examples&#34;&gt;TensorFlow Python Notebooks&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/Vict0rSch/deep_learning&#34;&gt;Keras and Lasagne Deep Learning Tutorials&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/guillaume-chevalier/LSTM-Human-Activity-Recognition&#34;&gt;Classification on raw time series in TensorFlow with a LSTM RNN&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/&#34;&gt;Using convolutional neural nets to detect facial keypoints tutorial&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/astorfi/TensorFlow-World&#34;&gt;TensorFlow-World&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-with-python&#34;&gt;Deep Learning with Python&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/grokking-deep-learning&#34;&gt;Grokking Deep Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/books/deep-learning-for-search&#34;&gt;Deep Learning for Search&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://blog.sicara.com/keras-tutorial-content-based-image-retrieval-convolutional-denoising-autoencoder-dc91450cc511&#34;&gt;Keras Tutorial: Content Based Image Retrieval Using a Convolutional Denoising Autoencoder&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/yunjey/pytorch-tutorial&#34;&gt;Pytorch Tutorial by Yunjey Choi&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ahmedbesbes.com/understanding-deep-convolutional-neural-networks-with-a-practical-use-case-in-tensorflow-and-keras.html&#34;&gt;Understanding deep Convolutional Neural Networks with a practical use-case in Tensorflow and Keras&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://ahmedbesbes.com/overview-and-benchmark-of-traditional-and-deep-learning-models-in-text-classification.html&#34;&gt;Overview and benchmark of traditional and deep learning models in text classification&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://github.com/MelAbgrall/HardwareforAI&#34;&gt;Hardware for AI: Understanding computer hardware &amp;amp; build your own computer&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://hackr.io/tutorials/learn-artificial-intelligence-ai&#34;&gt;Programming Community Curated Resources&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://amitness.com/2020/02/illustrated-self-supervised-learning/&#34;&gt;The Illustrated Self-Supervised Learning&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://amitness.com/2020/02/albert-visual-summary/&#34;&gt;Visual Paper Summary: ALBERT (A Lite BERT)&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;videos-and-lectures&#34;&gt;Videos and Lectures&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=RIkxVci-R4k&#34;&gt;How To Create A Mind&lt;/a&gt; By Ray Kurzweil&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=n1ViNeWhC24&#34;&gt;Deep Learning, Self-Taught Learning and Unsupervised Feature Learning&lt;/a&gt; By Andrew Ng&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=vShMxxqtDDs&amp;amp;index=3&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT&#34;&gt;Recent Developments in Deep Learning&lt;/a&gt; By Geoff Hinton&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=sc-KbuZqGkI&#34;&gt;The Unreasonable Effectiveness of Deep Learning&lt;/a&gt; by Yann LeCun&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=4xsVFLnHC_0&#34;&gt;Deep Learning of Representations&lt;/a&gt; by Yoshua bengio&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=6ufPpZDmPKA&#34;&gt;Principles of Hierarchical Temporal Memory&lt;/a&gt; by Jeff Hawkins&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=2QJi0ArLq7s&amp;amp;list=PL78U8qQHXgrhP9aZraxTT5-X1RccTcUYT&#34;&gt;Machine Learning Discussion Group – Deep Learning w/ Stanford AI Lab&lt;/a&gt; by Adam Coates&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://vimeo.com/80821560&#34;&gt;Making Sense of the World with Deep Learning&lt;/a&gt; By Adam Coates&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=wZfVBwOO0-k&#34;&gt;Demystifying Unsupervised Feature Learning&lt;/a&gt; By Adam Coates&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=3boKlkPBckA&#34;&gt;Visual Perception with Deep Learning&lt;/a&gt; By Yann LeCun&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=AyzOUbkUf3M&#34;&gt;The Next Generation of Neural Networks&lt;/a&gt; By Geoffrey Hinton at GoogleTechTalks&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.ted.com/talks/jeremy_howard_the_wonderful_and_terrifying_implications_of_computers_that_can_learn&#34;&gt;The wonderful and terrifying implications of computers that can learn&lt;/a&gt; By Jeremy Howard at TEDxBrussels&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/class/cs294a/handouts.html&#34;&gt;Unsupervised Deep Learning – Stanford&lt;/a&gt; by Andrew Ng in Stanford (2011)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://web.stanford.edu/class/cs224n/handouts/&#34;&gt;Natural Language Processing&lt;/a&gt; By Chris Manning in Stanford&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://googleresearch.blogspot.com/2015/09/a-beginners-guide-to-deep-neural.html&#34;&gt;A beginners Guide to Deep Neural Networks&lt;/a&gt; By Natalie Hammel and Lorraine Yurshansky&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=czLI3oLDe8M&#34;&gt;Deep Learning: Intelligence from Big Data&lt;/a&gt; by Steve Jurvetson (and panel) at VLAB in Stanford.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=FoO8qDB8gUU&#34;&gt;Introduction to Artificial Neural Networks and Deep Learning&lt;/a&gt; by Leo Isikdogan at Motorola Mobility HQ&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://nips.cc/Conferences/2016/Schedule&#34;&gt;NIPS 2016 lecture and workshop videos&lt;/a&gt; – NIPS 2016&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=oS5fz_mHVz0&amp;amp;list=PLWKotBjTDoLj3rXBL-nEIPRN9V3a9Cx07&#34;&gt;Deep Learning Crash Course&lt;/a&gt;: a series of mini-lectures by Leo Isikdogan on YouTube (2018)&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/deep-learning-crash-course&#34;&gt;Deep Learning Crash Course&lt;/a&gt; By Oliver Zeigermann&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://www.manning.com/livevideo/deep-learning-with-r-in-motion&#34;&gt;Deep Learning with R in Motion&lt;/a&gt;: a live video course that teaches how to apply deep learning to text and images using the powerful Keras library and its R language interface.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f5vUg6i&#34;&gt;8 Essential Tips for People starting a Career in Data Science&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fMEhi4D&#34;&gt;Cheatsheet: How to become a data scientist&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fruY2AC&#34;&gt;The Art of Learning Data Science&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fxReDab&#34;&gt;The Periodic Table of Data Science&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fXSE-us&#34;&gt;Aspiring Data Scientists! Start to learn Statistics with these 6 books&lt;/a&gt;!&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f8S3Ygd&#34;&gt;8 Skills You Need to Be a Data Scientist&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fKugicE&#34;&gt;Top 10 Essential Books for the Data Enthusiast&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/fTGDkju&#34;&gt;Aspiring data scientist? Master these fundamentals&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;&lt;a href=&#34;https://lnkd.in/f_Zhpzf&#34;&gt;How to Become a Data Scientist – On your own.&lt;/a&gt;&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;h2 id=&#34;gretl--great-statistical-software-for-beginners&#34;&gt;GRETL – Great Statistical software for Beginners&lt;/h2&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Simple Linear Regression &lt;a href=&#34;https://lnkd.in/ecfsV9c&#34;&gt;https://lnkd.in/ecfsV9c&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Coding Dummy Variables &lt;a href=&#34;https://lnkd.in/ef7Yd7f&#34;&gt;https://lnkd.in/ef7Yd7f&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Forecasting New Observations &lt;a href=&#34;https://lnkd.in/eNKbxbU&#34;&gt;https://lnkd.in/eNKbxbU&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Forecasting a Large Number of Observations &lt;a href=&#34;https://lnkd.in/eHmibGs&#34;&gt;https://lnkd.in/eHmibGs&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Logistic Regression &lt;a href=&#34;https://lnkd.in/eRfhQ87&#34;&gt;https://lnkd.in/eRfhQ87&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Forecasting and Confusion Matrix &lt;a href=&#34;https://lnkd.in/eaqrFJr&#34;&gt;https://lnkd.in/eaqrFJr&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Modeling and Forecasting Time Series Data &lt;a href=&#34;https://lnkd.in/e6fqKpF&#34;&gt;https://lnkd.in/e6fqKpF&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Comparing Time Series Trend Models &lt;a href=&#34;https://lnkd.in/eKjEUAE&#34;&gt;https://lnkd.in/eKjEUAE&lt;/a&gt;&lt;/li&gt;&#xA;&lt;li&gt;Khan Academy is the best online free resource to learn Math for Data Science. ( &lt;a href=&#34;https://www.khanacademy.org/math/&#34;&gt;https://www.khanacademy.org/math/&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Krista King has also done a great job in creating an exceptionally good introductory course. She is too good at designing the course. ( &lt;a href=&#34;https://www.udemy.com/user/kristaking/&#34;&gt;https://www.udemy.com/user/kristaking/&lt;/a&gt;.&lt;/li&gt;&#xA;&lt;li&gt;3Blue1Brown ( &lt;a href=&#34;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists&#34;&gt;https://www.youtube.com/channel/UCYO_jab_esuFRV4b17AJtAw/playlists&lt;/a&gt;).&lt;/li&gt;&#xA;&lt;li&gt;Every Intro to Data Science Course on the Internet, Ranked. (&lt;a href=&#34;https://lnkd.in/fQDMiNX&#34;&gt;https://lnkd.in/fQDMiNX&lt;/a&gt; )&lt;/li&gt;&#xA;&lt;li&gt;What would be useful for aspiring data scientists to know? (&lt;a href=&#34;https://lnkd.in/fmcFyN7&#34;&gt;https://lnkd.in/fmcFyN7&lt;/a&gt;)&lt;/li&gt;&#xA;&lt;/ol&gt;</description>
    </item>
  </channel>
</rss>
